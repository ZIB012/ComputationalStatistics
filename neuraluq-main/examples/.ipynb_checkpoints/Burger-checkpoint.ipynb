{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcccf0a2",
   "metadata": {},
   "source": [
    "## Burger equation\n",
    "$$\\begin{cases}\n",
    "    \\frac{\\partial u}{\\partial t} + u\\,\\frac{\\partial u}{\\partial x} = \\nu\\,\\frac{\\partial^2 u}{\\partial x^2} & \\text{in } [0, 1] \\times (0, T]\\\\\n",
    "    u(0, t) = u(1, t) = sin(2\\,\\pi\\,t) & \\forall t \\in (0, T]\\\\\n",
    "    u(x, 0) = sin(\\pi x) & \\forall x \\in [0, 1]\\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "It is a 1-dimensional \n",
    "PDE that includes a non-linear term and a smoothing term multiplied by a viscosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc0411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuraluq as neuq\n",
    "import neuraluq.variables as neuq_vars\n",
    "from neuraluq.config import tf\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd8c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(noise_u, noise_f):\n",
    "    data = sio.loadmat(\"../dataset/Burgy.mat\")\n",
    "    x_u_train, t_u_train = data[\"x_u_train\"], data[\"t_u_train\"]\n",
    "    x_f_train, t_f_train = data[\"x_f_train\"], data[\"t_f_train\"]\n",
    "    x_test, t_test, u_test = data[\"x_test\"], data[\"t_test\"], data[\"u_test\"]\n",
    "    x_test, t_test, u_test = (\n",
    "        x_test.reshape([-1, 1]),\n",
    "        t_test.reshape([-1, 1]),\n",
    "        u_test.reshape([-1, 1]),\n",
    "    )\n",
    "    u_train, f_train = data[\"u_train\"], data[\"f_train\"]\n",
    "    train_u = x_u_train, t_u_train, u_train\n",
    "    train_f = x_f_train, t_f_train, f_train\n",
    "    test = x_test, t_test, u_test\n",
    "    return train_u, train_f, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447a2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_fn(x, u, nu):\n",
    "    u_x, u_t = tf.split(tf.gradients(u, x)[0], 2, axis=-1)\n",
    "    u_xx = tf.gradients(u_x, x)[0][..., 0:1]\n",
    "    \n",
    "    f = u_t + u * u_x - tf.exp(nu) * u_xx\n",
    "    # f = u_t + u * u_x - nu * u_xx\n",
    "    \n",
    "    # tf.exp(k_1) Computes exponential of k_1 element-wise (y = e^{k_1})\n",
    "    # (KDV) f = u_t - tf.exp(k_1) * u * u_x - tf.exp(k_2) * u_xxx \n",
    "    ### DA CAPIRE LA STORIA DEL PERCHè PRENDE L'ESPONENZIALE DELLE VARIABILI\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6076c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@neuq.utils.timer\n",
    "def Samplable(\n",
    "    x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers\n",
    "):\n",
    "    # build processes\n",
    "    process_u = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.FNN(layers=layers),\n",
    "        prior=neuq_vars.fnn.Samplable(layers=layers, mean=0, sigma=1),\n",
    "    )\n",
    "    process_logk_1 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        prior=neuq_vars.const.Samplable(mean=0, sigma=1),\n",
    "    )\n",
    "    \n",
    "    # build likelihood\n",
    "    likelihood_u = neuq.likelihoods.Normal(\n",
    "        inputs=np.concatenate([x_u_train, t_u_train], axis=-1),\n",
    "        targets=u_train,\n",
    "        processes=[process_u],\n",
    "        sigma=noise,\n",
    "    )\n",
    "    likelihood_f = neuq.likelihoods.Normal(\n",
    "        inputs=np.concatenate([x_f_train, t_f_train], axis=-1),\n",
    "        targets=f_train,\n",
    "        processes=[process_u, process_logk_1],\n",
    "        pde=pde_fn,\n",
    "        sigma=noise,\n",
    "    )\n",
    "    # build model\n",
    "    model = neuq.models.Model(\n",
    "        processes=[process_u, process_logk_1],\n",
    "        likelihoods=[likelihood_u, likelihood_f],\n",
    "    )\n",
    "    # assign and compile method\n",
    "    # Change the parameters to make the acceptance rate close to 0.6.\n",
    "    method = neuq.inferences.HMC(\n",
    "        num_samples=500,\n",
    "        num_burnin=3000,\n",
    "        init_time_step=0.01,\n",
    "        leapfrog_step=50,\n",
    "        seed=66,\n",
    "    )\n",
    "    model.compile(method)\n",
    "    # obtain posterior samples\n",
    "    samples, results = model.run()\n",
    "    print(\"Acceptance rate: %.3f \\n\"%(np.mean(results)))\n",
    "\n",
    "    processes = [process_u, process_logk_1]\n",
    "    return processes, samples, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c52501",
   "metadata": {},
   "outputs": [],
   "source": [
    "@neuq.utils.timer\n",
    "def Trainable(\n",
    "    x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers\n",
    "):\n",
    "    # build processes\n",
    "    process_u = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.FNN(layers=layers),\n",
    "        posterior=neuq_vars.fnn.Trainable(layers=layers),\n",
    "    )\n",
    "    process_logk_1 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        posterior=neuq_vars.const.Trainable(value=0),\n",
    "    )\n",
    "    \n",
    "    loss_u = neuq.likelihoods.MSE(\n",
    "        inputs=np.concatenate([x_u_train, t_u_train], axis=-1),\n",
    "        targets=u_train,\n",
    "        processes=[process_u],\n",
    "        multiplier=1.0,\n",
    "    )\n",
    "    loss_f = neuq.likelihoods.MSE(\n",
    "        inputs=np.concatenate([x_f_train, t_f_train], axis=-1),\n",
    "        targets=f_train,\n",
    "        processes=[process_u, process_logk_1],\n",
    "        pde=pde_fn,\n",
    "        multiplier=1.0,\n",
    "    )\n",
    "    # build model\n",
    "    model = neuq.models.Model(\n",
    "        processes=[process_u, process_logk_1],\n",
    "        likelihoods=[loss_u, loss_f],\n",
    "    )\n",
    "    # assign and compile method\n",
    "    method = neuq.inferences.DEns(\n",
    "        num_samples=20, num_iterations=20000, optimizer=tf.train.AdamOptimizer(1e-3),\n",
    "    )\n",
    "    model.compile(method)\n",
    "    # obtain posterior samples\n",
    "    samples = model.run()\n",
    "    samples = neuq.utils.batch_samples(samples)  # reshape\n",
    "\n",
    "    processes = [process_u, process_logk_1]\n",
    "    return processes, samples, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e357024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(\n",
    "    logk_1_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    "):\n",
    "    ### DA CAPIRE LA STORIA DEL PERCHè PRENDE L'ESPONENZIALE DELLE VARIABILI\n",
    "    \n",
    "    k_1_pred = np.exp(logk_1_pred)\n",
    "    #k_1_pred = logk_1_pred\n",
    "    print(\"Mean & Std of k1 are %.3f, %.3f\" % (np.mean(k_1_pred), np.std(k_1_pred)))\n",
    "    \n",
    "    u_pred = np.reshape(u_pred, [-1, NT, NX])\n",
    "    mu = np.mean(u_pred, axis=0)\n",
    "    std = np.std(u_pred, axis=0)\n",
    "    \n",
    "    x_test = np.reshape(x_test, [NT, NX])\n",
    "    t_test = np.reshape(t_test, [NT, NX])\n",
    "    u_test = np.reshape(u_test, [NT, NX])\n",
    "    \n",
    "    # cambiare i per avere plot su altri istanti di tempo\n",
    "    # i = 0 --> first time instant\n",
    "    i = 0\n",
    "    \n",
    "    current_t = t_test[i][0]\n",
    "    # current_x*10 PERCHè PRIMA LA X è STATA NORMALIZZATA\n",
    "    current_x = x_u_train[t_u_train == current_t]*10\n",
    "    current_u = u_train[t_u_train == current_t]\n",
    "    # std = np.sqrt(std**2 + 0.1**2)\n",
    "    plt.plot(np.linspace(-10, 10, 300), mu[i, :], \"--\", label=\"mean\")\n",
    "    plt.fill_between(\n",
    "        np.linspace(-10, 10, 300), (mu + 2 * std)[i, :], (mu - 2 * std)[i, :], alpha=0.3\n",
    "    )\n",
    "    plt.plot(np.linspace(-10, 10, 300), u_test[i, :], label=\"reference\")\n",
    "    plt.plot(current_x, current_u, \"o\", label=\"observations\")\n",
    "    plt.legend()\n",
    "    plt.title(\"t=\" + str(current_t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881d9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "NT, NX = 60, 300\n",
    "noise = 0.1\n",
    "train_u, train_f, test = load_data(noise, noise)\n",
    "x_u_train, t_u_train, u_train = train_u\n",
    "x_f_train, t_f_train, f_train = train_f\n",
    "x_test, t_test, u_test = test\n",
    "\n",
    "layers = [2, 50, 50, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55be1919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting backend tensorflow.compat.v1\n",
      "\n",
      "Compiling a MCMC method\n",
      "\n",
      "sampling from posterior distribution ...\n",
      "\n",
      "Finished sampling from posterior distribution ...\n",
      "\n",
      "Acceptance rate: 0.766 \n",
      "\n",
      "Execution time for 'Samplable' function is: 113.406 s, 1.890 mins\n"
     ]
    }
   ],
   "source": [
    "processes_HMC, samples_HMC, model_HMC = Samplable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)\n",
    "\n",
    "#processes, samples, model = Trainable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ffbcb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean & Std of k1 are 0.482, 0.014\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred, logk_1_pred = model_HMC.predict(np.concatenate([x_test, t_test], axis=-1), samples_HMC, processes_HMC, pde_fn=None,)\n",
    "\n",
    "plots(\n",
    "    logk_1_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc7a6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting backend tensorflow.compat.v1\n",
      "\n",
      "Compiling a Ensemble method\n",
      "\n",
      "Generating 0th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.22449358\n",
      "Iteration:  100 , loss:  0.13504751\n",
      "Iteration:  200 , loss:  0.11389621\n",
      "Iteration:  300 , loss:  0.093103975\n",
      "Iteration:  400 , loss:  0.0629118\n",
      "Iteration:  500 , loss:  0.052387983\n",
      "Iteration:  600 , loss:  0.045014\n",
      "Iteration:  700 , loss:  0.037644695\n",
      "Iteration:  800 , loss:  0.032130335\n",
      "Iteration:  900 , loss:  0.028910493\n",
      "Iteration:  1000 , loss:  0.02678069\n",
      "Iteration:  1100 , loss:  0.025497915\n",
      "Iteration:  1200 , loss:  0.02472316\n",
      "Iteration:  1300 , loss:  0.023955664\n",
      "Iteration:  1400 , loss:  0.02334163\n",
      "Iteration:  1500 , loss:  0.022778163\n",
      "Iteration:  1600 , loss:  0.02219643\n",
      "Iteration:  1700 , loss:  0.021709593\n",
      "Iteration:  1800 , loss:  0.021139177\n",
      "Iteration:  1900 , loss:  0.020753324\n",
      "Iteration:  2000 , loss:  0.020153843\n",
      "Iteration:  2100 , loss:  0.020039266\n",
      "Iteration:  2200 , loss:  0.019193966\n",
      "Iteration:  2300 , loss:  0.018696032\n",
      "Iteration:  2400 , loss:  0.018293586\n",
      "Iteration:  2500 , loss:  0.017696816\n",
      "Iteration:  2600 , loss:  0.01715768\n",
      "Iteration:  2700 , loss:  0.016631406\n",
      "Iteration:  2800 , loss:  0.016077546\n",
      "Iteration:  2900 , loss:  0.0155161265\n",
      "Iteration:  3000 , loss:  0.014954226\n",
      "Iteration:  3100 , loss:  0.014382691\n",
      "Iteration:  3200 , loss:  0.013764376\n",
      "Iteration:  3300 , loss:  0.013175898\n",
      "Iteration:  3400 , loss:  0.012623612\n",
      "Iteration:  3500 , loss:  0.012092344\n",
      "Iteration:  3600 , loss:  0.011585658\n",
      "Iteration:  3700 , loss:  0.0117968535\n",
      "Iteration:  3800 , loss:  0.012038034\n",
      "Iteration:  3900 , loss:  0.010149842\n",
      "Iteration:  4000 , loss:  0.009718698\n",
      "Iteration:  4100 , loss:  0.00932463\n",
      "Iteration:  4200 , loss:  0.00898931\n",
      "Iteration:  4300 , loss:  0.008757541\n",
      "Iteration:  4400 , loss:  0.008459687\n",
      "Iteration:  4500 , loss:  0.008241708\n",
      "Iteration:  4600 , loss:  0.008058828\n",
      "Iteration:  4700 , loss:  0.00992882\n",
      "Iteration:  4800 , loss:  0.0077514267\n",
      "Iteration:  4900 , loss:  0.007835111\n",
      "Iteration:  5000 , loss:  0.009122223\n",
      "Iteration:  5100 , loss:  0.0073915143\n",
      "Iteration:  5200 , loss:  0.007477004\n",
      "Iteration:  5300 , loss:  0.007384814\n",
      "Iteration:  5400 , loss:  0.0070976084\n",
      "Iteration:  5500 , loss:  0.00710881\n",
      "Iteration:  5600 , loss:  0.0069298735\n",
      "Iteration:  5700 , loss:  0.00698137\n",
      "Iteration:  5800 , loss:  0.007030623\n",
      "Iteration:  5900 , loss:  0.007178829\n",
      "Iteration:  6000 , loss:  0.0066148713\n",
      "Iteration:  6100 , loss:  0.006543561\n",
      "Iteration:  6200 , loss:  0.0064771743\n",
      "Iteration:  6300 , loss:  0.006408622\n",
      "Iteration:  6400 , loss:  0.0066598803\n",
      "Iteration:  6500 , loss:  0.0062772254\n",
      "Iteration:  6600 , loss:  0.0062148725\n",
      "Iteration:  6700 , loss:  0.0061519397\n",
      "Iteration:  6800 , loss:  0.0063131573\n",
      "Iteration:  6900 , loss:  0.0060305274\n",
      "Iteration:  7000 , loss:  0.006044085\n",
      "Iteration:  7100 , loss:  0.0059214747\n",
      "Iteration:  7200 , loss:  0.0058924602\n",
      "Iteration:  7300 , loss:  0.006817158\n",
      "Iteration:  7400 , loss:  0.0057427385\n",
      "Iteration:  7500 , loss:  0.005689023\n",
      "Iteration:  7600 , loss:  0.005706846\n",
      "Iteration:  7700 , loss:  0.0055798646\n",
      "Iteration:  7800 , loss:  0.005529173\n",
      "Iteration:  7900 , loss:  0.0070264526\n",
      "Iteration:  8000 , loss:  0.005418985\n",
      "Iteration:  8100 , loss:  0.00536629\n",
      "Iteration:  8200 , loss:  0.005836704\n",
      "Iteration:  8300 , loss:  0.0052602636\n",
      "Iteration:  8400 , loss:  0.005202119\n",
      "Iteration:  8500 , loss:  0.005444351\n",
      "Iteration:  8600 , loss:  0.0051084887\n",
      "Iteration:  8700 , loss:  0.00503226\n",
      "Iteration:  8800 , loss:  0.0049805064\n",
      "Iteration:  8900 , loss:  0.0049157017\n",
      "Iteration:  9000 , loss:  0.004860049\n",
      "Iteration:  9100 , loss:  0.004795378\n",
      "Iteration:  9200 , loss:  0.0047355974\n",
      "Iteration:  9300 , loss:  0.0067739827\n",
      "Iteration:  9400 , loss:  0.0046146717\n",
      "Iteration:  9500 , loss:  0.0045580817\n",
      "Iteration:  9600 , loss:  0.0047199777\n",
      "Iteration:  9700 , loss:  0.0044378927\n",
      "Iteration:  9800 , loss:  0.0043849885\n",
      "Iteration:  9900 , loss:  0.0046973773\n",
      "Iteration:  10000 , loss:  0.0042677373\n",
      "Iteration:  10100 , loss:  0.0044009667\n",
      "Iteration:  10200 , loss:  0.0041678557\n",
      "Iteration:  10300 , loss:  0.0040956493\n",
      "Iteration:  10400 , loss:  0.004064481\n",
      "Iteration:  10500 , loss:  0.0039946903\n",
      "Iteration:  10600 , loss:  0.005531826\n",
      "Iteration:  10700 , loss:  0.0038569928\n",
      "Iteration:  10800 , loss:  0.00379619\n",
      "Iteration:  10900 , loss:  0.0038221765\n",
      "Iteration:  11000 , loss:  0.0036733532\n",
      "Iteration:  11100 , loss:  0.0036134517\n",
      "Iteration:  11200 , loss:  0.0035612944\n",
      "Iteration:  11300 , loss:  0.0034921137\n",
      "Iteration:  11400 , loss:  0.0034362208\n",
      "Iteration:  11500 , loss:  0.003424027\n",
      "Iteration:  11600 , loss:  0.0033832565\n",
      "Iteration:  11700 , loss:  0.0032627564\n",
      "Iteration:  11800 , loss:  0.003217314\n",
      "Iteration:  11900 , loss:  0.003239108\n",
      "Iteration:  12000 , loss:  0.0031017286\n",
      "Iteration:  12100 , loss:  0.0030496921\n",
      "Iteration:  12200 , loss:  0.0029971849\n",
      "Iteration:  12300 , loss:  0.0029721966\n",
      "Iteration:  12400 , loss:  0.002967855\n",
      "Iteration:  12500 , loss:  0.003367508\n",
      "Iteration:  12600 , loss:  0.0027976392\n",
      "Iteration:  12700 , loss:  0.0029087968\n",
      "Iteration:  12800 , loss:  0.0027098982\n",
      "Iteration:  12900 , loss:  0.002660683\n",
      "Iteration:  13000 , loss:  0.0028986805\n",
      "Iteration:  13100 , loss:  0.0025650016\n",
      "Iteration:  13200 , loss:  0.0025227403\n",
      "Iteration:  13300 , loss:  0.0024948071\n",
      "Iteration:  13400 , loss:  0.002434175\n",
      "Iteration:  13500 , loss:  0.0029304647\n",
      "Iteration:  13600 , loss:  0.0031369892\n",
      "Iteration:  13700 , loss:  0.0023087538\n",
      "Iteration:  13800 , loss:  0.0027641668\n",
      "Iteration:  13900 , loss:  0.0022285641\n",
      "Iteration:  14000 , loss:  0.0021939331\n",
      "Iteration:  14100 , loss:  0.0029158578\n",
      "Iteration:  14200 , loss:  0.0021139234\n",
      "Iteration:  14300 , loss:  0.0021256488\n",
      "Iteration:  14400 , loss:  0.0020451227\n",
      "Iteration:  14500 , loss:  0.0020059394\n",
      "Iteration:  14600 , loss:  0.001998483\n",
      "Iteration:  14700 , loss:  0.0020578518\n",
      "Iteration:  14800 , loss:  0.0019055537\n",
      "Iteration:  14900 , loss:  0.0019502426\n",
      "Iteration:  15000 , loss:  0.0018434462\n",
      "Iteration:  15100 , loss:  0.0018140539\n",
      "Iteration:  15200 , loss:  0.0018420622\n",
      "Iteration:  15300 , loss:  0.0017560374\n",
      "Iteration:  15400 , loss:  0.0017827819\n",
      "Iteration:  15500 , loss:  0.0017086205\n",
      "Iteration:  15600 , loss:  0.0016871283\n",
      "Iteration:  15700 , loss:  0.0016818384\n",
      "Iteration:  15800 , loss:  0.001632573\n",
      "Iteration:  15900 , loss:  0.002247978\n",
      "Iteration:  16000 , loss:  0.0015822293\n",
      "Iteration:  16100 , loss:  0.001565491\n",
      "Iteration:  16200 , loss:  0.0015409205\n",
      "Iteration:  16300 , loss:  0.0039046002\n",
      "Iteration:  16400 , loss:  0.0015017986\n",
      "Iteration:  16500 , loss:  0.0014984848\n",
      "Iteration:  16600 , loss:  0.0016021224\n",
      "Iteration:  16700 , loss:  0.0014497098\n",
      "Iteration:  16800 , loss:  0.001433061\n",
      "Iteration:  16900 , loss:  0.0014383008\n",
      "Iteration:  17000 , loss:  0.002093689\n",
      "Iteration:  17100 , loss:  0.0013872006\n",
      "Iteration:  17200 , loss:  0.0063423654\n",
      "Iteration:  17300 , loss:  0.0013590894\n",
      "Iteration:  17400 , loss:  0.0013509215\n",
      "Iteration:  17500 , loss:  0.0013326588\n",
      "Iteration:  17600 , loss:  0.0013205917\n",
      "Iteration:  17700 , loss:  0.0013568434\n",
      "Iteration:  17800 , loss:  0.0019370948\n",
      "Iteration:  17900 , loss:  0.0012851282\n",
      "Iteration:  18000 , loss:  0.001647055\n",
      "Iteration:  18100 , loss:  0.0034179045\n",
      "Iteration:  18200 , loss:  0.0012526067\n",
      "Iteration:  18300 , loss:  0.0012419587\n",
      "Iteration:  18400 , loss:  0.001234002\n",
      "Iteration:  18500 , loss:  0.0012240438\n",
      "Iteration:  18600 , loss:  0.0015501408\n",
      "Iteration:  18700 , loss:  0.0012034785\n",
      "Iteration:  18800 , loss:  0.0011951035\n",
      "Iteration:  18900 , loss:  0.0011858316\n",
      "Iteration:  19000 , loss:  0.0014214753\n",
      "Iteration:  19100 , loss:  0.0011699036\n",
      "Iteration:  19200 , loss:  0.0011594811\n",
      "Iteration:  19300 , loss:  0.0011702469\n",
      "Iteration:  19400 , loss:  0.001994338\n",
      "Iteration:  19500 , loss:  0.0011353936\n",
      "Iteration:  19600 , loss:  0.0011301162\n",
      "Iteration:  19700 , loss:  0.0011201256\n",
      "Iteration:  19800 , loss:  0.0012510122\n",
      "Iteration:  19900 , loss:  0.0011055188\n",
      "Generating 1th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.27833977\n",
      "Iteration:  100 , loss:  0.13584402\n",
      "Iteration:  200 , loss:  0.12608382\n",
      "Iteration:  300 , loss:  0.10802076\n",
      "Iteration:  400 , loss:  0.079940416\n",
      "Iteration:  500 , loss:  0.06929709\n",
      "Iteration:  600 , loss:  0.05720897\n",
      "Iteration:  700 , loss:  0.051326018\n",
      "Iteration:  800 , loss:  0.04556166\n",
      "Iteration:  900 , loss:  0.04168624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1000 , loss:  0.03871513\n",
      "Iteration:  1100 , loss:  0.035611372\n",
      "Iteration:  1200 , loss:  0.032545373\n",
      "Iteration:  1300 , loss:  0.029813353\n",
      "Iteration:  1400 , loss:  0.028800016\n",
      "Iteration:  1500 , loss:  0.025991244\n",
      "Iteration:  1600 , loss:  0.025160797\n",
      "Iteration:  1700 , loss:  0.02364617\n",
      "Iteration:  1800 , loss:  0.022892293\n",
      "Iteration:  1900 , loss:  0.022227772\n",
      "Iteration:  2000 , loss:  0.022537345\n",
      "Iteration:  2100 , loss:  0.021021694\n",
      "Iteration:  2200 , loss:  0.02045469\n",
      "Iteration:  2300 , loss:  0.019917285\n",
      "Iteration:  2400 , loss:  0.019668065\n",
      "Iteration:  2500 , loss:  0.018832022\n",
      "Iteration:  2600 , loss:  0.018321536\n",
      "Iteration:  2700 , loss:  0.017731128\n",
      "Iteration:  2800 , loss:  0.017128065\n",
      "Iteration:  2900 , loss:  0.016467433\n",
      "Iteration:  3000 , loss:  0.015721565\n",
      "Iteration:  3100 , loss:  0.014770638\n",
      "Iteration:  3200 , loss:  0.013737234\n",
      "Iteration:  3300 , loss:  0.012819943\n",
      "Iteration:  3400 , loss:  0.011894395\n",
      "Iteration:  3500 , loss:  0.011479512\n",
      "Iteration:  3600 , loss:  0.010616324\n",
      "Iteration:  3700 , loss:  0.010169721\n",
      "Iteration:  3800 , loss:  0.00958251\n",
      "Iteration:  3900 , loss:  0.0091607\n",
      "Iteration:  4000 , loss:  0.008700034\n",
      "Iteration:  4100 , loss:  0.008377127\n",
      "Iteration:  4200 , loss:  0.007822869\n",
      "Iteration:  4300 , loss:  0.007467542\n",
      "Iteration:  4400 , loss:  0.0071343523\n",
      "Iteration:  4500 , loss:  0.0068287244\n",
      "Iteration:  4600 , loss:  0.0065495986\n",
      "Iteration:  4700 , loss:  0.0063169627\n",
      "Iteration:  4800 , loss:  0.0060835946\n",
      "Iteration:  4900 , loss:  0.0058798897\n",
      "Iteration:  5000 , loss:  0.006219162\n",
      "Iteration:  5100 , loss:  0.0055449377\n",
      "Iteration:  5200 , loss:  0.0053973673\n",
      "Iteration:  5300 , loss:  0.005953126\n",
      "Iteration:  5400 , loss:  0.0057271505\n",
      "Iteration:  5500 , loss:  0.0050037145\n",
      "Iteration:  5600 , loss:  0.0048957383\n",
      "Iteration:  5700 , loss:  0.0047940146\n",
      "Iteration:  5800 , loss:  0.0049280077\n",
      "Iteration:  5900 , loss:  0.004665927\n",
      "Iteration:  6000 , loss:  0.006112108\n",
      "Iteration:  6100 , loss:  0.0044942517\n",
      "Iteration:  6200 , loss:  0.0044863424\n",
      "Iteration:  6300 , loss:  0.004324431\n",
      "Iteration:  6400 , loss:  0.0042678686\n",
      "Iteration:  6500 , loss:  0.0041862037\n",
      "Iteration:  6600 , loss:  0.004125957\n",
      "Iteration:  6700 , loss:  0.004066417\n",
      "Iteration:  6800 , loss:  0.0041050003\n",
      "Iteration:  6900 , loss:  0.0039617266\n",
      "Iteration:  7000 , loss:  0.0039003151\n",
      "Iteration:  7100 , loss:  0.0038582913\n",
      "Iteration:  7200 , loss:  0.0042670174\n",
      "Iteration:  7300 , loss:  0.0037382308\n",
      "Iteration:  7400 , loss:  0.0036961732\n",
      "Iteration:  7500 , loss:  0.0036335867\n",
      "Iteration:  7600 , loss:  0.0036072014\n",
      "Iteration:  7700 , loss:  0.0035929014\n",
      "Iteration:  7800 , loss:  0.0037083714\n",
      "Iteration:  7900 , loss:  0.004745528\n",
      "Iteration:  8000 , loss:  0.003521848\n",
      "Iteration:  8100 , loss:  0.0033245864\n",
      "Iteration:  8200 , loss:  0.0033105086\n",
      "Iteration:  8300 , loss:  0.0032311943\n",
      "Iteration:  8400 , loss:  0.003188936\n",
      "Iteration:  8500 , loss:  0.003154461\n",
      "Iteration:  8600 , loss:  0.0031032776\n",
      "Iteration:  8700 , loss:  0.0030775853\n",
      "Iteration:  8800 , loss:  0.0030227897\n",
      "Iteration:  8900 , loss:  0.0030294496\n",
      "Iteration:  9000 , loss:  0.0033854286\n",
      "Iteration:  9100 , loss:  0.002913158\n",
      "Iteration:  9200 , loss:  0.0028797928\n",
      "Iteration:  9300 , loss:  0.003076363\n",
      "Iteration:  9400 , loss:  0.0028265147\n",
      "Iteration:  9500 , loss:  0.002783232\n",
      "Iteration:  9600 , loss:  0.002756719\n",
      "Iteration:  9700 , loss:  0.003320602\n",
      "Iteration:  9800 , loss:  0.0026924142\n",
      "Iteration:  9900 , loss:  0.0026638843\n",
      "Iteration:  10000 , loss:  0.0026428679\n",
      "Iteration:  10100 , loss:  0.0030095917\n",
      "Iteration:  10200 , loss:  0.0025810972\n",
      "Iteration:  10300 , loss:  0.0025575946\n",
      "Iteration:  10400 , loss:  0.0025282241\n",
      "Iteration:  10500 , loss:  0.0027094136\n",
      "Iteration:  10600 , loss:  0.0024760065\n",
      "Iteration:  10700 , loss:  0.0024489067\n",
      "Iteration:  10800 , loss:  0.0024241526\n",
      "Iteration:  10900 , loss:  0.002398149\n",
      "Iteration:  11000 , loss:  0.0023750265\n",
      "Iteration:  11100 , loss:  0.002350289\n",
      "Iteration:  11200 , loss:  0.002323739\n",
      "Iteration:  11300 , loss:  0.0023035128\n",
      "Iteration:  11400 , loss:  0.0022819247\n",
      "Iteration:  11500 , loss:  0.0022518055\n",
      "Iteration:  11600 , loss:  0.0024909498\n",
      "Iteration:  11700 , loss:  0.0022043448\n",
      "Iteration:  11800 , loss:  0.0021813673\n",
      "Iteration:  11900 , loss:  0.0021575768\n",
      "Iteration:  12000 , loss:  0.00213546\n",
      "Iteration:  12100 , loss:  0.0021159314\n",
      "Iteration:  12200 , loss:  0.0021834245\n",
      "Iteration:  12300 , loss:  0.0020668036\n",
      "Iteration:  12400 , loss:  0.0020437767\n",
      "Iteration:  12500 , loss:  0.0020241826\n",
      "Iteration:  12600 , loss:  0.0020250177\n",
      "Iteration:  12700 , loss:  0.0019781992\n",
      "Iteration:  12800 , loss:  0.0019586412\n",
      "Iteration:  12900 , loss:  0.0035574813\n",
      "Iteration:  13000 , loss:  0.0019591588\n",
      "Iteration:  13100 , loss:  0.0020821702\n",
      "Iteration:  13200 , loss:  0.0022512984\n",
      "Iteration:  13300 , loss:  0.0018534428\n",
      "Iteration:  13400 , loss:  0.0018686642\n",
      "Iteration:  13500 , loss:  0.0018367206\n",
      "Iteration:  13600 , loss:  0.0020914138\n",
      "Iteration:  13700 , loss:  0.0017726474\n",
      "Iteration:  13800 , loss:  0.0017985058\n",
      "Iteration:  13900 , loss:  0.001735527\n",
      "Iteration:  14000 , loss:  0.0017218275\n",
      "Iteration:  14100 , loss:  0.0017688195\n",
      "Iteration:  14200 , loss:  0.0021516564\n",
      "Iteration:  14300 , loss:  0.0016528921\n",
      "Iteration:  14400 , loss:  0.0016329109\n",
      "Iteration:  14500 , loss:  0.0016141093\n",
      "Iteration:  14600 , loss:  0.0016000693\n",
      "Iteration:  14700 , loss:  0.0020075818\n",
      "Iteration:  14800 , loss:  0.0015653047\n",
      "Iteration:  14900 , loss:  0.0015348623\n",
      "Iteration:  15000 , loss:  0.0017397061\n",
      "Iteration:  15100 , loss:  0.0015098755\n",
      "Iteration:  15200 , loss:  0.004826768\n",
      "Iteration:  15300 , loss:  0.0014632315\n",
      "Iteration:  15400 , loss:  0.0014487361\n",
      "Iteration:  15500 , loss:  0.0014344294\n",
      "Iteration:  15600 , loss:  0.0015183566\n",
      "Iteration:  15700 , loss:  0.0014056034\n",
      "Iteration:  15800 , loss:  0.0013894642\n",
      "Iteration:  15900 , loss:  0.001376678\n",
      "Iteration:  16000 , loss:  0.0014739524\n",
      "Iteration:  16100 , loss:  0.0013522907\n",
      "Iteration:  16200 , loss:  0.0014489427\n",
      "Iteration:  16300 , loss:  0.0029873578\n",
      "Iteration:  16400 , loss:  0.0013203422\n",
      "Iteration:  16500 , loss:  0.0013151764\n",
      "Iteration:  16600 , loss:  0.0013020403\n",
      "Iteration:  16700 , loss:  0.0028058193\n",
      "Iteration:  16800 , loss:  0.0012836088\n",
      "Iteration:  16900 , loss:  0.0013777721\n",
      "Iteration:  17000 , loss:  0.0012673617\n",
      "Iteration:  17100 , loss:  0.0012595095\n",
      "Iteration:  17200 , loss:  0.0012663624\n",
      "Iteration:  17300 , loss:  0.0021732594\n",
      "Iteration:  17400 , loss:  0.0015958443\n",
      "Iteration:  17500 , loss:  0.0012296451\n",
      "Iteration:  17600 , loss:  0.0014148256\n",
      "Iteration:  17700 , loss:  0.001218742\n",
      "Iteration:  17800 , loss:  0.0012098585\n",
      "Iteration:  17900 , loss:  0.0013385322\n",
      "Iteration:  18000 , loss:  0.0012389007\n",
      "Iteration:  18100 , loss:  0.0012644229\n",
      "Iteration:  18200 , loss:  0.0011842853\n",
      "Iteration:  18300 , loss:  0.0011899174\n",
      "Iteration:  18400 , loss:  0.0011728804\n",
      "Iteration:  18500 , loss:  0.0011684238\n",
      "Iteration:  18600 , loss:  0.0011621537\n",
      "Iteration:  18700 , loss:  0.0011594621\n",
      "Iteration:  18800 , loss:  0.001689869\n",
      "Iteration:  18900 , loss:  0.0011452785\n",
      "Iteration:  19000 , loss:  0.001140222\n",
      "Iteration:  19100 , loss:  0.0013927764\n",
      "Iteration:  19200 , loss:  0.0011298433\n",
      "Iteration:  19300 , loss:  0.0011305015\n",
      "Iteration:  19400 , loss:  0.0012029323\n",
      "Iteration:  19500 , loss:  0.0011148585\n",
      "Iteration:  19600 , loss:  0.0011288276\n",
      "Iteration:  19700 , loss:  0.0011056059\n",
      "Iteration:  19800 , loss:  0.0012671228\n",
      "Iteration:  19900 , loss:  0.0011803793\n",
      "Generating 2th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.2596561\n",
      "Iteration:  100 , loss:  0.13688794\n",
      "Iteration:  200 , loss:  0.12733573\n",
      "Iteration:  300 , loss:  0.11380964\n",
      "Iteration:  400 , loss:  0.10028116\n",
      "Iteration:  500 , loss:  0.077206574\n",
      "Iteration:  600 , loss:  0.056320228\n",
      "Iteration:  700 , loss:  0.049762554\n",
      "Iteration:  800 , loss:  0.045561653\n",
      "Iteration:  900 , loss:  0.041552212\n",
      "Iteration:  1000 , loss:  0.037204172\n",
      "Iteration:  1100 , loss:  0.033258636\n",
      "Iteration:  1200 , loss:  0.030453727\n",
      "Iteration:  1300 , loss:  0.028688814\n",
      "Iteration:  1400 , loss:  0.02655963\n",
      "Iteration:  1500 , loss:  0.025034958\n",
      "Iteration:  1600 , loss:  0.023995472\n",
      "Iteration:  1700 , loss:  0.022832032\n",
      "Iteration:  1800 , loss:  0.021939922\n",
      "Iteration:  1900 , loss:  0.021039834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2000 , loss:  0.021749368\n",
      "Iteration:  2100 , loss:  0.01914372\n",
      "Iteration:  2200 , loss:  0.01813761\n",
      "Iteration:  2300 , loss:  0.01714496\n",
      "Iteration:  2400 , loss:  0.016175356\n",
      "Iteration:  2500 , loss:  0.0154529195\n",
      "Iteration:  2600 , loss:  0.014455013\n",
      "Iteration:  2700 , loss:  0.013781836\n",
      "Iteration:  2800 , loss:  0.013102314\n",
      "Iteration:  2900 , loss:  0.012524359\n",
      "Iteration:  3000 , loss:  0.01182336\n",
      "Iteration:  3100 , loss:  0.011203991\n",
      "Iteration:  3200 , loss:  0.010662695\n",
      "Iteration:  3300 , loss:  0.01015368\n",
      "Iteration:  3400 , loss:  0.009631513\n",
      "Iteration:  3500 , loss:  0.00920328\n",
      "Iteration:  3600 , loss:  0.008848176\n",
      "Iteration:  3700 , loss:  0.00843965\n",
      "Iteration:  3800 , loss:  0.008101767\n",
      "Iteration:  3900 , loss:  0.0077954386\n",
      "Iteration:  4000 , loss:  0.008141268\n",
      "Iteration:  4100 , loss:  0.0072460184\n",
      "Iteration:  4200 , loss:  0.0070062894\n",
      "Iteration:  4300 , loss:  0.0069694263\n",
      "Iteration:  4400 , loss:  0.0066414666\n",
      "Iteration:  4500 , loss:  0.0063716243\n",
      "Iteration:  4600 , loss:  0.006191768\n",
      "Iteration:  4700 , loss:  0.0060159834\n",
      "Iteration:  4800 , loss:  0.0058265524\n",
      "Iteration:  4900 , loss:  0.005644923\n",
      "Iteration:  5000 , loss:  0.0054898537\n",
      "Iteration:  5100 , loss:  0.005294636\n",
      "Iteration:  5200 , loss:  0.0051706946\n",
      "Iteration:  5300 , loss:  0.0050270534\n",
      "Iteration:  5400 , loss:  0.0048875217\n",
      "Iteration:  5500 , loss:  0.0047768923\n",
      "Iteration:  5600 , loss:  0.0046767006\n",
      "Iteration:  5700 , loss:  0.004585365\n",
      "Iteration:  5800 , loss:  0.0047695944\n",
      "Iteration:  5900 , loss:  0.004755538\n",
      "Iteration:  6000 , loss:  0.004319791\n",
      "Iteration:  6100 , loss:  0.004285159\n",
      "Iteration:  6200 , loss:  0.0041641593\n",
      "Iteration:  6300 , loss:  0.005640029\n",
      "Iteration:  6400 , loss:  0.0039823567\n",
      "Iteration:  6500 , loss:  0.0038974665\n",
      "Iteration:  6600 , loss:  0.0038150027\n",
      "Iteration:  6700 , loss:  0.0037277467\n",
      "Iteration:  6800 , loss:  0.0036434517\n",
      "Iteration:  6900 , loss:  0.0035607591\n",
      "Iteration:  7000 , loss:  0.003478467\n",
      "Iteration:  7100 , loss:  0.0037231846\n",
      "Iteration:  7200 , loss:  0.0033208032\n",
      "Iteration:  7300 , loss:  0.0032537063\n",
      "Iteration:  7400 , loss:  0.003181159\n",
      "Iteration:  7500 , loss:  0.003113978\n",
      "Iteration:  7600 , loss:  0.0030549043\n",
      "Iteration:  7700 , loss:  0.0030625805\n",
      "Iteration:  7800 , loss:  0.0029438455\n",
      "Iteration:  7900 , loss:  0.0028878385\n",
      "Iteration:  8000 , loss:  0.002988636\n",
      "Iteration:  8100 , loss:  0.0027915328\n",
      "Iteration:  8200 , loss:  0.0027477993\n",
      "Iteration:  8300 , loss:  0.0046349224\n",
      "Iteration:  8400 , loss:  0.0026659023\n",
      "Iteration:  8500 , loss:  0.0026267825\n",
      "Iteration:  8600 , loss:  0.0025984938\n",
      "Iteration:  8700 , loss:  0.0025669765\n",
      "Iteration:  8800 , loss:  0.0027973335\n",
      "Iteration:  8900 , loss:  0.0025001985\n",
      "Iteration:  9000 , loss:  0.0024525658\n",
      "Iteration:  9100 , loss:  0.00242382\n",
      "Iteration:  9200 , loss:  0.0023913186\n",
      "Iteration:  9300 , loss:  0.0026718944\n",
      "Iteration:  9400 , loss:  0.0023690744\n",
      "Iteration:  9500 , loss:  0.0023065715\n",
      "Iteration:  9600 , loss:  0.0022768232\n",
      "Iteration:  9700 , loss:  0.0024594914\n",
      "Iteration:  9800 , loss:  0.0022577313\n",
      "Iteration:  9900 , loss:  0.003171405\n",
      "Iteration:  10000 , loss:  0.0021841498\n",
      "Iteration:  10100 , loss:  0.0021550194\n",
      "Iteration:  10200 , loss:  0.0021226252\n",
      "Iteration:  10300 , loss:  0.0021009315\n",
      "Iteration:  10400 , loss:  0.0020771017\n",
      "Iteration:  10500 , loss:  0.0020532282\n",
      "Iteration:  10600 , loss:  0.0020293626\n",
      "Iteration:  10700 , loss:  0.0020099338\n",
      "Iteration:  10800 , loss:  0.0026931372\n",
      "Iteration:  10900 , loss:  0.0019635323\n",
      "Iteration:  11000 , loss:  0.0019623789\n",
      "Iteration:  11100 , loss:  0.0019270785\n",
      "Iteration:  11200 , loss:  0.0019007655\n",
      "Iteration:  11300 , loss:  0.0018823548\n",
      "Iteration:  11400 , loss:  0.0035427918\n",
      "Iteration:  11500 , loss:  0.0018414498\n",
      "Iteration:  11600 , loss:  0.0018637415\n",
      "Iteration:  11700 , loss:  0.0018034828\n",
      "Iteration:  11800 , loss:  0.0017846733\n",
      "Iteration:  11900 , loss:  0.0017689599\n",
      "Iteration:  12000 , loss:  0.0017476907\n",
      "Iteration:  12100 , loss:  0.0017558493\n",
      "Iteration:  12200 , loss:  0.0017114779\n",
      "Iteration:  12300 , loss:  0.0016931258\n",
      "Iteration:  12400 , loss:  0.0016815525\n",
      "Iteration:  12500 , loss:  0.0017760972\n",
      "Iteration:  12600 , loss:  0.0016410467\n",
      "Iteration:  12700 , loss:  0.0016230387\n",
      "Iteration:  12800 , loss:  0.0032769665\n",
      "Iteration:  12900 , loss:  0.0017671227\n",
      "Iteration:  13000 , loss:  0.0015713217\n",
      "Iteration:  13100 , loss:  0.0015553597\n",
      "Iteration:  13200 , loss:  0.0019499667\n",
      "Iteration:  13300 , loss:  0.001526077\n",
      "Iteration:  13400 , loss:  0.0015060443\n",
      "Iteration:  13500 , loss:  0.0016264573\n",
      "Iteration:  13600 , loss:  0.0015065266\n",
      "Iteration:  13700 , loss:  0.0015999788\n",
      "Iteration:  13800 , loss:  0.001449517\n",
      "Iteration:  13900 , loss:  0.0014283735\n",
      "Iteration:  14000 , loss:  0.0014139405\n",
      "Iteration:  14100 , loss:  0.001400406\n",
      "Iteration:  14200 , loss:  0.0013856671\n",
      "Iteration:  14300 , loss:  0.0037784171\n",
      "Iteration:  14400 , loss:  0.002416845\n",
      "Iteration:  14500 , loss:  0.0013458742\n",
      "Iteration:  14600 , loss:  0.0013327858\n",
      "Iteration:  14700 , loss:  0.0015680406\n",
      "Iteration:  14800 , loss:  0.00194111\n",
      "Iteration:  14900 , loss:  0.0012961854\n",
      "Iteration:  15000 , loss:  0.0012847201\n",
      "Iteration:  15100 , loss:  0.0012831535\n",
      "Iteration:  15200 , loss:  0.0012915718\n",
      "Iteration:  15300 , loss:  0.0012494514\n",
      "Iteration:  15400 , loss:  0.0012463124\n",
      "Iteration:  15500 , loss:  0.0017042093\n",
      "Iteration:  15600 , loss:  0.0012169057\n",
      "Iteration:  15700 , loss:  0.0012080886\n",
      "Iteration:  15800 , loss:  0.0011963949\n",
      "Iteration:  15900 , loss:  0.0012009828\n",
      "Iteration:  16000 , loss:  0.0011775001\n",
      "Iteration:  16100 , loss:  0.0011738078\n",
      "Iteration:  16200 , loss:  0.0011568717\n",
      "Iteration:  16300 , loss:  0.0011510972\n",
      "Iteration:  16400 , loss:  0.0011382594\n",
      "Iteration:  16500 , loss:  0.0011300951\n",
      "Iteration:  16600 , loss:  0.0011191079\n",
      "Iteration:  16700 , loss:  0.0011474299\n",
      "Iteration:  16800 , loss:  0.001142883\n",
      "Iteration:  16900 , loss:  0.0010912739\n",
      "Iteration:  17000 , loss:  0.0010817876\n",
      "Iteration:  17100 , loss:  0.0010879007\n",
      "Iteration:  17200 , loss:  0.0010639813\n",
      "Iteration:  17300 , loss:  0.0010588375\n",
      "Iteration:  17400 , loss:  0.0010462801\n",
      "Iteration:  17500 , loss:  0.0010385104\n",
      "Iteration:  17600 , loss:  0.0013158226\n",
      "Iteration:  17700 , loss:  0.0010201286\n",
      "Iteration:  17800 , loss:  0.0010129003\n",
      "Iteration:  17900 , loss:  0.0010822504\n",
      "Iteration:  18000 , loss:  0.0009942545\n",
      "Iteration:  18100 , loss:  0.0009900025\n",
      "Iteration:  18200 , loss:  0.0009772131\n",
      "Iteration:  18300 , loss:  0.000970116\n",
      "Iteration:  18400 , loss:  0.0009878969\n",
      "Iteration:  18500 , loss:  0.0013846788\n",
      "Iteration:  18600 , loss:  0.0009434385\n",
      "Iteration:  18700 , loss:  0.00096224726\n",
      "Iteration:  18800 , loss:  0.00092791324\n",
      "Iteration:  18900 , loss:  0.00091986166\n",
      "Iteration:  19000 , loss:  0.0009957192\n",
      "Iteration:  19100 , loss:  0.0013661184\n",
      "Iteration:  19200 , loss:  0.0008942619\n",
      "Iteration:  19300 , loss:  0.00088650524\n",
      "Iteration:  19400 , loss:  0.00096078427\n",
      "Iteration:  19500 , loss:  0.0020781578\n",
      "Iteration:  19600 , loss:  0.00086271827\n",
      "Iteration:  19700 , loss:  0.0008734101\n",
      "Iteration:  19800 , loss:  0.00084785506\n",
      "Iteration:  19900 , loss:  0.0020023193\n",
      "Generating 3th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.23724261\n",
      "Iteration:  100 , loss:  0.13377029\n",
      "Iteration:  200 , loss:  0.11573343\n",
      "Iteration:  300 , loss:  0.092745274\n",
      "Iteration:  400 , loss:  0.069075376\n",
      "Iteration:  500 , loss:  0.04724536\n",
      "Iteration:  600 , loss:  0.040188115\n",
      "Iteration:  700 , loss:  0.035755858\n",
      "Iteration:  800 , loss:  0.032680098\n",
      "Iteration:  900 , loss:  0.030350002\n",
      "Iteration:  1000 , loss:  0.028058548\n",
      "Iteration:  1100 , loss:  0.026012072\n",
      "Iteration:  1200 , loss:  0.024646014\n",
      "Iteration:  1300 , loss:  0.023357501\n",
      "Iteration:  1400 , loss:  0.022495639\n",
      "Iteration:  1500 , loss:  0.02267653\n",
      "Iteration:  1600 , loss:  0.021249902\n",
      "Iteration:  1700 , loss:  0.020708913\n",
      "Iteration:  1800 , loss:  0.020198585\n",
      "Iteration:  1900 , loss:  0.01966956\n",
      "Iteration:  2000 , loss:  0.019159883\n",
      "Iteration:  2100 , loss:  0.018670171\n",
      "Iteration:  2200 , loss:  0.018265795\n",
      "Iteration:  2300 , loss:  0.0176803\n",
      "Iteration:  2400 , loss:  0.017187012\n",
      "Iteration:  2500 , loss:  0.016648289\n",
      "Iteration:  2600 , loss:  0.016984377\n",
      "Iteration:  2700 , loss:  0.01562789\n",
      "Iteration:  2800 , loss:  0.015473856\n",
      "Iteration:  2900 , loss:  0.014565597\n",
      "Iteration:  3000 , loss:  0.014005115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3100 , loss:  0.013497876\n",
      "Iteration:  3200 , loss:  0.013016384\n",
      "Iteration:  3300 , loss:  0.012571102\n",
      "Iteration:  3400 , loss:  0.012151684\n",
      "Iteration:  3500 , loss:  0.011754181\n",
      "Iteration:  3600 , loss:  0.011380004\n",
      "Iteration:  3700 , loss:  0.012246737\n",
      "Iteration:  3800 , loss:  0.011304046\n",
      "Iteration:  3900 , loss:  0.010482863\n",
      "Iteration:  4000 , loss:  0.0109269265\n",
      "Iteration:  4100 , loss:  0.009915261\n",
      "Iteration:  4200 , loss:  0.009612906\n",
      "Iteration:  4300 , loss:  0.0093793245\n",
      "Iteration:  4400 , loss:  0.009160422\n",
      "Iteration:  4500 , loss:  0.008950302\n",
      "Iteration:  4600 , loss:  0.008831245\n",
      "Iteration:  4700 , loss:  0.008653606\n",
      "Iteration:  4800 , loss:  0.008376003\n",
      "Iteration:  4900 , loss:  0.008281927\n",
      "Iteration:  5000 , loss:  0.008041671\n",
      "Iteration:  5100 , loss:  0.00787303\n",
      "Iteration:  5200 , loss:  0.007718128\n",
      "Iteration:  5300 , loss:  0.00757285\n",
      "Iteration:  5400 , loss:  0.0083013885\n",
      "Iteration:  5500 , loss:  0.007297868\n",
      "Iteration:  5600 , loss:  0.007171423\n",
      "Iteration:  5700 , loss:  0.007940616\n",
      "Iteration:  5800 , loss:  0.0069285952\n",
      "Iteration:  5900 , loss:  0.0068281274\n",
      "Iteration:  6000 , loss:  0.0067175683\n",
      "Iteration:  6100 , loss:  0.010294078\n",
      "Iteration:  6200 , loss:  0.006531817\n",
      "Iteration:  6300 , loss:  0.006439316\n",
      "Iteration:  6400 , loss:  0.006469367\n",
      "Iteration:  6500 , loss:  0.0062837047\n",
      "Iteration:  6600 , loss:  0.006202013\n",
      "Iteration:  6700 , loss:  0.0076507144\n",
      "Iteration:  6800 , loss:  0.0060627186\n",
      "Iteration:  6900 , loss:  0.005995395\n",
      "Iteration:  7000 , loss:  0.0059320056\n",
      "Iteration:  7100 , loss:  0.00587531\n",
      "Iteration:  7200 , loss:  0.00581211\n",
      "Iteration:  7300 , loss:  0.008283162\n",
      "Iteration:  7400 , loss:  0.0057010073\n",
      "Iteration:  7500 , loss:  0.0056519145\n",
      "Iteration:  7600 , loss:  0.005595537\n",
      "Iteration:  7700 , loss:  0.005543381\n",
      "Iteration:  7800 , loss:  0.0054960945\n",
      "Iteration:  7900 , loss:  0.005462877\n",
      "Iteration:  8000 , loss:  0.0053984374\n",
      "Iteration:  8100 , loss:  0.0053534023\n",
      "Iteration:  8200 , loss:  0.0059419055\n",
      "Iteration:  8300 , loss:  0.005260189\n",
      "Iteration:  8400 , loss:  0.005219196\n",
      "Iteration:  8500 , loss:  0.009150283\n",
      "Iteration:  8600 , loss:  0.005127289\n",
      "Iteration:  8700 , loss:  0.0050859246\n",
      "Iteration:  8800 , loss:  0.0050402074\n",
      "Iteration:  8900 , loss:  0.005002341\n",
      "Iteration:  9000 , loss:  0.0055186823\n",
      "Iteration:  9100 , loss:  0.0050620693\n",
      "Iteration:  9200 , loss:  0.004876883\n",
      "Iteration:  9300 , loss:  0.0048486316\n",
      "Iteration:  9400 , loss:  0.0048523536\n",
      "Iteration:  9500 , loss:  0.004745697\n",
      "Iteration:  9600 , loss:  0.0047048586\n",
      "Iteration:  9700 , loss:  0.0046673473\n",
      "Iteration:  9800 , loss:  0.0054802415\n",
      "Iteration:  9900 , loss:  0.004690108\n",
      "Iteration:  10000 , loss:  0.004565158\n",
      "Iteration:  10100 , loss:  0.006015811\n",
      "Iteration:  10200 , loss:  0.005458299\n",
      "Iteration:  10300 , loss:  0.0044285124\n",
      "Iteration:  10400 , loss:  0.004391581\n",
      "Iteration:  10500 , loss:  0.0054408703\n",
      "Iteration:  10600 , loss:  0.004817077\n",
      "Iteration:  10700 , loss:  0.0042794575\n",
      "Iteration:  10800 , loss:  0.009419533\n",
      "Iteration:  10900 , loss:  0.0054372577\n",
      "Iteration:  11000 , loss:  0.00417053\n",
      "Iteration:  11100 , loss:  0.004142198\n",
      "Iteration:  11200 , loss:  0.0041018003\n",
      "Iteration:  11300 , loss:  0.0047454787\n",
      "Iteration:  11400 , loss:  0.0040640603\n",
      "Iteration:  11500 , loss:  0.0040406445\n",
      "Iteration:  11600 , loss:  0.0039693494\n",
      "Iteration:  11700 , loss:  0.0040382696\n",
      "Iteration:  11800 , loss:  0.0041083945\n",
      "Iteration:  11900 , loss:  0.0046522636\n",
      "Iteration:  12000 , loss:  0.0038327374\n",
      "Iteration:  12100 , loss:  0.0038093987\n",
      "Iteration:  12200 , loss:  0.003774311\n",
      "Iteration:  12300 , loss:  0.0037438967\n",
      "Iteration:  12400 , loss:  0.0037229264\n",
      "Iteration:  12500 , loss:  0.0036920833\n",
      "Iteration:  12600 , loss:  0.003660027\n",
      "Iteration:  12700 , loss:  0.004862525\n",
      "Iteration:  12800 , loss:  0.005105926\n",
      "Iteration:  12900 , loss:  0.0035966388\n",
      "Iteration:  13000 , loss:  0.0045136353\n",
      "Iteration:  13100 , loss:  0.0050290944\n",
      "Iteration:  13200 , loss:  0.0035315354\n",
      "Iteration:  13300 , loss:  0.0035206089\n",
      "Iteration:  13400 , loss:  0.003470937\n",
      "Iteration:  13500 , loss:  0.0034471753\n",
      "Iteration:  13600 , loss:  0.0034209471\n",
      "Iteration:  13700 , loss:  0.0036097155\n",
      "Iteration:  13800 , loss:  0.0033779885\n",
      "Iteration:  13900 , loss:  0.003358839\n",
      "Iteration:  14000 , loss:  0.0033397623\n",
      "Iteration:  14100 , loss:  0.003317787\n",
      "Iteration:  14200 , loss:  0.003310917\n",
      "Iteration:  14300 , loss:  0.0032794478\n",
      "Iteration:  14400 , loss:  0.0035082093\n",
      "Iteration:  14500 , loss:  0.0033458762\n",
      "Iteration:  14600 , loss:  0.004536245\n",
      "Iteration:  14700 , loss:  0.0032476834\n",
      "Iteration:  14800 , loss:  0.0032898923\n",
      "Iteration:  14900 , loss:  0.0031804806\n",
      "Iteration:  15000 , loss:  0.0031574562\n",
      "Iteration:  15100 , loss:  0.0032191454\n",
      "Iteration:  15200 , loss:  0.0031915172\n",
      "Iteration:  15300 , loss:  0.003628073\n",
      "Iteration:  15400 , loss:  0.0040168785\n",
      "Iteration:  15500 , loss:  0.0032014668\n",
      "Iteration:  15600 , loss:  0.003067186\n",
      "Iteration:  15700 , loss:  0.0032545805\n",
      "Iteration:  15800 , loss:  0.0030543725\n",
      "Iteration:  15900 , loss:  0.0032251142\n",
      "Iteration:  16000 , loss:  0.0037534158\n",
      "Iteration:  16100 , loss:  0.002995435\n",
      "Iteration:  16200 , loss:  0.002985551\n",
      "Iteration:  16300 , loss:  0.002969746\n",
      "Iteration:  16400 , loss:  0.002955974\n",
      "Iteration:  16500 , loss:  0.0029658913\n",
      "Iteration:  16600 , loss:  0.002931931\n",
      "Iteration:  16700 , loss:  0.005318991\n",
      "Iteration:  16800 , loss:  0.0029489384\n",
      "Iteration:  16900 , loss:  0.0029296374\n",
      "Iteration:  17000 , loss:  0.0030855031\n",
      "Iteration:  17100 , loss:  0.0028980295\n",
      "Iteration:  17200 , loss:  0.003294825\n",
      "Iteration:  17300 , loss:  0.0029043083\n",
      "Iteration:  17400 , loss:  0.002862015\n",
      "Iteration:  17500 , loss:  0.0028548227\n",
      "Iteration:  17600 , loss:  0.0028108282\n",
      "Iteration:  17700 , loss:  0.0028595366\n",
      "Iteration:  17800 , loss:  0.002780235\n",
      "Iteration:  17900 , loss:  0.0028219388\n",
      "Iteration:  18000 , loss:  0.0027597602\n",
      "Iteration:  18100 , loss:  0.002864119\n",
      "Iteration:  18200 , loss:  0.002760555\n",
      "Iteration:  18300 , loss:  0.0027193653\n",
      "Iteration:  18400 , loss:  0.0027099901\n",
      "Iteration:  18500 , loss:  0.002696012\n",
      "Iteration:  18600 , loss:  0.0027599253\n",
      "Iteration:  18700 , loss:  0.0027540615\n",
      "Iteration:  18800 , loss:  0.005723944\n",
      "Iteration:  18900 , loss:  0.0026477017\n",
      "Iteration:  19000 , loss:  0.0026394897\n",
      "Iteration:  19100 , loss:  0.0026660268\n",
      "Iteration:  19200 , loss:  0.0026120092\n",
      "Iteration:  19300 , loss:  0.002601965\n",
      "Iteration:  19400 , loss:  0.0025973853\n",
      "Iteration:  19500 , loss:  0.0025760983\n",
      "Iteration:  19600 , loss:  0.0025654086\n",
      "Iteration:  19700 , loss:  0.002555038\n",
      "Iteration:  19800 , loss:  0.002540803\n",
      "Iteration:  19900 , loss:  0.002557171\n",
      "Generating 4th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.42933404\n",
      "Iteration:  100 , loss:  0.14023347\n",
      "Iteration:  200 , loss:  0.13683464\n",
      "Iteration:  300 , loss:  0.12526996\n",
      "Iteration:  400 , loss:  0.11447813\n",
      "Iteration:  500 , loss:  0.095256604\n",
      "Iteration:  600 , loss:  0.06941852\n",
      "Iteration:  700 , loss:  0.05294493\n",
      "Iteration:  800 , loss:  0.044678744\n",
      "Iteration:  900 , loss:  0.04016464\n",
      "Iteration:  1000 , loss:  0.037323497\n",
      "Iteration:  1100 , loss:  0.034887403\n",
      "Iteration:  1200 , loss:  0.033323176\n",
      "Iteration:  1300 , loss:  0.031008897\n",
      "Iteration:  1400 , loss:  0.029185103\n",
      "Iteration:  1500 , loss:  0.027540125\n",
      "Iteration:  1600 , loss:  0.026073456\n",
      "Iteration:  1700 , loss:  0.024899013\n",
      "Iteration:  1800 , loss:  0.023925267\n",
      "Iteration:  1900 , loss:  0.023014225\n",
      "Iteration:  2000 , loss:  0.022320213\n",
      "Iteration:  2100 , loss:  0.021769568\n",
      "Iteration:  2200 , loss:  0.020466011\n",
      "Iteration:  2300 , loss:  0.0197176\n",
      "Iteration:  2400 , loss:  0.019111339\n",
      "Iteration:  2500 , loss:  0.018479314\n",
      "Iteration:  2600 , loss:  0.01794669\n",
      "Iteration:  2700 , loss:  0.017416574\n",
      "Iteration:  2800 , loss:  0.016883336\n",
      "Iteration:  2900 , loss:  0.01657376\n",
      "Iteration:  3000 , loss:  0.015832668\n",
      "Iteration:  3100 , loss:  0.015340713\n",
      "Iteration:  3200 , loss:  0.014849777\n",
      "Iteration:  3300 , loss:  0.016369369\n",
      "Iteration:  3400 , loss:  0.013971783\n",
      "Iteration:  3500 , loss:  0.013556156\n",
      "Iteration:  3600 , loss:  0.013180756\n",
      "Iteration:  3700 , loss:  0.012829419\n",
      "Iteration:  3800 , loss:  0.012495061\n",
      "Iteration:  3900 , loss:  0.0123567665\n",
      "Iteration:  4000 , loss:  0.011897981\n",
      "Iteration:  4100 , loss:  0.011627904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4200 , loss:  0.012622644\n",
      "Iteration:  4300 , loss:  0.011140136\n",
      "Iteration:  4400 , loss:  0.010955909\n",
      "Iteration:  4500 , loss:  0.010717335\n",
      "Iteration:  4600 , loss:  0.010529153\n",
      "Iteration:  4700 , loss:  0.010355644\n",
      "Iteration:  4800 , loss:  0.010177709\n",
      "Iteration:  4900 , loss:  0.010003274\n",
      "Iteration:  5000 , loss:  0.00985931\n",
      "Iteration:  5100 , loss:  0.009688288\n",
      "Iteration:  5200 , loss:  0.010766804\n",
      "Iteration:  5300 , loss:  0.0117607005\n",
      "Iteration:  5400 , loss:  0.009213176\n",
      "Iteration:  5500 , loss:  0.009059757\n",
      "Iteration:  5600 , loss:  0.008897007\n",
      "Iteration:  5700 , loss:  0.008736259\n",
      "Iteration:  5800 , loss:  0.008573597\n",
      "Iteration:  5900 , loss:  0.008583815\n",
      "Iteration:  6000 , loss:  0.008264767\n",
      "Iteration:  6100 , loss:  0.008209137\n",
      "Iteration:  6200 , loss:  0.008020476\n",
      "Iteration:  6300 , loss:  0.008868083\n",
      "Iteration:  6400 , loss:  0.0075971754\n",
      "Iteration:  6500 , loss:  0.00745904\n",
      "Iteration:  6600 , loss:  0.00732914\n",
      "Iteration:  6700 , loss:  0.008121469\n",
      "Iteration:  6800 , loss:  0.006978768\n",
      "Iteration:  6900 , loss:  0.0068433704\n",
      "Iteration:  7000 , loss:  0.007140846\n",
      "Iteration:  7100 , loss:  0.0065318937\n",
      "Iteration:  7200 , loss:  0.0064198077\n",
      "Iteration:  7300 , loss:  0.0065309764\n",
      "Iteration:  7400 , loss:  0.0061248797\n",
      "Iteration:  7500 , loss:  0.0064613875\n",
      "Iteration:  7600 , loss:  0.0076860087\n",
      "Iteration:  7700 , loss:  0.0057679266\n",
      "Iteration:  7800 , loss:  0.005678075\n",
      "Iteration:  7900 , loss:  0.0055726115\n",
      "Iteration:  8000 , loss:  0.006105189\n",
      "Iteration:  8100 , loss:  0.0053568333\n",
      "Iteration:  8200 , loss:  0.0057618227\n",
      "Iteration:  8300 , loss:  0.0053981226\n",
      "Iteration:  8400 , loss:  0.0050880965\n",
      "Iteration:  8500 , loss:  0.0050495113\n",
      "Iteration:  8600 , loss:  0.004925714\n",
      "Iteration:  8700 , loss:  0.004848676\n",
      "Iteration:  8800 , loss:  0.0052189864\n",
      "Iteration:  8900 , loss:  0.004708254\n",
      "Iteration:  9000 , loss:  0.0046354737\n",
      "Iteration:  9100 , loss:  0.0045751575\n",
      "Iteration:  9200 , loss:  0.0065243654\n",
      "Iteration:  9300 , loss:  0.005697076\n",
      "Iteration:  9400 , loss:  0.004392575\n",
      "Iteration:  9500 , loss:  0.004781821\n",
      "Iteration:  9600 , loss:  0.0042848587\n",
      "Iteration:  9700 , loss:  0.0042358227\n",
      "Iteration:  9800 , loss:  0.004188516\n",
      "Iteration:  9900 , loss:  0.0042235036\n",
      "Iteration:  10000 , loss:  0.0045736893\n",
      "Iteration:  10100 , loss:  0.0040571606\n",
      "Iteration:  10200 , loss:  0.004328024\n",
      "Iteration:  10300 , loss:  0.0039796825\n",
      "Iteration:  10400 , loss:  0.0039532995\n",
      "Iteration:  10500 , loss:  0.0045333356\n",
      "Iteration:  10600 , loss:  0.0041482877\n",
      "Iteration:  10700 , loss:  0.0038431613\n",
      "Iteration:  10800 , loss:  0.0039800806\n",
      "Iteration:  10900 , loss:  0.006231206\n",
      "Iteration:  11000 , loss:  0.0037528\n",
      "Iteration:  11100 , loss:  0.0037339157\n",
      "Iteration:  11200 , loss:  0.004445481\n",
      "Iteration:  11300 , loss:  0.00433555\n",
      "Iteration:  11400 , loss:  0.0036448296\n",
      "Iteration:  11500 , loss:  0.0037159487\n",
      "Iteration:  11600 , loss:  0.004396055\n",
      "Iteration:  11700 , loss:  0.0035702\n",
      "Iteration:  11800 , loss:  0.0035470275\n",
      "Iteration:  11900 , loss:  0.0035278006\n",
      "Iteration:  12000 , loss:  0.0035792976\n",
      "Iteration:  12100 , loss:  0.0048729377\n",
      "Iteration:  12200 , loss:  0.0037145363\n",
      "Iteration:  12300 , loss:  0.0034375973\n",
      "Iteration:  12400 , loss:  0.003416201\n",
      "Iteration:  12500 , loss:  0.003397374\n",
      "Iteration:  12600 , loss:  0.0034044865\n",
      "Iteration:  12700 , loss:  0.004620971\n",
      "Iteration:  12800 , loss:  0.0033378252\n",
      "Iteration:  12900 , loss:  0.0051417854\n",
      "Iteration:  13000 , loss:  0.0037737014\n",
      "Iteration:  13100 , loss:  0.003368519\n",
      "Iteration:  13200 , loss:  0.0032638875\n",
      "Iteration:  13300 , loss:  0.0034186682\n",
      "Iteration:  13400 , loss:  0.0032411409\n",
      "Iteration:  13500 , loss:  0.0032712095\n",
      "Iteration:  13600 , loss:  0.0031933403\n",
      "Iteration:  13700 , loss:  0.0031956893\n",
      "Iteration:  13800 , loss:  0.0031601647\n",
      "Iteration:  13900 , loss:  0.004270856\n",
      "Iteration:  14000 , loss:  0.0031275824\n",
      "Iteration:  14100 , loss:  0.0031120926\n",
      "Iteration:  14200 , loss:  0.0033196441\n",
      "Iteration:  14300 , loss:  0.0030795075\n",
      "Iteration:  14400 , loss:  0.0032888027\n",
      "Iteration:  14500 , loss:  0.0030624126\n",
      "Iteration:  14600 , loss:  0.0030508495\n",
      "Iteration:  14700 , loss:  0.0032954558\n",
      "Iteration:  14800 , loss:  0.0036431584\n",
      "Iteration:  14900 , loss:  0.0029961108\n",
      "Iteration:  15000 , loss:  0.0029844502\n",
      "Iteration:  15100 , loss:  0.0029552833\n",
      "Iteration:  15200 , loss:  0.002954992\n",
      "Iteration:  15300 , loss:  0.0038698683\n",
      "Iteration:  15400 , loss:  0.0030211317\n",
      "Iteration:  15500 , loss:  0.0028962903\n",
      "Iteration:  15600 , loss:  0.0030437363\n",
      "Iteration:  15700 , loss:  0.0028885356\n",
      "Iteration:  15800 , loss:  0.0028601422\n",
      "Iteration:  15900 , loss:  0.00334807\n",
      "Iteration:  16000 , loss:  0.0029523019\n",
      "Iteration:  16100 , loss:  0.0028622271\n",
      "Iteration:  16200 , loss:  0.0027914143\n",
      "Iteration:  16300 , loss:  0.0027865092\n",
      "Iteration:  16400 , loss:  0.002828\n",
      "Iteration:  16500 , loss:  0.0027465764\n",
      "Iteration:  16600 , loss:  0.0027353778\n",
      "Iteration:  16700 , loss:  0.0027174288\n",
      "Iteration:  16800 , loss:  0.0027141804\n",
      "Iteration:  16900 , loss:  0.0026861443\n",
      "Iteration:  17000 , loss:  0.0026718546\n",
      "Iteration:  17100 , loss:  0.0026710941\n",
      "Iteration:  17200 , loss:  0.0026404767\n",
      "Iteration:  17300 , loss:  0.0026491596\n",
      "Iteration:  17400 , loss:  0.002613706\n",
      "Iteration:  17500 , loss:  0.0027734116\n",
      "Iteration:  17600 , loss:  0.0025790602\n",
      "Iteration:  17700 , loss:  0.0025774965\n",
      "Iteration:  17800 , loss:  0.002550539\n",
      "Iteration:  17900 , loss:  0.0025338246\n",
      "Iteration:  18000 , loss:  0.0028326204\n",
      "Iteration:  18100 , loss:  0.0025132655\n",
      "Iteration:  18200 , loss:  0.0024911338\n",
      "Iteration:  18300 , loss:  0.0024927743\n",
      "Iteration:  18400 , loss:  0.0024724328\n",
      "Iteration:  18500 , loss:  0.0025331192\n",
      "Iteration:  18600 , loss:  0.0026465084\n",
      "Iteration:  18700 , loss:  0.0027140547\n",
      "Iteration:  18800 , loss:  0.0023995587\n",
      "Iteration:  18900 , loss:  0.0023888564\n",
      "Iteration:  19000 , loss:  0.0023951645\n",
      "Iteration:  19100 , loss:  0.0023573795\n",
      "Iteration:  19200 , loss:  0.0023448982\n",
      "Iteration:  19300 , loss:  0.002332283\n",
      "Iteration:  19400 , loss:  0.0023207243\n",
      "Iteration:  19500 , loss:  0.002302674\n",
      "Iteration:  19600 , loss:  0.0024093655\n",
      "Iteration:  19700 , loss:  0.0023426465\n",
      "Iteration:  19800 , loss:  0.0022627972\n",
      "Iteration:  19900 , loss:  0.0028276274\n",
      "Generating 5th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.22932965\n",
      "Iteration:  100 , loss:  0.13752541\n",
      "Iteration:  200 , loss:  0.121172495\n",
      "Iteration:  300 , loss:  0.10551904\n",
      "Iteration:  400 , loss:  0.075654\n",
      "Iteration:  500 , loss:  0.058468726\n",
      "Iteration:  600 , loss:  0.050526425\n",
      "Iteration:  700 , loss:  0.04382146\n",
      "Iteration:  800 , loss:  0.036891755\n",
      "Iteration:  900 , loss:  0.03196084\n",
      "Iteration:  1000 , loss:  0.029431326\n",
      "Iteration:  1100 , loss:  0.027917419\n",
      "Iteration:  1200 , loss:  0.026416194\n",
      "Iteration:  1300 , loss:  0.025024127\n",
      "Iteration:  1400 , loss:  0.023882966\n",
      "Iteration:  1500 , loss:  0.022912636\n",
      "Iteration:  1600 , loss:  0.022039674\n",
      "Iteration:  1700 , loss:  0.02129802\n",
      "Iteration:  1800 , loss:  0.020891642\n",
      "Iteration:  1900 , loss:  0.01981553\n",
      "Iteration:  2000 , loss:  0.018945435\n",
      "Iteration:  2100 , loss:  0.017841756\n",
      "Iteration:  2200 , loss:  0.016520616\n",
      "Iteration:  2300 , loss:  0.015612668\n",
      "Iteration:  2400 , loss:  0.013776248\n",
      "Iteration:  2500 , loss:  0.012923403\n",
      "Iteration:  2600 , loss:  0.012200944\n",
      "Iteration:  2700 , loss:  0.013046226\n",
      "Iteration:  2800 , loss:  0.011089737\n",
      "Iteration:  2900 , loss:  0.010499109\n",
      "Iteration:  3000 , loss:  0.010019939\n",
      "Iteration:  3100 , loss:  0.0095427595\n",
      "Iteration:  3200 , loss:  0.009151867\n",
      "Iteration:  3300 , loss:  0.008505726\n",
      "Iteration:  3400 , loss:  0.009482764\n",
      "Iteration:  3500 , loss:  0.007873262\n",
      "Iteration:  3600 , loss:  0.0073789475\n",
      "Iteration:  3700 , loss:  0.007211574\n",
      "Iteration:  3800 , loss:  0.006980317\n",
      "Iteration:  3900 , loss:  0.0067596575\n",
      "Iteration:  4000 , loss:  0.006692347\n",
      "Iteration:  4100 , loss:  0.006446735\n",
      "Iteration:  4200 , loss:  0.006309558\n",
      "Iteration:  4300 , loss:  0.0062010703\n",
      "Iteration:  4400 , loss:  0.0060530845\n",
      "Iteration:  4500 , loss:  0.005938434\n",
      "Iteration:  4600 , loss:  0.0058164005\n",
      "Iteration:  4700 , loss:  0.005708824\n",
      "Iteration:  4800 , loss:  0.0055938186\n",
      "Iteration:  4900 , loss:  0.005503771\n",
      "Iteration:  5000 , loss:  0.006839242\n",
      "Iteration:  5100 , loss:  0.0052660634\n",
      "Iteration:  5200 , loss:  0.005162716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5300 , loss:  0.0051475205\n",
      "Iteration:  5400 , loss:  0.005068993\n",
      "Iteration:  5500 , loss:  0.0048606824\n",
      "Iteration:  5600 , loss:  0.004768232\n",
      "Iteration:  5700 , loss:  0.0047048084\n",
      "Iteration:  5800 , loss:  0.004632834\n",
      "Iteration:  5900 , loss:  0.00606406\n",
      "Iteration:  6000 , loss:  0.004426516\n",
      "Iteration:  6100 , loss:  0.0043473747\n",
      "Iteration:  6200 , loss:  0.00427588\n",
      "Iteration:  6300 , loss:  0.004933166\n",
      "Iteration:  6400 , loss:  0.0041357595\n",
      "Iteration:  6500 , loss:  0.004070711\n",
      "Iteration:  6600 , loss:  0.0041861366\n",
      "Iteration:  6700 , loss:  0.0040347893\n",
      "Iteration:  6800 , loss:  0.0038833441\n",
      "Iteration:  6900 , loss:  0.0038312916\n",
      "Iteration:  7000 , loss:  0.0040434306\n",
      "Iteration:  7100 , loss:  0.0037232228\n",
      "Iteration:  7200 , loss:  0.0036445886\n",
      "Iteration:  7300 , loss:  0.0036008735\n",
      "Iteration:  7400 , loss:  0.0036100417\n",
      "Iteration:  7500 , loss:  0.0035546143\n",
      "Iteration:  7600 , loss:  0.0034094246\n",
      "Iteration:  7700 , loss:  0.0033519734\n",
      "Iteration:  7800 , loss:  0.0035047831\n",
      "Iteration:  7900 , loss:  0.0032349152\n",
      "Iteration:  8000 , loss:  0.0031801076\n",
      "Iteration:  8100 , loss:  0.0035202955\n",
      "Iteration:  8200 , loss:  0.0030556472\n",
      "Iteration:  8300 , loss:  0.003034175\n",
      "Iteration:  8400 , loss:  0.0030822703\n",
      "Iteration:  8500 , loss:  0.0028670428\n",
      "Iteration:  8600 , loss:  0.0028040255\n",
      "Iteration:  8700 , loss:  0.0027714707\n",
      "Iteration:  8800 , loss:  0.0029259622\n",
      "Iteration:  8900 , loss:  0.0025789253\n",
      "Iteration:  9000 , loss:  0.0025076098\n",
      "Iteration:  9100 , loss:  0.0024396598\n",
      "Iteration:  9200 , loss:  0.0024201488\n",
      "Iteration:  9300 , loss:  0.004395156\n",
      "Iteration:  9400 , loss:  0.0022723358\n",
      "Iteration:  9500 , loss:  0.002226659\n",
      "Iteration:  9600 , loss:  0.002212645\n",
      "Iteration:  9700 , loss:  0.0022497121\n",
      "Iteration:  9800 , loss:  0.0020928069\n",
      "Iteration:  9900 , loss:  0.0020522922\n",
      "Iteration:  10000 , loss:  0.0039786655\n",
      "Iteration:  10100 , loss:  0.0019658164\n",
      "Iteration:  10200 , loss:  0.0019292219\n",
      "Iteration:  10300 , loss:  0.0018913769\n",
      "Iteration:  10400 , loss:  0.0018404124\n",
      "Iteration:  10500 , loss:  0.0017999824\n",
      "Iteration:  10600 , loss:  0.0017647267\n",
      "Iteration:  10700 , loss:  0.001725375\n",
      "Iteration:  10800 , loss:  0.0018988\n",
      "Iteration:  10900 , loss:  0.0016536996\n",
      "Iteration:  11000 , loss:  0.0016420028\n",
      "Iteration:  11100 , loss:  0.0015921495\n",
      "Iteration:  11200 , loss:  0.002663034\n",
      "Iteration:  11300 , loss:  0.0015373393\n",
      "Iteration:  11400 , loss:  0.004324146\n",
      "Iteration:  11500 , loss:  0.0014881189\n",
      "Iteration:  11600 , loss:  0.0014771601\n",
      "Iteration:  11700 , loss:  0.0014817496\n",
      "Iteration:  11800 , loss:  0.0014235615\n",
      "Iteration:  11900 , loss:  0.0014071236\n",
      "Iteration:  12000 , loss:  0.0015639616\n",
      "Iteration:  12100 , loss:  0.0013693254\n",
      "Iteration:  12200 , loss:  0.001355284\n",
      "Iteration:  12300 , loss:  0.001338014\n",
      "Iteration:  12400 , loss:  0.0013237626\n",
      "Iteration:  12500 , loss:  0.0013128491\n",
      "Iteration:  12600 , loss:  0.0012954527\n",
      "Iteration:  12700 , loss:  0.0012851834\n",
      "Iteration:  12800 , loss:  0.0012703654\n",
      "Iteration:  12900 , loss:  0.001258307\n",
      "Iteration:  13000 , loss:  0.0012659112\n",
      "Iteration:  13100 , loss:  0.0012348972\n",
      "Iteration:  13200 , loss:  0.0013007929\n",
      "Iteration:  13300 , loss:  0.0012126117\n",
      "Iteration:  13400 , loss:  0.0012052963\n",
      "Iteration:  13500 , loss:  0.0015160898\n",
      "Iteration:  13600 , loss:  0.0011816781\n",
      "Iteration:  13700 , loss:  0.0013289766\n",
      "Iteration:  13800 , loss:  0.0013141875\n",
      "Iteration:  13900 , loss:  0.0011531358\n",
      "Iteration:  14000 , loss:  0.0011427486\n",
      "Iteration:  14100 , loss:  0.0011890437\n",
      "Iteration:  14200 , loss:  0.0011765689\n",
      "Iteration:  14300 , loss:  0.0013183182\n",
      "Iteration:  14400 , loss:  0.0011070365\n",
      "Iteration:  14500 , loss:  0.0011121037\n",
      "Iteration:  14600 , loss:  0.0010899719\n",
      "Iteration:  14700 , loss:  0.0011568965\n",
      "Iteration:  14800 , loss:  0.0024587037\n",
      "Iteration:  14900 , loss:  0.0010647267\n",
      "Iteration:  15000 , loss:  0.0011560114\n",
      "Iteration:  15100 , loss:  0.0016825383\n",
      "Iteration:  15200 , loss:  0.0010407369\n",
      "Iteration:  15300 , loss:  0.0010419079\n",
      "Iteration:  15400 , loss:  0.0011251317\n",
      "Iteration:  15500 , loss:  0.0010175036\n",
      "Iteration:  15600 , loss:  0.0010117403\n",
      "Iteration:  15700 , loss:  0.0014660791\n",
      "Iteration:  15800 , loss:  0.0014901978\n",
      "Iteration:  15900 , loss:  0.0009905584\n",
      "Iteration:  16000 , loss:  0.0009807573\n",
      "Iteration:  16100 , loss:  0.0009940775\n",
      "Iteration:  16200 , loss:  0.0009660279\n",
      "Iteration:  16300 , loss:  0.0010157761\n",
      "Iteration:  16400 , loss:  0.0010305138\n",
      "Iteration:  16500 , loss:  0.0019217759\n",
      "Iteration:  16600 , loss:  0.00093747245\n",
      "Iteration:  16700 , loss:  0.0016441214\n",
      "Iteration:  16800 , loss:  0.0009528061\n",
      "Iteration:  16900 , loss:  0.0009172204\n",
      "Iteration:  17000 , loss:  0.0009169092\n",
      "Iteration:  17100 , loss:  0.00090450724\n",
      "Iteration:  17200 , loss:  0.001723275\n",
      "Iteration:  17300 , loss:  0.00089005363\n",
      "Iteration:  17400 , loss:  0.0008883257\n",
      "Iteration:  17500 , loss:  0.0011167374\n",
      "Iteration:  17600 , loss:  0.0018876325\n",
      "Iteration:  17700 , loss:  0.00086425093\n",
      "Iteration:  17800 , loss:  0.004111525\n",
      "Iteration:  17900 , loss:  0.0008518261\n",
      "Iteration:  18000 , loss:  0.0008495668\n",
      "Iteration:  18100 , loss:  0.0008394574\n",
      "Iteration:  18200 , loss:  0.0008370577\n",
      "Iteration:  18300 , loss:  0.0008275702\n",
      "Iteration:  18400 , loss:  0.00091422716\n",
      "Iteration:  18500 , loss:  0.0008161365\n",
      "Iteration:  18600 , loss:  0.00081268133\n",
      "Iteration:  18700 , loss:  0.0008048492\n",
      "Iteration:  18800 , loss:  0.0008003915\n",
      "Iteration:  18900 , loss:  0.000800801\n",
      "Iteration:  19000 , loss:  0.0010142738\n",
      "Iteration:  19100 , loss:  0.0007832929\n",
      "Iteration:  19200 , loss:  0.0007808662\n",
      "Iteration:  19300 , loss:  0.0008066429\n",
      "Iteration:  19400 , loss:  0.0007682548\n",
      "Iteration:  19500 , loss:  0.000763364\n",
      "Iteration:  19600 , loss:  0.0008920819\n",
      "Iteration:  19700 , loss:  0.00075365254\n",
      "Iteration:  19800 , loss:  0.00080720487\n",
      "Iteration:  19900 , loss:  0.0018475915\n",
      "Generating 6th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.27731243\n",
      "Iteration:  100 , loss:  0.1388791\n",
      "Iteration:  200 , loss:  0.13107674\n",
      "Iteration:  300 , loss:  0.11682491\n",
      "Iteration:  400 , loss:  0.097128764\n",
      "Iteration:  500 , loss:  0.06757571\n",
      "Iteration:  600 , loss:  0.04561415\n",
      "Iteration:  700 , loss:  0.03576587\n",
      "Iteration:  800 , loss:  0.030069297\n",
      "Iteration:  900 , loss:  0.026784364\n",
      "Iteration:  1000 , loss:  0.02442524\n",
      "Iteration:  1100 , loss:  0.02307859\n",
      "Iteration:  1200 , loss:  0.022159789\n",
      "Iteration:  1300 , loss:  0.021756832\n",
      "Iteration:  1400 , loss:  0.020605318\n",
      "Iteration:  1500 , loss:  0.019789113\n",
      "Iteration:  1600 , loss:  0.019015934\n",
      "Iteration:  1700 , loss:  0.018397506\n",
      "Iteration:  1800 , loss:  0.019013021\n",
      "Iteration:  1900 , loss:  0.016914122\n",
      "Iteration:  2000 , loss:  0.016280241\n",
      "Iteration:  2100 , loss:  0.015660612\n",
      "Iteration:  2200 , loss:  0.015058724\n",
      "Iteration:  2300 , loss:  0.01446188\n",
      "Iteration:  2400 , loss:  0.013882547\n",
      "Iteration:  2500 , loss:  0.013385883\n",
      "Iteration:  2600 , loss:  0.012786865\n",
      "Iteration:  2700 , loss:  0.012274486\n",
      "Iteration:  2800 , loss:  0.012548827\n",
      "Iteration:  2900 , loss:  0.011323821\n",
      "Iteration:  3000 , loss:  0.010889477\n",
      "Iteration:  3100 , loss:  0.010441366\n",
      "Iteration:  3200 , loss:  0.0101016285\n",
      "Iteration:  3300 , loss:  0.009695354\n",
      "Iteration:  3400 , loss:  0.009374387\n",
      "Iteration:  3500 , loss:  0.009097018\n",
      "Iteration:  3600 , loss:  0.011820756\n",
      "Iteration:  3700 , loss:  0.008611158\n",
      "Iteration:  3800 , loss:  0.008415096\n",
      "Iteration:  3900 , loss:  0.008573064\n",
      "Iteration:  4000 , loss:  0.00805432\n",
      "Iteration:  4100 , loss:  0.007896193\n",
      "Iteration:  4200 , loss:  0.008874015\n",
      "Iteration:  4300 , loss:  0.007747623\n",
      "Iteration:  4400 , loss:  0.0074526835\n",
      "Iteration:  4500 , loss:  0.007422635\n",
      "Iteration:  4600 , loss:  0.0072070137\n",
      "Iteration:  4700 , loss:  0.00709797\n",
      "Iteration:  4800 , loss:  0.006936094\n",
      "Iteration:  4900 , loss:  0.0068171783\n",
      "Iteration:  5000 , loss:  0.0067104744\n",
      "Iteration:  5100 , loss:  0.0069637746\n",
      "Iteration:  5200 , loss:  0.0064865225\n",
      "Iteration:  5300 , loss:  0.006375326\n",
      "Iteration:  5400 , loss:  0.0063933497\n",
      "Iteration:  5500 , loss:  0.006175422\n",
      "Iteration:  5600 , loss:  0.006189121\n",
      "Iteration:  5700 , loss:  0.0062738466\n",
      "Iteration:  5800 , loss:  0.0059028636\n",
      "Iteration:  5900 , loss:  0.005817819\n",
      "Iteration:  6000 , loss:  0.0057534087\n",
      "Iteration:  6100 , loss:  0.005715036\n",
      "Iteration:  6200 , loss:  0.0058596856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6300 , loss:  0.0055137724\n",
      "Iteration:  6400 , loss:  0.005466517\n",
      "Iteration:  6500 , loss:  0.0055089574\n",
      "Iteration:  6600 , loss:  0.0053082155\n",
      "Iteration:  6700 , loss:  0.005244268\n",
      "Iteration:  6800 , loss:  0.0051863394\n",
      "Iteration:  6900 , loss:  0.005118027\n",
      "Iteration:  7000 , loss:  0.0050568134\n",
      "Iteration:  7100 , loss:  0.005077988\n",
      "Iteration:  7200 , loss:  0.0049336874\n",
      "Iteration:  7300 , loss:  0.004889548\n",
      "Iteration:  7400 , loss:  0.0048138727\n",
      "Iteration:  7500 , loss:  0.004755822\n",
      "Iteration:  7600 , loss:  0.004704673\n",
      "Iteration:  7700 , loss:  0.0050649727\n",
      "Iteration:  7800 , loss:  0.0046157506\n",
      "Iteration:  7900 , loss:  0.004515824\n",
      "Iteration:  8000 , loss:  0.004461908\n",
      "Iteration:  8100 , loss:  0.0044450862\n",
      "Iteration:  8200 , loss:  0.004358212\n",
      "Iteration:  8300 , loss:  0.0051651257\n",
      "Iteration:  8400 , loss:  0.004387702\n",
      "Iteration:  8500 , loss:  0.005785433\n",
      "Iteration:  8600 , loss:  0.0041054296\n",
      "Iteration:  8700 , loss:  0.004048453\n",
      "Iteration:  8800 , loss:  0.0039911065\n",
      "Iteration:  8900 , loss:  0.003962325\n",
      "Iteration:  9000 , loss:  0.004025734\n",
      "Iteration:  9100 , loss:  0.00386427\n",
      "Iteration:  9200 , loss:  0.0037724527\n",
      "Iteration:  9300 , loss:  0.004118915\n",
      "Iteration:  9400 , loss:  0.0036669052\n",
      "Iteration:  9500 , loss:  0.0036214662\n",
      "Iteration:  9600 , loss:  0.0035994942\n",
      "Iteration:  9700 , loss:  0.0035194142\n",
      "Iteration:  9800 , loss:  0.0034777094\n",
      "Iteration:  9900 , loss:  0.0034806344\n",
      "Iteration:  10000 , loss:  0.0033804374\n",
      "Iteration:  10100 , loss:  0.003335863\n",
      "Iteration:  10200 , loss:  0.0032935292\n",
      "Iteration:  10300 , loss:  0.0032674037\n",
      "Iteration:  10400 , loss:  0.0032093215\n",
      "Iteration:  10500 , loss:  0.00327982\n",
      "Iteration:  10600 , loss:  0.0035577896\n",
      "Iteration:  10700 , loss:  0.0030891101\n",
      "Iteration:  10800 , loss:  0.0030491843\n",
      "Iteration:  10900 , loss:  0.0030300966\n",
      "Iteration:  11000 , loss:  0.0030538614\n",
      "Iteration:  11100 , loss:  0.002934737\n",
      "Iteration:  11200 , loss:  0.00496778\n",
      "Iteration:  11300 , loss:  0.0028603314\n",
      "Iteration:  11400 , loss:  0.0028792352\n",
      "Iteration:  11500 , loss:  0.0028258217\n",
      "Iteration:  11600 , loss:  0.0027503711\n",
      "Iteration:  11700 , loss:  0.002715534\n",
      "Iteration:  11800 , loss:  0.0026795845\n",
      "Iteration:  11900 , loss:  0.0026485575\n",
      "Iteration:  12000 , loss:  0.002638089\n",
      "Iteration:  12100 , loss:  0.0025755009\n",
      "Iteration:  12200 , loss:  0.0026643714\n",
      "Iteration:  12300 , loss:  0.0025084466\n",
      "Iteration:  12400 , loss:  0.0024789171\n",
      "Iteration:  12500 , loss:  0.0024685883\n",
      "Iteration:  12600 , loss:  0.0024159756\n",
      "Iteration:  12700 , loss:  0.0023977747\n",
      "Iteration:  12800 , loss:  0.0025318852\n",
      "Iteration:  12900 , loss:  0.0023302746\n",
      "Iteration:  13000 , loss:  0.0023063202\n",
      "Iteration:  13100 , loss:  0.0024643806\n",
      "Iteration:  13200 , loss:  0.0023138649\n",
      "Iteration:  13300 , loss:  0.0022411223\n",
      "Iteration:  13400 , loss:  0.0022100357\n",
      "Iteration:  13500 , loss:  0.002642299\n",
      "Iteration:  13600 , loss:  0.0030063228\n",
      "Iteration:  13700 , loss:  0.0021465437\n",
      "Iteration:  13800 , loss:  0.002127926\n",
      "Iteration:  13900 , loss:  0.0043108896\n",
      "Iteration:  14000 , loss:  0.0020883337\n",
      "Iteration:  14100 , loss:  0.002074369\n",
      "Iteration:  14200 , loss:  0.0030141994\n",
      "Iteration:  14300 , loss:  0.0020341442\n",
      "Iteration:  14400 , loss:  0.002018364\n",
      "Iteration:  14500 , loss:  0.00200172\n",
      "Iteration:  14600 , loss:  0.0020235055\n",
      "Iteration:  14700 , loss:  0.0019790977\n",
      "Iteration:  14800 , loss:  0.0019496083\n",
      "Iteration:  14900 , loss:  0.0019342657\n",
      "Iteration:  15000 , loss:  0.002103484\n",
      "Iteration:  15100 , loss:  0.0019026498\n",
      "Iteration:  15200 , loss:  0.0019116184\n",
      "Iteration:  15300 , loss:  0.0018839515\n",
      "Iteration:  15400 , loss:  0.0019750753\n",
      "Iteration:  15500 , loss:  0.001842711\n",
      "Iteration:  15600 , loss:  0.0018314465\n",
      "Iteration:  15700 , loss:  0.0018629576\n",
      "Iteration:  15800 , loss:  0.001840675\n",
      "Iteration:  15900 , loss:  0.0017875006\n",
      "Iteration:  16000 , loss:  0.0020665866\n",
      "Iteration:  16100 , loss:  0.0017620791\n",
      "Iteration:  16200 , loss:  0.001751377\n",
      "Iteration:  16300 , loss:  0.001900289\n",
      "Iteration:  16400 , loss:  0.0017243746\n",
      "Iteration:  16500 , loss:  0.0017225358\n",
      "Iteration:  16600 , loss:  0.0017011225\n",
      "Iteration:  16700 , loss:  0.0017105921\n",
      "Iteration:  16800 , loss:  0.0016780846\n",
      "Iteration:  16900 , loss:  0.0016745764\n",
      "Iteration:  17000 , loss:  0.0022657793\n",
      "Iteration:  17100 , loss:  0.0016457478\n",
      "Iteration:  17200 , loss:  0.0016390214\n",
      "Iteration:  17300 , loss:  0.0016263922\n",
      "Iteration:  17400 , loss:  0.0016239887\n",
      "Iteration:  17500 , loss:  0.0016049943\n",
      "Iteration:  17600 , loss:  0.0015962437\n",
      "Iteration:  17700 , loss:  0.0016268464\n",
      "Iteration:  17800 , loss:  0.0035103243\n",
      "Iteration:  17900 , loss:  0.0015674013\n",
      "Iteration:  18000 , loss:  0.001778516\n",
      "Iteration:  18100 , loss:  0.0015497515\n",
      "Iteration:  18200 , loss:  0.0015705545\n",
      "Iteration:  18300 , loss:  0.0015361188\n",
      "Iteration:  18400 , loss:  0.004506875\n",
      "Iteration:  18500 , loss:  0.0015157094\n",
      "Iteration:  18600 , loss:  0.0026484798\n",
      "Iteration:  18700 , loss:  0.0014993532\n",
      "Iteration:  18800 , loss:  0.0015019885\n",
      "Iteration:  18900 , loss:  0.001636609\n",
      "Iteration:  19000 , loss:  0.0014754697\n",
      "Iteration:  19100 , loss:  0.0014860866\n",
      "Iteration:  19200 , loss:  0.0014608591\n",
      "Iteration:  19300 , loss:  0.0017743068\n",
      "Iteration:  19400 , loss:  0.0014463281\n",
      "Iteration:  19500 , loss:  0.0014383739\n",
      "Iteration:  19600 , loss:  0.0014340898\n",
      "Iteration:  19700 , loss:  0.0014244283\n",
      "Iteration:  19800 , loss:  0.0015588406\n",
      "Iteration:  19900 , loss:  0.0014203809\n",
      "Generating 7th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.26516443\n",
      "Iteration:  100 , loss:  0.13740426\n",
      "Iteration:  200 , loss:  0.12575127\n",
      "Iteration:  300 , loss:  0.10669203\n",
      "Iteration:  400 , loss:  0.08022445\n",
      "Iteration:  500 , loss:  0.059381165\n",
      "Iteration:  600 , loss:  0.05087386\n",
      "Iteration:  700 , loss:  0.04374933\n",
      "Iteration:  800 , loss:  0.038147796\n",
      "Iteration:  900 , loss:  0.03224718\n",
      "Iteration:  1000 , loss:  0.028337779\n",
      "Iteration:  1100 , loss:  0.026458643\n",
      "Iteration:  1200 , loss:  0.025002265\n",
      "Iteration:  1300 , loss:  0.02360934\n",
      "Iteration:  1400 , loss:  0.022600936\n",
      "Iteration:  1500 , loss:  0.021840114\n",
      "Iteration:  1600 , loss:  0.021112468\n",
      "Iteration:  1700 , loss:  0.020331532\n",
      "Iteration:  1800 , loss:  0.01956961\n",
      "Iteration:  1900 , loss:  0.01882042\n",
      "Iteration:  2000 , loss:  0.01788171\n",
      "Iteration:  2100 , loss:  0.016912503\n",
      "Iteration:  2200 , loss:  0.015787126\n",
      "Iteration:  2300 , loss:  0.015048135\n",
      "Iteration:  2400 , loss:  0.012991597\n",
      "Iteration:  2500 , loss:  0.011772524\n",
      "Iteration:  2600 , loss:  0.010999233\n",
      "Iteration:  2700 , loss:  0.01014601\n",
      "Iteration:  2800 , loss:  0.00989691\n",
      "Iteration:  2900 , loss:  0.009116013\n",
      "Iteration:  3000 , loss:  0.008713183\n",
      "Iteration:  3100 , loss:  0.008358352\n",
      "Iteration:  3200 , loss:  0.00804227\n",
      "Iteration:  3300 , loss:  0.0077764173\n",
      "Iteration:  3400 , loss:  0.007538129\n",
      "Iteration:  3500 , loss:  0.0073336223\n",
      "Iteration:  3600 , loss:  0.0071483343\n",
      "Iteration:  3700 , loss:  0.0069760485\n",
      "Iteration:  3800 , loss:  0.006824084\n",
      "Iteration:  3900 , loss:  0.0071700835\n",
      "Iteration:  4000 , loss:  0.0065338816\n",
      "Iteration:  4100 , loss:  0.0064899526\n",
      "Iteration:  4200 , loss:  0.0062580397\n",
      "Iteration:  4300 , loss:  0.006427753\n",
      "Iteration:  4400 , loss:  0.0059883883\n",
      "Iteration:  4500 , loss:  0.005900992\n",
      "Iteration:  4600 , loss:  0.0057170955\n",
      "Iteration:  4700 , loss:  0.0056273234\n",
      "Iteration:  4800 , loss:  0.005459941\n",
      "Iteration:  4900 , loss:  0.005338835\n",
      "Iteration:  5000 , loss:  0.0052278535\n",
      "Iteration:  5100 , loss:  0.005349585\n",
      "Iteration:  5200 , loss:  0.0050251\n",
      "Iteration:  5300 , loss:  0.0049369223\n",
      "Iteration:  5400 , loss:  0.0051005185\n",
      "Iteration:  5500 , loss:  0.0047769938\n",
      "Iteration:  5600 , loss:  0.004705364\n",
      "Iteration:  5700 , loss:  0.004657776\n",
      "Iteration:  5800 , loss:  0.004573813\n",
      "Iteration:  5900 , loss:  0.0045047943\n",
      "Iteration:  6000 , loss:  0.004568815\n",
      "Iteration:  6100 , loss:  0.0059824055\n",
      "Iteration:  6200 , loss:  0.004323151\n",
      "Iteration:  6300 , loss:  0.0042731985\n",
      "Iteration:  6400 , loss:  0.0042100647\n",
      "Iteration:  6500 , loss:  0.0045064995\n",
      "Iteration:  6600 , loss:  0.0041083703\n",
      "Iteration:  6700 , loss:  0.0040425984\n",
      "Iteration:  6800 , loss:  0.0041402243\n",
      "Iteration:  6900 , loss:  0.0039198813\n",
      "Iteration:  7000 , loss:  0.0038639163\n",
      "Iteration:  7100 , loss:  0.0038249884\n",
      "Iteration:  7200 , loss:  0.0038016625\n",
      "Iteration:  7300 , loss:  0.0036856942\n",
      "Iteration:  7400 , loss:  0.003622417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7500 , loss:  0.0035664928\n",
      "Iteration:  7600 , loss:  0.003516413\n",
      "Iteration:  7700 , loss:  0.0050117774\n",
      "Iteration:  7800 , loss:  0.0033732667\n",
      "Iteration:  7900 , loss:  0.0033199782\n",
      "Iteration:  8000 , loss:  0.0032587983\n",
      "Iteration:  8100 , loss:  0.0031831276\n",
      "Iteration:  8200 , loss:  0.0031230992\n",
      "Iteration:  8300 , loss:  0.003060043\n",
      "Iteration:  8400 , loss:  0.0029999276\n",
      "Iteration:  8500 , loss:  0.0039535332\n",
      "Iteration:  8600 , loss:  0.0028786338\n",
      "Iteration:  8700 , loss:  0.002986942\n",
      "Iteration:  8800 , loss:  0.0027646064\n",
      "Iteration:  8900 , loss:  0.0026981179\n",
      "Iteration:  9000 , loss:  0.002639079\n",
      "Iteration:  9100 , loss:  0.002580592\n",
      "Iteration:  9200 , loss:  0.0025301876\n",
      "Iteration:  9300 , loss:  0.0025844383\n",
      "Iteration:  9400 , loss:  0.0027860082\n",
      "Iteration:  9500 , loss:  0.0023558983\n",
      "Iteration:  9600 , loss:  0.0023052667\n",
      "Iteration:  9700 , loss:  0.0022607439\n",
      "Iteration:  9800 , loss:  0.0022190395\n",
      "Iteration:  9900 , loss:  0.002212964\n",
      "Iteration:  10000 , loss:  0.0021635906\n",
      "Iteration:  10100 , loss:  0.0020829947\n",
      "Iteration:  10200 , loss:  0.0020503493\n",
      "Iteration:  10300 , loss:  0.002012933\n",
      "Iteration:  10400 , loss:  0.00199043\n",
      "Iteration:  10500 , loss:  0.0019465521\n",
      "Iteration:  10600 , loss:  0.001996351\n",
      "Iteration:  10700 , loss:  0.0018915613\n",
      "Iteration:  10800 , loss:  0.0018694319\n",
      "Iteration:  10900 , loss:  0.0019354508\n",
      "Iteration:  11000 , loss:  0.0018209486\n",
      "Iteration:  11100 , loss:  0.0019016373\n",
      "Iteration:  11200 , loss:  0.0017902702\n",
      "Iteration:  11300 , loss:  0.0018696552\n",
      "Iteration:  11400 , loss:  0.0017442515\n",
      "Iteration:  11500 , loss:  0.0017991838\n",
      "Iteration:  11600 , loss:  0.0017122121\n",
      "Iteration:  11700 , loss:  0.0017134617\n",
      "Iteration:  11800 , loss:  0.0017690688\n",
      "Iteration:  11900 , loss:  0.0016773499\n",
      "Iteration:  12000 , loss:  0.0016574328\n",
      "Iteration:  12100 , loss:  0.0016536075\n",
      "Iteration:  12200 , loss:  0.0016386186\n",
      "Iteration:  12300 , loss:  0.0016213083\n",
      "Iteration:  12400 , loss:  0.0016113676\n",
      "Iteration:  12500 , loss:  0.0016004539\n",
      "Iteration:  12600 , loss:  0.0015902235\n",
      "Iteration:  12700 , loss:  0.0015867783\n",
      "Iteration:  12800 , loss:  0.0015703918\n",
      "Iteration:  12900 , loss:  0.0015643355\n",
      "Iteration:  13000 , loss:  0.001554723\n",
      "Iteration:  13100 , loss:  0.001558834\n",
      "Iteration:  13200 , loss:  0.0016178759\n",
      "Iteration:  13300 , loss:  0.0016984944\n",
      "Iteration:  13400 , loss:  0.0016799812\n",
      "Iteration:  13500 , loss:  0.0029593958\n",
      "Iteration:  13600 , loss:  0.0015135014\n",
      "Iteration:  13700 , loss:  0.001493081\n",
      "Iteration:  13800 , loss:  0.001485003\n",
      "Iteration:  13900 , loss:  0.0014930535\n",
      "Iteration:  14000 , loss:  0.0019218719\n",
      "Iteration:  14100 , loss:  0.0014614944\n",
      "Iteration:  14200 , loss:  0.00145841\n",
      "Iteration:  14300 , loss:  0.0031090695\n",
      "Iteration:  14400 , loss:  0.0017756551\n",
      "Iteration:  14500 , loss:  0.0014321158\n",
      "Iteration:  14600 , loss:  0.0014269198\n",
      "Iteration:  14700 , loss:  0.0014713218\n",
      "Iteration:  14800 , loss:  0.001559099\n",
      "Iteration:  14900 , loss:  0.0014043619\n",
      "Iteration:  15000 , loss:  0.0015057605\n",
      "Iteration:  15100 , loss:  0.0014404561\n",
      "Iteration:  15200 , loss:  0.0013839923\n",
      "Iteration:  15300 , loss:  0.0014010057\n",
      "Iteration:  15400 , loss:  0.0017250563\n",
      "Iteration:  15500 , loss:  0.0015700893\n",
      "Iteration:  15600 , loss:  0.0013573789\n",
      "Iteration:  15700 , loss:  0.0013607007\n",
      "Iteration:  15800 , loss:  0.0013942777\n",
      "Iteration:  15900 , loss:  0.0013470092\n",
      "Iteration:  16000 , loss:  0.0014517755\n",
      "Iteration:  16100 , loss:  0.0013518743\n",
      "Iteration:  16200 , loss:  0.0013714775\n",
      "Iteration:  16300 , loss:  0.001314787\n",
      "Iteration:  16400 , loss:  0.0013176824\n",
      "Iteration:  16500 , loss:  0.0013064786\n",
      "Iteration:  16600 , loss:  0.0013831542\n",
      "Iteration:  16700 , loss:  0.0013600877\n",
      "Iteration:  16800 , loss:  0.0013328346\n",
      "Iteration:  16900 , loss:  0.001289381\n",
      "Iteration:  17000 , loss:  0.001277718\n",
      "Iteration:  17100 , loss:  0.0012634848\n",
      "Iteration:  17200 , loss:  0.0012858282\n",
      "Iteration:  17300 , loss:  0.0012509134\n",
      "Iteration:  17400 , loss:  0.0012509669\n",
      "Iteration:  17500 , loss:  0.0012392694\n",
      "Iteration:  17600 , loss:  0.0012423319\n",
      "Iteration:  17700 , loss:  0.0025149062\n",
      "Iteration:  17800 , loss:  0.0012215388\n",
      "Iteration:  17900 , loss:  0.001221028\n",
      "Iteration:  18000 , loss:  0.0012553842\n",
      "Iteration:  18100 , loss:  0.0012040301\n",
      "Iteration:  18200 , loss:  0.0012009853\n",
      "Iteration:  18300 , loss:  0.0032188075\n",
      "Iteration:  18400 , loss:  0.0011892857\n",
      "Iteration:  18500 , loss:  0.0011810466\n",
      "Iteration:  18600 , loss:  0.0012514385\n",
      "Iteration:  18700 , loss:  0.0011692852\n",
      "Iteration:  18800 , loss:  0.0011639352\n",
      "Iteration:  18900 , loss:  0.0012342414\n",
      "Iteration:  19000 , loss:  0.001176672\n",
      "Iteration:  19100 , loss:  0.0011515892\n",
      "Iteration:  19200 , loss:  0.0011645159\n",
      "Iteration:  19300 , loss:  0.0012859593\n",
      "Iteration:  19400 , loss:  0.0016508782\n",
      "Iteration:  19500 , loss:  0.0012424863\n",
      "Iteration:  19600 , loss:  0.0011186515\n",
      "Iteration:  19700 , loss:  0.0011110334\n",
      "Iteration:  19800 , loss:  0.0011072432\n",
      "Iteration:  19900 , loss:  0.0011151939\n",
      "Generating 8th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.30899087\n",
      "Iteration:  100 , loss:  0.13393012\n",
      "Iteration:  200 , loss:  0.12234774\n",
      "Iteration:  300 , loss:  0.11088264\n",
      "Iteration:  400 , loss:  0.09678629\n",
      "Iteration:  500 , loss:  0.070800185\n",
      "Iteration:  600 , loss:  0.058080252\n",
      "Iteration:  700 , loss:  0.051933806\n",
      "Iteration:  800 , loss:  0.047753714\n",
      "Iteration:  900 , loss:  0.04287459\n",
      "Iteration:  1000 , loss:  0.03819251\n",
      "Iteration:  1100 , loss:  0.03369683\n",
      "Iteration:  1200 , loss:  0.03033897\n",
      "Iteration:  1300 , loss:  0.027691219\n",
      "Iteration:  1400 , loss:  0.025494974\n",
      "Iteration:  1500 , loss:  0.024039092\n",
      "Iteration:  1600 , loss:  0.0229097\n",
      "Iteration:  1700 , loss:  0.021813145\n",
      "Iteration:  1800 , loss:  0.020794537\n",
      "Iteration:  1900 , loss:  0.019603897\n",
      "Iteration:  2000 , loss:  0.018496796\n",
      "Iteration:  2100 , loss:  0.017482923\n",
      "Iteration:  2200 , loss:  0.016597427\n",
      "Iteration:  2300 , loss:  0.015837075\n",
      "Iteration:  2400 , loss:  0.01521479\n",
      "Iteration:  2500 , loss:  0.014724519\n",
      "Iteration:  2600 , loss:  0.014073738\n",
      "Iteration:  2700 , loss:  0.013528956\n",
      "Iteration:  2800 , loss:  0.01299252\n",
      "Iteration:  2900 , loss:  0.012595329\n",
      "Iteration:  3000 , loss:  0.011960912\n",
      "Iteration:  3100 , loss:  0.011469485\n",
      "Iteration:  3200 , loss:  0.010970933\n",
      "Iteration:  3300 , loss:  0.010474197\n",
      "Iteration:  3400 , loss:  0.009974439\n",
      "Iteration:  3500 , loss:  0.01025045\n",
      "Iteration:  3600 , loss:  0.009537917\n",
      "Iteration:  3700 , loss:  0.008623911\n",
      "Iteration:  3800 , loss:  0.008383243\n",
      "Iteration:  3900 , loss:  0.007942439\n",
      "Iteration:  4000 , loss:  0.008397027\n",
      "Iteration:  4100 , loss:  0.0073931585\n",
      "Iteration:  4200 , loss:  0.0070456415\n",
      "Iteration:  4300 , loss:  0.0068294816\n",
      "Iteration:  4400 , loss:  0.0066394964\n",
      "Iteration:  4500 , loss:  0.006765349\n",
      "Iteration:  4600 , loss:  0.010412413\n",
      "Iteration:  4700 , loss:  0.0061744233\n",
      "Iteration:  4800 , loss:  0.006048134\n",
      "Iteration:  4900 , loss:  0.005922925\n",
      "Iteration:  5000 , loss:  0.0058252565\n",
      "Iteration:  5100 , loss:  0.005700834\n",
      "Iteration:  5200 , loss:  0.005646182\n",
      "Iteration:  5300 , loss:  0.00613847\n",
      "Iteration:  5400 , loss:  0.005405557\n",
      "Iteration:  5500 , loss:  0.0053177867\n",
      "Iteration:  5600 , loss:  0.0053036883\n",
      "Iteration:  5700 , loss:  0.005913914\n",
      "Iteration:  5800 , loss:  0.0050620884\n",
      "Iteration:  5900 , loss:  0.0051728804\n",
      "Iteration:  6000 , loss:  0.0049020215\n",
      "Iteration:  6100 , loss:  0.0048323064\n",
      "Iteration:  6200 , loss:  0.004746764\n",
      "Iteration:  6300 , loss:  0.0046694316\n",
      "Iteration:  6400 , loss:  0.0048057996\n",
      "Iteration:  6500 , loss:  0.0067853816\n",
      "Iteration:  6600 , loss:  0.004443159\n",
      "Iteration:  6700 , loss:  0.0043724217\n",
      "Iteration:  6800 , loss:  0.004322395\n",
      "Iteration:  6900 , loss:  0.0042243595\n",
      "Iteration:  7000 , loss:  0.0041561592\n",
      "Iteration:  7100 , loss:  0.004101075\n",
      "Iteration:  7200 , loss:  0.004017861\n",
      "Iteration:  7300 , loss:  0.003953915\n",
      "Iteration:  7400 , loss:  0.003900376\n",
      "Iteration:  7500 , loss:  0.0038241479\n",
      "Iteration:  7600 , loss:  0.0039401986\n",
      "Iteration:  7700 , loss:  0.0036980102\n",
      "Iteration:  7800 , loss:  0.0036367998\n",
      "Iteration:  7900 , loss:  0.0040783053\n",
      "Iteration:  8000 , loss:  0.0035130735\n",
      "Iteration:  8100 , loss:  0.0035062023\n",
      "Iteration:  8200 , loss:  0.0034901246\n",
      "Iteration:  8300 , loss:  0.0033373055\n",
      "Iteration:  8400 , loss:  0.0046319435\n",
      "Iteration:  8500 , loss:  0.0032259454\n",
      "Iteration:  8600 , loss:  0.003172531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  8700 , loss:  0.005737745\n",
      "Iteration:  8800 , loss:  0.003069333\n",
      "Iteration:  8900 , loss:  0.0030208398\n",
      "Iteration:  9000 , loss:  0.0031454512\n",
      "Iteration:  9100 , loss:  0.0029222155\n",
      "Iteration:  9200 , loss:  0.0028837984\n",
      "Iteration:  9300 , loss:  0.0028297522\n",
      "Iteration:  9400 , loss:  0.0027837534\n",
      "Iteration:  9500 , loss:  0.0046016374\n",
      "Iteration:  9600 , loss:  0.0051065926\n",
      "Iteration:  9700 , loss:  0.0026518938\n",
      "Iteration:  9800 , loss:  0.0026111244\n",
      "Iteration:  9900 , loss:  0.0026280957\n",
      "Iteration:  10000 , loss:  0.0025314675\n",
      "Iteration:  10100 , loss:  0.0024977238\n",
      "Iteration:  10200 , loss:  0.00264556\n",
      "Iteration:  10300 , loss:  0.0025187812\n",
      "Iteration:  10400 , loss:  0.0023885593\n",
      "Iteration:  10500 , loss:  0.0023706355\n",
      "Iteration:  10600 , loss:  0.0023513483\n",
      "Iteration:  10700 , loss:  0.0023523797\n",
      "Iteration:  10800 , loss:  0.0022642615\n",
      "Iteration:  10900 , loss:  0.0022382454\n",
      "Iteration:  11000 , loss:  0.002221244\n",
      "Iteration:  11100 , loss:  0.0021833575\n",
      "Iteration:  11200 , loss:  0.002193554\n",
      "Iteration:  11300 , loss:  0.0021337569\n",
      "Iteration:  11400 , loss:  0.0021099467\n",
      "Iteration:  11500 , loss:  0.0021356302\n",
      "Iteration:  11600 , loss:  0.002064163\n",
      "Iteration:  11700 , loss:  0.0020608276\n",
      "Iteration:  11800 , loss:  0.002021712\n",
      "Iteration:  11900 , loss:  0.0020014795\n",
      "Iteration:  12000 , loss:  0.0019844256\n",
      "Iteration:  12100 , loss:  0.0019629349\n",
      "Iteration:  12200 , loss:  0.0020057003\n",
      "Iteration:  12300 , loss:  0.0019380072\n",
      "Iteration:  12400 , loss:  0.0019219796\n",
      "Iteration:  12500 , loss:  0.0018935924\n",
      "Iteration:  12600 , loss:  0.0019401646\n",
      "Iteration:  12700 , loss:  0.0018615457\n",
      "Iteration:  12800 , loss:  0.0018764803\n",
      "Iteration:  12900 , loss:  0.001831305\n",
      "Iteration:  13000 , loss:  0.0055423444\n",
      "Iteration:  13100 , loss:  0.001802975\n",
      "Iteration:  13200 , loss:  0.0021542623\n",
      "Iteration:  13300 , loss:  0.0017745929\n",
      "Iteration:  13400 , loss:  0.0018019087\n",
      "Iteration:  13500 , loss:  0.0017478536\n",
      "Iteration:  13600 , loss:  0.0017347408\n",
      "Iteration:  13700 , loss:  0.0017354897\n",
      "Iteration:  13800 , loss:  0.0017091618\n",
      "Iteration:  13900 , loss:  0.0021038859\n",
      "Iteration:  14000 , loss:  0.0017512641\n",
      "Iteration:  14100 , loss:  0.003024382\n",
      "Iteration:  14200 , loss:  0.0016606122\n",
      "Iteration:  14300 , loss:  0.0018053628\n",
      "Iteration:  14400 , loss:  0.0023072292\n",
      "Iteration:  14500 , loss:  0.001626163\n",
      "Iteration:  14600 , loss:  0.0016206928\n",
      "Iteration:  14700 , loss:  0.0016044406\n",
      "Iteration:  14800 , loss:  0.0015938941\n",
      "Iteration:  14900 , loss:  0.0015836589\n",
      "Iteration:  15000 , loss:  0.0015724493\n",
      "Iteration:  15100 , loss:  0.0015783599\n",
      "Iteration:  15200 , loss:  0.0015531881\n",
      "Iteration:  15300 , loss:  0.0015429088\n",
      "Iteration:  15400 , loss:  0.001999364\n",
      "Iteration:  15500 , loss:  0.0015231431\n",
      "Iteration:  15600 , loss:  0.0015243161\n",
      "Iteration:  15700 , loss:  0.001581139\n",
      "Iteration:  15800 , loss:  0.0014952733\n",
      "Iteration:  15900 , loss:  0.0015107652\n",
      "Iteration:  16000 , loss:  0.001477268\n",
      "Iteration:  16100 , loss:  0.0014687901\n",
      "Iteration:  16200 , loss:  0.001482537\n",
      "Iteration:  16300 , loss:  0.0014516687\n",
      "Iteration:  16400 , loss:  0.0017740331\n",
      "Iteration:  16500 , loss:  0.0014658091\n",
      "Iteration:  16600 , loss:  0.0014301618\n",
      "Iteration:  16700 , loss:  0.0014579683\n",
      "Iteration:  16800 , loss:  0.0015642478\n",
      "Iteration:  16900 , loss:  0.0014457717\n",
      "Iteration:  17000 , loss:  0.001593185\n",
      "Iteration:  17100 , loss:  0.0013878844\n",
      "Iteration:  17200 , loss:  0.0013820388\n",
      "Iteration:  17300 , loss:  0.0013736722\n",
      "Iteration:  17400 , loss:  0.0013661128\n",
      "Iteration:  17500 , loss:  0.0025567624\n",
      "Iteration:  17600 , loss:  0.0013520843\n",
      "Iteration:  17700 , loss:  0.0013455201\n",
      "Iteration:  17800 , loss:  0.0013384522\n",
      "Iteration:  17900 , loss:  0.0013371323\n",
      "Iteration:  18000 , loss:  0.0013248522\n",
      "Iteration:  18100 , loss:  0.0013889997\n",
      "Iteration:  18200 , loss:  0.0013113277\n",
      "Iteration:  18300 , loss:  0.0013067287\n",
      "Iteration:  18400 , loss:  0.0012980833\n",
      "Iteration:  18500 , loss:  0.0012919992\n",
      "Iteration:  18600 , loss:  0.0012863269\n",
      "Iteration:  18700 , loss:  0.0012790388\n",
      "Iteration:  18800 , loss:  0.0012801914\n",
      "Iteration:  18900 , loss:  0.0012666679\n",
      "Iteration:  19000 , loss:  0.0012604427\n",
      "Iteration:  19100 , loss:  0.001254597\n",
      "Iteration:  19200 , loss:  0.0012478016\n",
      "Iteration:  19300 , loss:  0.0012430822\n",
      "Iteration:  19400 , loss:  0.0016073616\n",
      "Iteration:  19500 , loss:  0.0012295072\n",
      "Iteration:  19600 , loss:  0.0012366557\n",
      "Iteration:  19700 , loss:  0.0012175542\n",
      "Iteration:  19800 , loss:  0.0015464544\n",
      "Iteration:  19900 , loss:  0.0012230988\n",
      "Generating 9th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.19996782\n",
      "Iteration:  100 , loss:  0.13620359\n",
      "Iteration:  200 , loss:  0.12600382\n",
      "Iteration:  300 , loss:  0.10722197\n",
      "Iteration:  400 , loss:  0.06858962\n",
      "Iteration:  500 , loss:  0.05674523\n",
      "Iteration:  600 , loss:  0.04994221\n",
      "Iteration:  700 , loss:  0.042793997\n",
      "Iteration:  800 , loss:  0.039649863\n",
      "Iteration:  900 , loss:  0.036739733\n",
      "Iteration:  1000 , loss:  0.03337807\n",
      "Iteration:  1100 , loss:  0.030286217\n",
      "Iteration:  1200 , loss:  0.027559673\n",
      "Iteration:  1300 , loss:  0.025116421\n",
      "Iteration:  1400 , loss:  0.023265654\n",
      "Iteration:  1500 , loss:  0.021852192\n",
      "Iteration:  1600 , loss:  0.020677447\n",
      "Iteration:  1700 , loss:  0.020126203\n",
      "Iteration:  1800 , loss:  0.018534094\n",
      "Iteration:  1900 , loss:  0.017750224\n",
      "Iteration:  2000 , loss:  0.016669804\n",
      "Iteration:  2100 , loss:  0.01572723\n",
      "Iteration:  2200 , loss:  0.015431936\n",
      "Iteration:  2300 , loss:  0.014331391\n",
      "Iteration:  2400 , loss:  0.013699213\n",
      "Iteration:  2500 , loss:  0.013187369\n",
      "Iteration:  2600 , loss:  0.012630228\n",
      "Iteration:  2700 , loss:  0.012153044\n",
      "Iteration:  2800 , loss:  0.012566573\n",
      "Iteration:  2900 , loss:  0.011259086\n",
      "Iteration:  3000 , loss:  0.011190731\n",
      "Iteration:  3100 , loss:  0.010443189\n",
      "Iteration:  3200 , loss:  0.010196388\n",
      "Iteration:  3300 , loss:  0.009714015\n",
      "Iteration:  3400 , loss:  0.009382475\n",
      "Iteration:  3500 , loss:  0.009083589\n",
      "Iteration:  3600 , loss:  0.010549417\n",
      "Iteration:  3700 , loss:  0.008590184\n",
      "Iteration:  3800 , loss:  0.00962167\n",
      "Iteration:  3900 , loss:  0.008365349\n",
      "Iteration:  4000 , loss:  0.0078755515\n",
      "Iteration:  4100 , loss:  0.007691507\n",
      "Iteration:  4200 , loss:  0.007825117\n",
      "Iteration:  4300 , loss:  0.0073441854\n",
      "Iteration:  4400 , loss:  0.0071590254\n",
      "Iteration:  4500 , loss:  0.007012834\n",
      "Iteration:  4600 , loss:  0.0068452815\n",
      "Iteration:  4700 , loss:  0.006693459\n",
      "Iteration:  4800 , loss:  0.0065560774\n",
      "Iteration:  4900 , loss:  0.00641076\n",
      "Iteration:  5000 , loss:  0.006274538\n",
      "Iteration:  5100 , loss:  0.0065435763\n",
      "Iteration:  5200 , loss:  0.0060195187\n",
      "Iteration:  5300 , loss:  0.0058960645\n",
      "Iteration:  5400 , loss:  0.007318926\n",
      "Iteration:  5500 , loss:  0.0058343997\n",
      "Iteration:  5600 , loss:  0.005607847\n",
      "Iteration:  5700 , loss:  0.0054284837\n",
      "Iteration:  5800 , loss:  0.0053460053\n",
      "Iteration:  5900 , loss:  0.0052001793\n",
      "Iteration:  6000 , loss:  0.0050940597\n",
      "Iteration:  6100 , loss:  0.0049760193\n",
      "Iteration:  6200 , loss:  0.007479674\n",
      "Iteration:  6300 , loss:  0.0047931406\n",
      "Iteration:  6400 , loss:  0.0046048863\n",
      "Iteration:  6500 , loss:  0.004487134\n",
      "Iteration:  6600 , loss:  0.0043647867\n",
      "Iteration:  6700 , loss:  0.0042545935\n",
      "Iteration:  6800 , loss:  0.0043207975\n",
      "Iteration:  6900 , loss:  0.0040404187\n",
      "Iteration:  7000 , loss:  0.0039690062\n",
      "Iteration:  7100 , loss:  0.003964197\n",
      "Iteration:  7200 , loss:  0.00394605\n",
      "Iteration:  7300 , loss:  0.0036841196\n",
      "Iteration:  7400 , loss:  0.003605366\n",
      "Iteration:  7500 , loss:  0.0035324069\n",
      "Iteration:  7600 , loss:  0.0034574396\n",
      "Iteration:  7700 , loss:  0.0035102586\n",
      "Iteration:  7800 , loss:  0.0033992701\n",
      "Iteration:  7900 , loss:  0.0032479449\n",
      "Iteration:  8000 , loss:  0.0031878473\n",
      "Iteration:  8100 , loss:  0.0050175264\n",
      "Iteration:  8200 , loss:  0.0030558836\n",
      "Iteration:  8300 , loss:  0.0029962678\n",
      "Iteration:  8400 , loss:  0.0029324556\n",
      "Iteration:  8500 , loss:  0.003300042\n",
      "Iteration:  8600 , loss:  0.0028111448\n",
      "Iteration:  8700 , loss:  0.0027615144\n",
      "Iteration:  8800 , loss:  0.0027894601\n",
      "Iteration:  8900 , loss:  0.0026420276\n",
      "Iteration:  9000 , loss:  0.0026311672\n",
      "Iteration:  9100 , loss:  0.0025876258\n",
      "Iteration:  9200 , loss:  0.002485927\n",
      "Iteration:  9300 , loss:  0.0024396197\n",
      "Iteration:  9400 , loss:  0.0025274276\n",
      "Iteration:  9500 , loss:  0.0023429543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  9600 , loss:  0.002298842\n",
      "Iteration:  9700 , loss:  0.0022750362\n",
      "Iteration:  9800 , loss:  0.0029980168\n",
      "Iteration:  9900 , loss:  0.0023060192\n",
      "Iteration:  10000 , loss:  0.002214622\n",
      "Iteration:  10100 , loss:  0.0020928206\n",
      "Iteration:  10200 , loss:  0.0020556569\n",
      "Iteration:  10300 , loss:  0.0020396635\n",
      "Iteration:  10400 , loss:  0.002781502\n",
      "Iteration:  10500 , loss:  0.0019471758\n",
      "Iteration:  10600 , loss:  0.001913965\n",
      "Iteration:  10700 , loss:  0.001883236\n",
      "Iteration:  10800 , loss:  0.0045107277\n",
      "Iteration:  10900 , loss:  0.0018170128\n",
      "Iteration:  11000 , loss:  0.001784073\n",
      "Iteration:  11100 , loss:  0.001765073\n",
      "Iteration:  11200 , loss:  0.0017247044\n",
      "Iteration:  11300 , loss:  0.001709328\n",
      "Iteration:  11400 , loss:  0.0016685319\n",
      "Iteration:  11500 , loss:  0.0016435167\n",
      "Iteration:  11600 , loss:  0.0017539542\n",
      "Iteration:  11700 , loss:  0.0015932714\n",
      "Iteration:  11800 , loss:  0.0015645146\n",
      "Iteration:  11900 , loss:  0.0015400111\n",
      "Iteration:  12000 , loss:  0.0015213545\n",
      "Iteration:  12100 , loss:  0.0015235504\n",
      "Iteration:  12200 , loss:  0.0014708104\n",
      "Iteration:  12300 , loss:  0.0014503365\n",
      "Iteration:  12400 , loss:  0.0014292763\n",
      "Iteration:  12500 , loss:  0.0014304435\n",
      "Iteration:  12600 , loss:  0.0014147649\n",
      "Iteration:  12700 , loss:  0.0013685339\n",
      "Iteration:  12800 , loss:  0.0015671361\n",
      "Iteration:  12900 , loss:  0.0013720498\n",
      "Iteration:  13000 , loss:  0.001851447\n",
      "Iteration:  13100 , loss:  0.0013267415\n",
      "Iteration:  13200 , loss:  0.0012766737\n",
      "Iteration:  13300 , loss:  0.0012608652\n",
      "Iteration:  13400 , loss:  0.0012528782\n",
      "Iteration:  13500 , loss:  0.0012287413\n",
      "Iteration:  13600 , loss:  0.0012155051\n",
      "Iteration:  13700 , loss:  0.0017740558\n",
      "Iteration:  13800 , loss:  0.0011850849\n",
      "Iteration:  13900 , loss:  0.0011856284\n",
      "Iteration:  14000 , loss:  0.0011579961\n",
      "Iteration:  14100 , loss:  0.0011483476\n",
      "Iteration:  14200 , loss:  0.0011336401\n",
      "Iteration:  14300 , loss:  0.0039828205\n",
      "Iteration:  14400 , loss:  0.0011321816\n",
      "Iteration:  14500 , loss:  0.0010984889\n",
      "Iteration:  14600 , loss:  0.0012583409\n",
      "Iteration:  14700 , loss:  0.0010767491\n",
      "Iteration:  14800 , loss:  0.0010668411\n",
      "Iteration:  14900 , loss:  0.0033001108\n",
      "Iteration:  15000 , loss:  0.0010470727\n",
      "Iteration:  15100 , loss:  0.001055228\n",
      "Iteration:  15200 , loss:  0.0010285422\n",
      "Iteration:  15300 , loss:  0.0010274777\n",
      "Iteration:  15400 , loss:  0.0010107793\n",
      "Iteration:  15500 , loss:  0.0010032069\n",
      "Iteration:  15600 , loss:  0.0011299325\n",
      "Iteration:  15700 , loss:  0.0009872757\n",
      "Iteration:  15800 , loss:  0.0032035923\n",
      "Iteration:  15900 , loss:  0.00097249926\n",
      "Iteration:  16000 , loss:  0.0009710909\n",
      "Iteration:  16100 , loss:  0.000958615\n",
      "Iteration:  16200 , loss:  0.00095272844\n",
      "Iteration:  16300 , loss:  0.0035448465\n",
      "Iteration:  16400 , loss:  0.0009397899\n",
      "Iteration:  16500 , loss:  0.0009336234\n",
      "Iteration:  16600 , loss:  0.0009268578\n",
      "Iteration:  16700 , loss:  0.0010111989\n",
      "Iteration:  16800 , loss:  0.000981233\n",
      "Iteration:  16900 , loss:  0.00091400277\n",
      "Iteration:  17000 , loss:  0.0011257692\n",
      "Iteration:  17100 , loss:  0.00095660123\n",
      "Iteration:  17200 , loss:  0.00089659356\n",
      "Iteration:  17300 , loss:  0.0008927736\n",
      "Iteration:  17400 , loss:  0.0008843774\n",
      "Iteration:  17500 , loss:  0.00088151003\n",
      "Iteration:  17600 , loss:  0.0008791329\n",
      "Iteration:  17700 , loss:  0.0008705758\n",
      "Iteration:  17800 , loss:  0.0008768683\n",
      "Iteration:  17900 , loss:  0.00087191927\n",
      "Iteration:  18000 , loss:  0.00087023014\n",
      "Iteration:  18100 , loss:  0.0008531195\n",
      "Iteration:  18200 , loss:  0.000850139\n",
      "Iteration:  18300 , loss:  0.0012597743\n",
      "Iteration:  18400 , loss:  0.0013619021\n",
      "Iteration:  18500 , loss:  0.000836498\n",
      "Iteration:  18600 , loss:  0.0008335806\n",
      "Iteration:  18700 , loss:  0.0008401315\n",
      "Iteration:  18800 , loss:  0.0010242884\n",
      "Iteration:  18900 , loss:  0.00082163507\n",
      "Iteration:  19000 , loss:  0.0008217995\n",
      "Iteration:  19100 , loss:  0.000823366\n",
      "Iteration:  19200 , loss:  0.0027668062\n",
      "Iteration:  19300 , loss:  0.00080785854\n",
      "Iteration:  19400 , loss:  0.0008050474\n",
      "Iteration:  19500 , loss:  0.0008070853\n",
      "Iteration:  19600 , loss:  0.0007978198\n",
      "Iteration:  19700 , loss:  0.0008017061\n",
      "Iteration:  19800 , loss:  0.0009096416\n",
      "Iteration:  19900 , loss:  0.0007882272\n",
      "Generating 10th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.5200735\n",
      "Iteration:  100 , loss:  0.13930613\n",
      "Iteration:  200 , loss:  0.13487089\n",
      "Iteration:  300 , loss:  0.12467639\n",
      "Iteration:  400 , loss:  0.11470864\n",
      "Iteration:  500 , loss:  0.1032236\n",
      "Iteration:  600 , loss:  0.07982\n",
      "Iteration:  700 , loss:  0.05518339\n",
      "Iteration:  800 , loss:  0.04408289\n",
      "Iteration:  900 , loss:  0.040135548\n",
      "Iteration:  1000 , loss:  0.03813734\n",
      "Iteration:  1100 , loss:  0.036091\n",
      "Iteration:  1200 , loss:  0.03401315\n",
      "Iteration:  1300 , loss:  0.031839475\n",
      "Iteration:  1400 , loss:  0.02965382\n",
      "Iteration:  1500 , loss:  0.02766293\n",
      "Iteration:  1600 , loss:  0.02573788\n",
      "Iteration:  1700 , loss:  0.024060603\n",
      "Iteration:  1800 , loss:  0.022565149\n",
      "Iteration:  1900 , loss:  0.021752546\n",
      "Iteration:  2000 , loss:  0.020781498\n",
      "Iteration:  2100 , loss:  0.020138944\n",
      "Iteration:  2200 , loss:  0.019608088\n",
      "Iteration:  2300 , loss:  0.0191184\n",
      "Iteration:  2400 , loss:  0.018652374\n",
      "Iteration:  2500 , loss:  0.018263768\n",
      "Iteration:  2600 , loss:  0.01867291\n",
      "Iteration:  2700 , loss:  0.017273717\n",
      "Iteration:  2800 , loss:  0.016812287\n",
      "Iteration:  2900 , loss:  0.016357524\n",
      "Iteration:  3000 , loss:  0.015904505\n",
      "Iteration:  3100 , loss:  0.015446416\n",
      "Iteration:  3200 , loss:  0.0149918785\n",
      "Iteration:  3300 , loss:  0.01455403\n",
      "Iteration:  3400 , loss:  0.0141456025\n",
      "Iteration:  3500 , loss:  0.015400939\n",
      "Iteration:  3600 , loss:  0.013310165\n",
      "Iteration:  3700 , loss:  0.014357568\n",
      "Iteration:  3800 , loss:  0.012732816\n",
      "Iteration:  3900 , loss:  0.01273156\n",
      "Iteration:  4000 , loss:  0.011741205\n",
      "Iteration:  4100 , loss:  0.011409731\n",
      "Iteration:  4200 , loss:  0.011107228\n",
      "Iteration:  4300 , loss:  0.01080315\n",
      "Iteration:  4400 , loss:  0.010533898\n",
      "Iteration:  4500 , loss:  0.010283263\n",
      "Iteration:  4600 , loss:  0.010909508\n",
      "Iteration:  4700 , loss:  0.012109266\n",
      "Iteration:  4800 , loss:  0.009629656\n",
      "Iteration:  4900 , loss:  0.009566468\n",
      "Iteration:  5000 , loss:  0.009271327\n",
      "Iteration:  5100 , loss:  0.009099526\n",
      "Iteration:  5200 , loss:  0.008943658\n",
      "Iteration:  5300 , loss:  0.008799977\n",
      "Iteration:  5400 , loss:  0.008646341\n",
      "Iteration:  5500 , loss:  0.008492774\n",
      "Iteration:  5600 , loss:  0.008341114\n",
      "Iteration:  5700 , loss:  0.008199271\n",
      "Iteration:  5800 , loss:  0.008016299\n",
      "Iteration:  5900 , loss:  0.007871354\n",
      "Iteration:  6000 , loss:  0.0077498527\n",
      "Iteration:  6100 , loss:  0.0076000113\n",
      "Iteration:  6200 , loss:  0.0074794954\n",
      "Iteration:  6300 , loss:  0.0073625664\n",
      "Iteration:  6400 , loss:  0.007252572\n",
      "Iteration:  6500 , loss:  0.007152279\n",
      "Iteration:  6600 , loss:  0.007058461\n",
      "Iteration:  6700 , loss:  0.0071156984\n",
      "Iteration:  6800 , loss:  0.006945728\n",
      "Iteration:  6900 , loss:  0.0068084905\n",
      "Iteration:  7000 , loss:  0.0067380667\n",
      "Iteration:  7100 , loss:  0.006693492\n",
      "Iteration:  7200 , loss:  0.0078025693\n",
      "Iteration:  7300 , loss:  0.0065316902\n",
      "Iteration:  7400 , loss:  0.0064844014\n",
      "Iteration:  7500 , loss:  0.0064746435\n",
      "Iteration:  7600 , loss:  0.006343954\n",
      "Iteration:  7700 , loss:  0.0062866667\n",
      "Iteration:  7800 , loss:  0.006228562\n",
      "Iteration:  7900 , loss:  0.0068589943\n",
      "Iteration:  8000 , loss:  0.006115107\n",
      "Iteration:  8100 , loss:  0.006059255\n",
      "Iteration:  8200 , loss:  0.006007842\n",
      "Iteration:  8300 , loss:  0.005948504\n",
      "Iteration:  8400 , loss:  0.005894408\n",
      "Iteration:  8500 , loss:  0.00584168\n",
      "Iteration:  8600 , loss:  0.0062905494\n",
      "Iteration:  8700 , loss:  0.0057317195\n",
      "Iteration:  8800 , loss:  0.005984193\n",
      "Iteration:  8900 , loss:  0.0056212833\n",
      "Iteration:  9000 , loss:  0.0055901436\n",
      "Iteration:  9100 , loss:  0.005509753\n",
      "Iteration:  9200 , loss:  0.006127122\n",
      "Iteration:  9300 , loss:  0.005397757\n",
      "Iteration:  9400 , loss:  0.0053450367\n",
      "Iteration:  9500 , loss:  0.0052809035\n",
      "Iteration:  9600 , loss:  0.0052368813\n",
      "Iteration:  9700 , loss:  0.005257383\n",
      "Iteration:  9800 , loss:  0.0051018563\n",
      "Iteration:  9900 , loss:  0.005049011\n",
      "Iteration:  10000 , loss:  0.004979686\n",
      "Iteration:  10100 , loss:  0.00491915\n",
      "Iteration:  10200 , loss:  0.0048589897\n",
      "Iteration:  10300 , loss:  0.004860469\n",
      "Iteration:  10400 , loss:  0.0047845948\n",
      "Iteration:  10500 , loss:  0.004769189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10600 , loss:  0.0058547435\n",
      "Iteration:  10700 , loss:  0.004587205\n",
      "Iteration:  10800 , loss:  0.0055352855\n",
      "Iteration:  10900 , loss:  0.004444512\n",
      "Iteration:  11000 , loss:  0.0044037583\n",
      "Iteration:  11100 , loss:  0.0048159445\n",
      "Iteration:  11200 , loss:  0.0042960052\n",
      "Iteration:  11300 , loss:  0.0045347135\n",
      "Iteration:  11400 , loss:  0.004213425\n",
      "Iteration:  11500 , loss:  0.0043811267\n",
      "Iteration:  11600 , loss:  0.0041228626\n",
      "Iteration:  11700 , loss:  0.0040838695\n",
      "Iteration:  11800 , loss:  0.004048977\n",
      "Iteration:  11900 , loss:  0.004012829\n",
      "Iteration:  12000 , loss:  0.003973286\n",
      "Iteration:  12100 , loss:  0.003937081\n",
      "Iteration:  12200 , loss:  0.0039234557\n",
      "Iteration:  12300 , loss:  0.00386796\n",
      "Iteration:  12400 , loss:  0.003834615\n",
      "Iteration:  12500 , loss:  0.0038018473\n",
      "Iteration:  12600 , loss:  0.0037668983\n",
      "Iteration:  12700 , loss:  0.0037363512\n",
      "Iteration:  12800 , loss:  0.0037044887\n",
      "Iteration:  12900 , loss:  0.006118864\n",
      "Iteration:  13000 , loss:  0.0036386524\n",
      "Iteration:  13100 , loss:  0.0036066705\n",
      "Iteration:  13200 , loss:  0.0036038547\n",
      "Iteration:  13300 , loss:  0.0035438144\n",
      "Iteration:  13400 , loss:  0.0035125345\n",
      "Iteration:  13500 , loss:  0.0034851064\n",
      "Iteration:  13600 , loss:  0.003451596\n",
      "Iteration:  13700 , loss:  0.003442767\n",
      "Iteration:  13800 , loss:  0.0033946065\n",
      "Iteration:  13900 , loss:  0.0070284335\n",
      "Iteration:  14000 , loss:  0.0033326205\n",
      "Iteration:  14100 , loss:  0.0033160225\n",
      "Iteration:  14200 , loss:  0.0032768052\n",
      "Iteration:  14300 , loss:  0.0034250112\n",
      "Iteration:  14400 , loss:  0.0032338826\n",
      "Iteration:  14500 , loss:  0.0031895908\n",
      "Iteration:  14600 , loss:  0.0031642485\n",
      "Iteration:  14700 , loss:  0.003346809\n",
      "Iteration:  14800 , loss:  0.0035093927\n",
      "Iteration:  14900 , loss:  0.0030829147\n",
      "Iteration:  15000 , loss:  0.0030675905\n",
      "Iteration:  15100 , loss:  0.0030374601\n",
      "Iteration:  15200 , loss:  0.0046051173\n",
      "Iteration:  15300 , loss:  0.0029835266\n",
      "Iteration:  15400 , loss:  0.002962741\n",
      "Iteration:  15500 , loss:  0.0030000797\n",
      "Iteration:  15600 , loss:  0.0029130122\n",
      "Iteration:  15700 , loss:  0.0036112475\n",
      "Iteration:  15800 , loss:  0.0034026501\n",
      "Iteration:  15900 , loss:  0.0028457441\n",
      "Iteration:  16000 , loss:  0.0028272616\n",
      "Iteration:  16100 , loss:  0.002804107\n",
      "Iteration:  16200 , loss:  0.0028328\n",
      "Iteration:  16300 , loss:  0.0027686246\n",
      "Iteration:  16400 , loss:  0.0028796627\n",
      "Iteration:  16500 , loss:  0.002724592\n",
      "Iteration:  16600 , loss:  0.0027136074\n",
      "Iteration:  16700 , loss:  0.002718033\n",
      "Iteration:  16800 , loss:  0.002669501\n",
      "Iteration:  16900 , loss:  0.002653726\n",
      "Iteration:  17000 , loss:  0.002636638\n",
      "Iteration:  17100 , loss:  0.002730585\n",
      "Iteration:  17200 , loss:  0.0026005583\n",
      "Iteration:  17300 , loss:  0.0027276964\n",
      "Iteration:  17400 , loss:  0.0025697532\n",
      "Iteration:  17500 , loss:  0.0025526877\n",
      "Iteration:  17600 , loss:  0.0025634659\n",
      "Iteration:  17700 , loss:  0.0025293934\n",
      "Iteration:  17800 , loss:  0.0025075872\n",
      "Iteration:  17900 , loss:  0.003819846\n",
      "Iteration:  18000 , loss:  0.0025019231\n",
      "Iteration:  18100 , loss:  0.0024650537\n",
      "Iteration:  18200 , loss:  0.0024755346\n",
      "Iteration:  18300 , loss:  0.0028289477\n",
      "Iteration:  18400 , loss:  0.0026683062\n",
      "Iteration:  18500 , loss:  0.0027541807\n",
      "Iteration:  18600 , loss:  0.0023913488\n",
      "Iteration:  18700 , loss:  0.004096357\n",
      "Iteration:  18800 , loss:  0.0024813062\n",
      "Iteration:  18900 , loss:  0.0023513653\n",
      "Iteration:  19000 , loss:  0.002581633\n",
      "Iteration:  19100 , loss:  0.0023263572\n",
      "Iteration:  19200 , loss:  0.0023143454\n",
      "Iteration:  19300 , loss:  0.0022988343\n",
      "Iteration:  19400 , loss:  0.0022862302\n",
      "Iteration:  19500 , loss:  0.002632568\n",
      "Iteration:  19600 , loss:  0.0022747102\n",
      "Iteration:  19700 , loss:  0.0022887087\n",
      "Iteration:  19800 , loss:  0.0022345036\n",
      "Iteration:  19900 , loss:  0.0022349055\n",
      "Generating 11th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.30368173\n",
      "Iteration:  100 , loss:  0.13927253\n",
      "Iteration:  200 , loss:  0.13436408\n",
      "Iteration:  300 , loss:  0.12234485\n",
      "Iteration:  400 , loss:  0.104633555\n",
      "Iteration:  500 , loss:  0.079093166\n",
      "Iteration:  600 , loss:  0.054547057\n",
      "Iteration:  700 , loss:  0.046818648\n",
      "Iteration:  800 , loss:  0.04133127\n",
      "Iteration:  900 , loss:  0.036534224\n",
      "Iteration:  1000 , loss:  0.032332327\n",
      "Iteration:  1100 , loss:  0.028954413\n",
      "Iteration:  1200 , loss:  0.026212815\n",
      "Iteration:  1300 , loss:  0.023815185\n",
      "Iteration:  1400 , loss:  0.02218692\n",
      "Iteration:  1500 , loss:  0.021701409\n",
      "Iteration:  1600 , loss:  0.019318342\n",
      "Iteration:  1700 , loss:  0.018234596\n",
      "Iteration:  1800 , loss:  0.017067228\n",
      "Iteration:  1900 , loss:  0.016149655\n",
      "Iteration:  2000 , loss:  0.015192417\n",
      "Iteration:  2100 , loss:  0.014148351\n",
      "Iteration:  2200 , loss:  0.013145482\n",
      "Iteration:  2300 , loss:  0.01218248\n",
      "Iteration:  2400 , loss:  0.011369042\n",
      "Iteration:  2500 , loss:  0.010401224\n",
      "Iteration:  2600 , loss:  0.009722775\n",
      "Iteration:  2700 , loss:  0.009093778\n",
      "Iteration:  2800 , loss:  0.008640517\n",
      "Iteration:  2900 , loss:  0.008841416\n",
      "Iteration:  3000 , loss:  0.008404042\n",
      "Iteration:  3100 , loss:  0.0077585364\n",
      "Iteration:  3200 , loss:  0.0076068495\n",
      "Iteration:  3300 , loss:  0.0075564724\n",
      "Iteration:  3400 , loss:  0.007177983\n",
      "Iteration:  3500 , loss:  0.0070003266\n",
      "Iteration:  3600 , loss:  0.006838538\n",
      "Iteration:  3700 , loss:  0.006685573\n",
      "Iteration:  3800 , loss:  0.00653637\n",
      "Iteration:  3900 , loss:  0.0063920915\n",
      "Iteration:  4000 , loss:  0.006942667\n",
      "Iteration:  4100 , loss:  0.006199465\n",
      "Iteration:  4200 , loss:  0.0059701507\n",
      "Iteration:  4300 , loss:  0.005843671\n",
      "Iteration:  4400 , loss:  0.005918343\n",
      "Iteration:  4500 , loss:  0.0056084087\n",
      "Iteration:  4600 , loss:  0.0055012647\n",
      "Iteration:  4700 , loss:  0.0054701306\n",
      "Iteration:  4800 , loss:  0.0052987053\n",
      "Iteration:  4900 , loss:  0.0052123936\n",
      "Iteration:  5000 , loss:  0.0051683947\n",
      "Iteration:  5100 , loss:  0.00502739\n",
      "Iteration:  5200 , loss:  0.004948111\n",
      "Iteration:  5300 , loss:  0.0049029877\n",
      "Iteration:  5400 , loss:  0.004834014\n",
      "Iteration:  5500 , loss:  0.004709057\n",
      "Iteration:  5600 , loss:  0.0046373256\n",
      "Iteration:  5700 , loss:  0.0046083783\n",
      "Iteration:  5800 , loss:  0.004672332\n",
      "Iteration:  5900 , loss:  0.0044861897\n",
      "Iteration:  6000 , loss:  0.0043736184\n",
      "Iteration:  6100 , loss:  0.0043113\n",
      "Iteration:  6200 , loss:  0.0042535434\n",
      "Iteration:  6300 , loss:  0.004200081\n",
      "Iteration:  6400 , loss:  0.0064322785\n",
      "Iteration:  6500 , loss:  0.0040807584\n",
      "Iteration:  6600 , loss:  0.003991576\n",
      "Iteration:  6700 , loss:  0.0039233505\n",
      "Iteration:  6800 , loss:  0.0038474351\n",
      "Iteration:  6900 , loss:  0.0037973812\n",
      "Iteration:  7000 , loss:  0.0057393685\n",
      "Iteration:  7100 , loss:  0.0036069367\n",
      "Iteration:  7200 , loss:  0.0035224175\n",
      "Iteration:  7300 , loss:  0.003437881\n",
      "Iteration:  7400 , loss:  0.0034965598\n",
      "Iteration:  7500 , loss:  0.0032629604\n",
      "Iteration:  7600 , loss:  0.0031808265\n",
      "Iteration:  7700 , loss:  0.0031028693\n",
      "Iteration:  7800 , loss:  0.0030906973\n",
      "Iteration:  7900 , loss:  0.0030001968\n",
      "Iteration:  8000 , loss:  0.002894301\n",
      "Iteration:  8100 , loss:  0.0028347888\n",
      "Iteration:  8200 , loss:  0.0027792358\n",
      "Iteration:  8300 , loss:  0.004771888\n",
      "Iteration:  8400 , loss:  0.002677321\n",
      "Iteration:  8500 , loss:  0.0026316717\n",
      "Iteration:  8600 , loss:  0.0026511587\n",
      "Iteration:  8700 , loss:  0.002548075\n",
      "Iteration:  8800 , loss:  0.002983354\n",
      "Iteration:  8900 , loss:  0.0024679145\n",
      "Iteration:  9000 , loss:  0.002434162\n",
      "Iteration:  9100 , loss:  0.0024000437\n",
      "Iteration:  9200 , loss:  0.0023679968\n",
      "Iteration:  9300 , loss:  0.002353357\n",
      "Iteration:  9400 , loss:  0.0023067067\n",
      "Iteration:  9500 , loss:  0.0023132085\n",
      "Iteration:  9600 , loss:  0.0022710478\n",
      "Iteration:  9700 , loss:  0.0022252307\n",
      "Iteration:  9800 , loss:  0.0021975683\n",
      "Iteration:  9900 , loss:  0.002172093\n",
      "Iteration:  10000 , loss:  0.0021460499\n",
      "Iteration:  10100 , loss:  0.0021215898\n",
      "Iteration:  10200 , loss:  0.0020954325\n",
      "Iteration:  10300 , loss:  0.0020753439\n",
      "Iteration:  10400 , loss:  0.0020476407\n",
      "Iteration:  10500 , loss:  0.002021496\n",
      "Iteration:  10600 , loss:  0.0020169562\n",
      "Iteration:  10700 , loss:  0.0019704346\n",
      "Iteration:  10800 , loss:  0.0019492767\n",
      "Iteration:  10900 , loss:  0.0019194\n",
      "Iteration:  11000 , loss:  0.0020385678\n",
      "Iteration:  11100 , loss:  0.0018870969\n",
      "Iteration:  11200 , loss:  0.001901773\n",
      "Iteration:  11300 , loss:  0.0018120036\n",
      "Iteration:  11400 , loss:  0.0018508772\n",
      "Iteration:  11500 , loss:  0.0017580084\n",
      "Iteration:  11600 , loss:  0.0017330655\n",
      "Iteration:  11700 , loss:  0.001743061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  11800 , loss:  0.0016814788\n",
      "Iteration:  11900 , loss:  0.0018086913\n",
      "Iteration:  12000 , loss:  0.0016335989\n",
      "Iteration:  12100 , loss:  0.0016084226\n",
      "Iteration:  12200 , loss:  0.0015866846\n",
      "Iteration:  12300 , loss:  0.0018707643\n",
      "Iteration:  12400 , loss:  0.003272292\n",
      "Iteration:  12500 , loss:  0.001520203\n",
      "Iteration:  12600 , loss:  0.0014991658\n",
      "Iteration:  12700 , loss:  0.0015577618\n",
      "Iteration:  12800 , loss:  0.0017812657\n",
      "Iteration:  12900 , loss:  0.0014457621\n",
      "Iteration:  13000 , loss:  0.0014253252\n",
      "Iteration:  13100 , loss:  0.0014142474\n",
      "Iteration:  13200 , loss:  0.0013939181\n",
      "Iteration:  13300 , loss:  0.0014215783\n",
      "Iteration:  13400 , loss:  0.001362513\n",
      "Iteration:  13500 , loss:  0.0013601213\n",
      "Iteration:  13600 , loss:  0.0014127936\n",
      "Iteration:  13700 , loss:  0.0013232451\n",
      "Iteration:  13800 , loss:  0.0022710944\n",
      "Iteration:  13900 , loss:  0.001331442\n",
      "Iteration:  14000 , loss:  0.0012942355\n",
      "Iteration:  14100 , loss:  0.0012827178\n",
      "Iteration:  14200 , loss:  0.0012996006\n",
      "Iteration:  14300 , loss:  0.0013365184\n",
      "Iteration:  14400 , loss:  0.0029642866\n",
      "Iteration:  14500 , loss:  0.0012406477\n",
      "Iteration:  14600 , loss:  0.0012392347\n",
      "Iteration:  14700 , loss:  0.0012308354\n",
      "Iteration:  14800 , loss:  0.0012163287\n",
      "Iteration:  14900 , loss:  0.004165795\n",
      "Iteration:  15000 , loss:  0.0012015691\n",
      "Iteration:  15100 , loss:  0.0011960911\n",
      "Iteration:  15200 , loss:  0.0033021448\n",
      "Iteration:  15300 , loss:  0.0011807652\n",
      "Iteration:  15400 , loss:  0.0011966289\n",
      "Iteration:  15500 , loss:  0.0038162312\n",
      "Iteration:  15600 , loss:  0.0011616497\n",
      "Iteration:  15700 , loss:  0.0012981063\n",
      "Iteration:  15800 , loss:  0.0014205383\n",
      "Iteration:  15900 , loss:  0.00114398\n",
      "Iteration:  16000 , loss:  0.002220416\n",
      "Iteration:  16100 , loss:  0.0011330029\n",
      "Iteration:  16200 , loss:  0.0011300966\n",
      "Iteration:  16300 , loss:  0.0016841061\n",
      "Iteration:  16400 , loss:  0.0011174581\n",
      "Iteration:  16500 , loss:  0.0011558925\n",
      "Iteration:  16600 , loss:  0.0011068913\n",
      "Iteration:  16700 , loss:  0.0011083648\n",
      "Iteration:  16800 , loss:  0.001097179\n",
      "Iteration:  16900 , loss:  0.0011015486\n",
      "Iteration:  17000 , loss:  0.0011370269\n",
      "Iteration:  17100 , loss:  0.0010832358\n",
      "Iteration:  17200 , loss:  0.0032846513\n",
      "Iteration:  17300 , loss:  0.0010742937\n",
      "Iteration:  17400 , loss:  0.0010894934\n",
      "Iteration:  17500 , loss:  0.0026107961\n",
      "Iteration:  17600 , loss:  0.0010614067\n",
      "Iteration:  17700 , loss:  0.0010569474\n",
      "Iteration:  17800 , loss:  0.00121371\n",
      "Iteration:  17900 , loss:  0.0010483457\n",
      "Iteration:  18000 , loss:  0.0010474259\n",
      "Iteration:  18100 , loss:  0.0014813165\n",
      "Iteration:  18200 , loss:  0.0017328754\n",
      "Iteration:  18300 , loss:  0.0010319636\n",
      "Iteration:  18400 , loss:  0.0014014435\n",
      "Iteration:  18500 , loss:  0.0013921394\n",
      "Iteration:  18600 , loss:  0.0010201642\n",
      "Iteration:  18700 , loss:  0.0010227074\n",
      "Iteration:  18800 , loss:  0.0010124741\n",
      "Iteration:  18900 , loss:  0.0010302783\n",
      "Iteration:  19000 , loss:  0.0010050104\n",
      "Iteration:  19100 , loss:  0.0010583771\n",
      "Iteration:  19200 , loss:  0.0009974252\n",
      "Iteration:  19300 , loss:  0.0009999992\n",
      "Iteration:  19400 , loss:  0.0009908753\n",
      "Iteration:  19500 , loss:  0.0012129168\n",
      "Iteration:  19600 , loss:  0.0009830461\n",
      "Iteration:  19700 , loss:  0.0010419559\n",
      "Iteration:  19800 , loss:  0.002310668\n",
      "Iteration:  19900 , loss:  0.00097241893\n",
      "Generating 12th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.23221302\n",
      "Iteration:  100 , loss:  0.13693076\n",
      "Iteration:  200 , loss:  0.12852435\n",
      "Iteration:  300 , loss:  0.11192895\n",
      "Iteration:  400 , loss:  0.08049626\n",
      "Iteration:  500 , loss:  0.060385123\n",
      "Iteration:  600 , loss:  0.047046427\n",
      "Iteration:  700 , loss:  0.039363757\n",
      "Iteration:  800 , loss:  0.034769144\n",
      "Iteration:  900 , loss:  0.031808756\n",
      "Iteration:  1000 , loss:  0.028525664\n",
      "Iteration:  1100 , loss:  0.024962028\n",
      "Iteration:  1200 , loss:  0.022461923\n",
      "Iteration:  1300 , loss:  0.020839259\n",
      "Iteration:  1400 , loss:  0.019152554\n",
      "Iteration:  1500 , loss:  0.017442722\n",
      "Iteration:  1600 , loss:  0.015984962\n",
      "Iteration:  1700 , loss:  0.0146542005\n",
      "Iteration:  1800 , loss:  0.01342753\n",
      "Iteration:  1900 , loss:  0.012373354\n",
      "Iteration:  2000 , loss:  0.01215575\n",
      "Iteration:  2100 , loss:  0.010697255\n",
      "Iteration:  2200 , loss:  0.010908993\n",
      "Iteration:  2300 , loss:  0.009418547\n",
      "Iteration:  2400 , loss:  0.00897576\n",
      "Iteration:  2500 , loss:  0.008589009\n",
      "Iteration:  2600 , loss:  0.0082345735\n",
      "Iteration:  2700 , loss:  0.007885173\n",
      "Iteration:  2800 , loss:  0.007632478\n",
      "Iteration:  2900 , loss:  0.0073165796\n",
      "Iteration:  3000 , loss:  0.006945993\n",
      "Iteration:  3100 , loss:  0.0065891207\n",
      "Iteration:  3200 , loss:  0.0062872902\n",
      "Iteration:  3300 , loss:  0.0060052406\n",
      "Iteration:  3400 , loss:  0.0057547754\n",
      "Iteration:  3500 , loss:  0.0059846793\n",
      "Iteration:  3600 , loss:  0.00531663\n",
      "Iteration:  3700 , loss:  0.0051417938\n",
      "Iteration:  3800 , loss:  0.0049881814\n",
      "Iteration:  3900 , loss:  0.0053136838\n",
      "Iteration:  4000 , loss:  0.0047132554\n",
      "Iteration:  4100 , loss:  0.004584483\n",
      "Iteration:  4200 , loss:  0.004465243\n",
      "Iteration:  4300 , loss:  0.004330603\n",
      "Iteration:  4400 , loss:  0.004202223\n",
      "Iteration:  4500 , loss:  0.004074904\n",
      "Iteration:  4600 , loss:  0.00397137\n",
      "Iteration:  4700 , loss:  0.0038010636\n",
      "Iteration:  4800 , loss:  0.0036756103\n",
      "Iteration:  4900 , loss:  0.0035542857\n",
      "Iteration:  5000 , loss:  0.0037689311\n",
      "Iteration:  5100 , loss:  0.003339346\n",
      "Iteration:  5200 , loss:  0.0032480014\n",
      "Iteration:  5300 , loss:  0.003171933\n",
      "Iteration:  5400 , loss:  0.0036898553\n",
      "Iteration:  5500 , loss:  0.003028567\n",
      "Iteration:  5600 , loss:  0.004118842\n",
      "Iteration:  5700 , loss:  0.0028950186\n",
      "Iteration:  5800 , loss:  0.0032595573\n",
      "Iteration:  5900 , loss:  0.0028185921\n",
      "Iteration:  6000 , loss:  0.0027373726\n",
      "Iteration:  6100 , loss:  0.004056787\n",
      "Iteration:  6200 , loss:  0.0026432888\n",
      "Iteration:  6300 , loss:  0.0032181537\n",
      "Iteration:  6400 , loss:  0.002690588\n",
      "Iteration:  6500 , loss:  0.0025124801\n",
      "Iteration:  6600 , loss:  0.0024725264\n",
      "Iteration:  6700 , loss:  0.0024294616\n",
      "Iteration:  6800 , loss:  0.0023890976\n",
      "Iteration:  6900 , loss:  0.0023541006\n",
      "Iteration:  7000 , loss:  0.0023300224\n",
      "Iteration:  7100 , loss:  0.0022817575\n",
      "Iteration:  7200 , loss:  0.0022356308\n",
      "Iteration:  7300 , loss:  0.002228913\n",
      "Iteration:  7400 , loss:  0.0024246129\n",
      "Iteration:  7500 , loss:  0.0022421046\n",
      "Iteration:  7600 , loss:  0.0020920841\n",
      "Iteration:  7700 , loss:  0.0020816957\n",
      "Iteration:  7800 , loss:  0.002150834\n",
      "Iteration:  7900 , loss:  0.0045301653\n",
      "Iteration:  8000 , loss:  0.0019600452\n",
      "Iteration:  8100 , loss:  0.0019400872\n",
      "Iteration:  8200 , loss:  0.0018981873\n",
      "Iteration:  8300 , loss:  0.0018776263\n",
      "Iteration:  8400 , loss:  0.0018614925\n",
      "Iteration:  8500 , loss:  0.0018256394\n",
      "Iteration:  8600 , loss:  0.0017858967\n",
      "Iteration:  8700 , loss:  0.0017819497\n",
      "Iteration:  8800 , loss:  0.0017520769\n",
      "Iteration:  8900 , loss:  0.0017030049\n",
      "Iteration:  9000 , loss:  0.0016766288\n",
      "Iteration:  9100 , loss:  0.0016537303\n",
      "Iteration:  9200 , loss:  0.0016273557\n",
      "Iteration:  9300 , loss:  0.0016274856\n",
      "Iteration:  9400 , loss:  0.0016402585\n",
      "Iteration:  9500 , loss:  0.0015964853\n",
      "Iteration:  9600 , loss:  0.0025856546\n",
      "Iteration:  9700 , loss:  0.0015138033\n",
      "Iteration:  9800 , loss:  0.0015160902\n",
      "Iteration:  9900 , loss:  0.0028806976\n",
      "Iteration:  10000 , loss:  0.0014539534\n",
      "Iteration:  10100 , loss:  0.0014390063\n",
      "Iteration:  10200 , loss:  0.0014254553\n",
      "Iteration:  10300 , loss:  0.0014033441\n",
      "Iteration:  10400 , loss:  0.0019987577\n",
      "Iteration:  10500 , loss:  0.0013633866\n",
      "Iteration:  10600 , loss:  0.0013477097\n",
      "Iteration:  10700 , loss:  0.0021816476\n",
      "Iteration:  10800 , loss:  0.0013156699\n",
      "Iteration:  10900 , loss:  0.0017981352\n",
      "Iteration:  11000 , loss:  0.0012852869\n",
      "Iteration:  11100 , loss:  0.0012707175\n",
      "Iteration:  11200 , loss:  0.001259303\n",
      "Iteration:  11300 , loss:  0.0012427655\n",
      "Iteration:  11400 , loss:  0.0012303718\n",
      "Iteration:  11500 , loss:  0.0012167384\n",
      "Iteration:  11600 , loss:  0.0018560322\n",
      "Iteration:  11700 , loss:  0.0011914363\n",
      "Iteration:  11800 , loss:  0.0012032237\n",
      "Iteration:  11900 , loss:  0.0011727171\n",
      "Iteration:  12000 , loss:  0.0020920038\n",
      "Iteration:  12100 , loss:  0.0011434713\n",
      "Iteration:  12200 , loss:  0.0011334374\n",
      "Iteration:  12300 , loss:  0.0011221106\n",
      "Iteration:  12400 , loss:  0.0011102683\n",
      "Iteration:  12500 , loss:  0.0011005951\n",
      "Iteration:  12600 , loss:  0.0015647402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  12700 , loss:  0.0010792598\n",
      "Iteration:  12800 , loss:  0.0010694329\n",
      "Iteration:  12900 , loss:  0.0010599452\n",
      "Iteration:  13000 , loss:  0.0010504875\n",
      "Iteration:  13100 , loss:  0.0010578068\n",
      "Iteration:  13200 , loss:  0.0013178505\n",
      "Iteration:  13300 , loss:  0.0010214252\n",
      "Iteration:  13400 , loss:  0.001180955\n",
      "Iteration:  13500 , loss:  0.0010047171\n",
      "Iteration:  13600 , loss:  0.0009954257\n",
      "Iteration:  13700 , loss:  0.002774065\n",
      "Iteration:  13800 , loss:  0.0009770386\n",
      "Iteration:  13900 , loss:  0.0009911434\n",
      "Iteration:  14000 , loss:  0.0010718076\n",
      "Iteration:  14100 , loss:  0.00095179724\n",
      "Iteration:  14200 , loss:  0.001128832\n",
      "Iteration:  14300 , loss:  0.00093547336\n",
      "Iteration:  14400 , loss:  0.0009643468\n",
      "Iteration:  14500 , loss:  0.0009194107\n",
      "Iteration:  14600 , loss:  0.001241514\n",
      "Iteration:  14700 , loss:  0.0009037012\n",
      "Iteration:  14800 , loss:  0.00095732085\n",
      "Iteration:  14900 , loss:  0.00096057035\n",
      "Iteration:  15000 , loss:  0.00088122225\n",
      "Iteration:  15100 , loss:  0.00087366125\n",
      "Iteration:  15200 , loss:  0.0009461576\n",
      "Iteration:  15300 , loss:  0.0008612952\n",
      "Iteration:  15400 , loss:  0.0008544958\n",
      "Iteration:  15500 , loss:  0.00084392034\n",
      "Iteration:  15600 , loss:  0.0008376804\n",
      "Iteration:  15700 , loss:  0.0008307048\n",
      "Iteration:  15800 , loss:  0.00082304125\n",
      "Iteration:  15900 , loss:  0.0008203214\n",
      "Iteration:  16000 , loss:  0.00093894894\n",
      "Iteration:  16100 , loss:  0.0008067589\n",
      "Iteration:  16200 , loss:  0.000796153\n",
      "Iteration:  16300 , loss:  0.000811067\n",
      "Iteration:  16400 , loss:  0.000783365\n",
      "Iteration:  16500 , loss:  0.00078168703\n",
      "Iteration:  16600 , loss:  0.00094954635\n",
      "Iteration:  16700 , loss:  0.000764722\n",
      "Iteration:  16800 , loss:  0.0014043945\n",
      "Iteration:  16900 , loss:  0.0007747001\n",
      "Iteration:  17000 , loss:  0.0007467712\n",
      "Iteration:  17100 , loss:  0.00084843015\n",
      "Iteration:  17200 , loss:  0.0007347553\n",
      "Iteration:  17300 , loss:  0.0007294158\n",
      "Iteration:  17400 , loss:  0.0007358043\n",
      "Iteration:  17500 , loss:  0.0007177915\n",
      "Iteration:  17600 , loss:  0.0007135895\n",
      "Iteration:  17700 , loss:  0.0007263449\n",
      "Iteration:  17800 , loss:  0.0007019243\n",
      "Iteration:  17900 , loss:  0.00076115486\n",
      "Iteration:  18000 , loss:  0.00069135206\n",
      "Iteration:  18100 , loss:  0.000710621\n",
      "Iteration:  18200 , loss:  0.00069142017\n",
      "Iteration:  18300 , loss:  0.00067905756\n",
      "Iteration:  18400 , loss:  0.0006716277\n",
      "Iteration:  18500 , loss:  0.0006975196\n",
      "Iteration:  18600 , loss:  0.00066136033\n",
      "Iteration:  18700 , loss:  0.0006598403\n",
      "Iteration:  18800 , loss:  0.00065309124\n",
      "Iteration:  18900 , loss:  0.00064809143\n",
      "Iteration:  19000 , loss:  0.0008099858\n",
      "Iteration:  19100 , loss:  0.0006386058\n",
      "Iteration:  19200 , loss:  0.00068481383\n",
      "Iteration:  19300 , loss:  0.0006962217\n",
      "Iteration:  19400 , loss:  0.00078076485\n",
      "Iteration:  19500 , loss:  0.0006217576\n",
      "Iteration:  19600 , loss:  0.000618637\n",
      "Iteration:  19700 , loss:  0.0006167308\n",
      "Iteration:  19800 , loss:  0.00061200187\n",
      "Iteration:  19900 , loss:  0.0007477606\n",
      "Generating 13th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.5271263\n",
      "Iteration:  100 , loss:  0.13912432\n",
      "Iteration:  200 , loss:  0.13553762\n",
      "Iteration:  300 , loss:  0.12765276\n",
      "Iteration:  400 , loss:  0.12030641\n",
      "Iteration:  500 , loss:  0.11252725\n",
      "Iteration:  600 , loss:  0.100231126\n",
      "Iteration:  700 , loss:  0.08235021\n",
      "Iteration:  800 , loss:  0.06796789\n",
      "Iteration:  900 , loss:  0.054118678\n",
      "Iteration:  1000 , loss:  0.04626828\n",
      "Iteration:  1100 , loss:  0.043617163\n",
      "Iteration:  1200 , loss:  0.042033948\n",
      "Iteration:  1300 , loss:  0.04067205\n",
      "Iteration:  1400 , loss:  0.039191503\n",
      "Iteration:  1500 , loss:  0.037410054\n",
      "Iteration:  1600 , loss:  0.03538155\n",
      "Iteration:  1700 , loss:  0.03339638\n",
      "Iteration:  1800 , loss:  0.031151917\n",
      "Iteration:  1900 , loss:  0.029536383\n",
      "Iteration:  2000 , loss:  0.028031206\n",
      "Iteration:  2100 , loss:  0.02677806\n",
      "Iteration:  2200 , loss:  0.026794186\n",
      "Iteration:  2300 , loss:  0.024104178\n",
      "Iteration:  2400 , loss:  0.022817288\n",
      "Iteration:  2500 , loss:  0.021766776\n",
      "Iteration:  2600 , loss:  0.02077889\n",
      "Iteration:  2700 , loss:  0.01993315\n",
      "Iteration:  2800 , loss:  0.019243067\n",
      "Iteration:  2900 , loss:  0.018581377\n",
      "Iteration:  3000 , loss:  0.017957425\n",
      "Iteration:  3100 , loss:  0.017381642\n",
      "Iteration:  3200 , loss:  0.016661184\n",
      "Iteration:  3300 , loss:  0.015989933\n",
      "Iteration:  3400 , loss:  0.015275311\n",
      "Iteration:  3500 , loss:  0.015024375\n",
      "Iteration:  3600 , loss:  0.013901977\n",
      "Iteration:  3700 , loss:  0.013333492\n",
      "Iteration:  3800 , loss:  0.012585986\n",
      "Iteration:  3900 , loss:  0.012036042\n",
      "Iteration:  4000 , loss:  0.011550911\n",
      "Iteration:  4100 , loss:  0.011124215\n",
      "Iteration:  4200 , loss:  0.010729166\n",
      "Iteration:  4300 , loss:  0.010967047\n",
      "Iteration:  4400 , loss:  0.010186134\n",
      "Iteration:  4500 , loss:  0.0098278215\n",
      "Iteration:  4600 , loss:  0.009609124\n",
      "Iteration:  4700 , loss:  0.009357812\n",
      "Iteration:  4800 , loss:  0.009235122\n",
      "Iteration:  4900 , loss:  0.0091542285\n",
      "Iteration:  5000 , loss:  0.008719505\n",
      "Iteration:  5100 , loss:  0.008535018\n",
      "Iteration:  5200 , loss:  0.008305631\n",
      "Iteration:  5300 , loss:  0.0081034945\n",
      "Iteration:  5400 , loss:  0.010262417\n",
      "Iteration:  5500 , loss:  0.0076876143\n",
      "Iteration:  5600 , loss:  0.007488868\n",
      "Iteration:  5700 , loss:  0.0076284995\n",
      "Iteration:  5800 , loss:  0.007100885\n",
      "Iteration:  5900 , loss:  0.0069245617\n",
      "Iteration:  6000 , loss:  0.0070547597\n",
      "Iteration:  6100 , loss:  0.006617602\n",
      "Iteration:  6200 , loss:  0.006442126\n",
      "Iteration:  6300 , loss:  0.0063449685\n",
      "Iteration:  6400 , loss:  0.006202597\n",
      "Iteration:  6500 , loss:  0.00603675\n",
      "Iteration:  6600 , loss:  0.0059203757\n",
      "Iteration:  6700 , loss:  0.005813996\n",
      "Iteration:  6800 , loss:  0.005693488\n",
      "Iteration:  6900 , loss:  0.005590207\n",
      "Iteration:  7000 , loss:  0.0054872506\n",
      "Iteration:  7100 , loss:  0.0055829464\n",
      "Iteration:  7200 , loss:  0.005294382\n",
      "Iteration:  7300 , loss:  0.0052021844\n",
      "Iteration:  7400 , loss:  0.006745892\n",
      "Iteration:  7500 , loss:  0.005025315\n",
      "Iteration:  7600 , loss:  0.00495999\n",
      "Iteration:  7700 , loss:  0.0049733664\n",
      "Iteration:  7800 , loss:  0.0047735674\n",
      "Iteration:  7900 , loss:  0.004699658\n",
      "Iteration:  8000 , loss:  0.004616149\n",
      "Iteration:  8100 , loss:  0.004548235\n",
      "Iteration:  8200 , loss:  0.004474369\n",
      "Iteration:  8300 , loss:  0.0044185454\n",
      "Iteration:  8400 , loss:  0.004326158\n",
      "Iteration:  8500 , loss:  0.0042614345\n",
      "Iteration:  8600 , loss:  0.00420917\n",
      "Iteration:  8700 , loss:  0.004288037\n",
      "Iteration:  8800 , loss:  0.0040726615\n",
      "Iteration:  8900 , loss:  0.004094509\n",
      "Iteration:  9000 , loss:  0.0072909733\n",
      "Iteration:  9100 , loss:  0.0039039985\n",
      "Iteration:  9200 , loss:  0.0038487688\n",
      "Iteration:  9300 , loss:  0.0038070548\n",
      "Iteration:  9400 , loss:  0.003800233\n",
      "Iteration:  9500 , loss:  0.0037022517\n",
      "Iteration:  9600 , loss:  0.0045664003\n",
      "Iteration:  9700 , loss:  0.0036103274\n",
      "Iteration:  9800 , loss:  0.0035728388\n",
      "Iteration:  9900 , loss:  0.003521574\n",
      "Iteration:  10000 , loss:  0.0034825888\n",
      "Iteration:  10100 , loss:  0.0034407289\n",
      "Iteration:  10200 , loss:  0.0034018352\n",
      "Iteration:  10300 , loss:  0.0033891972\n",
      "Iteration:  10400 , loss:  0.0033256281\n",
      "Iteration:  10500 , loss:  0.0033281571\n",
      "Iteration:  10600 , loss:  0.0036302828\n",
      "Iteration:  10700 , loss:  0.0032198296\n",
      "Iteration:  10800 , loss:  0.0031988733\n",
      "Iteration:  10900 , loss:  0.003184031\n",
      "Iteration:  11000 , loss:  0.0033539264\n",
      "Iteration:  11100 , loss:  0.0030928627\n",
      "Iteration:  11200 , loss:  0.0030732725\n",
      "Iteration:  11300 , loss:  0.0031160235\n",
      "Iteration:  11400 , loss:  0.0030086697\n",
      "Iteration:  11500 , loss:  0.0029821661\n",
      "Iteration:  11600 , loss:  0.0029844665\n",
      "Iteration:  11700 , loss:  0.0031683764\n",
      "Iteration:  11800 , loss:  0.0029062324\n",
      "Iteration:  11900 , loss:  0.0028860993\n",
      "Iteration:  12000 , loss:  0.0030338303\n",
      "Iteration:  12100 , loss:  0.0028390228\n",
      "Iteration:  12200 , loss:  0.003575012\n",
      "Iteration:  12300 , loss:  0.0027975359\n",
      "Iteration:  12400 , loss:  0.0027902303\n",
      "Iteration:  12500 , loss:  0.0029351069\n",
      "Iteration:  12600 , loss:  0.0027409277\n",
      "Iteration:  12700 , loss:  0.0027231658\n",
      "Iteration:  12800 , loss:  0.0027055242\n",
      "Iteration:  12900 , loss:  0.0026996518\n",
      "Iteration:  13000 , loss:  0.0028866634\n",
      "Iteration:  13100 , loss:  0.002658309\n",
      "Iteration:  13200 , loss:  0.003123478\n",
      "Iteration:  13300 , loss:  0.0026254216\n",
      "Iteration:  13400 , loss:  0.003084674\n",
      "Iteration:  13500 , loss:  0.0025963478\n",
      "Iteration:  13600 , loss:  0.0025840346\n",
      "Iteration:  13700 , loss:  0.0032324842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  13800 , loss:  0.002555711\n",
      "Iteration:  13900 , loss:  0.0050415276\n",
      "Iteration:  14000 , loss:  0.0042308574\n",
      "Iteration:  14100 , loss:  0.0025164417\n",
      "Iteration:  14200 , loss:  0.002600517\n",
      "Iteration:  14300 , loss:  0.00249426\n",
      "Iteration:  14400 , loss:  0.0024783215\n",
      "Iteration:  14500 , loss:  0.0024770733\n",
      "Iteration:  14600 , loss:  0.0024545311\n",
      "Iteration:  14700 , loss:  0.0026144683\n",
      "Iteration:  14800 , loss:  0.0024308714\n",
      "Iteration:  14900 , loss:  0.002418541\n",
      "Iteration:  15000 , loss:  0.0024099713\n",
      "Iteration:  15100 , loss:  0.0024622865\n",
      "Iteration:  15200 , loss:  0.0028763744\n",
      "Iteration:  15300 , loss:  0.0023751396\n",
      "Iteration:  15400 , loss:  0.0023606818\n",
      "Iteration:  15500 , loss:  0.0023957756\n",
      "Iteration:  15600 , loss:  0.0023392302\n",
      "Iteration:  15700 , loss:  0.002327761\n",
      "Iteration:  15800 , loss:  0.0023247101\n",
      "Iteration:  15900 , loss:  0.002361264\n",
      "Iteration:  16000 , loss:  0.0025273983\n",
      "Iteration:  16100 , loss:  0.005379223\n",
      "Iteration:  16200 , loss:  0.0022688808\n",
      "Iteration:  16300 , loss:  0.0022720331\n",
      "Iteration:  16400 , loss:  0.0023486265\n",
      "Iteration:  16500 , loss:  0.002235954\n",
      "Iteration:  16600 , loss:  0.0029700897\n",
      "Iteration:  16700 , loss:  0.0022133226\n",
      "Iteration:  16800 , loss:  0.0022131724\n",
      "Iteration:  16900 , loss:  0.002760694\n",
      "Iteration:  17000 , loss:  0.002180408\n",
      "Iteration:  17100 , loss:  0.0028472503\n",
      "Iteration:  17200 , loss:  0.0029973253\n",
      "Iteration:  17300 , loss:  0.002147273\n",
      "Iteration:  17400 , loss:  0.0021573983\n",
      "Iteration:  17500 , loss:  0.0025558448\n",
      "Iteration:  17600 , loss:  0.0021287184\n",
      "Iteration:  17700 , loss:  0.002103707\n",
      "Iteration:  17800 , loss:  0.0020920967\n",
      "Iteration:  17900 , loss:  0.002082119\n",
      "Iteration:  18000 , loss:  0.0021673166\n",
      "Iteration:  18100 , loss:  0.0020590108\n",
      "Iteration:  18200 , loss:  0.002049415\n",
      "Iteration:  18300 , loss:  0.0020372975\n",
      "Iteration:  18400 , loss:  0.0020856964\n",
      "Iteration:  18500 , loss:  0.0020391543\n",
      "Iteration:  18600 , loss:  0.00243844\n",
      "Iteration:  18700 , loss:  0.0019926922\n",
      "Iteration:  18800 , loss:  0.0020634627\n",
      "Iteration:  18900 , loss:  0.0025565792\n",
      "Iteration:  19000 , loss:  0.0019591656\n",
      "Iteration:  19100 , loss:  0.0019474769\n",
      "Iteration:  19200 , loss:  0.0019398681\n",
      "Iteration:  19300 , loss:  0.0019394698\n",
      "Iteration:  19400 , loss:  0.0019241875\n",
      "Iteration:  19500 , loss:  0.0019021978\n",
      "Iteration:  19600 , loss:  0.0019154472\n",
      "Iteration:  19700 , loss:  0.0019167445\n",
      "Iteration:  19800 , loss:  0.0018686001\n",
      "Iteration:  19900 , loss:  0.0018569872\n",
      "Generating 14th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.2142056\n",
      "Iteration:  100 , loss:  0.13418852\n",
      "Iteration:  200 , loss:  0.11926203\n",
      "Iteration:  300 , loss:  0.101751134\n",
      "Iteration:  400 , loss:  0.07598213\n",
      "Iteration:  500 , loss:  0.061723936\n",
      "Iteration:  600 , loss:  0.052010458\n",
      "Iteration:  700 , loss:  0.044060957\n",
      "Iteration:  800 , loss:  0.03915929\n",
      "Iteration:  900 , loss:  0.036225535\n",
      "Iteration:  1000 , loss:  0.03383332\n",
      "Iteration:  1100 , loss:  0.03168525\n",
      "Iteration:  1200 , loss:  0.030058255\n",
      "Iteration:  1300 , loss:  0.028131023\n",
      "Iteration:  1400 , loss:  0.026685705\n",
      "Iteration:  1500 , loss:  0.025431711\n",
      "Iteration:  1600 , loss:  0.025321461\n",
      "Iteration:  1700 , loss:  0.023617014\n",
      "Iteration:  1800 , loss:  0.023034465\n",
      "Iteration:  1900 , loss:  0.023107339\n",
      "Iteration:  2000 , loss:  0.021990126\n",
      "Iteration:  2100 , loss:  0.021558948\n",
      "Iteration:  2200 , loss:  0.02108639\n",
      "Iteration:  2300 , loss:  0.020663299\n",
      "Iteration:  2400 , loss:  0.02020621\n",
      "Iteration:  2500 , loss:  0.019737214\n",
      "Iteration:  2600 , loss:  0.019257892\n",
      "Iteration:  2700 , loss:  0.019138686\n",
      "Iteration:  2800 , loss:  0.018277923\n",
      "Iteration:  2900 , loss:  0.01781778\n",
      "Iteration:  3000 , loss:  0.019829337\n",
      "Iteration:  3100 , loss:  0.01690577\n",
      "Iteration:  3200 , loss:  0.016527623\n",
      "Iteration:  3300 , loss:  0.015986316\n",
      "Iteration:  3400 , loss:  0.01553691\n",
      "Iteration:  3500 , loss:  0.015119186\n",
      "Iteration:  3600 , loss:  0.017736955\n",
      "Iteration:  3700 , loss:  0.014207464\n",
      "Iteration:  3800 , loss:  0.013850721\n",
      "Iteration:  3900 , loss:  0.0133373635\n",
      "Iteration:  4000 , loss:  0.012910975\n",
      "Iteration:  4100 , loss:  0.012468458\n",
      "Iteration:  4200 , loss:  0.012032603\n",
      "Iteration:  4300 , loss:  0.011678955\n",
      "Iteration:  4400 , loss:  0.011155843\n",
      "Iteration:  4500 , loss:  0.011121314\n",
      "Iteration:  4600 , loss:  0.010336231\n",
      "Iteration:  4700 , loss:  0.009910854\n",
      "Iteration:  4800 , loss:  0.009518959\n",
      "Iteration:  4900 , loss:  0.00918128\n",
      "Iteration:  5000 , loss:  0.0088396175\n",
      "Iteration:  5100 , loss:  0.008495905\n",
      "Iteration:  5200 , loss:  0.008211336\n",
      "Iteration:  5300 , loss:  0.007939541\n",
      "Iteration:  5400 , loss:  0.0077337157\n",
      "Iteration:  5500 , loss:  0.0074926475\n",
      "Iteration:  5600 , loss:  0.0073354244\n",
      "Iteration:  5700 , loss:  0.00713359\n",
      "Iteration:  5800 , loss:  0.0069792746\n",
      "Iteration:  5900 , loss:  0.006829961\n",
      "Iteration:  6000 , loss:  0.0074325437\n",
      "Iteration:  6100 , loss:  0.0065859733\n",
      "Iteration:  6200 , loss:  0.006505001\n",
      "Iteration:  6300 , loss:  0.0063708303\n",
      "Iteration:  6400 , loss:  0.006792846\n",
      "Iteration:  6500 , loss:  0.006670187\n",
      "Iteration:  6600 , loss:  0.0062108254\n",
      "Iteration:  6700 , loss:  0.0061215754\n",
      "Iteration:  6800 , loss:  0.0060490454\n",
      "Iteration:  6900 , loss:  0.0058296905\n",
      "Iteration:  7000 , loss:  0.005645917\n",
      "Iteration:  7100 , loss:  0.0055639916\n",
      "Iteration:  7200 , loss:  0.005466515\n",
      "Iteration:  7300 , loss:  0.005373848\n",
      "Iteration:  7400 , loss:  0.0067557516\n",
      "Iteration:  7500 , loss:  0.0051912423\n",
      "Iteration:  7600 , loss:  0.0051046936\n",
      "Iteration:  7700 , loss:  0.0050147516\n",
      "Iteration:  7800 , loss:  0.004930822\n",
      "Iteration:  7900 , loss:  0.00484061\n",
      "Iteration:  8000 , loss:  0.0047784694\n",
      "Iteration:  8100 , loss:  0.0046639172\n",
      "Iteration:  8200 , loss:  0.0045815436\n",
      "Iteration:  8300 , loss:  0.0044970415\n",
      "Iteration:  8400 , loss:  0.004416759\n",
      "Iteration:  8500 , loss:  0.0043394757\n",
      "Iteration:  8600 , loss:  0.00426595\n",
      "Iteration:  8700 , loss:  0.004339583\n",
      "Iteration:  8800 , loss:  0.0041205655\n",
      "Iteration:  8900 , loss:  0.0041460567\n",
      "Iteration:  9000 , loss:  0.0039936565\n",
      "Iteration:  9100 , loss:  0.003933563\n",
      "Iteration:  9200 , loss:  0.0050122794\n",
      "Iteration:  9300 , loss:  0.0038277304\n",
      "Iteration:  9400 , loss:  0.0037726783\n",
      "Iteration:  9500 , loss:  0.003724139\n",
      "Iteration:  9600 , loss:  0.0036786618\n",
      "Iteration:  9700 , loss:  0.0036308197\n",
      "Iteration:  9800 , loss:  0.0043484177\n",
      "Iteration:  9900 , loss:  0.003543434\n",
      "Iteration:  10000 , loss:  0.0035165057\n",
      "Iteration:  10100 , loss:  0.00347254\n",
      "Iteration:  10200 , loss:  0.004864356\n",
      "Iteration:  10300 , loss:  0.003799134\n",
      "Iteration:  10400 , loss:  0.003336034\n",
      "Iteration:  10500 , loss:  0.0033248088\n",
      "Iteration:  10600 , loss:  0.0032580253\n",
      "Iteration:  10700 , loss:  0.003217924\n",
      "Iteration:  10800 , loss:  0.0032196785\n",
      "Iteration:  10900 , loss:  0.0036983194\n",
      "Iteration:  11000 , loss:  0.00310242\n",
      "Iteration:  11100 , loss:  0.003166235\n",
      "Iteration:  11200 , loss:  0.0030406194\n",
      "Iteration:  11300 , loss:  0.002992816\n",
      "Iteration:  11400 , loss:  0.0029997346\n",
      "Iteration:  11500 , loss:  0.0029286765\n",
      "Iteration:  11600 , loss:  0.0028998759\n",
      "Iteration:  11700 , loss:  0.0031162791\n",
      "Iteration:  11800 , loss:  0.0028258367\n",
      "Iteration:  11900 , loss:  0.00282934\n",
      "Iteration:  12000 , loss:  0.0027649058\n",
      "Iteration:  12100 , loss:  0.0027445909\n",
      "Iteration:  12200 , loss:  0.0027083466\n",
      "Iteration:  12300 , loss:  0.0026861858\n",
      "Iteration:  12400 , loss:  0.002655855\n",
      "Iteration:  12500 , loss:  0.002629993\n",
      "Iteration:  12600 , loss:  0.0028423031\n",
      "Iteration:  12700 , loss:  0.0025805945\n",
      "Iteration:  12800 , loss:  0.0025614281\n",
      "Iteration:  12900 , loss:  0.0025475426\n",
      "Iteration:  13000 , loss:  0.0025118869\n",
      "Iteration:  13100 , loss:  0.0024973068\n",
      "Iteration:  13200 , loss:  0.0024721818\n",
      "Iteration:  13300 , loss:  0.002447363\n",
      "Iteration:  13400 , loss:  0.0024307529\n",
      "Iteration:  13500 , loss:  0.0024182026\n",
      "Iteration:  13600 , loss:  0.0023862324\n",
      "Iteration:  13700 , loss:  0.0023731175\n",
      "Iteration:  13800 , loss:  0.0023491746\n",
      "Iteration:  13900 , loss:  0.0053102253\n",
      "Iteration:  14000 , loss:  0.00265348\n",
      "Iteration:  14100 , loss:  0.002290439\n",
      "Iteration:  14200 , loss:  0.0022915509\n",
      "Iteration:  14300 , loss:  0.0022570346\n",
      "Iteration:  14400 , loss:  0.00397445\n",
      "Iteration:  14500 , loss:  0.0028393832\n",
      "Iteration:  14600 , loss:  0.0022004466\n",
      "Iteration:  14700 , loss:  0.0028225607\n",
      "Iteration:  14800 , loss:  0.002338287\n",
      "Iteration:  14900 , loss:  0.0021489784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  15000 , loss:  0.0023832622\n",
      "Iteration:  15100 , loss:  0.0021494518\n",
      "Iteration:  15200 , loss:  0.004068292\n",
      "Iteration:  15300 , loss:  0.002260313\n",
      "Iteration:  15400 , loss:  0.002072507\n",
      "Iteration:  15500 , loss:  0.00207358\n",
      "Iteration:  15600 , loss:  0.0020348406\n",
      "Iteration:  15700 , loss:  0.0021516625\n",
      "Iteration:  15800 , loss:  0.002013341\n",
      "Iteration:  15900 , loss:  0.0019982865\n",
      "Iteration:  16000 , loss:  0.001976573\n",
      "Iteration:  16100 , loss:  0.0019652052\n",
      "Iteration:  16200 , loss:  0.0019451553\n",
      "Iteration:  16300 , loss:  0.001978378\n",
      "Iteration:  16400 , loss:  0.0019695638\n",
      "Iteration:  16500 , loss:  0.001903205\n",
      "Iteration:  16600 , loss:  0.0018919224\n",
      "Iteration:  16700 , loss:  0.0037879983\n",
      "Iteration:  16800 , loss:  0.001864013\n",
      "Iteration:  16900 , loss:  0.0018539522\n",
      "Iteration:  17000 , loss:  0.0019197954\n",
      "Iteration:  17100 , loss:  0.0018274272\n",
      "Iteration:  17200 , loss:  0.0018154576\n",
      "Iteration:  17300 , loss:  0.0018900267\n",
      "Iteration:  17400 , loss:  0.0018201496\n",
      "Iteration:  17500 , loss:  0.0019552072\n",
      "Iteration:  17600 , loss:  0.0023176472\n",
      "Iteration:  17700 , loss:  0.001756694\n",
      "Iteration:  17800 , loss:  0.0017513825\n",
      "Iteration:  17900 , loss:  0.0017352145\n",
      "Iteration:  18000 , loss:  0.0018351129\n",
      "Iteration:  18100 , loss:  0.0017218692\n",
      "Iteration:  18200 , loss:  0.002212915\n",
      "Iteration:  18300 , loss:  0.0017294211\n",
      "Iteration:  18400 , loss:  0.0018333877\n",
      "Iteration:  18500 , loss:  0.0036646025\n",
      "Iteration:  18600 , loss:  0.0016637978\n",
      "Iteration:  18700 , loss:  0.0016557158\n",
      "Iteration:  18800 , loss:  0.0016475053\n",
      "Iteration:  18900 , loss:  0.0024209814\n",
      "Iteration:  19000 , loss:  0.0016263812\n",
      "Iteration:  19100 , loss:  0.0017172596\n",
      "Iteration:  19200 , loss:  0.0016594857\n",
      "Iteration:  19300 , loss:  0.0016132041\n",
      "Iteration:  19400 , loss:  0.001592953\n",
      "Iteration:  19500 , loss:  0.0016964247\n",
      "Iteration:  19600 , loss:  0.001710322\n",
      "Iteration:  19700 , loss:  0.0021776375\n",
      "Iteration:  19800 , loss:  0.0015564752\n",
      "Iteration:  19900 , loss:  0.002230151\n",
      "Generating 15th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.219446\n",
      "Iteration:  100 , loss:  0.13543114\n",
      "Iteration:  200 , loss:  0.11781453\n",
      "Iteration:  300 , loss:  0.08169446\n",
      "Iteration:  400 , loss:  0.05846784\n",
      "Iteration:  500 , loss:  0.049541578\n",
      "Iteration:  600 , loss:  0.042545397\n",
      "Iteration:  700 , loss:  0.036156535\n",
      "Iteration:  800 , loss:  0.030871024\n",
      "Iteration:  900 , loss:  0.026792344\n",
      "Iteration:  1000 , loss:  0.024376212\n",
      "Iteration:  1100 , loss:  0.022763226\n",
      "Iteration:  1200 , loss:  0.021479873\n",
      "Iteration:  1300 , loss:  0.020490844\n",
      "Iteration:  1400 , loss:  0.019448988\n",
      "Iteration:  1500 , loss:  0.018666564\n",
      "Iteration:  1600 , loss:  0.018327361\n",
      "Iteration:  1700 , loss:  0.017150478\n",
      "Iteration:  1800 , loss:  0.016524596\n",
      "Iteration:  1900 , loss:  0.015946278\n",
      "Iteration:  2000 , loss:  0.015331668\n",
      "Iteration:  2100 , loss:  0.014710557\n",
      "Iteration:  2200 , loss:  0.014064685\n",
      "Iteration:  2300 , loss:  0.013360074\n",
      "Iteration:  2400 , loss:  0.012629549\n",
      "Iteration:  2500 , loss:  0.011877128\n",
      "Iteration:  2600 , loss:  0.0111132795\n",
      "Iteration:  2700 , loss:  0.010484081\n",
      "Iteration:  2800 , loss:  0.009996808\n",
      "Iteration:  2900 , loss:  0.009610068\n",
      "Iteration:  3000 , loss:  0.0093895495\n",
      "Iteration:  3100 , loss:  0.008869251\n",
      "Iteration:  3200 , loss:  0.0085654585\n",
      "Iteration:  3300 , loss:  0.008289079\n",
      "Iteration:  3400 , loss:  0.008398781\n",
      "Iteration:  3500 , loss:  0.008549337\n",
      "Iteration:  3600 , loss:  0.0075224387\n",
      "Iteration:  3700 , loss:  0.0075825704\n",
      "Iteration:  3800 , loss:  0.007096747\n",
      "Iteration:  3900 , loss:  0.006883655\n",
      "Iteration:  4000 , loss:  0.0067049367\n",
      "Iteration:  4100 , loss:  0.0065646814\n",
      "Iteration:  4200 , loss:  0.0064000525\n",
      "Iteration:  4300 , loss:  0.0062483614\n",
      "Iteration:  4400 , loss:  0.0063420306\n",
      "Iteration:  4500 , loss:  0.0060034324\n",
      "Iteration:  4600 , loss:  0.0059464583\n",
      "Iteration:  4700 , loss:  0.005778932\n",
      "Iteration:  4800 , loss:  0.005691881\n",
      "Iteration:  4900 , loss:  0.005563473\n",
      "Iteration:  5000 , loss:  0.005594637\n",
      "Iteration:  5100 , loss:  0.005396854\n",
      "Iteration:  5200 , loss:  0.0052483166\n",
      "Iteration:  5300 , loss:  0.005142887\n",
      "Iteration:  5400 , loss:  0.0050323037\n",
      "Iteration:  5500 , loss:  0.005603273\n",
      "Iteration:  5600 , loss:  0.0048083914\n",
      "Iteration:  5700 , loss:  0.004698777\n",
      "Iteration:  5800 , loss:  0.004613801\n",
      "Iteration:  5900 , loss:  0.004538373\n",
      "Iteration:  6000 , loss:  0.0043634186\n",
      "Iteration:  6100 , loss:  0.004266225\n",
      "Iteration:  6200 , loss:  0.004284677\n",
      "Iteration:  6300 , loss:  0.005110787\n",
      "Iteration:  6400 , loss:  0.003931767\n",
      "Iteration:  6500 , loss:  0.0038322832\n",
      "Iteration:  6600 , loss:  0.0037291043\n",
      "Iteration:  6700 , loss:  0.0036218907\n",
      "Iteration:  6800 , loss:  0.0035293642\n",
      "Iteration:  6900 , loss:  0.0034254838\n",
      "Iteration:  7000 , loss:  0.0033482146\n",
      "Iteration:  7100 , loss:  0.0037786036\n",
      "Iteration:  7200 , loss:  0.0031555821\n",
      "Iteration:  7300 , loss:  0.0030699417\n",
      "Iteration:  7400 , loss:  0.002986257\n",
      "Iteration:  7500 , loss:  0.0029106084\n",
      "Iteration:  7600 , loss:  0.002887057\n",
      "Iteration:  7700 , loss:  0.0027682874\n",
      "Iteration:  7800 , loss:  0.0027004436\n",
      "Iteration:  7900 , loss:  0.0026396718\n",
      "Iteration:  8000 , loss:  0.0025756164\n",
      "Iteration:  8100 , loss:  0.0035917896\n",
      "Iteration:  8200 , loss:  0.0024599233\n",
      "Iteration:  8300 , loss:  0.002431427\n",
      "Iteration:  8400 , loss:  0.0023543611\n",
      "Iteration:  8500 , loss:  0.0023015125\n",
      "Iteration:  8600 , loss:  0.0022845794\n",
      "Iteration:  8700 , loss:  0.0022051907\n",
      "Iteration:  8800 , loss:  0.0021615343\n",
      "Iteration:  8900 , loss:  0.0021260325\n",
      "Iteration:  9000 , loss:  0.0020701215\n",
      "Iteration:  9100 , loss:  0.002236073\n",
      "Iteration:  9200 , loss:  0.0024289112\n",
      "Iteration:  9300 , loss:  0.0019452425\n",
      "Iteration:  9400 , loss:  0.002726016\n",
      "Iteration:  9500 , loss:  0.0018669246\n",
      "Iteration:  9600 , loss:  0.0018367564\n",
      "Iteration:  9700 , loss:  0.0017998382\n",
      "Iteration:  9800 , loss:  0.0017545642\n",
      "Iteration:  9900 , loss:  0.0019389752\n",
      "Iteration:  10000 , loss:  0.0016836302\n",
      "Iteration:  10100 , loss:  0.0016850531\n",
      "Iteration:  10200 , loss:  0.0016145468\n",
      "Iteration:  10300 , loss:  0.0015899966\n",
      "Iteration:  10400 , loss:  0.0030320683\n",
      "Iteration:  10500 , loss:  0.0015202855\n",
      "Iteration:  10600 , loss:  0.005736177\n",
      "Iteration:  10700 , loss:  0.0014779619\n",
      "Iteration:  10800 , loss:  0.0014351503\n",
      "Iteration:  10900 , loss:  0.0014102844\n",
      "Iteration:  11000 , loss:  0.00146048\n",
      "Iteration:  11100 , loss:  0.0013868127\n",
      "Iteration:  11200 , loss:  0.0013374893\n",
      "Iteration:  11300 , loss:  0.0013271181\n",
      "Iteration:  11400 , loss:  0.0012948005\n",
      "Iteration:  11500 , loss:  0.0013291726\n",
      "Iteration:  11600 , loss:  0.0013874201\n",
      "Iteration:  11700 , loss:  0.0014761013\n",
      "Iteration:  11800 , loss:  0.0012192848\n",
      "Iteration:  11900 , loss:  0.0012156721\n",
      "Iteration:  12000 , loss:  0.0012053694\n",
      "Iteration:  12100 , loss:  0.0033670238\n",
      "Iteration:  12200 , loss:  0.0011580625\n",
      "Iteration:  12300 , loss:  0.0011704061\n",
      "Iteration:  12400 , loss:  0.001131692\n",
      "Iteration:  12500 , loss:  0.0011375824\n",
      "Iteration:  12600 , loss:  0.0011082727\n",
      "Iteration:  12700 , loss:  0.0010971754\n",
      "Iteration:  12800 , loss:  0.001095983\n",
      "Iteration:  12900 , loss:  0.0010748095\n",
      "Iteration:  13000 , loss:  0.0010662308\n",
      "Iteration:  13100 , loss:  0.0018649995\n",
      "Iteration:  13200 , loss:  0.0010460297\n",
      "Iteration:  13300 , loss:  0.0010372235\n",
      "Iteration:  13400 , loss:  0.0010756876\n",
      "Iteration:  13500 , loss:  0.0010219314\n",
      "Iteration:  13600 , loss:  0.0010114046\n",
      "Iteration:  13700 , loss:  0.0010043444\n",
      "Iteration:  13800 , loss:  0.001012895\n",
      "Iteration:  13900 , loss:  0.0027757084\n",
      "Iteration:  14000 , loss:  0.0009810072\n",
      "Iteration:  14100 , loss:  0.0009774755\n",
      "Iteration:  14200 , loss:  0.0010464385\n",
      "Iteration:  14300 , loss:  0.00097522064\n",
      "Iteration:  14400 , loss:  0.0013250408\n",
      "Iteration:  14500 , loss:  0.0009715689\n",
      "Iteration:  14600 , loss:  0.0009513101\n",
      "Iteration:  14700 , loss:  0.0012515062\n",
      "Iteration:  14800 , loss:  0.0009573312\n",
      "Iteration:  14900 , loss:  0.000925087\n",
      "Iteration:  15000 , loss:  0.0009253999\n",
      "Iteration:  15100 , loss:  0.0009118081\n",
      "Iteration:  15200 , loss:  0.0009052743\n",
      "Iteration:  15300 , loss:  0.00090124103\n",
      "Iteration:  15400 , loss:  0.00089478464\n",
      "Iteration:  15500 , loss:  0.0009059379\n",
      "Iteration:  15600 , loss:  0.000883898\n",
      "Iteration:  15700 , loss:  0.0009261678\n",
      "Iteration:  15800 , loss:  0.00087391725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  15900 , loss:  0.0009267061\n",
      "Iteration:  16000 , loss:  0.0008646121\n",
      "Iteration:  16100 , loss:  0.00091078447\n",
      "Iteration:  16200 , loss:  0.0010110078\n",
      "Iteration:  16300 , loss:  0.002122438\n",
      "Iteration:  16400 , loss:  0.0008460784\n",
      "Iteration:  16500 , loss:  0.0017565179\n",
      "Iteration:  16600 , loss:  0.0008858213\n",
      "Iteration:  16700 , loss:  0.00083323976\n",
      "Iteration:  16800 , loss:  0.0024241689\n",
      "Iteration:  16900 , loss:  0.0008259666\n",
      "Iteration:  17000 , loss:  0.0008210591\n",
      "Iteration:  17100 , loss:  0.00083892455\n",
      "Iteration:  17200 , loss:  0.002452123\n",
      "Iteration:  17300 , loss:  0.0011913553\n",
      "Iteration:  17400 , loss:  0.00080575165\n",
      "Iteration:  17500 , loss:  0.0008361786\n",
      "Iteration:  17600 , loss:  0.0008534882\n",
      "Iteration:  17700 , loss:  0.00079520314\n",
      "Iteration:  17800 , loss:  0.00079303177\n",
      "Iteration:  17900 , loss:  0.00078832544\n",
      "Iteration:  18000 , loss:  0.00078563206\n",
      "Iteration:  18100 , loss:  0.0008898939\n",
      "Iteration:  18200 , loss:  0.0007788548\n",
      "Iteration:  18300 , loss:  0.00131374\n",
      "Iteration:  18400 , loss:  0.00077286444\n",
      "Iteration:  18500 , loss:  0.00084936124\n",
      "Iteration:  18600 , loss:  0.00076673954\n",
      "Iteration:  18700 , loss:  0.00076657615\n",
      "Iteration:  18800 , loss:  0.0007690388\n",
      "Iteration:  18900 , loss:  0.0012592351\n",
      "Iteration:  19000 , loss:  0.00075547816\n",
      "Iteration:  19100 , loss:  0.0007887258\n",
      "Iteration:  19200 , loss:  0.00075041945\n",
      "Iteration:  19300 , loss:  0.00093131745\n",
      "Iteration:  19400 , loss:  0.00074499357\n",
      "Iteration:  19500 , loss:  0.0007611815\n",
      "Iteration:  19600 , loss:  0.00073998165\n",
      "Iteration:  19700 , loss:  0.00073911645\n",
      "Iteration:  19800 , loss:  0.0007580689\n",
      "Iteration:  19900 , loss:  0.00073263096\n",
      "Generating 16th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.9932948\n",
      "Iteration:  100 , loss:  0.13783374\n",
      "Iteration:  200 , loss:  0.13580085\n",
      "Iteration:  300 , loss:  0.13265526\n",
      "Iteration:  400 , loss:  0.12688124\n",
      "Iteration:  500 , loss:  0.12052553\n",
      "Iteration:  600 , loss:  0.11371163\n",
      "Iteration:  700 , loss:  0.10592055\n",
      "Iteration:  800 , loss:  0.0930801\n",
      "Iteration:  900 , loss:  0.07994412\n",
      "Iteration:  1000 , loss:  0.071525775\n",
      "Iteration:  1100 , loss:  0.05772842\n",
      "Iteration:  1200 , loss:  0.050685782\n",
      "Iteration:  1300 , loss:  0.046923686\n",
      "Iteration:  1400 , loss:  0.04443737\n",
      "Iteration:  1500 , loss:  0.042588383\n",
      "Iteration:  1600 , loss:  0.040649075\n",
      "Iteration:  1700 , loss:  0.038787052\n",
      "Iteration:  1800 , loss:  0.037074357\n",
      "Iteration:  1900 , loss:  0.035555694\n",
      "Iteration:  2000 , loss:  0.033973496\n",
      "Iteration:  2100 , loss:  0.032253277\n",
      "Iteration:  2200 , loss:  0.030369103\n",
      "Iteration:  2300 , loss:  0.028649516\n",
      "Iteration:  2400 , loss:  0.026073003\n",
      "Iteration:  2500 , loss:  0.0243029\n",
      "Iteration:  2600 , loss:  0.02307682\n",
      "Iteration:  2700 , loss:  0.022621373\n",
      "Iteration:  2800 , loss:  0.021465667\n",
      "Iteration:  2900 , loss:  0.02160285\n",
      "Iteration:  3000 , loss:  0.020233307\n",
      "Iteration:  3100 , loss:  0.01961725\n",
      "Iteration:  3200 , loss:  0.018974893\n",
      "Iteration:  3300 , loss:  0.018307876\n",
      "Iteration:  3400 , loss:  0.017661462\n",
      "Iteration:  3500 , loss:  0.017106561\n",
      "Iteration:  3600 , loss:  0.016813152\n",
      "Iteration:  3700 , loss:  0.015713701\n",
      "Iteration:  3800 , loss:  0.015119038\n",
      "Iteration:  3900 , loss:  0.01455759\n",
      "Iteration:  4000 , loss:  0.013983689\n",
      "Iteration:  4100 , loss:  0.013462972\n",
      "Iteration:  4200 , loss:  0.012956683\n",
      "Iteration:  4300 , loss:  0.012489994\n",
      "Iteration:  4400 , loss:  0.013257728\n",
      "Iteration:  4500 , loss:  0.01164205\n",
      "Iteration:  4600 , loss:  0.011292796\n",
      "Iteration:  4700 , loss:  0.010992065\n",
      "Iteration:  4800 , loss:  0.010688983\n",
      "Iteration:  4900 , loss:  0.01084041\n",
      "Iteration:  5000 , loss:  0.010181771\n",
      "Iteration:  5100 , loss:  0.009960255\n",
      "Iteration:  5200 , loss:  0.009736538\n",
      "Iteration:  5300 , loss:  0.009525118\n",
      "Iteration:  5400 , loss:  0.009314839\n",
      "Iteration:  5500 , loss:  0.009103785\n",
      "Iteration:  5600 , loss:  0.008952012\n",
      "Iteration:  5700 , loss:  0.008725971\n",
      "Iteration:  5800 , loss:  0.009575743\n",
      "Iteration:  5900 , loss:  0.0082828915\n",
      "Iteration:  6000 , loss:  0.008004967\n",
      "Iteration:  6100 , loss:  0.0077575506\n",
      "Iteration:  6200 , loss:  0.007524983\n",
      "Iteration:  6300 , loss:  0.00779941\n",
      "Iteration:  6400 , loss:  0.0071546515\n",
      "Iteration:  6500 , loss:  0.0068499395\n",
      "Iteration:  6600 , loss:  0.006745833\n",
      "Iteration:  6700 , loss:  0.0066294833\n",
      "Iteration:  6800 , loss:  0.0063038124\n",
      "Iteration:  6900 , loss:  0.006145453\n",
      "Iteration:  7000 , loss:  0.0062146354\n",
      "Iteration:  7100 , loss:  0.005850354\n",
      "Iteration:  7200 , loss:  0.0057226736\n",
      "Iteration:  7300 , loss:  0.005622941\n",
      "Iteration:  7400 , loss:  0.0063574053\n",
      "Iteration:  7500 , loss:  0.005398438\n",
      "Iteration:  7600 , loss:  0.0054928977\n",
      "Iteration:  7700 , loss:  0.0055668056\n",
      "Iteration:  7800 , loss:  0.0051324144\n",
      "Iteration:  7900 , loss:  0.0050613657\n",
      "Iteration:  8000 , loss:  0.0049863085\n",
      "Iteration:  8100 , loss:  0.0049402653\n",
      "Iteration:  8200 , loss:  0.004862764\n",
      "Iteration:  8300 , loss:  0.0048046727\n",
      "Iteration:  8400 , loss:  0.0047465456\n",
      "Iteration:  8500 , loss:  0.0046985224\n",
      "Iteration:  8600 , loss:  0.0046522366\n",
      "Iteration:  8700 , loss:  0.0046010325\n",
      "Iteration:  8800 , loss:  0.0045577576\n",
      "Iteration:  8900 , loss:  0.0045916694\n",
      "Iteration:  9000 , loss:  0.0045229956\n",
      "Iteration:  9100 , loss:  0.0044331755\n",
      "Iteration:  9200 , loss:  0.004395486\n",
      "Iteration:  9300 , loss:  0.0044705183\n",
      "Iteration:  9400 , loss:  0.004324641\n",
      "Iteration:  9500 , loss:  0.004285824\n",
      "Iteration:  9600 , loss:  0.0042761005\n",
      "Iteration:  9700 , loss:  0.004215045\n",
      "Iteration:  9800 , loss:  0.0041822167\n",
      "Iteration:  9900 , loss:  0.004756711\n",
      "Iteration:  10000 , loss:  0.00411591\n",
      "Iteration:  10100 , loss:  0.0040850947\n",
      "Iteration:  10200 , loss:  0.004419052\n",
      "Iteration:  10300 , loss:  0.004532125\n",
      "Iteration:  10400 , loss:  0.003990298\n",
      "Iteration:  10500 , loss:  0.004236839\n",
      "Iteration:  10600 , loss:  0.0040512783\n",
      "Iteration:  10700 , loss:  0.0042511276\n",
      "Iteration:  10800 , loss:  0.0038718814\n",
      "Iteration:  10900 , loss:  0.003844414\n",
      "Iteration:  11000 , loss:  0.003825009\n",
      "Iteration:  11100 , loss:  0.0038054648\n",
      "Iteration:  11200 , loss:  0.0040095574\n",
      "Iteration:  11300 , loss:  0.0037559008\n",
      "Iteration:  11400 , loss:  0.0037182337\n",
      "Iteration:  11500 , loss:  0.0036790362\n",
      "Iteration:  11600 , loss:  0.0036448268\n",
      "Iteration:  11700 , loss:  0.003631968\n",
      "Iteration:  11800 , loss:  0.0035899077\n",
      "Iteration:  11900 , loss:  0.0048962506\n",
      "Iteration:  12000 , loss:  0.004055906\n",
      "Iteration:  12100 , loss:  0.0035073576\n",
      "Iteration:  12200 , loss:  0.0039121173\n",
      "Iteration:  12300 , loss:  0.0034848377\n",
      "Iteration:  12400 , loss:  0.003424049\n",
      "Iteration:  12500 , loss:  0.0034534214\n",
      "Iteration:  12600 , loss:  0.005497667\n",
      "Iteration:  12700 , loss:  0.0033434583\n",
      "Iteration:  12800 , loss:  0.0035611033\n",
      "Iteration:  12900 , loss:  0.0032824052\n",
      "Iteration:  13000 , loss:  0.0032668088\n",
      "Iteration:  13100 , loss:  0.0032232336\n",
      "Iteration:  13200 , loss:  0.0032018018\n",
      "Iteration:  13300 , loss:  0.0031835213\n",
      "Iteration:  13400 , loss:  0.003133111\n",
      "Iteration:  13500 , loss:  0.0031048153\n",
      "Iteration:  13600 , loss:  0.0030730488\n",
      "Iteration:  13700 , loss:  0.0038847947\n",
      "Iteration:  13800 , loss:  0.0030459785\n",
      "Iteration:  13900 , loss:  0.0029757696\n",
      "Iteration:  14000 , loss:  0.0029430732\n",
      "Iteration:  14100 , loss:  0.002914561\n",
      "Iteration:  14200 , loss:  0.0029638896\n",
      "Iteration:  14300 , loss:  0.0028438233\n",
      "Iteration:  14400 , loss:  0.0039081657\n",
      "Iteration:  14500 , loss:  0.002777531\n",
      "Iteration:  14600 , loss:  0.0027992546\n",
      "Iteration:  14700 , loss:  0.0027250366\n",
      "Iteration:  14800 , loss:  0.005653944\n",
      "Iteration:  14900 , loss:  0.002688955\n",
      "Iteration:  15000 , loss:  0.0026128897\n",
      "Iteration:  15100 , loss:  0.0025806057\n",
      "Iteration:  15200 , loss:  0.0027236505\n",
      "Iteration:  15300 , loss:  0.0025273862\n",
      "Iteration:  15400 , loss:  0.0028744307\n",
      "Iteration:  15500 , loss:  0.002459784\n",
      "Iteration:  15600 , loss:  0.002422797\n",
      "Iteration:  15700 , loss:  0.0023898054\n",
      "Iteration:  15800 , loss:  0.0024439106\n",
      "Iteration:  15900 , loss:  0.0025564653\n",
      "Iteration:  16000 , loss:  0.0022979877\n",
      "Iteration:  16100 , loss:  0.0023358203\n",
      "Iteration:  16200 , loss:  0.002260078\n",
      "Iteration:  16300 , loss:  0.0051942063\n",
      "Iteration:  16400 , loss:  0.002316914\n",
      "Iteration:  16500 , loss:  0.0023131403\n",
      "Iteration:  16600 , loss:  0.0021258614\n",
      "Iteration:  16700 , loss:  0.0021231363\n",
      "Iteration:  16800 , loss:  0.0020841514\n",
      "Iteration:  16900 , loss:  0.0030505867\n",
      "Iteration:  17000 , loss:  0.0020288355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  17100 , loss:  0.0019998853\n",
      "Iteration:  17200 , loss:  0.002079042\n",
      "Iteration:  17300 , loss:  0.001957662\n",
      "Iteration:  17400 , loss:  0.0019344008\n",
      "Iteration:  17500 , loss:  0.003768594\n",
      "Iteration:  17600 , loss:  0.0018945264\n",
      "Iteration:  17700 , loss:  0.002107859\n",
      "Iteration:  17800 , loss:  0.0018567429\n",
      "Iteration:  17900 , loss:  0.001845723\n",
      "Iteration:  18000 , loss:  0.0018226096\n",
      "Iteration:  18100 , loss:  0.0018064389\n",
      "Iteration:  18200 , loss:  0.0019080138\n",
      "Iteration:  18300 , loss:  0.0017753548\n",
      "Iteration:  18400 , loss:  0.0017995293\n",
      "Iteration:  18500 , loss:  0.0048089265\n",
      "Iteration:  18600 , loss:  0.0017324782\n",
      "Iteration:  18700 , loss:  0.0017228923\n",
      "Iteration:  18800 , loss:  0.0017060563\n",
      "Iteration:  18900 , loss:  0.00169511\n",
      "Iteration:  19000 , loss:  0.0017393013\n",
      "Iteration:  19100 , loss:  0.0016695719\n",
      "Iteration:  19200 , loss:  0.0016589029\n",
      "Iteration:  19300 , loss:  0.0017305885\n",
      "Iteration:  19400 , loss:  0.0016557499\n",
      "Iteration:  19500 , loss:  0.0016256772\n",
      "Iteration:  19600 , loss:  0.0017856397\n",
      "Iteration:  19700 , loss:  0.0016664687\n",
      "Iteration:  19800 , loss:  0.0015955354\n",
      "Iteration:  19900 , loss:  0.0016017497\n",
      "Generating 17th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.23276693\n",
      "Iteration:  100 , loss:  0.13724643\n",
      "Iteration:  200 , loss:  0.12565824\n",
      "Iteration:  300 , loss:  0.11075196\n",
      "Iteration:  400 , loss:  0.08804181\n",
      "Iteration:  500 , loss:  0.05929759\n",
      "Iteration:  600 , loss:  0.04765941\n",
      "Iteration:  700 , loss:  0.04229793\n",
      "Iteration:  800 , loss:  0.03733689\n",
      "Iteration:  900 , loss:  0.03407857\n",
      "Iteration:  1000 , loss:  0.031237975\n",
      "Iteration:  1100 , loss:  0.028939346\n",
      "Iteration:  1200 , loss:  0.027027097\n",
      "Iteration:  1300 , loss:  0.0258294\n",
      "Iteration:  1400 , loss:  0.024669832\n",
      "Iteration:  1500 , loss:  0.023565523\n",
      "Iteration:  1600 , loss:  0.022733523\n",
      "Iteration:  1700 , loss:  0.021986274\n",
      "Iteration:  1800 , loss:  0.021484468\n",
      "Iteration:  1900 , loss:  0.020815\n",
      "Iteration:  2000 , loss:  0.020525688\n",
      "Iteration:  2100 , loss:  0.020285308\n",
      "Iteration:  2200 , loss:  0.018902173\n",
      "Iteration:  2300 , loss:  0.019217623\n",
      "Iteration:  2400 , loss:  0.017716737\n",
      "Iteration:  2500 , loss:  0.017176343\n",
      "Iteration:  2600 , loss:  0.017126005\n",
      "Iteration:  2700 , loss:  0.016033435\n",
      "Iteration:  2800 , loss:  0.015480408\n",
      "Iteration:  2900 , loss:  0.014956552\n",
      "Iteration:  3000 , loss:  0.014394547\n",
      "Iteration:  3100 , loss:  0.013852535\n",
      "Iteration:  3200 , loss:  0.013595125\n",
      "Iteration:  3300 , loss:  0.012896153\n",
      "Iteration:  3400 , loss:  0.012313736\n",
      "Iteration:  3500 , loss:  0.011796468\n",
      "Iteration:  3600 , loss:  0.011329795\n",
      "Iteration:  3700 , loss:  0.010903025\n",
      "Iteration:  3800 , loss:  0.010508229\n",
      "Iteration:  3900 , loss:  0.010149368\n",
      "Iteration:  4000 , loss:  0.009829203\n",
      "Iteration:  4100 , loss:  0.0095429085\n",
      "Iteration:  4200 , loss:  0.009289872\n",
      "Iteration:  4300 , loss:  0.009075021\n",
      "Iteration:  4400 , loss:  0.008867278\n",
      "Iteration:  4500 , loss:  0.0086848885\n",
      "Iteration:  4600 , loss:  0.008520994\n",
      "Iteration:  4700 , loss:  0.008605911\n",
      "Iteration:  4800 , loss:  0.008378622\n",
      "Iteration:  4900 , loss:  0.008157729\n",
      "Iteration:  5000 , loss:  0.008025609\n",
      "Iteration:  5100 , loss:  0.007921565\n",
      "Iteration:  5200 , loss:  0.00780631\n",
      "Iteration:  5300 , loss:  0.0076442985\n",
      "Iteration:  5400 , loss:  0.007610272\n",
      "Iteration:  5500 , loss:  0.0074605877\n",
      "Iteration:  5600 , loss:  0.007361477\n",
      "Iteration:  5700 , loss:  0.0072751744\n",
      "Iteration:  5800 , loss:  0.0071938904\n",
      "Iteration:  5900 , loss:  0.008348482\n",
      "Iteration:  6000 , loss:  0.007138752\n",
      "Iteration:  6100 , loss:  0.0069519966\n",
      "Iteration:  6200 , loss:  0.0071841497\n",
      "Iteration:  6300 , loss:  0.006802926\n",
      "Iteration:  6400 , loss:  0.0067349263\n",
      "Iteration:  6500 , loss:  0.0066902656\n",
      "Iteration:  6600 , loss:  0.0065852776\n",
      "Iteration:  6700 , loss:  0.0065174554\n",
      "Iteration:  6800 , loss:  0.0064461133\n",
      "Iteration:  6900 , loss:  0.0063733566\n",
      "Iteration:  7000 , loss:  0.0063111926\n",
      "Iteration:  7100 , loss:  0.0062390743\n",
      "Iteration:  7200 , loss:  0.006165484\n",
      "Iteration:  7300 , loss:  0.006101988\n",
      "Iteration:  7400 , loss:  0.006034863\n",
      "Iteration:  7500 , loss:  0.0059655504\n",
      "Iteration:  7600 , loss:  0.006079112\n",
      "Iteration:  7700 , loss:  0.0058392994\n",
      "Iteration:  7800 , loss:  0.005786578\n",
      "Iteration:  7900 , loss:  0.0057349363\n",
      "Iteration:  8000 , loss:  0.005662216\n",
      "Iteration:  8100 , loss:  0.005676922\n",
      "Iteration:  8200 , loss:  0.005554797\n",
      "Iteration:  8300 , loss:  0.0055236993\n",
      "Iteration:  8400 , loss:  0.005454215\n",
      "Iteration:  8500 , loss:  0.005404377\n",
      "Iteration:  8600 , loss:  0.005358545\n",
      "Iteration:  8700 , loss:  0.0053099394\n",
      "Iteration:  8800 , loss:  0.006059053\n",
      "Iteration:  8900 , loss:  0.005351516\n",
      "Iteration:  9000 , loss:  0.005176775\n",
      "Iteration:  9100 , loss:  0.005188635\n",
      "Iteration:  9200 , loss:  0.005092062\n",
      "Iteration:  9300 , loss:  0.005052907\n",
      "Iteration:  9400 , loss:  0.0050114733\n",
      "Iteration:  9500 , loss:  0.0050396873\n",
      "Iteration:  9600 , loss:  0.0049324823\n",
      "Iteration:  9700 , loss:  0.004893258\n",
      "Iteration:  9800 , loss:  0.004873353\n",
      "Iteration:  9900 , loss:  0.0052138097\n",
      "Iteration:  10000 , loss:  0.004777502\n",
      "Iteration:  10100 , loss:  0.0047406657\n",
      "Iteration:  10200 , loss:  0.0047055436\n",
      "Iteration:  10300 , loss:  0.0069037443\n",
      "Iteration:  10400 , loss:  0.0046296697\n",
      "Iteration:  10500 , loss:  0.0045901258\n",
      "Iteration:  10600 , loss:  0.004744604\n",
      "Iteration:  10700 , loss:  0.0045158714\n",
      "Iteration:  10800 , loss:  0.004488279\n",
      "Iteration:  10900 , loss:  0.0044406066\n",
      "Iteration:  11000 , loss:  0.0044065267\n",
      "Iteration:  11100 , loss:  0.004366182\n",
      "Iteration:  11200 , loss:  0.004514491\n",
      "Iteration:  11300 , loss:  0.004291433\n",
      "Iteration:  11400 , loss:  0.004327228\n",
      "Iteration:  11500 , loss:  0.0042128144\n",
      "Iteration:  11600 , loss:  0.0051197885\n",
      "Iteration:  11700 , loss:  0.004133449\n",
      "Iteration:  11800 , loss:  0.0041143643\n",
      "Iteration:  11900 , loss:  0.004051163\n",
      "Iteration:  12000 , loss:  0.0040239864\n",
      "Iteration:  12100 , loss:  0.003969764\n",
      "Iteration:  12200 , loss:  0.0039826958\n",
      "Iteration:  12300 , loss:  0.003919941\n",
      "Iteration:  12400 , loss:  0.0038443054\n",
      "Iteration:  12500 , loss:  0.0038043219\n",
      "Iteration:  12600 , loss:  0.0037604286\n",
      "Iteration:  12700 , loss:  0.0037183587\n",
      "Iteration:  12800 , loss:  0.0036770746\n",
      "Iteration:  12900 , loss:  0.003959821\n",
      "Iteration:  13000 , loss:  0.0035907007\n",
      "Iteration:  13100 , loss:  0.0035501919\n",
      "Iteration:  13200 , loss:  0.0035279181\n",
      "Iteration:  13300 , loss:  0.003711469\n",
      "Iteration:  13400 , loss:  0.004131982\n",
      "Iteration:  13500 , loss:  0.003383417\n",
      "Iteration:  13600 , loss:  0.003341706\n",
      "Iteration:  13700 , loss:  0.0033045246\n",
      "Iteration:  13800 , loss:  0.0032649606\n",
      "Iteration:  13900 , loss:  0.0032226564\n",
      "Iteration:  14000 , loss:  0.0031877314\n",
      "Iteration:  14100 , loss:  0.0031494803\n",
      "Iteration:  14200 , loss:  0.0031118502\n",
      "Iteration:  14300 , loss:  0.0030805836\n",
      "Iteration:  14400 , loss:  0.0030576123\n",
      "Iteration:  14500 , loss:  0.0030076262\n",
      "Iteration:  14600 , loss:  0.0029797466\n",
      "Iteration:  14700 , loss:  0.0031897293\n",
      "Iteration:  14800 , loss:  0.0029111158\n",
      "Iteration:  14900 , loss:  0.0028894206\n",
      "Iteration:  15000 , loss:  0.0028515903\n",
      "Iteration:  15100 , loss:  0.0028210224\n",
      "Iteration:  15200 , loss:  0.0043840082\n",
      "Iteration:  15300 , loss:  0.00276551\n",
      "Iteration:  15400 , loss:  0.0027404344\n",
      "Iteration:  15500 , loss:  0.005073051\n",
      "Iteration:  15600 , loss:  0.002687975\n",
      "Iteration:  15700 , loss:  0.0033781491\n",
      "Iteration:  15800 , loss:  0.0027283016\n",
      "Iteration:  15900 , loss:  0.0026164628\n",
      "Iteration:  16000 , loss:  0.002595987\n",
      "Iteration:  16100 , loss:  0.0025766985\n",
      "Iteration:  16200 , loss:  0.0025508124\n",
      "Iteration:  16300 , loss:  0.0025443921\n",
      "Iteration:  16400 , loss:  0.002540872\n",
      "Iteration:  16500 , loss:  0.002488338\n",
      "Iteration:  16600 , loss:  0.002516048\n",
      "Iteration:  16700 , loss:  0.0024486384\n",
      "Iteration:  16800 , loss:  0.0024749376\n",
      "Iteration:  16900 , loss:  0.002492608\n",
      "Iteration:  17000 , loss:  0.0023920643\n",
      "Iteration:  17100 , loss:  0.0023969454\n",
      "Iteration:  17200 , loss:  0.0023606229\n",
      "Iteration:  17300 , loss:  0.0023447487\n",
      "Iteration:  17400 , loss:  0.0023193\n",
      "Iteration:  17500 , loss:  0.005505668\n",
      "Iteration:  17600 , loss:  0.006208451\n",
      "Iteration:  17700 , loss:  0.0022658734\n",
      "Iteration:  17800 , loss:  0.0022583832\n",
      "Iteration:  17900 , loss:  0.0022319234\n",
      "Iteration:  18000 , loss:  0.002274671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  18100 , loss:  0.002430301\n",
      "Iteration:  18200 , loss:  0.002179034\n",
      "Iteration:  18300 , loss:  0.002180757\n",
      "Iteration:  18400 , loss:  0.0021447097\n",
      "Iteration:  18500 , loss:  0.0021336584\n",
      "Iteration:  18600 , loss:  0.0023389235\n",
      "Iteration:  18700 , loss:  0.0020935934\n",
      "Iteration:  18800 , loss:  0.0031551588\n",
      "Iteration:  18900 , loss:  0.0020595426\n",
      "Iteration:  19000 , loss:  0.0020504277\n",
      "Iteration:  19100 , loss:  0.0024075303\n",
      "Iteration:  19200 , loss:  0.0020080036\n",
      "Iteration:  19300 , loss:  0.0025714505\n",
      "Iteration:  19400 , loss:  0.002117264\n",
      "Iteration:  19500 , loss:  0.0019562682\n",
      "Iteration:  19600 , loss:  0.0019664154\n",
      "Iteration:  19700 , loss:  0.0019215953\n",
      "Iteration:  19800 , loss:  0.0019046149\n",
      "Iteration:  19900 , loss:  0.0018884968\n",
      "Generating 18th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.2704936\n",
      "Iteration:  100 , loss:  0.13813828\n",
      "Iteration:  200 , loss:  0.12506497\n",
      "Iteration:  300 , loss:  0.1105999\n",
      "Iteration:  400 , loss:  0.094017506\n",
      "Iteration:  500 , loss:  0.077608876\n",
      "Iteration:  600 , loss:  0.054039724\n",
      "Iteration:  700 , loss:  0.045326285\n",
      "Iteration:  800 , loss:  0.03919556\n",
      "Iteration:  900 , loss:  0.035336334\n",
      "Iteration:  1000 , loss:  0.03312851\n",
      "Iteration:  1100 , loss:  0.030957112\n",
      "Iteration:  1200 , loss:  0.028967885\n",
      "Iteration:  1300 , loss:  0.02748333\n",
      "Iteration:  1400 , loss:  0.025671164\n",
      "Iteration:  1500 , loss:  0.024478104\n",
      "Iteration:  1600 , loss:  0.02358953\n",
      "Iteration:  1700 , loss:  0.02245171\n",
      "Iteration:  1800 , loss:  0.021429243\n",
      "Iteration:  1900 , loss:  0.020725084\n",
      "Iteration:  2000 , loss:  0.020499293\n",
      "Iteration:  2100 , loss:  0.018585216\n",
      "Iteration:  2200 , loss:  0.017457968\n",
      "Iteration:  2300 , loss:  0.016350072\n",
      "Iteration:  2400 , loss:  0.015407313\n",
      "Iteration:  2500 , loss:  0.015603362\n",
      "Iteration:  2600 , loss:  0.01375703\n",
      "Iteration:  2700 , loss:  0.01303193\n",
      "Iteration:  2800 , loss:  0.014364864\n",
      "Iteration:  2900 , loss:  0.011684403\n",
      "Iteration:  3000 , loss:  0.011095701\n",
      "Iteration:  3100 , loss:  0.010582861\n",
      "Iteration:  3200 , loss:  0.010778196\n",
      "Iteration:  3300 , loss:  0.0099465605\n",
      "Iteration:  3400 , loss:  0.009308422\n",
      "Iteration:  3500 , loss:  0.008984601\n",
      "Iteration:  3600 , loss:  0.008855854\n",
      "Iteration:  3700 , loss:  0.0083157\n",
      "Iteration:  3800 , loss:  0.008010527\n",
      "Iteration:  3900 , loss:  0.00783973\n",
      "Iteration:  4000 , loss:  0.009281704\n",
      "Iteration:  4100 , loss:  0.0071323086\n",
      "Iteration:  4200 , loss:  0.006960026\n",
      "Iteration:  4300 , loss:  0.007091216\n",
      "Iteration:  4400 , loss:  0.0063355635\n",
      "Iteration:  4500 , loss:  0.0060976576\n",
      "Iteration:  4600 , loss:  0.005960561\n",
      "Iteration:  4700 , loss:  0.005659053\n",
      "Iteration:  4800 , loss:  0.005476503\n",
      "Iteration:  4900 , loss:  0.0053862664\n",
      "Iteration:  5000 , loss:  0.006030906\n",
      "Iteration:  5100 , loss:  0.004996299\n",
      "Iteration:  5200 , loss:  0.0048513766\n",
      "Iteration:  5300 , loss:  0.004722185\n",
      "Iteration:  5400 , loss:  0.004616507\n",
      "Iteration:  5500 , loss:  0.004472404\n",
      "Iteration:  5600 , loss:  0.0043706456\n",
      "Iteration:  5700 , loss:  0.0042518307\n",
      "Iteration:  5800 , loss:  0.0041522156\n",
      "Iteration:  5900 , loss:  0.004058382\n",
      "Iteration:  6000 , loss:  0.004933011\n",
      "Iteration:  6100 , loss:  0.0038858717\n",
      "Iteration:  6200 , loss:  0.0038070576\n",
      "Iteration:  6300 , loss:  0.003729802\n",
      "Iteration:  6400 , loss:  0.0036612584\n",
      "Iteration:  6500 , loss:  0.0035955324\n",
      "Iteration:  6600 , loss:  0.0035300292\n",
      "Iteration:  6700 , loss:  0.0034722202\n",
      "Iteration:  6800 , loss:  0.0052217366\n",
      "Iteration:  6900 , loss:  0.0033584207\n",
      "Iteration:  7000 , loss:  0.003309553\n",
      "Iteration:  7100 , loss:  0.0032639592\n",
      "Iteration:  7200 , loss:  0.0033626696\n",
      "Iteration:  7300 , loss:  0.0032044237\n",
      "Iteration:  7400 , loss:  0.003238756\n",
      "Iteration:  7500 , loss:  0.0031340418\n",
      "Iteration:  7600 , loss:  0.0035047778\n",
      "Iteration:  7700 , loss:  0.003038573\n",
      "Iteration:  7800 , loss:  0.0033399083\n",
      "Iteration:  7900 , loss:  0.0029903217\n",
      "Iteration:  8000 , loss:  0.0029415016\n",
      "Iteration:  8100 , loss:  0.0050200457\n",
      "Iteration:  8200 , loss:  0.0028743893\n",
      "Iteration:  8300 , loss:  0.0028463658\n",
      "Iteration:  8400 , loss:  0.0028184967\n",
      "Iteration:  8500 , loss:  0.0027980339\n",
      "Iteration:  8600 , loss:  0.0027687594\n",
      "Iteration:  8700 , loss:  0.0028059536\n",
      "Iteration:  8800 , loss:  0.0027845183\n",
      "Iteration:  8900 , loss:  0.0027571367\n",
      "Iteration:  9000 , loss:  0.0027331393\n",
      "Iteration:  9100 , loss:  0.0026525774\n",
      "Iteration:  9200 , loss:  0.0026290473\n",
      "Iteration:  9300 , loss:  0.0026076261\n",
      "Iteration:  9400 , loss:  0.00258696\n",
      "Iteration:  9500 , loss:  0.0025641106\n",
      "Iteration:  9600 , loss:  0.0025487703\n",
      "Iteration:  9700 , loss:  0.0026991195\n",
      "Iteration:  9800 , loss:  0.0025002172\n",
      "Iteration:  9900 , loss:  0.002696969\n",
      "Iteration:  10000 , loss:  0.0024588797\n",
      "Iteration:  10100 , loss:  0.0040104785\n",
      "Iteration:  10200 , loss:  0.002416436\n",
      "Iteration:  10300 , loss:  0.0024575978\n",
      "Iteration:  10400 , loss:  0.0023788738\n",
      "Iteration:  10500 , loss:  0.0023562065\n",
      "Iteration:  10600 , loss:  0.002339921\n",
      "Iteration:  10700 , loss:  0.0023142016\n",
      "Iteration:  10800 , loss:  0.0023188537\n",
      "Iteration:  10900 , loss:  0.0025285135\n",
      "Iteration:  11000 , loss:  0.002253831\n",
      "Iteration:  11100 , loss:  0.0022360273\n",
      "Iteration:  11200 , loss:  0.0025133402\n",
      "Iteration:  11300 , loss:  0.0021944465\n",
      "Iteration:  11400 , loss:  0.002189025\n",
      "Iteration:  11500 , loss:  0.002155351\n",
      "Iteration:  11600 , loss:  0.0021365748\n",
      "Iteration:  11700 , loss:  0.0025232688\n",
      "Iteration:  11800 , loss:  0.002097723\n",
      "Iteration:  11900 , loss:  0.0022757566\n",
      "Iteration:  12000 , loss:  0.0022951406\n",
      "Iteration:  12100 , loss:  0.0020399014\n",
      "Iteration:  12200 , loss:  0.0034902387\n",
      "Iteration:  12300 , loss:  0.0027446533\n",
      "Iteration:  12400 , loss:  0.001982879\n",
      "Iteration:  12500 , loss:  0.0020683021\n",
      "Iteration:  12600 , loss:  0.0019920194\n",
      "Iteration:  12700 , loss:  0.0019273155\n",
      "Iteration:  12800 , loss:  0.0019106605\n",
      "Iteration:  12900 , loss:  0.0018914342\n",
      "Iteration:  13000 , loss:  0.0018879267\n",
      "Iteration:  13100 , loss:  0.0018798232\n",
      "Iteration:  13200 , loss:  0.0035115872\n",
      "Iteration:  13300 , loss:  0.0032611373\n",
      "Iteration:  13400 , loss:  0.0018062866\n",
      "Iteration:  13500 , loss:  0.001803065\n",
      "Iteration:  13600 , loss:  0.0018120857\n",
      "Iteration:  13700 , loss:  0.001759449\n",
      "Iteration:  13800 , loss:  0.001747303\n",
      "Iteration:  13900 , loss:  0.0018009292\n",
      "Iteration:  14000 , loss:  0.0017157131\n",
      "Iteration:  14100 , loss:  0.0017074342\n",
      "Iteration:  14200 , loss:  0.001703009\n",
      "Iteration:  14300 , loss:  0.0016796379\n",
      "Iteration:  14400 , loss:  0.0016623343\n",
      "Iteration:  14500 , loss:  0.0016494257\n",
      "Iteration:  14600 , loss:  0.0023302415\n",
      "Iteration:  14700 , loss:  0.0018630587\n",
      "Iteration:  14800 , loss:  0.0016120693\n",
      "Iteration:  14900 , loss:  0.0016272407\n",
      "Iteration:  15000 , loss:  0.0015958331\n",
      "Iteration:  15100 , loss:  0.0018244002\n",
      "Iteration:  15200 , loss:  0.0015684902\n",
      "Iteration:  15300 , loss:  0.0019086625\n",
      "Iteration:  15400 , loss:  0.0016287339\n",
      "Iteration:  15500 , loss:  0.0015338061\n",
      "Iteration:  15600 , loss:  0.0015308111\n",
      "Iteration:  15700 , loss:  0.0018726324\n",
      "Iteration:  15800 , loss:  0.0026318403\n",
      "Iteration:  15900 , loss:  0.0014931916\n",
      "Iteration:  16000 , loss:  0.0027480351\n",
      "Iteration:  16100 , loss:  0.0016624898\n",
      "Iteration:  16200 , loss:  0.0014637036\n",
      "Iteration:  16300 , loss:  0.0014542441\n",
      "Iteration:  16400 , loss:  0.0014554975\n",
      "Iteration:  16500 , loss:  0.0014548708\n",
      "Iteration:  16600 , loss:  0.0014252369\n",
      "Iteration:  16700 , loss:  0.0014168225\n",
      "Iteration:  16800 , loss:  0.0014146833\n",
      "Iteration:  16900 , loss:  0.0013973507\n",
      "Iteration:  17000 , loss:  0.001391038\n",
      "Iteration:  17100 , loss:  0.0013918625\n",
      "Iteration:  17200 , loss:  0.0013700555\n",
      "Iteration:  17300 , loss:  0.0013611778\n",
      "Iteration:  17400 , loss:  0.0013775559\n",
      "Iteration:  17500 , loss:  0.0040573664\n",
      "Iteration:  17600 , loss:  0.0013338581\n",
      "Iteration:  17700 , loss:  0.0014775286\n",
      "Iteration:  17800 , loss:  0.0013335653\n",
      "Iteration:  17900 , loss:  0.0013063855\n",
      "Iteration:  18000 , loss:  0.001307281\n",
      "Iteration:  18100 , loss:  0.0012942378\n",
      "Iteration:  18200 , loss:  0.0014528609\n",
      "Iteration:  18300 , loss:  0.001294862\n",
      "Iteration:  18400 , loss:  0.0012608538\n",
      "Iteration:  18500 , loss:  0.0012556455\n",
      "Iteration:  18600 , loss:  0.0012435218\n",
      "Iteration:  18700 , loss:  0.0012392703\n",
      "Iteration:  18800 , loss:  0.0012243161\n",
      "Iteration:  18900 , loss:  0.0012667105\n",
      "Iteration:  19000 , loss:  0.0012055648\n",
      "Iteration:  19100 , loss:  0.0011963089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  19200 , loss:  0.0011878574\n",
      "Iteration:  19300 , loss:  0.0013041178\n",
      "Iteration:  19400 , loss:  0.0022402601\n",
      "Iteration:  19500 , loss:  0.0011588954\n",
      "Iteration:  19600 , loss:  0.0011617441\n",
      "Iteration:  19700 , loss:  0.0012595964\n",
      "Iteration:  19800 , loss:  0.0011421358\n",
      "Iteration:  19900 , loss:  0.0011216939\n",
      "Generating 19th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.24592707\n",
      "Iteration:  100 , loss:  0.13797694\n",
      "Iteration:  200 , loss:  0.1306599\n",
      "Iteration:  300 , loss:  0.11763199\n",
      "Iteration:  400 , loss:  0.09593147\n",
      "Iteration:  500 , loss:  0.070917845\n",
      "Iteration:  600 , loss:  0.054905105\n",
      "Iteration:  700 , loss:  0.04759116\n",
      "Iteration:  800 , loss:  0.043794964\n",
      "Iteration:  900 , loss:  0.041125186\n",
      "Iteration:  1000 , loss:  0.03777674\n",
      "Iteration:  1100 , loss:  0.03554207\n",
      "Iteration:  1200 , loss:  0.033384778\n",
      "Iteration:  1300 , loss:  0.031202506\n",
      "Iteration:  1400 , loss:  0.028903779\n",
      "Iteration:  1500 , loss:  0.026330352\n",
      "Iteration:  1600 , loss:  0.02404023\n",
      "Iteration:  1700 , loss:  0.022540577\n",
      "Iteration:  1800 , loss:  0.021367157\n",
      "Iteration:  1900 , loss:  0.020233346\n",
      "Iteration:  2000 , loss:  0.019205598\n",
      "Iteration:  2100 , loss:  0.01810265\n",
      "Iteration:  2200 , loss:  0.017889285\n",
      "Iteration:  2300 , loss:  0.0162445\n",
      "Iteration:  2400 , loss:  0.01520003\n",
      "Iteration:  2500 , loss:  0.014424278\n",
      "Iteration:  2600 , loss:  0.013248451\n",
      "Iteration:  2700 , loss:  0.012179839\n",
      "Iteration:  2800 , loss:  0.0110993795\n",
      "Iteration:  2900 , loss:  0.010139727\n",
      "Iteration:  3000 , loss:  0.010119405\n",
      "Iteration:  3100 , loss:  0.008885789\n",
      "Iteration:  3200 , loss:  0.0084773665\n",
      "Iteration:  3300 , loss:  0.008051211\n",
      "Iteration:  3400 , loss:  0.0078253765\n",
      "Iteration:  3500 , loss:  0.007393043\n",
      "Iteration:  3600 , loss:  0.0073033837\n",
      "Iteration:  3700 , loss:  0.006728376\n",
      "Iteration:  3800 , loss:  0.006403129\n",
      "Iteration:  3900 , loss:  0.0062301913\n",
      "Iteration:  4000 , loss:  0.0058099157\n",
      "Iteration:  4100 , loss:  0.005576615\n",
      "Iteration:  4200 , loss:  0.0053844587\n",
      "Iteration:  4300 , loss:  0.0052381745\n",
      "Iteration:  4400 , loss:  0.0050753253\n",
      "Iteration:  4500 , loss:  0.0049524964\n",
      "Iteration:  4600 , loss:  0.004913466\n",
      "Iteration:  4700 , loss:  0.0047620186\n",
      "Iteration:  4800 , loss:  0.0046212263\n",
      "Iteration:  4900 , loss:  0.0045255977\n",
      "Iteration:  5000 , loss:  0.00443001\n",
      "Iteration:  5100 , loss:  0.0044237114\n",
      "Iteration:  5200 , loss:  0.004252582\n",
      "Iteration:  5300 , loss:  0.004171352\n",
      "Iteration:  5400 , loss:  0.0040960563\n",
      "Iteration:  5500 , loss:  0.0040248996\n",
      "Iteration:  5600 , loss:  0.0039493227\n",
      "Iteration:  5700 , loss:  0.0038805988\n",
      "Iteration:  5800 , loss:  0.0038140719\n",
      "Iteration:  5900 , loss:  0.0037502372\n",
      "Iteration:  6000 , loss:  0.0039059406\n",
      "Iteration:  6100 , loss:  0.0036241561\n",
      "Iteration:  6200 , loss:  0.003569149\n",
      "Iteration:  6300 , loss:  0.003500836\n",
      "Iteration:  6400 , loss:  0.0034409654\n",
      "Iteration:  6500 , loss:  0.0033886728\n",
      "Iteration:  6600 , loss:  0.0033179424\n",
      "Iteration:  6700 , loss:  0.0032578441\n",
      "Iteration:  6800 , loss:  0.004160829\n",
      "Iteration:  6900 , loss:  0.0031321286\n",
      "Iteration:  7000 , loss:  0.003066538\n",
      "Iteration:  7100 , loss:  0.0030029102\n",
      "Iteration:  7200 , loss:  0.0029367756\n",
      "Iteration:  7300 , loss:  0.0053337547\n",
      "Iteration:  7400 , loss:  0.0028288574\n",
      "Iteration:  7500 , loss:  0.0027416141\n",
      "Iteration:  7600 , loss:  0.0038098842\n",
      "Iteration:  7700 , loss:  0.002617357\n",
      "Iteration:  7800 , loss:  0.0025605129\n",
      "Iteration:  7900 , loss:  0.002536161\n",
      "Iteration:  8000 , loss:  0.0024458475\n",
      "Iteration:  8100 , loss:  0.0023931486\n",
      "Iteration:  8200 , loss:  0.0050438736\n",
      "Iteration:  8300 , loss:  0.0022949802\n",
      "Iteration:  8400 , loss:  0.0022475307\n",
      "Iteration:  8500 , loss:  0.0028273326\n",
      "Iteration:  8600 , loss:  0.0021609466\n",
      "Iteration:  8700 , loss:  0.0021200757\n",
      "Iteration:  8800 , loss:  0.0020799572\n",
      "Iteration:  8900 , loss:  0.002045031\n",
      "Iteration:  9000 , loss:  0.0020035435\n",
      "Iteration:  9100 , loss:  0.0021496094\n",
      "Iteration:  9200 , loss:  0.0022578244\n",
      "Iteration:  9300 , loss:  0.0018977072\n",
      "Iteration:  9400 , loss:  0.0018867076\n",
      "Iteration:  9500 , loss:  0.0018348256\n",
      "Iteration:  9600 , loss:  0.0018026212\n",
      "Iteration:  9700 , loss:  0.0017744567\n",
      "Iteration:  9800 , loss:  0.0017701592\n",
      "Iteration:  9900 , loss:  0.0017187423\n",
      "Iteration:  10000 , loss:  0.0016938564\n",
      "Iteration:  10100 , loss:  0.0017149091\n",
      "Iteration:  10200 , loss:  0.00164573\n",
      "Iteration:  10300 , loss:  0.0016214937\n",
      "Iteration:  10400 , loss:  0.0015993584\n",
      "Iteration:  10500 , loss:  0.0025209424\n",
      "Iteration:  10600 , loss:  0.0020270548\n",
      "Iteration:  10700 , loss:  0.0015374555\n",
      "Iteration:  10800 , loss:  0.0021716747\n",
      "Iteration:  10900 , loss:  0.0015020586\n",
      "Iteration:  11000 , loss:  0.002065646\n",
      "Iteration:  11100 , loss:  0.001653387\n",
      "Iteration:  11200 , loss:  0.0014496422\n",
      "Iteration:  11300 , loss:  0.0014451478\n",
      "Iteration:  11400 , loss:  0.0014598288\n",
      "Iteration:  11500 , loss:  0.0014041974\n",
      "Iteration:  11600 , loss:  0.0014221646\n",
      "Iteration:  11700 , loss:  0.0014340095\n",
      "Iteration:  11800 , loss:  0.0013637905\n",
      "Iteration:  11900 , loss:  0.0013498426\n",
      "Iteration:  12000 , loss:  0.0013369448\n",
      "Iteration:  12100 , loss:  0.0013713357\n",
      "Iteration:  12200 , loss:  0.0013135824\n",
      "Iteration:  12300 , loss:  0.0013004536\n",
      "Iteration:  12400 , loss:  0.0014058716\n",
      "Iteration:  12500 , loss:  0.0012875131\n",
      "Iteration:  12600 , loss:  0.0012653525\n",
      "Iteration:  12700 , loss:  0.0013107399\n",
      "Iteration:  12800 , loss:  0.0012427673\n",
      "Iteration:  12900 , loss:  0.001238503\n",
      "Iteration:  13000 , loss:  0.0012209064\n",
      "Iteration:  13100 , loss:  0.0012749232\n",
      "Iteration:  13200 , loss:  0.0012050993\n",
      "Iteration:  13300 , loss:  0.0012982364\n",
      "Iteration:  13400 , loss:  0.0017259088\n",
      "Iteration:  13500 , loss:  0.0011676111\n",
      "Iteration:  13600 , loss:  0.0011631253\n",
      "Iteration:  13700 , loss:  0.0011476539\n",
      "Iteration:  13800 , loss:  0.0016566552\n",
      "Iteration:  13900 , loss:  0.0015700953\n",
      "Iteration:  14000 , loss:  0.0011173309\n",
      "Iteration:  14100 , loss:  0.001216657\n",
      "Iteration:  14200 , loss:  0.0010976951\n",
      "Iteration:  14300 , loss:  0.001088682\n",
      "Iteration:  14400 , loss:  0.0012704715\n",
      "Iteration:  14500 , loss:  0.0010694719\n",
      "Iteration:  14600 , loss:  0.0023753375\n",
      "Iteration:  14700 , loss:  0.0010507256\n",
      "Iteration:  14800 , loss:  0.0010426325\n",
      "Iteration:  14900 , loss:  0.0010587808\n",
      "Iteration:  15000 , loss:  0.0010238163\n",
      "Iteration:  15100 , loss:  0.0010148702\n",
      "Iteration:  15200 , loss:  0.0012320708\n",
      "Iteration:  15300 , loss:  0.0011504309\n",
      "Iteration:  15400 , loss:  0.0009882967\n",
      "Iteration:  15500 , loss:  0.0017016509\n",
      "Iteration:  15600 , loss:  0.0010142011\n",
      "Iteration:  15700 , loss:  0.00108753\n",
      "Iteration:  15800 , loss:  0.0012625594\n",
      "Iteration:  15900 , loss:  0.0011232657\n",
      "Iteration:  16000 , loss:  0.0011328934\n",
      "Iteration:  16100 , loss:  0.0014412242\n",
      "Iteration:  16200 , loss:  0.00092334574\n",
      "Iteration:  16300 , loss:  0.0009384017\n",
      "Iteration:  16400 , loss:  0.00091175624\n",
      "Iteration:  16500 , loss:  0.0009021525\n",
      "Iteration:  16600 , loss:  0.0013459979\n",
      "Iteration:  16700 , loss:  0.0008996213\n",
      "Iteration:  16800 , loss:  0.00088557514\n",
      "Iteration:  16900 , loss:  0.0008934749\n",
      "Iteration:  17000 , loss:  0.0008675086\n",
      "Iteration:  17100 , loss:  0.00086905767\n",
      "Iteration:  17200 , loss:  0.0009147406\n",
      "Iteration:  17300 , loss:  0.0008464779\n",
      "Iteration:  17400 , loss:  0.0008412658\n",
      "Iteration:  17500 , loss:  0.00084120734\n",
      "Iteration:  17600 , loss:  0.00083073287\n",
      "Iteration:  17700 , loss:  0.0009182534\n",
      "Iteration:  17800 , loss:  0.0008170296\n",
      "Iteration:  17900 , loss:  0.0008316627\n",
      "Iteration:  18000 , loss:  0.00080931326\n",
      "Iteration:  18100 , loss:  0.0012099724\n",
      "Iteration:  18200 , loss:  0.00083813\n",
      "Iteration:  18300 , loss:  0.00080012635\n",
      "Iteration:  18400 , loss:  0.0008101041\n",
      "Iteration:  18500 , loss:  0.00077923294\n",
      "Iteration:  18600 , loss:  0.0016668197\n",
      "Iteration:  18700 , loss:  0.0007700699\n",
      "Iteration:  18800 , loss:  0.0007646143\n",
      "Iteration:  18900 , loss:  0.00076917844\n",
      "Iteration:  19000 , loss:  0.0007551961\n",
      "Iteration:  19100 , loss:  0.0007727301\n",
      "Iteration:  19200 , loss:  0.00074586424\n",
      "Iteration:  19300 , loss:  0.00074350473\n",
      "Iteration:  19400 , loss:  0.0018354307\n",
      "Iteration:  19500 , loss:  0.00073300034\n",
      "Iteration:  19600 , loss:  0.000763824\n",
      "Iteration:  19700 , loss:  0.0007408061\n",
      "Iteration:  19800 , loss:  0.0007208149\n",
      "Iteration:  19900 , loss:  0.0007246353\n",
      "Execution time for 'Trainable' function is: 316.576 s, 5.276 mins\n"
     ]
    }
   ],
   "source": [
    "#processes, samples, model = Samplable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)\n",
    "\n",
    "processes_DE, samples_DE, model_DE = Trainable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e63fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean & Std of k1 are 0.502, 0.005\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred, logk_1_pred = model_DE.predict(np.concatenate([x_test, t_test], axis=-1), samples_DE, processes_DE, pde_fn=None,)\n",
    "plots(\n",
    "    logk_1_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf64da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
