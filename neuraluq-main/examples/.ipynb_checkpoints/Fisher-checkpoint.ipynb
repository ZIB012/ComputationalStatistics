{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d62174",
   "metadata": {},
   "source": [
    "## Fisher's equation\n",
    "It is a kind of reaction–diffusion system that can be used to model population growth and wave propagation.\n",
    "$$ \\frac{\\partial\\,u}{\\partial t} = r\\,u(1-u) + d\\frac{\\partial^2 u}{\\partial t^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc0411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuraluq as neuq\n",
    "import neuraluq.variables as neuq_vars\n",
    "from neuraluq.config import tf\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd8c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(noise_u, noise_f):\n",
    "    data = sio.loadmat(\"../dataset/Fisher.mat\")\n",
    "    x_u_train, t_u_train = data[\"x_u_train\"], data[\"t_u_train\"]\n",
    "    x_f_train, t_f_train = data[\"x_f_train\"], data[\"t_f_train\"]\n",
    "    x_test, t_test, u_test = data[\"x_test\"], data[\"t_test\"], data[\"u_test\"]\n",
    "    x_test, t_test, u_test = (\n",
    "        x_test.reshape([-1, 1]),\n",
    "        t_test.reshape([-1, 1]),\n",
    "        u_test.reshape([-1, 1]),\n",
    "    )\n",
    "    u_train, f_train = data[\"u_train\"], data[\"f_train\"]\n",
    "    train_u = x_u_train, t_u_train, u_train\n",
    "    train_f = x_f_train, t_f_train, f_train\n",
    "    test = x_test, t_test, u_test\n",
    "    return train_u, train_f, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447a2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_fn(x, u, r):\n",
    "    d = 1\n",
    "    \n",
    "    u_x, u_t = tf.split(tf.gradients(u, x)[0], 2, axis=-1)\n",
    "    u_xx = tf.gradients(u_x, x)[0][..., 0:1]\n",
    "    \n",
    "    f = u_t - r * u * (1 - u) - d * u_xx\n",
    "    #f = u_t - r * u_xx\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6076c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@neuq.utils.timer\n",
    "def Samplable(\n",
    "    x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers\n",
    "):\n",
    "    # build processes\n",
    "    process_u = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.FNN(layers=layers),\n",
    "        prior=neuq_vars.fnn.Samplable(layers=layers, mean=0, sigma=1),\n",
    "    )\n",
    "    process_logk_1 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        prior=neuq_vars.const.Samplable(mean=1, sigma=1),\n",
    "    )\n",
    "    \n",
    "    # build likelihood\n",
    "    likelihood_u = neuq.likelihoods.Normal(\n",
    "        inputs=np.concatenate([x_u_train, t_u_train], axis=-1),\n",
    "        targets=u_train,\n",
    "        processes=[process_u],\n",
    "        sigma=noise,\n",
    "    )\n",
    "    likelihood_f = neuq.likelihoods.Normal(\n",
    "        inputs=np.concatenate([x_f_train, t_f_train], axis=-1),\n",
    "        targets=f_train,\n",
    "        processes=[process_u, process_logk_1],\n",
    "        pde=pde_fn,\n",
    "        sigma=noise,\n",
    "    )\n",
    "    # build model\n",
    "    model = neuq.models.Model(\n",
    "        processes=[process_u, process_logk_1],\n",
    "        likelihoods=[likelihood_u, likelihood_f],\n",
    "    )\n",
    "    # assign and compile method\n",
    "    # Change the parameters to make the acceptance rate close to 0.6.\n",
    "    method = neuq.inferences.HMC(\n",
    "        num_samples=500,\n",
    "        num_burnin=3000,\n",
    "        init_time_step=0.01,\n",
    "        leapfrog_step=50,\n",
    "        seed=66,\n",
    "    )\n",
    "    model.compile(method)\n",
    "    # obtain posterior samples\n",
    "    samples, results = model.run()\n",
    "    print(\"Acceptance rate: %.3f \\n\"%(np.mean(results)))\n",
    "\n",
    "    processes = [process_u, process_logk_1]\n",
    "    return processes, samples, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c52501",
   "metadata": {},
   "outputs": [],
   "source": [
    "@neuq.utils.timer\n",
    "def Trainable(\n",
    "    x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers\n",
    "):\n",
    "    # build processes\n",
    "    process_u = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.FNN(layers=layers),\n",
    "        posterior=neuq_vars.fnn.Trainable(layers=layers),\n",
    "    )\n",
    "    process_logk_1 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        posterior=neuq_vars.const.Trainable(value=1),\n",
    "    )\n",
    "    \n",
    "    loss_u = neuq.likelihoods.MSE(\n",
    "        inputs=np.concatenate([x_u_train, t_u_train], axis=-1),\n",
    "        targets=u_train,\n",
    "        processes=[process_u],\n",
    "        multiplier=1.0,\n",
    "    )\n",
    "    loss_f = neuq.likelihoods.MSE(\n",
    "        inputs=np.concatenate([x_f_train, t_f_train], axis=-1),\n",
    "        targets=f_train,\n",
    "        processes=[process_u, process_logk_1],\n",
    "        pde=pde_fn,\n",
    "        multiplier=1.0,\n",
    "    )\n",
    "    # build model\n",
    "    model = neuq.models.Model(\n",
    "        processes=[process_u, process_logk_1],\n",
    "        likelihoods=[loss_u, loss_f],\n",
    "    )\n",
    "    # assign and compile method\n",
    "    method = neuq.inferences.DEns(\n",
    "        num_samples=20, num_iterations=20000, optimizer=tf.train.AdamOptimizer(1e-3),\n",
    "    )\n",
    "    model.compile(method)\n",
    "    # obtain posterior samples\n",
    "    samples = model.run()\n",
    "    samples = neuq.utils.batch_samples(samples)  # reshape\n",
    "\n",
    "    processes = [process_u, process_logk_1]\n",
    "    return processes, samples, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de00c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(\n",
    "    logk_1_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    "):\n",
    "    ### DA CAPIRE LA STORIA DEL PERCHè PRENDE L'ESPONENZIALE DELLE VARIABILI\n",
    "    \n",
    "    #k_1_pred = np.exp(logk_1_pred)\n",
    "    k_1_pred = logk_1_pred\n",
    "    print(\"Mean & Std of k1 are %.3f, %.3f\" % (np.mean(k_1_pred), np.std(k_1_pred)))\n",
    "    \n",
    "    u_pred = np.reshape(u_pred, [-1, NT, NX])\n",
    "    mu = np.mean(u_pred, axis=0)\n",
    "    std = np.std(u_pred, axis=0)\n",
    "    \n",
    "    x_test = np.reshape(x_test, [NT, NX])\n",
    "    t_test = np.reshape(t_test, [NT, NX])\n",
    "    u_test = np.reshape(u_test, [NT, NX])\n",
    "    \n",
    "    # cambiare i per avere plot su altri istanti di tempo\n",
    "    i = 2\n",
    "    \n",
    "    current_t = t_test[i][0]\n",
    "    # current_x*10 PERCHè PRIMA LA X è STATA NORMALIZZATA\n",
    "    current_x = x_u_train[t_u_train == current_t]\n",
    "    current_u = u_train[t_u_train == current_t]\n",
    "    # std = np.sqrt(std**2 + 0.1**2)\n",
    "    plt.plot(np.linspace(0, 3, NX), mu[i, :], \"--\", label=\"mean\")\n",
    "    plt.fill_between(\n",
    "        np.linspace(0, 3, NX), (mu + 2 * std)[i, :], (mu - 2 * std)[i, :], alpha=0.3\n",
    "    )\n",
    "    plt.plot(np.linspace(0, 3, NX), u_test[i, :], label=\"reference\")\n",
    "    plt.plot(current_x, current_u, \"o\", label=\"observations\")\n",
    "    plt.legend()\n",
    "    plt.title(\"t=\" + str(current_t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881d9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "NT, NX = 60, 300\n",
    "noise = 0.1\n",
    "train_u, train_f, test = load_data(noise, noise)\n",
    "x_u_train, t_u_train, u_train = train_u\n",
    "x_f_train, t_f_train, f_train = train_f\n",
    "x_test, t_test, u_test = test\n",
    "\n",
    "layers = [2, 50, 50, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205e1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting backend tensorflow.compat.v1\n",
      "\n",
      "Compiling a MCMC method\n",
      "\n",
      "sampling from posterior distribution ...\n",
      "\n",
      "Finished sampling from posterior distribution ...\n",
      "\n",
      "Acceptance rate: 0.704 \n",
      "\n",
      "Execution time for 'Samplable' function is: 223.335 s, 3.722 mins\n"
     ]
    }
   ],
   "source": [
    "processes, samples, model = Samplable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)\n",
    "\n",
    "#processes, samples, model = Trainable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "145f6e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean & Std of k1 are -0.997, 0.097\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGxCAYAAABvIsx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACaZklEQVR4nOzdd3ib5dX48e+jYcvykPcecfYezg4EEhISVspogVIIm5a3tAXytoS8pYz21wJtSdNJC4WmlBVKWC1hBQiB7MRJyJ5ecbyHvK31/P5Q7FiWZMu25Hk+16VL8qNn3Eps6ege5yiqqqoIIYQQQgwimr5ugBBCCCGEv0mAI4QQQohBRwIcIYQQQgw6EuAIIYQQYtCRAEcIIYQQg44EOEIIIYQYdCTAEUIIIcSgIwGOEEIIIQYdCXCEEEIIMehIgCOE6DNbt27l8ccfp7q62m/n3LhxI3PnzsVoNBIbG8vtt99OaWmpz8e//vrrTJ06FYPBQHJyMg888AB1dXV+a58QondIgCOE6DNbt27liSee8FuA88UXX3D55ZeTkJDAu+++y+9//3s2btzIokWLaG5u7vT4V155hZtuuomZM2fywQcf8Nhjj7F27Vquu+46v7RPCNF7dH3dACGE8Jef/OQnjB49mjfffBOdzvn2lpmZyQUXXMCLL77I//zP/3g91m6385Of/IQlS5bw/PPPA7Bw4ULCw8O5+eab+eCDD7j88st75XUIIXpOenCEEH3i8ccf5yc/+QngDEIURUFRFDZt2tSt8xUWFrJr1y6WL1/eGtwAzJs3j9GjR/P22293ePz27dspKirijjvucNl+/fXXExYW1unxQoj+RXpwhBB94u6776ayspI//vGPvPXWWyQlJQEwfvx4HA4HDoej03MoioJWqwXg4MGDAEyePNltv8mTJ7Nly5YOz+XteL1ez9ixY1ufF0IMDNKDI4ToE6mpqaSnpwMwbdo05syZw5w5c4iIiODOO+9Er9d3elu0aFHr+SoqKgCIjo52u1Z0dHTr89709HghRP8iPThCiH7n8ccf5wc/+EGn+4WHh7ttUxTF477etvv7eCFE/yABjhCi30lPTyc1NbXT/doGHTExMQAee1oqKys99sy01fb4hISELh8vhOhfZIhKCNHvdGeIauLEiQAcOHDA7XwHDhxofd6bSZMmeTzeZrNx9OjRTo8XQvQv0oMjhOgzwcHBADQ2Nrps784QVUpKCrNmzeLll1/mxz/+cevk4+3bt3Ps2DEeeOCBDs81e/ZskpKSWLt2LTfeeGPr9jfffJO6ujrJhSPEAKOoqqr2dSOEEEPTpk2bWLhwId/73ve47bbb0Ov1jBkzxuPcGl/Pd+mll7Js2TK+//3vU1paysMPP4zJZGL37t2tAVVeXh4jRozgtttu44UXXmg9/uWXX2b58uV897vf5aabbuLEiRM89NBDzJw5k48//tgvr1kI0TtkiEoI0WcWLFjAqlWr+M9//sOFF17IzJkz2bNnT4/Ot2HDBoqKili2bBk//OEPWbhwIZ9++mlrcAOgqip2ux273e5y/C233MKrr77K9u3bWbp0KY8++ii33norb731VrfbJIToG9KDI4QQQohBR3pwhBBCCDHoSIAjhBBCiEFHAhwhhBBCDDoS4AghhBBi0JEARwghhBCDjgQ4QgghhBh0hmQmY4fDwdmzZwkPD5cCekIIIcQAoaoqtbW1JCcno9F03EczJAOcs2fPkpaW1tfNEEIIIUQ3FBQUdFqQd0gGOC1p4AsKCoiIiOjj1gghhBDCFzU1NaSlpflUzmVIBjgtw1IRERES4AghhBADjC/TS2SSsRBCCCEGHQlwhBBCCDHoSIAjhBBCiEFnSM7BEUII0TdUVcVms2G32/u6KaKf0uv1aLXaHp9HAhwhhBC9wmKxUFRURENDQ183RfRjiqKQmppKWFhYj84jAY4QQoiAczgc5OTkoNVqSU5OJigoSBKtCjeqqlJWVsaZM2cYNWpUj3pyJMARQggRcBaLBYfDQVpaGkajsa+bI/qxuLg4cnNzsVqtPQpwZJKxEEKIXtNZen0h/NWzJ79pQgghhBh0JMARQgghxKAjAY4QQgghBh0JcIQQQggx6MgqKiHE4GCzQO6XkLMZbM0QGgtjLof48SDLkYUYcqQHRwgx8B3/GP44HV6+DrasgR3Pwme/gGfnObdVnu7rFooONFhsXm9NVrtf9+2OBQsW8MMf/pAHHniAqKgoEhISeO6556ivr+eOO+4gPDycESNG8MEHH7Qec/jwYa644grCwsJISEhg+fLllJeXtz7/4YcfcuGFFxIZGUlMTAxXXXUVp06dan0+NzcXRVF46623WLhwIUajkSlTprBt27ZuvYahSFFVVe3rRvS2mpoaTCYTZrOZiIiIvm6OEKK7VBU+fQK++p3zZ+O5XpvQOCg9Aqc+BbsF9KHw7ZdhxCV9294hrKmpiZycHDIzMzEYDC7PDXv4fa/HLRwTxz/umNX687iffUij1XOZh9mZ0az73tzWn7N+8QmV9RaXfXKfurLLbV+wYAHZ2dk89NBD3Hjjjaxbt47HHnuMpUuXcu2117JgwQJ+97vf8cYbb5Cfn4/ZbGby5Mncc8893HrrrTQ2NrJy5UpsNhufffYZAOvXr0dRFCZNmkR9fT2PPvooubm57Nu3D41GQ25uLpmZmYwdO5bf/va3jBo1ip/+9Kfs2rWLkydPotMN3gGYjn5XuvL5PXj/hYQQg47dYSe7NJuyhjLiQmLJ2rMO7e6/O5+c+wNY+H8QFHr+gIpT8N4PIW8LvHoj3PCSMwASooumTJnCI488AsCqVat46qmniI2N5Z577gHg0Ucf5dlnn+Xrr79mw4YNZGVl8atf/ar1+BdffJG0tDSOHz/O6NGj+eY3v+ly/hdeeIH4+HgOHz7MxIkTW7f/+Mc/5sornUHZE088wYQJEzh58iRjx44N9Ese8CTAEUIMCBvzNvLUzqcoaShp3ZZgs/Gw0cjiRU/B9NvcD4oZAcvfhrfugcPvwpt3wd2fQMKEXmy56Mzhny/1+pym3fypPT9b7PO+X61c2LOGtTF58uTWx1qtlpiYGCZNmtS6LSEhAYDS0lL27NnD559/7rGW0qlTpxg9ejSnTp3iZz/7Gdu3b6e8vByHwwFAfn6+S4DT9rpJSUmt15AAp3MS4Agh+r2NeRtZsWkFKq4j6qVaLSsSYlkdm4LXjz1dMHzzRWi8DnK+gNe/A9/7EgwyPN1fGIN8/ygK1L6d0ev1Lj8riuKyrSX7rsPhwOFwsGzZMp5++mm387QEKcuWLSMtLY3nn3+e5ORkHA4HEydOxGJxHVLzdg3ROZlkLITo1+wOO0/tfMotuAFQFQVQeHrn09gdnudlAKDVwfVrITIdqnJh42OBaq4QZGVlcejQIYYNG8bIkSNdbqGhoVRUVHDkyBEeeeQRFi1axLhx46iqqurrZg86EuAIIfq17NJsl2Gp9lRUihuKyS7N7vhExmi4+s/Ox7tfhJwv/dhKIc677777qKys5KabbmLnzp2cPn2ajz/+mDvvvBO73U5UVBQxMTE899xznDx5ks8++4wVK1b0dbMHHQlwhBD9WllDmf/2y7wIpt/ufPzBQ9BRr48Q3ZScnMyWLVuw2+0sXbqUiRMncv/992MymdBoNGg0Gl5//XX27NnDxIkTefDBB/nNb37T180edGQOjhCiX4szxvl1PxY/DofegdLDsP81mHZLt9smhoZNmza5bcvNzXXb1jbryqhRo3jrrbe8nnPx4sUcPnzY6/HDhg2jfRaXyMhIt23CO+nBEUL0a1nxWSQYE/CWi1hBIdGYSFZ8lm8nDImCi37sfPzZ/wNLg1/aKYToXyTAEUL0a1qNlodnPQyA0u7bq3Iu7Fk5ayVajdb3k876LpjSobYI9r7st7YKIfoPCXCEEP3eYl0Uq0vKiLe7Lo9NMCawesFqFmd4z43ikS4YLrzf+XjrH8Bu9VNLhRD9hczBEUL0f1+uZnFDIwtHzid73t3OTMbGOLLis7rWc9PW1Ftg09NgLoAD/4ap3/Fvm4UQfUoCHCFE/1aZA0edtYq0Fz7IzHg/ZXDVG2Du92Hj47DtzzDlJqk6LsQgEtAhqs2bN7Ns2TKSk5NRFIV33nmnw/03bdqEoihut6NHj7rst379esaPH09wcDDjx4/n7bffDuCrEEL0qd0vACqMXAz+Cm5aTL8ddCFQchDyt/v33EKIPhXQAKe+vp4pU6bwpz/9qUvHHTt2jKKiotbbqFGjWp/btm0bN954I8uXL2f//v0sX76cG264gR07dvi7+UKIvmZpgOx/OR/PvMf/5w+JgsnXOx/vfM7/5xdC9JmADlFdfvnlXH551yv3xsfHExkZ6fG5NWvWcOmll7Jq1SrAWdX1iy++YM2aNbz22ms9aa4Qor859BY0VTtLLIy6NDDXmHkPZL8ER96D2mIITwzMdYQQvapfrqKaNm0aSUlJLFq0iM8//9zluW3btrFkyRKXbUuXLmXr1q1ez9fc3ExNTY3LTQgxALT03sy4E7o7mbgzSZMhdRY4bPD1usBcQwjR6/pVgJOUlMRzzz3H+vXreeuttxgzZgyLFi1i8+bNrfsUFxe3lqVvkZCQQHFxsdfzPvnkk5hMptZbWlpawF6DEMJPyk9CwXZQNM4JwIHUks147ysgmWKFH6iqyne/+12io6NRFIV9+/b1dZOGnH61imrMmDGMGTOm9ee5c+dSUFDAb3/7Wy666KLW7Uq7lQ6qqrpta2vVqlUuhcxqamokyBGiv9v3ivN+5OLADxtNuBY+WAnlx6BwD6TOCOz1xKD34YcfsnbtWjZt2sTw4cOJjY3t6yYNOf2qB8eTOXPmcOLEidafExMT3XprSktL3Xp12goODiYiIsLlJoToxxx22P+68/HUmwN/PUMEjP8GdmDXzj+y4fQGdhXvwi7FOIUHFoul031OnTpFUlIS8+bNIzExEZ2u6/0Jqqpis9m600TBAAhw9u7dS1JSUuvPc+fO5ZNPPnHZ5+OPP2bevHm93TQhRKDkbYXas2AwwZiuL1Tojo0p41malsydtdms/HIld350J0vXL2Vj3sZeuf6QpKpgqe/9WxeHIRcsWMAPfvADVqxYQWxsLJdeeimHDx/miiuuICwsjISEBJYvX055eTkAt99+Oz/84Q/Jz89HURSGDRt27uWq/PrXv2b48OGEhIQwZcoU3nzzzdbrtKRK+eijj5gxYwbBwcF8+eWXPh/36aefMmPGDIxGI/PmzePYsWMur+O9995jxowZGAwGYmNjue6661qfs1gsPPTQQ6SkpBAaGsrs2bM9FhkdSAI6RFVXV8fJkydbf87JyWHfvn1ER0eTnp7OqlWrKCws5KWXXgKcK6SGDRvGhAkTsFgsvPzyy6xfv57169e3nuP+++/noosu4umnn+bqq6/m3XffZePGjXz11VeBfClCiN508Nyb97hvOMsqBNjGvI2sOPoiqtZ1InNpQykrNq3oXjkI0TlrA/wqufev+39nISi0S4f885//5H/+53/YsmULlZWVXHzxxdxzzz2sXr2axsZGVq5cyQ033MBnn33G73//e0aMGMFzzz3Hrl270J77vXrkkUd46623ePbZZxk1ahSbN2/mlltuIS4ujosvvrj1Wg899BC//e1vGT58OJGRkT4f99Of/pRnnnmGuLg47r33Xu688062bNkCwPvvv891113HT3/6U/71r39hsVh4//33W4+94447yM3N5fXXXyc5OZm3336byy67jAMHDrikahlIFDWAtdc3bdrEwoUL3bbfdtttrF27lttvv53c3NzWKPHXv/41zz33HIWFhYSEhDBhwgRWrVrFFVdc4XL8m2++ySOPPMLp06cZMWIEv/zlL10i0c7U1NRgMpkwm80yXCVEf2O3wm9HQWMV3PouDF8Q2Ms57Cxdv5SShhKPzysoJBgT+PCbH3a/LISgqamJnJwcMjMzMRgMzo2W+gER4CxYsACz2czevXsBePTRR9mxYwcfffRR6z5nzpwhLS2NY8eOMXr0aNasWcOaNWvIzc0FnHnhYmNj+eyzz5g7d27rcXfffTcNDQ28+uqrrZ+Z77zzDldffXWXj9u4cSOLFi0CYMOGDVx55ZU0NjZiMBiYN28ew4cP5+WX3YvLnjp1ilGjRnHmzBmSk8//fyxevJhZs2bxq1/9yud/K3/w+LtyTlc+vwPag7NgwQI6ip/Wrl3r8vNDDz3EQw891Ol5v/Wtb/Gtb32rp80TQvRHpz53Bjeh8TBsfsAvl12a7TW4AVBRKW4oJrs0m5mJMwPeniFFb3QGG31x3S6aMeP8xPM9e/bw+eefExYW5rbfqVOnGD16tNv2w4cP09TUxKWXuuZzslgsTJs2zeu1unLc5MmTWx+3TO0oLS0lPT2dffv2cc89npNlZmdno6qqW7ubm5uJiYnxeMxA0K9WUQkhBIffdd5PuCZwuW/aKGso8+t+ogsUpctDRX0lNPR8Ox0OB8uWLePpp59226/tnNG2HA4H4BwqSklJcXkuONh1GLb9tXw9Tq/Xtz5uWVnccnxISIjHdrXso9Vq2bNnT+twWgtPQdxAIQGOEKL/cNjh+AfOx2Ov6pVLxhnj/LqfGPyysrJYv349w4YN83l1VEv9xPz8fJd5M4E6rr3Jkyfz6aefcscdd7g9N23aNOx2O6WlpcyfH/he094iAY4Qov8o2AENFc7VUxm9szIyKz6LBGMCpQ2lqLgPqbfMwcmKz+qV9oj+77777uP555/npptu4ic/+QmxsbGcPHmS119/neeff96tFwQgPDycH//4xzz44IM4HA4uvPBCampq2Lp1K2FhYdx2220er9Xd49p77LHHWLRoESNGjODb3/42NpuNDz74gIceeojRo0dz8803c+utt/LMM88wbdo0ysvL+eyzz5g0aZLbPNiBot8vExdCDCFHz63qGLUUtPqO9/UTrUbLw7MeBpzBTFstP62ctVImGItWycnJbNmyBbvdztKlS5k4cSL3338/JpMJjcb7x+ovfvELHn30UZ588knGjRvH0qVL+c9//kNmZmaH1+vucW0tWLCAf//737z33ntMnTqVSy65xKVI9T/+8Q9uvfVW/vd//5cxY8bwjW98gx07dgzopLgBXUXVX8kqKiH6IVWFP2ZB5Wm4fq0zu3Av2pi3kad2PuUy4ThRY2DlRU/KEnE/6GhljBBtDYhVVEII4bOyY87gRhvkLM/QyxZnLGZh2kKyS7MpO76BuK1/JsuYjDZ9Ua+3RQjRcxLgCCH6h2PnhqcyL4Lg8D5pglajdS4FjxoLX/wJKnOcgVf82D5pjxCi+2QOjhCifzi6wXk/9sq+bQc4A6zMcytWjr3f8b5CiH5JAhwhRN+rLYbC3c7Ho3un9lSnxp5bOdISeAkhBhQJcIQQfe/4h877lOkQ4TlRWq9rCbQKdzsDMCHEgCIBjhCi7534xHnfX3pvwBloJZ/LfXPqs75tixCiyyTAEUL0LbsNcjY7H4/sZyuWWtojAY4QA44EOEKIvlW4B5prICQakqb0dWtcjbjEeX/qczhX00cIMTBIgCOE6FunPnXeD1/QK8U1uyR1JgSFQUM5FH/d160RQnSBBDhCiL7VMvzT0lvSn2j1zrw8IMNU/YTdYWdX8S42nN7AruJd2B32Pm3Ppk2bUBSF6urqPm2HP91+++1cc801fd2MHpNEf0KIvtNY5RyiAhixsG/b4s2IS+DYBmeAM39FX7dmSPNUTiPBmMDDsx6WchrdkJubS2ZmJnv37mXq1Kmt23//+98zGKo4SQ+OEKLv5GwG1QGxY8CU2tet8aylZyl/O1jq+7YtQ9jGvI2s2LTCJbgBKG0oZcWmFWzM29hHLet9FosloOc3mUxERkYG9Bq9QQIcIUTf6c/DUy2ih0NkOjiskLulr1szJNkddp7a+RQq7r0KLdue3vl0wIarmpub+dGPfkR8fDwGg4ELL7yQXbt2ueyzZcsWpkyZgsFgYPbs2Rw4cKD1uby8PJYtW0ZUVBShoaFMmDCBDRvOJ5A8fPgwV1xxBWFhYSQkJLB8+XLKy8tbn1+wYAE/+MEPWLFiBbGxsVx66aXcdNNNfPvb33Zpg9VqJTY2ln/84x8AfPjhh1x44YVERkYSExPDVVddxalTp1r3b6lGPm3aNBRFYcGCBYD7EFVnr79lmO7TTz9lxowZGI1G5s2bx7Fjx1r32b9/PwsXLiQ8PJyIiAimT5/O7t27u/pf0SUS4Agh+oaqwskBEOAoSpvVVDIPpy9kl2a79dy0paJS3FBMdml2QK7/0EMPsX79ev75z3+SnZ3NyJEjWbp0KZWVla37/OQnP+G3v/0tu3btIj4+nm984xtYrVYA7rvvPpqbm9m8eTMHDhzg6aefJiwsDICioiIuvvhipk6dyu7du/nwww8pKSnhhhtucGnDP//5T3Q6HVu2bOFvf/sbN998M++99x51dXWt+3z00UfU19fzzW9+E4D6+npWrFjBrl27+PTTT9FoNFx77bU4zq0I3LlzJwAbN26kqKiIt956q9uvH+CnP/0pzzzzDLt370an03HnnXe2PnfzzTeTmprKrl272LNnDw8//DB6vb5b/x8+U4cgs9msAqrZbO7rpggxdJWfVNXHIlT1iRhVba7r69Z07NA7zrb+cWZft2TAamxsVA8fPqw2NjZ2+dj3T72vTlw7sdPb+6fe93u76+rqVL1er77yyiut2ywWi5qcnKz++te/Vj///HMVUF9//fXW5ysqKtSQkBB13bp1qqqq6qRJk9THH3/c4/l/9rOfqUuWLHHZVlBQoALqsWPHVFVV1YsvvlidOnWqyz4Wi0WNjY1VX3rppdZtN910k3r99dd7fS2lpaUqoB44cEBVVVXNyclRAXXv3r0u+912223q1Vdf7dPrV1W19d9g48aNrfu8//77KtD6/x0eHq6uXbvWa9va6uh3pSuf39KDI4ToGy29IelzICi0b9vSmcyLQNFA+TEwn+nr1gw5ccY4v+7XFadOncJqtXLBBRe0btPr9cyaNYsjR460bps7d27r4+joaMaMGdP6/I9+9CP+3//7f1xwwQU89thjfP31+ZQDe/bs4fPPPycsLKz1Nnbs2NZrt5gxY4ZLu/R6Pddffz2vvPIK4Oyteffdd7n55ptd2v6d73yH4cOHExER0ToklZ+f7/fXDzB58uTWx0lJzpIrpaWlAKxYsYK7776bxYsX89RTT7m8tkCRAEcI0TdyvnDeD1/Qp83wSUjU+bINOV/2bVuGoKz4LBKMCSgoHp9XUEg0JpIVn+X3a6vnVhMpiuK2vf02t3ade/7uu+/m9OnTLF++nAMHDjBjxgz++Mc/AuBwOFi2bBn79u1zuZ04cYKLLrqo9Vyhoe5fAm6++WY2btxIaWkp77zzDgaDgcsvP1/uZNmyZVRUVPD888+zY8cOduzYAXRtknJXXn/bIaeW51qGwx5//HEOHTrElVdeyWeffcb48eN5++23fW5Hd0iAI4TofQ7H+Qm7mRd1vG9/MexC533uV33bjiFIq9Hy8KyHAdyCnJafV85aiTYAiSJHjhxJUFAQX311/v/darWye/duxo0b17pt+/btrY+rqqo4fvx4a08MQFpaGvfeey9vvfUW//u//8vzzz8PQFZWFocOHWLYsGGMHDnS5eYpqGlr3rx5pKWlsW7dOl555RWuv/56goKCAKioqODIkSM88sgjLFq0iHHjxlFVVeVyfMu+drv3ydm+vn5fjB49mgcffJCPP/6Y6667rnUydKBIgCOE6H1lR6CxEvRGSJ7W163xzbD5zvtc6cHpC4szFrN6wWrijfEu2xOMCaxesDpgeXBCQ0P5n//5H37yk5/w4YcfcvjwYe655x4aGhq46667Wvf7+c9/zqeffsrBgwe5/fbbiY2NbV2J9MADD/DRRx+Rk5NDdnY2n332WWtwcN9991FZWclNN93Ezp07OX36NB9//DF33nlnh4EHOHtJvvOd7/DXv/6VTz75hFtuuaX1uaioKGJiYnjuuec4efIkn332GStWuOZxio+PJyQkpHVis9ls7vbr70hjYyM/+MEP2LRpE3l5eWzZsoVdu3Z1OUDqKkn0J4TofS29IOlznNmCB4L02aBooToPqvOdS8dFr1qcsZiFaQvJLs2mrKGMOGMcWfFZAem5aeupp57C4XCwfPlyamtrmTFjBh999BFRUVEu+9x///2cOHGCKVOm8N5777n0kNx3332cOXOGiIgILrvsMn73u98BkJyczJYtW1i5ciVLly6lubmZjIwMLrvsMjSazvsgbr75Zn71q1+RkZHhMk9Go9Hw+uuv86Mf/YiJEycyZswY/vCHP7QuBQfQ6XT84Q9/4Oc//zmPPvoo8+fPZ9OmTd16/R3RarVUVFRw6623UlJSQmxsLNdddx1PPPGET8d3l6KqgyBdYRfV1NRgMpkwm81ERET0dXOEGHrW3QJH/gOLHoX5/9vXrfHd84ugcDdc81eYelNft2ZAaWpqIicnh8zMTAwGQ183R/RjHf2udOXzW4aohBC9q+38m5Zhn4FC5uEIMWBIgCOE6F0Dcf5NC5mHI8SAIQGOEKJ3DcT5Ny1c5uEU9HVrhBAdkABHCNG7WgKcluGegSQ4/HyvU57UpRKiP5MARwjRexyO84HBQJt/06J1Ho4MU3XHEFzXIrrIX78jEuAIIXpP2VFoqBiY829atM7DkYnGXdGS5bahoaGPWyL6u5ZMy1ptz5b/Sx4cIUTvGcjzb1q0zMOpynXOw4lM6+sWDQharZbIyMjW2kRGo7HTUgdi6HE4HJSVlWE0GtHpehaiSIAjhOg9LcNTGRd0vF9/FhwOyVOhcA/kbYXIG/u6RQNGYmIicL4AoxCeaDQa0tPTexwAS4AjhOgdqgr55+r1pM/teN/+Ln2uM8Ap2A5TJMDxlaIoJCUlER8fj9Vq7evmiH4qKCjIpyzOnQlogLN582Z+85vfsGfPHoqKinj77bdba3N48tZbb/Hss8+yb98+mpubmTBhAo8//jhLly5t3Wft2rXccccdbsc2NjZKdkwh+rOqXKgrBo0eUvxf9blXpc+BbX+C/B193ZIBSavV9nh+hRCdCegk4/r6eqZMmcKf/vQnn/bfvHkzl156KRs2bGDPnj0sXLiQZcuWsXfvXpf9IiIiKCoqcrlJcCNEP1dwLhhIngb6kL5tS0+lzXHelx6GxqqO9xVC9ImA9uBcfvnlXH755T7vv2bNGpeff/WrX/Huu+/yn//8h2nTzq+4UBSldSxXCDFA5G9z3qfP7tt2+ENYHESPgMpTULALRi/p6xYJIdrp18vEHQ4HtbW1REdHu2yvq6sjIyOD1NRUrrrqKrcenvaam5upqalxuQkhetlgmX/TouV1tARuQoh+pV8HOM888wz19fXccMMNrdvGjh3L2rVree+993jttdcwGAxccMEFnDhxwut5nnzySUwmU+stLU2WdQrRqxoqnTlwANIGQQ8OOOfhwPmhNyFEv9JvA5zXXnuNxx9/nHXr1hEfH9+6fc6cOdxyyy1MmTKF+fPn88YbbzB69Gj++Mc/ej3XqlWrMJvNrbeCAqkhI0SvagkCYkdDaGzftsVfWgKcwj1ga+7btggh3PTLZeLr1q3jrrvu4t///jeLFy/ucF+NRsPMmTM77MEJDg4mODjY380UQviqZXhqsPTeAMSMBGOMMzNz0X5Im9XXLRJCtNHvenBee+01br/9dl599VWuvPLKTvdXVZV9+/aRlJTUC60TQnTLYJt/A6AobebhbO/btggh3AQ0wKmrq2Pfvn3s27cPgJycHPbt20d+fj7gHDq69dZbW/d/7bXXuPXWW3nmmWeYM2cOxcXFFBcXYzabW/d54okn+Oijjzh9+jT79u3jrrvuYt++fdx7772BfClCiO6yNsHZbOfjlmGdwaKlR0oCHCH6nYAGOLt372batGmtS7xXrFjBtGnTePTRRwEoKipqDXYA/va3v2Gz2bjvvvtISkpqvd1///2t+1RXV/Pd736XcePGsWTJEgoLC9m8eTOzZkn3sBD90tm9YLdAaBxED+/r1vhX25VUUiVbiH5FUYdg7fqamhpMJhNms5mIiIi+bo4Qg9uXq+HTJ2DcMrjx5b5ujX/ZLPBUGtia4L5dEDe6r1skxKDWlc/vfjcHRwgxyJzZ5bwfTBOMW+iCIGW687EsFxeiX5EARwgROKoKZ3Y7H6fO7Nu2BErL62oJ5IQQ/YIEOEKIwDEXQH0paHSQNKWvWxMYrQHO7r5thxDChQQ4QojAafnQT5gw8AtsetMS4JQehiYpAyNEfyEBjhAicAr3OO9TZvRtOwIpPAEi0wH1/HJ4IUSfkwBHCBE4rfNvBnGAA+d7cQpkHo4Q/YUEOEKIwLBboWif8/Fg7sEBSD2Xh0smGgvRb0iAI4QIjJJDzvwwwSZn3abBrO1KqqGXWkyIfkkCHCFEYLTOv5kGmkH+VpM4CbTB0FgJlaf7ujVCCCTAEUIEylCYYNxCFwTJU52PZZhKiH5BAhwhRGAMlQnGLVonGu/s23YIIQAJcIQQgdBkhvLjzsdDoQcHJKOxEP2MBDhCCP8rzAZUZ36YsLi+bk3vaAlwSg6Bpb5v2yKEkABHCBEAheeGp4ZK7w2AKQXCk0G1w9m9fd0aIYY8CXCEEP535twE46Ey/6ZFmgxTCdFfSIAjhPAvVR2aPTggGY2F6Ed0fd0AIcTgYXfYyT61gTLqiQsxkpUwAW1fN6o3tc1orKqgKH3bHiGGMAlwhBB+sTFvI0/tfIqShhKIjwUg4b1reHjWwyzOWNzHreslSZNBo4f6UqjOh6iMvm6REEOWDFEJIXpsY95GVmxa4Qxu2ihtKGXFphVszNvYRy3rZfoQZ1ZjkHk4QvQxCXCEED1id9h5audTqLjXYGrZ9vTOp7E77L3dtL6RJoU3hegPJMARQvRIdmm2W89NWyoqxQ3FZJdm92Kr+pBkNBaiX5AARwjRI2UNZX7db8BrWRpffACsTX3bFiGGMAlwhBA9Emf0LVOxr/sNeJEZYIwBh9UZ5Agh+oQEOEKIHsmKzyLBmICC5yXRCgqJxkSy4rN6uWV9RFHO5/9pyQckhOh1EuAIIXpEq9Hy8KyHAVDazTNuCXpWzlqJVjOEMuK0DFMV7unbdggxhEmAI4ToscUZi1k97xfE220u2xOMCaxesHro5MFpkTLdeX9GenCE6CuS6E8I4ReLNeEsLDhLdmw6ZVc8TZwxjqz4rKHVc9OiJcCpyoH6CgiN6dv2CDEESYAjhPCPM3vQAjMTZ8LwKwJ2GZvdQaPVTrPNgc2u4lBVFAW0ioJeq8Gg12LQa1D6skxCSCTEjIKKE85hqtFL+q4tQgxREuAIIfwjQAU2Gyw2KuosVDdYMTdaabJ2njBQo4HQIB0mo55oYxBRoUHotb08Ip8641yAs1sCHCH6gAQ4QoieU9Xz801Sex7gNFntFJubKK5poq7J1vkB7TgcUNtko7bJxpnKRjQaiDQGkWQyEB9uQKvphd6dlOmw/zWZhyNEH5EARwjRc9V50FDuLDSZOLnbp6lpspJf0UBJTROqe+WHbnM4oLLOQmWdhWPaWpIjQ0iPNmLQB3B+UNuVVFJZXIheJwGOEKLnWnopEieC3tDlw+uabZwqraOsttnPDXNns6vkVzRQUNlAkimE4XGhgQl04ieANhiaqqHiFMSO9P81hBBeyTJxIUTPteR76eL8G6vdwdHiGnacruiV4KYtVYWz1Y1sPVXOydJabHaHfy+gC4KkKc7HkvBPiF4nAY4Qoue6Mf+mtKaJbacqOFPZ6NfhqK5yOCC3vIFtpysoqfFz7ShJ+CdEn5EhKiFEz9gsULTf+diHHhyr3cGx4lqKzf2rEGWz1cGBM2aKw5sYmxROsM4Pw1aS8E+IPhPQHpzNmzezbNkykpOTURSFd955p9NjvvjiC6ZPn47BYGD48OH89a9/ddtn/fr1jB8/nuDgYMaPH8/bb78dgNYLIXxSegjszWCIhJgRHe5qbrSy43Rlvwtu2iqrbWb76UpKa/3QRqksLkSfCWiAU19fz5QpU/jTn/7k0/45OTlcccUVzJ8/n7179/J///d//OhHP2L9+vWt+2zbto0bb7yR5cuXs3//fpYvX84NN9zAjh07AvUyhBAdaemdSJne4UqhM1UN7Mmr9CmPTV+z2hx8XWDmeEktDkcPxs8iM8AYK5XFhegDiqr2zui3oii8/fbbXHPNNV73WblyJe+99x5Hjhxp3Xbvvfeyf/9+tm3bBsCNN95ITU0NH3zwQes+l112GVFRUbz22ms+taWmpgaTyYTZbCYiIqJ7L0gI4fT2vc58LxevhIX/5/a0qqocK6nlTGVjHzSu50xGPZNSTN1fafXqjXD8Q7jsKZjzP/5tnBBDTFc+v/vVJONt27axZIlrxs+lS5eye/durFZrh/ts3brV63mbm5upqalxuQkh/OSM9wzGNruDfQXVAza4ATA3WNmVW4m50dq9E7T8u8g8HCF6Vb8KcIqLi0lISHDZlpCQgM1mo7y8vMN9iouLvZ73ySefxGQytd7S0tL833ghhqLGKmc5Ajg/ofYci83BnrwqKuosfdAw/2q2OtiTV0lpd1ZZpZ77d5Gl4kL0qn4V4ABuBfJaRtDabve0T0eF9VatWoXZbG69FRQU+LHFQgxhhdnO+6hMl4rZTVY7u/Mqqe1GmYX+yuGAr8+Yya9o6NqByVnO+6pcqC/3e7uEEJ71qwAnMTHRrSemtLQUnU5HTExMh/u079VpKzg4mIiICJebEMIPWvK7tMl/02S1syeviobm/j+ZuDuOl9RysrTO9wNaKouD5MMRohf1qzw4c+fO5T//+Y/Lto8//pgZM2ag1+tb9/nkk0948MEHXfaZN29er7ZVCIHrCirOBzeNFv8FN6qqUllvIae8nqTIEFIiQwAorGrkNx8fw+ZwYHeoGPRajHotocE64sKDyUqPYnpGlN/a0VZueT02h4MxCeEd9h63aq0svgdGLw1Im4QQrgIa4NTV1XHy5MnWn3Nycti3bx/R0dGkp6ezatUqCgsLeemllwDniqk//elPrFixgnvuuYdt27bxwgsvuKyOuv/++7nooot4+umnufrqq3n33XfZuHEjX331VSBfihCiPVU9P68kZQbNNjvZfgpumm12jhTVsq+gmoOFZqrPTfC9alISKdNSAOeK9Lrm80NgVruzeji1zZwuryc2LLg1wGmw2Hhj9xmmpJqYmGJCr+155/WZykYcDhiX5EOQI5XFheh1AQ1wdu/ezcKFC1t/XrFiBQC33XYba9eupaioiPz8/NbnMzMz2bBhAw8++CB//vOfSU5O5g9/+APf/OY3W/eZN28er7/+Oo888gg/+9nPGDFiBOvWrWP27NmBfClCiPaqcqGhAjR6rPETyM6rpqGHwU1tk5V/7znD7rwqLLbztaG0ikJKVAgRIfrWbXHhwTzxjQnoNApajUKT1U6DxU5tk42SmiZGJ4S37nuitI6vTpbz1clygnUapqZFcsGIWN+Ckw6crW5ERWV8UkTH55HK4kL0ul7Lg9OfSB4cIfzgwJuw/i7U5Cz2LFlPdUM3l1G3YbU7eGj919Q22YgODWJqWiTT0iIZERdGkK77vS5nqxv58kQ5e/KqqGw4v6or0WTgkjHxzBsR06OK4smRIYxP7uC9xG6FJ1PB1gQ/2COVxYXopq58fverOThCiAHk3HBLReSkbgU3DlVld24V2flVfPei4WgUBb1Ww82z0ok0BjEiLrRHvSttJUeGcOPMNK6fkUpOeT3bT1ew9VQFxeYmXt2ZT2ZsKJmxod0+/9nqRnRaxaXXyIVW76wsXrDDOawnAY4QAScBjhCie87NvykOn9jlQ3PL63llZz455fUAzMivYkZGtPPxsGj/tbEdjaIwIi6MEXFhXDctlW2nnUFO2+Amt6Ke9CgjGk3Xgqv8igZ0GoXhcWGed0iZ4QxwzuyGKd/uycsQQvhAAhwhRNfZLKhFX6MA5ugpPh9W32zjrb2FbD5ehgoY9BqWTkhkfFLvDxWHBGm5ZGy8y7aKumZ+/eExEiKC+c6sdEZ565Hx4nRZPXqthrRoo/uTkvBPiF4lAY4Qosuqc/cSaW/GEhRJY1iGT8ccPlvDP7bmUHVuOGvO8Gi+lZVKpDEokE3tkiJzEzqtQkFVI09/dIwLR8Zyw4xUjEG+v1UeK64lWKchPsLg+kRLyYbig87K4nqD+8FCCL/pV4n+hBD9X4PFRumRLQDURE/yaUWQw6Hyxp4CqhqsJIQH89DSMdx94fB+FdwATEwx8ctrJnLRqFgU4KuT5Tz23iEOnTV36TwHz5qpbmhXoiIyvU1l8a/912ghhEcS4AghfGazO9hfYCa8fB8ANT4OT2k0CnddkMklY+J59Krx3ifj9gPhBj23zh3GT5aOIS48mKoGK7/beIJXd+bj66JThwP2nzHTYGlTqkJRsKdMZ5chmA1HXmdX8S7sjsGZ7VmI/kACHCGEz44U1VLfbCOi0tkDYY7xHuAcOmvmi+NlrT+nRRv5zux0gnuwHLs3jU4I5/GrxrfO0wnWabq0qstqc7Avvxqr3ZnPZ2PeRpaqedyZlMDKok+486M7Wbp+KRvzNgak/UIMdTIHRwjhk/yKBkpqmtBZzITW5gBQEz3Z474fHy7m33vOoACpUSGM8LayqJ8L1mv5zqx0ZmZEuayOsjkc6DSdfz9ssNj5+oyZCnU3P/7if1Fx7QEqbShlxaYVrF6wmsUZi/3efiGGMunBEUJ0ytxg5URpLUBr701DWAbWYNdaTw5V5fVd+byx+wyqCvNGxJLuaUXRADMqIRztuWXjVruD3350nP9+fdanIauKukZ+tf0pt+AGaN329M6nZbhKCD+THhwhRIesdgcHCs20fJabKvYD7svDrXYHL3yVw+68KgC+lZXK0gkJfkvW119k51dxsqyOk2V1nK1u4vZ5wzrMsny69gAVzaVen1dRKW4oJrs0m5mJMwPRZCGGJAlwhBAdOny2hibr+d4FU6UzwKmJOT881Wyz86fPTnKkuBatRuHOC4YxOzOm19vaG2ZnxtBkdfDqjnx25lZSXtfMjy4ZRZjB89tpjbXSp/OWNZR1vpMQwmcyRCWE8KqgsoGy2ubzG1SVCA89ONtPV3LkXP6XBxePGrTBTYuLR8fx4KWjMAZpOV1ez1MfHaWirtnjvhF63zIzxxnj/NlEIYY86cERQnhU23R+3k2LkPoCgizVODR6aiPHtW6/aFQslfUWJqeaAjqhWKdVMAbpCNZp0Gs16LVK6xCYqqrYHCo2u0qzzU6j1U6z1dHJGbtvbGIED182lt9tPE6xuYmnPjzKA4tHkxIZ4rLf8PBJmPSxmK3lHs+joJBgTCArPitgbRViKJIARwjhxuFQOVhYg6NdfNDSe1MbOY5mVYfG7kCndS6fvnZail/boNUomIx6ooxBRBh0hBl0BOu6tsTc7lCpa7JR02TF3GilqsHi16AnOTKEVZeP43cbj1PTaMXhcJ9IrFG0XJd+H/849YTbcy2zk1bOWolWMzCWzwsxUEiAI4Rwc7Ksjvpmm9v2lvk31VGT+csXJwH4n4tHdDnw8EanVYgPNxAfEUyUMah15VJ3tQRJJqOetHPb6pptlNc2U1rbTE1j16ugtxcdGsTKy8ZS3WAhNcrzirHJ0fO5g8d4K//PLj05CfoIVl7whCwRFyIAJMARQriorLeQX9Hg8bmWFVTvlCdxsKSGIK2GYnMTGTGhHvf3VVSontQoI3FhwV2u4t1VYcE6woJ1DIsNpcFi42x1E0Xmxh717LScs8XxEudk67bDdZOj5zMxah6naw9gPPki4858zqTxizFIcCNEQEiAI4RoZbU7vNZdUuwWwqsPA/BWaRJajcL3F4zodnCjKJAQYSAjxki4Qd/tNveEMUjHyPgwhseGUlbXTH5lA+aGnvXq5Fc08PtPT6BRFB5aOsalsrhG0TIyYioJsUuZdPJD6vJ24XCoAQ/qhBiKZBWVEKLV8ZJarz0Z4eajaBxWKtUw8tUE7r4wk4kppm5dJ9FkYO6IGCammPosuGlLo1FIiDAwc1g0WRlRRIV2v00JEcGkRxtptNpZvfE4xTVNbvu0lLgwVh3l5FnPk4+FED0jAY4QAoDS2iaKqt0/jFuYT24HYL9jBNfPSGPmMN+WP7cVadQza3g0E1NMGIP6ZwdydGgQ0zOimZYeSbiX3DYdCdZr+eElI0mPNlLbZGP1x8fdlpA3GVNoDo5B47BiPr2H0lrv/+5CiO6RAEcIgdXu4GhRrdfnm6x2mnJ2AM78N5eOS+jS+fU6DeOTI5gxLJqIftBj44uYsGBmZUYzPjmiw0zFnhiDdDy4eBSJJgOVDRZWbzyOue2EZkWh5lwvTkTlfrdkikKInpMARwjBseJaLDbvk2wNei0XGfMASJs0v0vlF+IjgpkzPJrkdvlhBgJFUUiODGHuiBhSo7vW/nCDnhWLRxMTGkRJTTNrNh6nwXJ+ZVpLokRTxX5sdpWDhWafalsJIXwjAY4QQ1xZbTPF5o6HSHTN1Zga8wGojZnS4b4ttFqFCSkRTE6N9Nsy8r6i12oYmxjBjGFRGIN8fy3RoUGsuHQ0EQYdUcYgNG0Cw5ZSFxEtS+8brOSU1/u34UIMYf1zEFwI0SusdgdHi2u8Pv/23kKmpJmYaXVWEK8PG4YtOLLT84YbdExK7b/zbLor0hjE7OExnCyto6DS81L69hIiDPzfFeOINga5rJYyRzkDHGP9GfRNlVgN0eSU1xMTGozJODCG8YToz6QHR4gh7GRpnddVU18cL+P9A0X89qPjBJfsBVwLbHqTHBnCzGHRgy64aaHVKIxJDGdqeiR6H+fmxLbJ76OqKqfK6rAHhVMfPhw434ujqnDwrBmbPXAlJoQYKiTAEWKIqqq3UFjV6PG5gsoGXtvpHJK6anIS8TUHANcCm+0pCoxJDGd8csSQyOsSGxbM7MxoIrvQ2+JQVf65LY8nPzjK7tzK1uXipsqvW/dptNg5XlLn9/YKMdRIgCPEEORwqBwp8jw01WS189fNp7A5VCanmrh8QkJriQZzzFSPx2i1ClPTIl2S2g0FBr2WrPQo0mN8e90aRSH4XK/PC1tyOBU0FjifIbrF2epGWTouRA9JgCPEEJRTUU+DxX1ZsqqqvLwjj5KaZqKMeu6cl0lofR56ixm7Npg60xi3Y4L1GmZkRBETFtwbTe93NBqF0QnhTEiJQOPDO+qNM9KYkmrCalf503FnosSIyq9BdR2WOlJUS7NNlo4L0V0S4AgxxNQ128ir8LxaZ+upCrafrkSjwHfnDyfMoMNUcW7+TdREVG2Qy/7GIC0zMqL7RTbivpZkCiErParTeTkajcI984eTEhnCnqZkmglCb63BWJvrsp/V5uBIB7mJhBAdkwBHiCFEVVWOFtXg8DKH9UChsw7V1VNTGJUQDpwfPmk/PBUarGP6sChCurBserCLNAYx04el5Aa9lvsWjiAoKJivHcOA85Xa2yqvbaaw2vM8KSFExyTAEWIIOWtuorqDYpLfvWg4350/nMsnJrZuM1XsA6CmTYATZtAxPSNqwOe3CQRjkI4Zw6I7XeodH27gu/OHs98xEgDN2T0e9zteUkujh+FEIUTHJMARYoiw2BycKOl4yEOjKMzKjG5NSKexNRBmPgacX0EVGqwjKz2qy+ULhpIgnYas9Ciiw4I63G9iiglj5mwAUuoPe9zHblc5XFQjWY6F6CJ5hxJiiDhRWovN7v4heay4lpe25XqshWSqPICiOmgKSaTZmIgxSEtWRqQENz7QahSmpkYSH9Hx5Ov0yRcBEFZ9FI292eM+VfUWznhZ0i+E8EzepYQYAqrqLR4rhTdZ7fxjaw6bT5Tz36+L3J6PODc8ZY6ZRrBeQ5YMS3WJRqMwKcVEosngdZ8mY7Kzsrhqw3JmH6/syMPhcA9ET5bWudSyEkJ0TAIcIQY5h0PlaLHnoak3dhdQXmchNiyIqyYnuT3fMv+mNm4qWelRGPQS3HSVoihMSI7wHuS0qSz+9Y5P+fyYM4N0e3aHyuGzMlQlhK8kwBFikCuoaqC+2f2b/9dnqtl8ohwFuGNepnvwoqqtK3sSxl9IaPDgLL3QG1qCnIQIz0FOy/ymK6IKAXjv67Mea4RVN1gpqJShKiF80SsBzl/+8hcyMzMxGAxMnz6dL7/80uu+t99+O4qiuN0mTJjQus/atWs97tPUJJk/hWiryWrndJl7zpu6Zhv/3JYHwOJxCYxJDHfbx9BQSHBTOapGT/iwGQFv62DXEuTEhbvPyWmp8TXccoQLRsSgqvD8lzmYG91XvJ0qk6EqIXwR8ABn3bp1PPDAA/z0pz9l7969zJ8/n8svv5z8/HyP+//+97+nqKio9VZQUEB0dDTXX3+9y34REREu+xUVFWEweB/nFmIoOlFSh93DfI7XduZjbrSSaDJw7bQUj8e2DE8pSZNBL39b/tAyJ6f96ipz1GRUFIz1Z7h9ShjJJgPmRisvfJWDo92QlP1cmQ0ZqhKiYwEPcFavXs1dd93F3Xffzbhx41izZg1paWk8++yzHvc3mUwkJia23nbv3k1VVRV33HGHy36Korjsl5iY6PF8QgxVlfUWSmrcezXNjVYOFppRFLjzgmFeV0Ql1ToLbJI6M5DNHHI0GoXJKSaXPDn2oHDqI5yVxeNqDvK9i0cQpNVwuKiGDR7m41TVW2VVlRCdCGiAY7FY2LNnD0uWLHHZvmTJErZu3erTOV544QUWL15MRkaGy/a6ujoyMjJITU3lqquuYu/evV7P0dzcTE1NjctNiMHMObHY8++5KUTPL66eyN0XZjI8NszjPuEGHTFV5ypcS4DjdzqthimpkRiDz897qjk3DyeiYj8pkSHcPDsdcGaX9tQLd7K0ThIACtGBgAY45eXl2O12EhISXLYnJCRQXFzc6fFFRUV88MEH3H333S7bx44dy9q1a3nvvfd47bXXMBgMXHDBBZw4ccLjeZ588klMJlPrLS0trfsvSogBoKCqgYZm7x9+ESF6ZmfGeHxOr9MwJcmAUtwS4Mj8m0AI0mmYlnY+YWLLROOWid0XjIzl3ouG85OlY9BqFLfj7Q6VI16CWCFEL00yVhTXP05VVd22ebJ27VoiIyO55pprXLbPmTOHW265hSlTpjB//nzeeOMNRo8ezR//+EeP51m1ahVms7n1VlBQ0O3XIkR/12S1c7rcfWJxbkU9e/KqOjxWUWBSiglD2UFwWCE0DiIzOjxGdF9IkJap6ZFoNeeXikdUHmitLD5jWDS6DkqUV9ZZpFaVEF4ENMCJjY1Fq9W69daUlpa69eq0p6oqL774IsuXLycoqON05xqNhpkzZ3rtwQkODiYiIsLlJsRgdbK0Dnu7jMU2h4N/bs3l2S9OsfFIiddjh8eFER0aBGd2OTekznJGPSJgIgx6JqaYqI8chV0b7LGyuM3u4M09ZzwGqCdKaj1moRZiqAtogBMUFMT06dP55JNPXLZ/8sknzJs3r8Njv/jiC06ePMldd93V6XVUVWXfvn0kJbknKhNiKKlusFBsdp9Y/MnhEgqqGgkN0jJrWLTHY2PCghgWY3T+0BrgyPBUb4gLD2ZkYjS1Uc50GO0ri286XsaHh4r557ZcqhosLs/Z7CrHvCRyFGIoC/gQ1YoVK/j73//Oiy++yJEjR3jwwQfJz8/n3nvvBZzDR7feeqvbcS+88AKzZ89m4sSJbs898cQTfPTRR5w+fZp9+/Zx1113sW/fvtZzCjEUqarnD7rS2ibe238WgBtnphER4l7lOlivYUKy6fzQ8ZndznuZYNxr0mOM2JOnA86Jxm0tGB1HerSRBoudF7e4Lx0vq232uGJOiKEs4AHOjTfeyJo1a/j5z3/O1KlT2bx5Mxs2bGhdFVVUVOSWE8dsNrN+/XqvvTfV1dV897vfZdy4cSxZsoTCwkI2b97MrFmzAv1yhOi3zpqbqG1yTwD3+s4CrHaVcYnhzB3ueWLxhGTT+eXiNWeh5gwoGkieFsgmi3aiRjl7tk2VX7ts12k13DM/kyCthiNFtXx2tNTt2GPFtVhsjl5ppxADgaIOwWxRNTU1mEwmzGazzMcRg4LV7mDrqQqs7T7g9hVU86fPT6LVKDyxbILHekjDYo2MjG+TyfjQ2/Dv2yFxEtz7VYBbLlxUF8CaiaiKls+v3YNDZ3R5+vNjpbyyI58grYbHlo13K/2QFGlgQrKpN1ssRK/qyue31KISYhDIKa93C25sdgev73L2ji4dn+AxuAk36Nxz4eTvcN6nzw1IW0UHItMgIhVFtRNZ9bXb0wtGxzEuKRyL3cE/tuS6VR0vqm6ioq65t1orRL8mAY4QA1x9s42Cyga37TqthptnZzA2MZwrJ7lPwNdoYGKKCU37HCv525z3abMD0VzRmXTnv/vIpoNuTymKwu1zh2HQayioavC4RPxocS02uwxVCSEBjhAD3PGSWrwNNE9KMfHjJWMIbl8pHBgZF+5eIby5DorPlWhIn+PnlgqfnOs5iyjdQ0pUiNvTMWHBfHf+cB5fNoG0aKPb840Wz3mQhBhqJMARYgArr2umos512bCqqtQ1d1xtOipUT1q0+4cnhbtBtYMpDUyp/myq8FVLz1nBTsbEGQk36Nx2mZwa6bEqeYuCygaPlciFGEokwBFigHI4VI57WBa+r6CaVW8d4HMPK20AtBqFcUkRnrOJ52933svwVN9JmABB4WCpRVN+hMmpkei03pMtHimqYfOJMpdtqurc3n6OjhBDiQQ4QgxQZ6oaaWhXbNFqd7BudwGNVrtbQrgWI+PDMAa59woA5wMcGZ7qOxotpJ3LP5S/nZAgLeOTPK8WOVVWxzOfHOfVHfmcbTcfp67JRp6HuVlCDBUS4AgxAFlsDk6X17lt33ikhPI6C5Eheo8TiyONelI9zOsAwG47n8FYApy+1bKC7VzAGR9hINXDkOLw2FAmp5iwOVRe3JLjVnU8p7yOBkvHw5VCDFYS4AgxAJ0ur8PWrt6UudHK+weKAPhmVqrbxGKNBu9DUwClh8BSB8ERED8+IO0WPmoZImzpUQNGx4cT1m4+jqIo3Do3A2OQltyKBj465Fr3z+FwDlUJMRRJgCPEAFPbZKWwyn158Lv7CmmyOhgWY2T2cPd6U8NiQt1XTbXV8mGaOtM5TCL6TuoMULTOjNLmMwBoNAqTUkxo2y3rjzQGcdPMdADe23+W4nYlG6rqrVJxXAxJEuAIMcCcKK1zWxZeUNXAlyfLAWe9KU27XhpjsJZhMaEdn7h1/o0k+OtzQaGQNNn5uE0vTmiwjtGJ4W67zxkezYTkCGwOlZe25brVqjpRUkuzTSqOi6FFAhwhBpCy2mYq69wnD58sqUMBZmREMSre/QNwXGKEe0K/tlS1TYAjK6j6hbRz86DaBDgAKZEhbkvEFUVh+ZwMgnQajpfUcbDQ7PK8za5yvNh9zpYQg1kH/dVCiP7E4VA5UeK+LBxg4dh4RieGE+IhoV+iyUBUaFDHJzcXQO1Z0OggZbo/mit6Kn0O7HgWCra7PTUuKQJzY4VLcc3YsGBumplGsE7LpBT3elQlNU0k1ho6zJ8jxGAiPThCDBCeloW3lRIZQnS7QEanVRiVEObliDZaegkSJzuHR0Tfa1nJVnIImlwnCgfpNIxPdl86Pn9UHLMyo71OJD8mZRzEECIBjhADgLdl4dn5VR4nHLcYERdGsM6HCcMy/6b/CU+EqGGgOs4v328jNizYYymHFnXNNk6Xuf7ONFmljIMYOiTAEWIAyCmvd1sWXttk5R9bcnn8v4c4Ueo+dBVm0HnPedOezL/pn7zMw2kxKj6MkCD3ALagqoGfvXuQP31+kvp2ZTukjIMYKiTAEaKfq2+2cabKPSPte/vP0mi1kxoZwohY92GosYnh3nPetNVYDaWHnY/TJMFfv9IyTOVhHg44K8ZP8DBUlRhhIDRYR02TjX/vOePynJRxEEOFBDhC9HOeloUX1zTxxXFn/aEbZ6a5rZBKNBmINHYysbjFmV2AClGZEJ7ghxYLv2kJcM7sBrvnXpdIYxDpMa5VxfVaDbfNyQDgq5Plbsn+6pps5EsZBzHISYAjRD9WUddMeW2z2/a3swtxqDA5xcTYRNdv8FqNwsh4HyYWt5D5N/1X7BgwRIK1AYoPeN1tRFwYxnZDVaMSwlk4Jg6Al7fnYW03uTinvF7KOIhBTQIcIfopVVU5XuI+sfhUWR178qtQFGdJhvYyYowYPCwX9yp/m/Ne5t/0PxpNm7IN27zuptUoHldVXTstBVOInpLaZj446FrGwe5QOeqhGr0Qg4UEOEL0U2fNTW4TRFVV5c1zcyrmDY9xW0UTrNeQ0VnG4rasTc7hD4CMC3vUXhEgwy5w3udu6XA3T0NVxiAd356ZBsCGA0VuZRwq6ywUmaWMgxicJMARoh+y2R2cKnXvvVFVmJYeSZRRz9VTU9yeHxkf5larqENndoG9GcISIGZET5osAqUl8Mzb4qye2YERce6rqmZkRDEpxcSc4TGEBbnndj1eUueSMFCIwUIyGQvRD+VWNHj80NFoFJaMT+SSsfHoNK7fTyJC9CRGGLp2obxzvQIZF4AvK65E70uaAkFh0FTtrPieOMnrrlqNwrikCLLzqlq3KYrCfQtHuP2+tLDaHBwvqWWih+zHQgxk0oMjRD/TZLWTX9lxMjZPH1aj4sN8WxbeVu5XzvthMjzVb2l151dTtfx/dSA6NIjkSNehy7a/L6qqumUzLjY3UVHnPpldiIFMAhwh+pmTpXVuIxHNNjvPfHKMvflVqO3XjANx4cGd15tqz9Z8PkOuBDj9W0bLPJzOAxyAUQlhBOnc397L65r5/WcneHVnvttzR4trsUtuHDGISIAjRD9ibrBSbG5y2/7pkVKOFNXy+q4CbO0+hBSFri0Lb1G4B2xNEBoHsaO722TRG4bNd977MA8HnHlwxia6V5WvrLdwsLCGzSfKOdlujlejxU6Oh3IgQgxUEuAI0Y8c91ByobbJ2rrE95ppKei1rn+2yZEhhAZ3YzpdS2+AzL/p/5Kngj4UGqug7IhPh8RHGIhtVzl8dEI4F46MBeBf2/OwtQuW8ioaqG2SMg5icJAAR4h+oqSmCXOD+4fL+weKaLTaSYsKYXZmtMtzWo1CZmw3q3/L/JuBQ6s/n6fIx2EqcJbraL+q7ltZqYQF6yisbuSTwyUuzznLONR6HAYVYqCRAEeIfsDhUN2GDMCZyXjTMWdJhm9NT0XTrqclLbqLSf1a2CxQsNP5WAKcgaGL83AADHotI+Jchy/DDDqun+FMEPmf/UWUt5tcXNNopaBScuOIgU8CHCH6gYKqBhotdrft//26CJtDZUxCOOOTXDPV6rQKGe0Su/nsbDbYGsEYA3Fju3cO0buGtcmH04UelrToEMINrkOY84bHMDohDIvdwas78t16bE6V1dFkdf99FGIgkQBHiD5msTk4Xe6+LLy8rpktp8oBZ8r99kvAM2ND3ebj+Ezm3ww8yVmgC4GGCig76vNhiqIwtl1wrCgKy+dkoNUoFNc0UdcuY7bdoboV6BRioJEAR4g+drq8Drvd/Rt5TGgQ9y0cyaXjE9xWSQXrNaRGdbP3BmT+zUCkC4K0Wc7HOV926VBTiJ60aNfflyRTCA8sGsUT35hAuEHvdkxFncXjij4hBgoJcIToQ/XNNgqrPM93UBSFKamR3Dgjze25zNjQrpVkaMvadL6CeOZF3TuH6Bst/185X3T50OFxoW65ccYlRXTYC3ispFbKOIgBSwIcIfrQidI6j9Mpmm3e5z+EBGlJNoV4fb4jdoedXQdfZkOwwq6oROwxo7p1HtFHhi9w3ud8CY6uzZHRazWMTnDPjQPOIamNR0rIr2hw2W61OTjhIXWBEAOBBDhC9JHKegvlte7p8U+V1fGTN7/mw3O5b9obHheKphu9NxvzNrJ0/VLu/Pr3rIyP5c7IIJa+dRkb8zZ2+VyijyRNhWATNJvh7L4uH55oMnjMeP323kJe31XAv3bk4WiXSLKoWso4iIFJAhwh+oCqqhwv8fzN+J29hTRY7BSZ3YeuQoN1XS+oiTO4WbFpBSUNrnlPShtKWbFphQQ5A4VWB5nnshrnbOrWKcYmhtO+lNnicfEY9BpyyuvZfKLM7Rgp4yAGol4JcP7yl7+QmZmJwWBg+vTpfPml9wlymzZtQlEUt9vRo66rBtavX8/48eMJDg5m/PjxvP3224F+GUL4zVlzE3VNNrftR4pqOFJci1ajsGxKstvzI+JCu1xQ0+6w89TOp1Bx/4Bq2fb0zqexd3HIQ/SRzIud96c3devw0GAd6dGuySEjjUFcMzUFgPXZhZgbXRNONlrsnC6TMg5iYAl4gLNu3ToeeOABfvrTn7J3717mz5/P5ZdfTn6+e7G3to4dO0ZRUVHrbdSo83MFtm3bxo033sjy5cvZv38/y5cv54YbbmDHjh2BfjlC9JjN7vD4YaGqKm/vLQTg4lFxxIa5ptkPM+iIa5d63xfZpdluPTcu10WluKGY7NLsLp9b9IGWeTj5O8DavYR8mbGhbgkiF46JJz3aSKPVzr/3FLgdk1/ZQI2UcRADSMADnNWrV3PXXXdx9913M27cONasWUNaWhrPPvtsh8fFx8eTmJjYetNqz/8xrlmzhksvvZRVq1YxduxYVq1axaJFi1izZk2AX40QPZdX2UCz1X1lyv4zZk6X1xOk1XDl5CS354d3o/cGoKzBfcihJ/uJPhY7CsKTwN58fjVcF2k1CqMTwty2LZ+TgQJsP13J0WLXPDiqCofP1rjN0RGivwpogGOxWNizZw9Llixx2b5kyRK2bt3a4bHTpk0jKSmJRYsW8fnnn7s8t23bNrdzLl261Os5m5ubqampcbkJ0RearHa3lSoADlXlnX3O3ptLxsZjCnHNSxJu0BEf3vW5NwBxxji/7if6mKK0WU3V9eXiLeIjDESHuU44zowNZcEY5+/BazsL3DIc1zXZyK90//0Voj8KaIBTXl6O3W4nISHBZXtCQgLFxZ5XiCQlJfHcc8+xfv163nrrLcaMGcOiRYvYvHlz6z7FxcVdOueTTz6JyWRqvaWluecVEaI3nCyt8zhZM7e8nsLqRkL0Wi6bmOj2/PB29YS6Iis+iwRjAt76fhQUEo2JZMVndfsaopf1cB5OC08Tjq+dlsK0tEjumZ/pscfwdHkd9c3u88eE6G90ne/Sc+3/SFRV9drVPmbMGMaMGdP689y5cykoKOC3v/0tF110PilZV865atUqVqxY0fpzTU2NBDmi15kbrV4zww6PC+Pn35jA2eomwoJd/ywjQvTdmnvTQqvR8vCsh1mx6UEUVUVt83einAt7Vs5aiVbTjaKdom8MPxfgnN0HjVUQEtWt0xiDdKRHG8ktb3DZdt/CkV6PcTick+GnZ0R1a8hUiN4S0B6c2NhYtFqtW89KaWmpWw9MR+bMmcOJEydaf05MTOzSOYODg4mIiHC5CdHbTnaSMC3JFML0DPcPquFxoR727prFGYtZHTKWeLvrSqkEYwKrF6xmccbiHl9D9KKIZIgdDaiQs7nT3TsyLCaUYL33j4LS2ia3oarqBitnvGTgFqK/CGiAExQUxPTp0/nkk09ctn/yySfMmzfP5/Ps3buXpKTzky7nzp3rds6PP/64S+cUojeV1jZRVe++AsVqd3jMd9MiIkTvtpqqWxwOFufv56OCs7w48Yc8Pf9pXlz6Ih9+80MJbgaq4Qud96c+69FpdB1kOH5r7xkeeecg2fnVbs+dlIrjop8L+BDVihUrWL58OTNmzGDu3Lk899xz5Ofnc++99wLO4aPCwkJeeuklwLlCatiwYUyYMAGLxcLLL7/M+vXrWb9+fes577//fi666CKefvpprr76at599102btzIV199FeiXI0SXORwqJ0s85xD54ngZ63YXsHR8It+anur2fGZsz3tvACg5CHUlaPWhzJxyG+j8EDSJvjVyMez8G5z81LnEqQfDRQkRBs6ENrgF4RpFwaHC67vymZAc4bK03G53Vhyflt694TEhAi3gAc6NN95IRUUFP//5zykqKmLixIls2LCBjIwMAIqKilxy4lgsFn784x9TWFhISEgIEyZM4P333+eKK65o3WfevHm8/vrrPPLII/zsZz9jxIgRrFu3jtmzZwf65QjRZWeqGmmwuH/Tbbbaef9AEaqKxzk2PZ174+LkuR7PzIskuBkshl0I2mAwF0DZMYgf26PTjU4IZ2dOpUtttCsmJrHjdCVldc28u+8sN850nbtYUWehyNxIUjdrowkRSIrafnB1CKipqcFkMmE2m2U+jggoi83B1lPl2Ozuf2YbDhTx1t5C4sKC+cU1E9C1W84yJS3SfwHOP66AvC1wxW9h1j3+Oafoe/+61jlEteSXMO8HPT7dseJaCtotAz9YaGbNpydQFPjZleNJjza6PK/TKswdEUOwTiapi8Dryue31KISIoByyus9BjcNFhsfHnJOlP/G1GS34Ka7WYs9ajKfTwg3UubbDCojL3Xen/yk4/18NDwuFL3O9XdxYoqJGRlRqCq8vD0PR7vvxDa7yvFiKeMg+h8JcIQIkPpmG2eqPCdF+/hQCQ0WO8kmA7OHRbs974+VU61OfwGqHWJGQnSm/84r+l5LwJq3FSz1PT6dXqthZLx7zqUbZ6YRrNNwuryeL0+Uuz1fUtNEaY3nFAhC9BUJcIQIkBOldXgaAK5ptPLJEWdtqGumpaDRuE4ODTPoiPPHyqkWLd/uW77ti8EjdhREpoPdAjneixh3RbLJQLjBdXpm1LlinAa9xutc5qPFtVjt7iVIhOgrEuAIEQAVdc2U1zZ7fK6wuhGtRmFYjJFpaZFuz2fGdq/mlEeq6lxlAzBKhqcGHUVpM0y10U+nVBiT6L5s/JKx8fy/qydy0SjPJT0sNgfHijvO9SREb5IARwg/U1WV416WhQOMS4rgqesmcfeFw90CGWOwlnh/zb0BKD0CNYWgM0DGBf47r+g/WoapTn6Cxy7Dbog0BpFocq19ptUoRBqDvBzhVGxuosxLYC9Eb5MARwg/K6xu7LRWjzFI5/YBAn7uvYHzw1PD5oNelvIOSpkXgUYPVblQccpvpx0ZH4ZW4/l38WChmT98egKbhyGpo8U1MlQl+gUJcITwI6vdwakyz5M9y2qb2VdQ7Zb2voUxSEtiRPcqhnt1omX+jQxPDVrBYZAx1/nYT6upAAx6rcdEk81WOy9syeHrQjMfHS7x8LyD4yUyVCX6ngQ4QvhRbnk9Vpvnb6/v7CvkT5+f5M09Zzw+n+Hv3pvGKufqGoDRS/x3XtH/jL7MeX9sg19Pmx5txBjkmt8mWK/lhunOhH///fqsxyGpouomyutkqEr0LQlwhPCTBouNAi/LwgurGtmZUwnArEz3ZeEGvZakQPTeqHaIGwfRw/17btG/jLnceZ+7xRnY+olGozDKQ52qOcOjGZMQjtWu8urOfI+9kkeKZKhK9C0JcITwkxMldTi8vJ+/s68QFZiREUVGjHu3f0aM0W25eI8dfd95P/aKjvcTA1/0cGcgq9rhhH9WU7WICw8mJsx1crGiKNwyJx2tRuFAodljMU4ZqhJ9TQIcIfygst7idfXI6fI69hZUoyjwjSnJbs8H6TQkR/p5ArCt+fzy8DFX+vfcon9qCWSPve/3U49OCHfLf5NkCuGyCYmAsxinp8riRdWyqkr0HQlwhOgh57Jw799U395bCMDc4TEeA5mMGKPX1SrdlvslWGohLBGSp/n33KJ/GnMuwDmx0Rng+lFosI60djWoAK6clERsWBBVDVZ25lZ6PFaGqkRfCXg1cSEGu8LqRuqaPC8LP1JUw5GiWrQaxWPvjU6rkOLv3huAo+cmm465DDTyPWZISM7CHpZItq2Ksl2/Jy5zIVnxWWg1/imCmRkbSrG5CUubSfRBOg23zR1Go9XuMWklnE8AODHF5Jd2COErCXCE6IGOloUDaBRnADM6IYxYD+UX0qON6LR+DkBUFY594Hwsw1NDxsaCz3gqPpwSNQiO/wuO/4sEYwIPz3qYxRk9TxOg12oYER/GkbM1LtvHJXVc0RmcCQDjw4OJ9/dEeiE6IF/thOiBnA6WhQOMSQznsavG862sVLfntFrFY7d/jxXtg9qzoA91JoETg97GvI2s2LSCEtV1aKq0oZQVm1awMc8/E4+TTQYiQvRen69tsnot13CkuJZmm/s8HSECRQIcIbqpvtlGQaXnZeFtaTQKwXr3YYK0qBD0/u69gfPDUyMvAb18Yx7s7A47T+18ChX3pdot257e+TR2R8+DC0VRGONh2Tg4UyE88s5B/rzpJLVNVrfnrTYHR4tkVZXoPRLgCNFNx0tqvZb+2ZtfxUeHil3mK7Sl0RCY3huAo/913svw1JCQXZpNSYN7RuEWKirFDcVkl2b75Xomo56kSPfAOdFkIDo0iAaLnX97SWZZVtvM2epGv7RDiM5IgCNEN5TVNlNRZ/H4nM3h4N97zvDvPWf47Gipx31SIo0E6/wz+dO1Yceg9LCzNtGYy/x/ftHvlDWU+XU/X4yIC0OrdV35p9Uo3DInAwXYeqqCI0U1Ho89VlJLo0WGqkTgSYAjRBc5HConOlgWvvVUBaW1zYQbdCwYE+f2vKI4l4YHxKF3nPcjLoGQqMBcQ/QrcUb337Ge7OcLg17LcA91qkbEhXHxaOd1Xtqe57EH025XOVxk9lqTTQh/kQBHiC7Kr2ygwcs3UKvdwX/2nwXgiolJGDzMvUkyhXjc7heH3nbeT7g2MOcX/U5WfBYJxgQUPOdSUlBINCaSFZ/l1+umRRkxBrv/Hn8zK5Uoo56y2mbeO/e30F5VvZV8H+avCdETEuAI0QVNVjs55d6XhW86VkZVg5Uoo95r782w2AD13pQegbIjoA06X5tIDHpajZaHZz0M4BbkKOc6SVbOWum3fDgtNBqF0R4mHIcEabl5dgYAHx8uJq/C89/LqbI6j5ORhfAXCXCE6IKTpXXYHZ671pusdjYcLAJg2eRkjyuk4sMNGIMClH6qpfdmxCIIiQzMNUS/tDhjMasXrCbeGO+yPcFuY/WUH/klD44nsWHBxIW753eamhbJrGHRXDQqzuPzAA4HHCysweHl70mInpJEf0L4qLrBQrG5yevzG4+UUNtkIz48mHkjYzzuE7DeG1WV4akhbnHGYhamLSS7NJuyhjLidjxPVs5naDM8r2jyl9EJ4VTUN7sVmr37wsxOC8jWN9s4WVbnsSdIiJ6SAEcIH6iqylEvCcxaTEuPIr+ygekZUeg8lEeIDQ8m3OA9SVqPlB6G8uOgDZbhqSFMq9EyM3Gm84fGZjj2GRx8CxY9hlu1TD8JCdKSHh1Kbruh27bBjaqqNFrtHnsv8ysaiAkNIsZDpm8hekKGqITwwZkq7/WmWqREhvD9BSOZnem59yYzxn3Vid+09N6MXAyGzlPniyFg1BLQG6E6D87uDeilMmNDvU6cr6hrZvUnx/nLplNeV04dOlvjNWeUEN0lAY4QnbDYHJwqq/P6vC/LXaNCgzAZA9R7o6pwcL3z8YRrAnMNMfAEhcLopc7HLb8fAaLVKIxOCPP4nEOFU2X1HC2u5cuT5R73sdgcHPaSN0eI7pIAR4hOnCytw2b3HsSs213A2q25VNZ7TvwHzm+4AVOwAypPO2tPjbkicNcRA8+kG5z3X78B9o57IHsqPsJAdFiQ2/a48GCunpoMwL93n6G6wfPfSXlts0+lT4TwlQQ4QnTA3GjtMLV8WW0znx8r46uT5ZTWep6AbDLqiQ51f+P3m32vOu/HXw3Bnr9FiyFq1KVgjIX6Ujj1acAvNyYhHA/Tz1g8LoFhMUYarXZe3Znv9fgTpbWydFz4jQQ4QnihqipHO+k2f3tvIXaHyvikCMYmep77MiyQc2+sjefn30y9KXDXEQOTVg+Trnc+bgmEAyg0WEe6hxprWo3CbXOHoVUUsvOr2ZNX5fH4lqXj3lIxCNEVEuAI4UVhdSO1HUwszquoZ2duJQDfykr1uE+YQec1D4hfHH0fmmvAlA4ZFwbuOmLgagl8j22ARs+BhT8NiwklWO/+0ZIWbWTpxAQAXt6R57Wnpr7ZxrFOViwK4QsJcITwoNlm52Sp94nFAOuzCwGYnRlNupfaUgGdewOw/zXn/ZQb8Tg2IETiZIifAHaLc8l4gOm0Gq95bZZNTibZZCAsWEdds/cvD2erGymp8Z5zSghfyDuiEB50NrH40Fkzh4tq0GoUrpma4nEfY7CW+ED23tQUwanPnI+nyPCU8EJRzvfitATEAZYQYSDKw7wzvVbDDy8ZxaNXjSfJFNLhOQ4X1dBgCezEaDG4SYAjRDvVDRaKqjv+9vjhwWIAFoz2noo+MzYUJUDJ1QA48AaoDkibAzEjAncdMfBNugEULZzZBeUneuWSYxM9TziOCw92KWPiLc2C3a5y4IxZSjmIbpMAR4g2HA6VI0Wdj//fe/EIrpiUyFWTkzw+HxKkJSHc4O/mnaeqsPcV52OZXCw6E54AIxc5H+99uVcu6Zxw7H2I1u5Q+eBgEX//KsdrkFPbZONEJ0PFQngjAY4QbRRUNVDfwdyAFqHBOq6bluq19EJGjLHTOjw9kvsVlB9z5r6ZcF3griMGj6xbnfd7/wW25l65ZEcZjotrmnhn71l25FSyK9f75OeCygZKZT6O6IZeCXD+8pe/kJmZicFgYPr06Xz55Zde933rrbe49NJLiYuLIyIigrlz5/LRRx+57LN27VoURXG7NTXJH4HoviarndNl9R3uU1HX3Gnm4mC9huRO5hf02O4XnPeTb5DSDMI3oy+H8GRoqIDD7/XKJbUahdGJnnMzpUSGcOW5HtBXduRhbvSe/+aQzMcR3RDwAGfdunU88MAD/PSnP2Xv3r3Mnz+fyy+/nPx8z8meNm/ezKWXXsqGDRvYs2cPCxcuZNmyZezd61pLJSIigqKiIpebwRDAIQEx6B0tru0w/0ajxc4v3j/Crz865jUbKziXyQa096a2GI78x/l45l2Bu44YXLQ6mHGH8/Guv/faZePDDV7nqV0xKZG0qBDqLXb+tT2vw/k4X58xS34c0SUBD3BWr17NXXfdxd133824ceNYs2YNaWlpPPvssx73X7NmDQ899BAzZ85k1KhR/OpXv2LUqFH85z//cdlPURQSExNdbkJ0V2lNE+W1HXfbf3y4mLpmGzVNVsIM7lWRAYJ0GpIjA9x7k/0SOGzOycWJkwJ7LTG4ZN0KGh0UbIfig7122TGJ4Wg9BP06jYY7L8xEq1HYV1DN9tOVXs9R12TjaLHUqxK+C2iAY7FY2LNnD0uWLHHZvmTJErZu3erTORwOB7W1tURHR7tsr6urIyMjg9TUVK666iq3Hp62mpubqampcbkJ0cJqd3CspOOJxdUNFj4+XALAddNS0XnJOZMRY/T4Ru43dhvsWet8LL03oqvCE2HsVc7HLcOcvcCg1zI8zvOE47QoI8vODVW9ujOfijrvXzSKqpso7KB0ihBtBTTAKS8vx263k5CQ4LI9ISGB4uJin87xzDPPUF9fzw033NC6bezYsaxdu5b33nuP1157DYPBwAUXXMCJE56XPz755JOYTKbWW1paWvdflBh0TpXV0Wx1dLjPO/vO0mxzMDw2lKz0SI/76HUaUgLde3P8Q6gpBGOMs/aUEF01827n/f510NR7X/bSooxeez4vn5jEiLhQrHYHuRUdF9w8VlzT4XwdIVr0yiTj9rlAVFX1KT/Ia6+9xuOPP866deuIj49v3T5nzhxuueUWpkyZwvz583njjTcYPXo0f/zjHz2eZ9WqVZjN5tZbQUFBz16QGDTMDVbOVHb8jTC/soEtJ8sBuHFmmtff3fRoIzptgP+kdj3vvM+6FXQBTCIoBq9hF0LsGLDWw/7Xe+2yGo3COC/12rQahbsvHM4jV45jekZUh+dxOODAGTPNNnsgmikGkYC+G8fGxqLVat16a0pLS916ddpbt24dd911F2+88QaLFy/ucF+NRsPMmTO99uAEBwcTERHhchPC4VA53EkxTVVVeWN3ASowa1g0I+I8rwjRaRXSogLce1O0H05vciZsm35HYK8lBi9FgVn3OB9v/7Nz2LOXmIx6Urz8ncSFB5Ma5bnkSXtNVjsHC2s6XdEohraABjhBQUFMnz6dTz75xGX7J598wrx587we99prr3H77bfz6quvcuWVV3Z6HVVV2bdvH0lJnpOuCeFJbkV9pzlv6pvt1DRZ0WkUrsvyXJIBeqn3ZssfnPcTroWojMBeSwxuU292DnNW5cKRd3v10iPjwwjSdfy3crq8jj98eoJmq/demqp6iyQBFB0K+BDVihUr+Pvf/86LL77IkSNHePDBB8nPz+fee+8FnMNHt956a+v+r732GrfeeivPPPMMc+bMobi4mOLiYsxmc+s+TzzxBB999BGnT59m37593HXXXezbt6/1nEJ0pq7ZRm5FxzlvwFkN/LGrJvDQZWOIDfM8JKTVKqRF+/bNs9uqcuHQuUKJF9wf2GuJwS/ICLO+53z81RpnZuxeotdqGJvouRgngM3h4LnNp/m60Mwbe850eK78igaKzDLpWHgW8ADnxhtvZM2aNfz85z9n6tSpbN68mQ0bNpCR4fwGWlRU5JIT529/+xs2m4377ruPpKSk1tv9959/U6+urua73/0u48aNY8mSJRQWFrJ582ZmzZoV6JcjBgFVVTlSVIOj43nFrbQaheGxnoemwNl7ow90783WPznrTo24BJImB/ZaYmiYdQ/ojVD8tXPosxfFRxiI9ZIbR6fRcNvcYQB8cbyMfQXVHZ7rSJFMOhaeKeoQHMSsqanBZDJhNptlPs4QlF/RwPFOloXXN9v46mQ5l4yN7zB40WoVLhwZG9gAp74cfjcRbI1w63sw/OLAXUsMLR+shB1/heEL4NbeHapqstrZdroCu93zR9Abuwv4+HAJYcE6nvjGBEwhnsuigDN7+Mxh0V7LQojBoyuf31KLSgwpjRY7p8o6H7f/79dF/HvPGZ7ddKrD/dKieqH3ZudzzuAmaSpkXhTYa4mhZc73nZPWT2+Cs/t69dIGvZaRXibtA1w7LYW0qBDqmm28+FUOjg6+izdbHZLpWLiRAEcMGaqqcrio8zfBkpomPjtWCsCicfFe99NqFTJiAjz3prHK+Q0b4MIHnCtghPCXqAyY+E3n4y9+3euXT40KIdLouWdGr9Vwz/zhBGk1HCqq4cODHedOq2m0cvisrKwS50mAI4aMM1WNVNV3Plb/ZvYZ7A6ViSkRTEg2ed2vd+be/BGazBA3DsZ9I7DXEkPTRT8GRQPH3ocze3r10oqiMC4pAi+JwUmODOE7s9IBOF1e32EvDji/nJwu73zxgBgaJMARQ0Kjxc5JH5aUHimqYW9+NRoFbpjuPeO1VquQHuiVU3WlsP1czbZFPwONzC8QARA3Bqbc5Hz82c97/fKhwboOJ/FfMDKGH14yku8vGIHGhx7MnLJ6WVklAAlwxBDg69CUzeHg1Z3OFX0LxsR3WDSzV3pvvnwGrA2QMh3GXBHYa4mh7eKVoNE75+Kc/qLXL58RYyTcSxkHRVGYkhrpEtx0Ngx1pKiGqnqLX9soBh4JcMSgV1Dp29DUZ0dLKTI3ERas4+opyV730wWw98busLOreBcbDr7ErgMvYwdY9KjMvRGBFZUBM85lx/7sF72aFwecQcz4ZO9DVS2arHZe+CqHjw6VdLifwwH7z1R3mshTDG6eQ2YhBon6ZhsnyzpeEt5iSmokR4trmZoWSWiw9z+NQPXebMzbyFM7n6Kk4dybd0I0CcTxsNZGx8VKhPCD+T+G7H/BmV1wbAOM7TyLvD+FG/RkxoZxqoOh5P0F1Ww7XYFGgRFxoYxK6CBhoF1lb341M4ZFyfLxIUp6cMSg5XCoHDrre0K/hAgDP7pkFPNHxnrdJ1C9NxvzNrJi04rzwc05pdhZsWkFG/M2+v2aQrgIT4A5/+N8/NFPwdrU603IiPY+VAUwKzOaWcOicajw182nqW7oeBiqyWpnX0E1NruPbwJiUJEARwxaORX11PiQ4dTa7s2vo0r3w2JC/V5zyu6w89TOp1BxHxZo2fL0zqexO6R6sgiw+SsgLBGqcmDbH3v98hqNwoQUk9ehKkVRuHVuBsmRBsyNVv76xelOg5e6Jhv7z5hxSI6cIUcCHDEomRus5PqwXNThUHn6w6Os3ZpLbVPHwVCQThOQmlPZpdluPTdtqagUNxSTXZrt92sL4SI4HJb8P+fjzc9AdX7H+wdAWLCOER0kADTotdy3YCQhei0ny+o6rVcFzsKchyRHzpAjAY4YdGx2BwfPmn2aJ/nlyXJyKxrYk1dFZ1/wMmND0Wr8P9m3rKHMr/sJ0SOTvgUZFzqzZ3/0f33ShPRoo9cEgOAcTr7rwkzAuThg2+mKTs9ZUtPE0WLf5uOJwUECHDHoHCuppdHS+XBOTaOV9dnOb3/fmJLcYa0bg15LSgfLxnsizhjn1/2E6BFFgSt+4yzhcOQ/cLL353+1rKrq6AvF1LRIrpqURLhBR1QHwVBbhVWNnCyVIGeokABHDCrF5iaKqn2bHPnGngIaLHbSokK4ZKz3kgwAmXGhaALQewOQFZ9FQlAkipcuJwWFRGMiWfFZAbm+EG4SxsPs7zkfv3e/M5t2LzMG6Rid6H2VFDi/mDy+bAJjE30vmpxb3kCOZDseEiTAEYNGo8XOkeIan/Y9UlTD9tOVKMDyuRkdflM0BmlJNhn81Ep3WksdD1dUAdC+Fcq5LStnrUQrmYxFb1r4U4jKhJoz8MHDfdKElMgQ4sKDvT6v0SguPa/F5ia3RQOenCqtI7+iwS9tFP2XBDhiUHA4VA4UmrHbO594Y7U7eHl7HgALxsR1mCYeYER8WIcrq3rsw/9jcXkBqxs0xIe49iQlGBNYvWA1izMkE47oZcFhcO1fAQX2vwpH/tsnzRiXFEGQrvOPqq/PVPOL9w/z8vY8nyYTHy+ppaBSgpzBTBL9iUHhVFmdT0vCwfktr8FqxxSi59ppKR3uG27QEd/BN8geO7oB9r0MKCy+8m8sTJtFdmk2ZQ1lxBnjyIrPkp4b0XfS58AF98OWNfCf+yFtNnZjdK/+jgbpNExIjmBvfnWH+2kUBYvdwZZTFSRHhrB0QmKn5z5WXIuiQGpUgOvKiT6hqENw3VxNTQ0mkwmz2UxEhO9jt6J/Kq1t4uuCrs0RqGu2UVrb1GnvzbT0SGLCAhTgVOfDcwugocL5IXJp7xc6FKJTtmZ4biGUHmLj8Fk8FaK6pDVIMCbw8KyHA97LeLykttNhpY1HSnh9VwEK8MNLRjI5NdKnc49NCpcgZ4Doyue3DFGJAa3JaufwWd/m3bQV1kkFY4Co0KDABTfWRlh3izO4SZrinO8gRH+kC4ZvPs/GcBMrHEXu2bYbSnsl2/bIuDDCOshyDLBobDwXjYpFBZ778jQFVb4NQR0tkuGqwUgCHDFgORwqX58xY/Nh3g3AjtMV7Mip8DnZ18j4jgOgblNV+O8KKNoPxhi48WXnh4gQ/ZQ9bixPJaV5yLVNawbuQGfb1mgUJqWYOlwQoCgK35mVzpiEcJqsDn6/8QQVdc0+nf9YcS15FbK6ajCRAEcMWMdKan2ed1NZb+HlHfk8/2UO2Z2M5YMzkVhHeXF6ZOfzzkmbiga+9Q+ITA/MdYTwk+zSbEqsNV6r2vdWtu3QYB1jkzpeOq7Tavj+ghEkmwxUN1r5+HDHlcfbOlFSx6ky78U+xcAiAY4YkM5WN1JY1ejTvqqq8q/teTRa7QyPDWVaWmSH+2s0MCI+1A+t9ODwe/DhSufjS38Owy8OzHWE8KP+lG07yRRCUmTHaRtCg3U8sHg0l01I5IYZaV06f05ZPceKa6WswyAgAY6fyR9F4JkbrRz1Md8NwPbTlRwoNKPTKNw+b1inCftSo4wYgwKwwPD0Jlh/F6gOmLYc5v7A/9cQIgD6W7btsYkRhAZ3/DcaHRrEt6antg5pqaqKw8f354LKBg6drZECnQOcBDh+1mxzcLxEUoEHSrPNztdnqnF0nssLgOoGC6/tchYM/MaUZJI7Kbeg0yoMiwlA782ZPfDad8BugXHL4Ko1Xrv7hehvsuKzSDAmtCaebE+BXs22rdUoTE7teD5OW3aHsxd33a4Cn7+EFpub2HemutNq5aL/kgAnAPIrGmQcNwAcDpUDZ8w0W317w1FVlVd25NNgsZMRY/QpL0ZmbKhPScW6JH87vHwtWOsh82L45guglRRUYuDQarQ8PMuZzbh9kKOoKqiwcsp9vZqzKTRYx7gk39J8HC+pZfOJcj49Wsq7+8/6fI3KOgt78qposgZu8rQIHAlwAiSnrJ5cqXfiV0eKa6hu8G1SMUBeRQN7C6rRnhua6uzbXkiQljR/58I4/hG8dLWzlk/aHPj2q7JiSgxIizMWs3rBauKN7bJtO1RWl5ax+ONfgflMr7Yp0WQgLbrzv9lxSRF8Z5ZzMv9/vy7ig4NFPl+jtsnG7twqapt8f+8R/YMk+vNzor8mq52vTpS3/jw6IZz0GEkg1VN5FfWcKOl6r9iRohqKzU0s7KSYJsDkVBPxEX6sObXvVXj3B6DaYdRSuH4tBMnvghjY7A67ayZjxYj2leuhphAiUuGW9RA/ttfa43CoZOdX+fTlZ8OBIt7aWwjAzbPSfXpfaKHVKkxMNnVYG0sEXlc+vyXACXCAA5Ils6e6k6m4qyKNemYMi/bPyWwW+PgR2Pk358+Tvw1X/wm0AVp2LkRfqy6Af10LFScgKAy+8UeYeF2vXb7JamdXbqVPw9dv7y3k/QPOHpw7LhjGBSNiu3StkfFhDIsN0CpL0SnJZNzPHC2qpbDatyXNwpW5wcqhwq5lKt6ZU0lZrW/JvVqMTuw4t4bPzIWw9srzwc38H8M1z0pwIwa3yDS48yMYNh8sdfDmHfDhKrD3zrCOQa9lckokGh8+0a6Zmszicc6em1e25/ucS6vFydI6DhaascsKq35PZjr2kiPnygmkdLKKR5zXYLGx70x1l95ICiobeHFLDlqNwqNXjSfBhyGnpEgDEQbfAhC37vmWQoOqCvtfhw8fhqZqMJjg2udgzGU+t12IAS00Bpa/A5/9wlmcc/tfIPcruPrPkDQ54Jc3GfWMTYzotHSLoijcOCMNu0NlQrKJiG4k9Cw2N1HXbGNyqikwKSWEX8j/TC+SIMd3zTY7e/Orsdp8X6JpsTl4/svT2BwqE1NMPlUB12oVn0sybMzbyFM7n3IvNDjhLhZnvwknz9XiSZoC1/8TojN9brsQg4JWB5c+Aakz4d37oPhreH4hXPAAXPQT0PtxjpsHyZEh1DXbOi3KqSgKN8/OcNnWZLVj0Pu+CqyuycaOnEomJEX4d+6e8BsZouplR87WcMbHAnBDldXuYG9+NY2Wri3NfDP7DGfNTZhC9Nw2NwPFhzwzI2LDCNZ1/qa2MW8jKzat8FBosIQVO3/JxrNbQBsMix6Duz+V4EYMbeOugvt2wrhvgMMGX/4W/jTT2csZwHpVAKPiw4gJC+rSMWW1zTz67iE+PeJ7WQcAu91ZD+9osSQF7I8kwOkDUrnWO7tDZX9BNXVNti4dtze/is+OlgJwx7xhhPsw5GQM1pIa1Xlvmt1h56mdT7UWFWyrZcvT8YnY790M81fIfBshAMIT4MZ/wQ0vQXgymPPh7e/B3y5ylizxEujYHXZ2Fe9iw+kN7Cre1eUCnoriLMrZWabjtnbnVVLZYOG1XQVdWkLe4kxlIztzK6lr7tr7lggsGaLqI8eKa7E7VJmN34bDobL/THWXct2A89vXi1tyAbh0XAITU0w+HTc2MaLTsg1wrtBgg/dvdqqiUIydbHstM326shBDyPirYeSlsOOv8NUaKDkIbyyHqGEw5/sw5SYwOFfDeB0GnvUwizMW+3xJnVbDtPRIduZUYvFhmPuyCYk0Wx3890AR67MLqWmycf30VDRdyDZe12RjZ04FI+PCSYsO8akHWQSW9OD0oZOldZwslYzH4Axuvi40U1ln6fKxHxwschbSjAth6uhysis+42TNPhyq929+CREGokN96MZurKLs0Js+taM3Cg0KMSAFGZ29m/fvg/n/C4ZIqMqFDx6C346CN+9i4/bVXoaBS1mxaQUb8zZ26ZIGvZYpaZE+lXNQFIVrpqXwraxUAD45XMLfv8zB2sUyDQ6HM2vynrwqGizSm9PXJA+OH/Pg2B12tp/dxZacHCL00QwPn4RG6Xx+R2p0CGMSwjuN+L2u4PGTvjp/S3BT3sWl3S1sdgcv7nuPM5rXqbWdz0Fk0sdyXfp9TI6e77K/Vqswd3iM5wmFqgplx5wTho9/CHlb2RWs486khE7b8eLSF5mZKH04QnTKUg/7X4Mdf4Py49iBpWnJlGi1Hmu0KSgkGBP48Jsfdvk9qbyumf0F1bR80jlUO6drD1BjrfT4Pr3tdAVrt+RiV1XGJYbz/QUjCQny/Zot56+1VTI2LoXLRsxDr/PfYEl//hwIdNuga5/fvTJE9Ze//IXf/OY3FBUVMWHCBNasWcP8+fO97v/FF1+wYsUKDh06RHJyMg899BD33nuvyz7r16/nZz/7GadOnWLEiBH88pe/5Nprrw30S/HKU9eqtw/Y9s5UNmK1qUxI9j5k4q+u2660vzfO/9DMlcRpZlDRjZ6bFofNWzji+BO0+7Jltpbzj1NPcAePufwfjIgNOx/c1JVC8QFnt3nBTsjfBg0VLufJihhDglal1F7vYRbO+Tff3io0KMSAFxQKM++GGXfB2Wyyd/2FEvNOr7urqBQ3FJN9djszUy/o0qViw4IZmxTBkbM1fF35JW/l/xmz1fsXobnDY4gw6PjLplPUW+xdqonrdv5T8JvsOH48/SG+MbrnKSP68+dAoNvWHQHvwVm3bh3Lly/nL3/5CxdccAF/+9vf+Pvf/87hw4dJT0932z8nJ4eJEydyzz338L3vfY8tW7bw/e9/n9dee41vfvObAGzbto358+fzi1/8gmuvvZa3336bRx99lK+++orZs2d32iZ/9+C0rLDxNAkV4I4Rj3Ua5ABEheqZnBqJXus6cujt/C1F71YvWN2jX6C+PL+K6vO/T1uF1Y3syKlg2eREfnngFpc3rPYi9TH8Ov1nhDYUYmo+S7pShlJ5CkoOQX2p+wE6A6TPgdGXweilED289TUALq/DX/9GQgxlG05vYOWXKzvd7+myCq7Qx0PcWIgb45zHY0qFiBTnvcH7+/krB/7LU9mrvD7f/n0ov6IBk1GPycc8OV9Xfsk/Tj3h9fkVk3/JdyZd6dOqTU/68+dAoNvWVr8q1TB79myysrJ49tlnW7eNGzeOa665hieffNJt/5UrV/Lee+9x5MiR1m333nsv+/fvZ9u2bQDceOON1NTU8MEHH7Tuc9lllxEVFcVrr73WaZv8GeDYHXaWrl/a4STUyKA4fjb5ZZ+Gq0KDdUxNi2ztEu3s/D3puu0P5weI1Mfx2IS/o0VF47CgOGwoDhsa1YbisDofO6woqvPe2ljDf3adwNZUS2xKDf8K3dZpO14sKmFmk6chMAViRkDCREieChkXQNJU0LnPz/H0DSXRmMjKWSsluBGiB3YV7+LOj+7sdD/vf8fnBIWBMRpCosEY0/rYbjCx9Ox/KLF7L4AcpYvilyN/g6LR49DoUBU9qkaHqmhxaPT892ApkWEGj6UdHKqdn++/ueMvWkFxPD7tFYbHRpAebfRpblCLvn6f7uj8gW5be/1miMpisbBnzx4efvhhl+1Llixh69atHo/Ztm0bS5Yscdm2dOlSXnjhBaxWK3q9nm3btvHggw+67bNmzRqP52xubqa5+fwfRU1N11L/d6SzFTYA1ZYyQj9ayAyLA1wi3DaP1ba9AioOrQYNkK1XKIn2vpS5tet2zShmWuztzum6p/u1VLKDdJTEef8laT3/M8OY2dxmGEnt/HWASnZwECWJHdd6qbaWYfpgTsdvXO3MBdDDhnojhHZeS+aswUSjKZWQuOEQleH85hc/HuLHObvLfbA4YzEL0xYGfIxZiKEmKz6LBGMCpQ2lHnvCW4eB7/sEyk9A2VHnXDlzgbOCufmMM4O4pc55q853OT7bEExJJ/PoqmxVGD5f5vV9aBHgUBXYo4CiaZ0rpKKwyxCEOaHjWnbVljJC3r+QFIsDu6KARoNGo2nt5ehItl6hJNJ7T1Lr+/SfJjLT2vU+i2y9QonJezhw/vyT3M7vPNb7e2DrsaXZvT5HMaABTnl5OXa7nYQE11+shIQEiouLPR5TXFzscX+bzUZ5eTlJSUle9/F2zieffJInnvDeddgTvq6cMdtrCG7qeu6bslAj0HmuljJ7I3Tn/HrfioCWYQNbU9fPr/Et4VaZ9vwfiIqCqtHh0AQ57xWd85uURk91s0KZRUejYiApLg6tUQFyOj1/xYXPop92CWh7tnBQq9HKRGIh/Eyr0fLwrIdZsWlF69B1i5YAYOWslWjDEyE8ETI9DGk310FdCTRUOufRNVa2Pi4zH4W6g522ozjIiN2iOnuPVfcVVBpFBVRQHS7f6yoV3z5Kqx0NBDV393Og8y9yZc3VUB/I81e5nd/nY/tglWmvTDJuvzpIVdUOVwx52r/99q6cc9WqVaxYsaL155qaGtLS0nxrfCfijHE+7Vc29Qm2G0c5f3Bp5/nHattI/tw+diUXjv2683Ys+zPETOzw/J5my8VVHIRtj3R+/mueg9jJPp77/OO48q/hq4c6Pf+Zuc/ymSkLh6IDLz0iXxwv41/b8wC4b8EIpqVHoah2TD50DV81Zh66HgY3QojAWZyxmNULVnucqOrTMHBwmPMWM8LtqbjiXeDDEFjhvL/xecRU5w+qwzlcrtrQnBs2/zq/nHW787HaHJgMWm6amcao+FCK6w9D3tOdnr806/+xLWQUCi2BkvOzLUinIckUQlx4MDoPQ1dxlYdh9y87PX/cFashenyn+3k+/6863+/y1RA9rt2xR2CPD8f6+FnpTwENcGJjY9FqtW49K6WlpW49MC0SExM97q/T6YiJielwH2/nDA4OJji487pE3dFZ1yo4P2CTkq+izoc5OO0FqyOICvoHVZZy6KjrdvTVXgODjmRFDSNh/x877xoecUX3zh+eSEL2M53OURoWNQtHB/8+X5+p5pUdzuDmmqnJTEuPAkCjaLku/b4OJ/fdOfYB4sN966kSQvSdQA0D+/o+PTx80vkNigZVG4RKUOsCzXGjo7knPo2/bT7F8eomfv5lDddOC+eyiZdgOvtCp1+0khMvp97L+1ylA7R1CimRIaREhrhkYs5KmEDC4b93/j497obuvU8nTCTh8Audn3+8+/mzEieRcMSHY/tglWlAv9IGBQUxffp0PvnkE5ftn3zyCfPmzfN4zNy5c932//jjj5kxYwZ6vb7DfbydM5BaulYBr2Op16Z936cJxp5oFC3XpH0fb8ENnOu67eYbQEft98f5LTb45rAfdLiPr/8+Oq2GeSNiuHJSksv2ydHzuWPEY5j0rt2kkUFx3DPmcW6ZfFXXGy6E6BMtw8BXDL+CmYkz/TLHzZ/v0ymRIfz0inFcNCoWFYgJDWr9otURX85vt6vkVzSw7VQFe/IqOVvdiM3uCPj7dE/OH+i29USvLRP/61//yty5c3nuued4/vnnOXToEBkZGaxatYrCwkJeeukl4Pwy8e9973vcc889bNu2jXvvvddlmfjWrVu56KKL+OUvf8nVV1/Nu+++yyOPPNJny8TB8wqbyKA4rk37fpeXQHviKX+DP1fwBGKFULG5iaPFNdjsqsf2d/Xfp7C6kYTwYK9DTZ4SeE1LjyHOh6riQojBz9v73E0jf0h6cOefHe2dLqtjeFxY689fnv2MT0uf69H7XHtajUJsWDAJEcHsq/ySX+96OmArOXvyOdBbq0z71TJxcCb6+/Wvf01RURETJ07kd7/7HRdddBEAt99+O7m5uWzatKl1/y+++IIHH3ywNdHfypUr3RL9vfnmmzzyyCOcPn26NdHfdddd51N7+lsmY1+1fIA3qdVMTkzj4ozZ/SaDZVsWm4NjxbWU1LhOSu4sg2h75kYrjRY7iSZDl9sAkBwZwvhk//3/CiEGPk/vcxpFw5GiWs5WN3b7vLVNVh597xApUcEsnFyHoqv1++eARgOmEC3FzUewUE1qRGKfZzK2O1RqGq1UN1qpqG8kuySb6uYKEkLjuGXqwj7NZCylGvwY4ABU1Vv4zt+3c8XEJMYlBfbDNTkyhJHxYQTp+s/k2SJzI8dL6rD6UOCuI3XNNn7z0TFqmqw8uHg06dFdm0Nj0GuZMzxaJhYLIXx2srSW3PKur0ICOFBo5i+bTmK1qwTrNHxreioXj4rzqaBvdwXpNJhCnMkII0L0hAXrAvp5YLE5aLDYqG1y3mqarNQ32/AURYQbdMweHuP3NvSbPDhD0d+/Os2RolqOFtXyjanJXDkpqUsVabvibHUjpbVNjIgLIyUyJKB/SJ0xN1o5UVLb5UrgnjRa7KzZeJzC6kZMIXpCPNWM6sTElAgJboQQXTIyPhy9VsOJkq4XQZ6UYuLxZRNYuzWXE6V1vLIjny9PlPOdWemMjA/r/ATdYLE5KKttpqxNHb9gvQZjkJYQvY6QIC3BOg1BOg16rQadRkF77tbyaaECDlXF4QCbw4HNrmK1O2i2OWi22WmyOmi02mmw2Hv8xbW3SQ+On3twqhss/ODVvXx10jkGOyEpgrvnZxJu8C3dd3eFBGkZHhdKYoSh06Kd/lTXbCOnrN5tOKq7Gi12fv/pCU6W1REWrOOhpWNIjuw8D1Bbw2JDA/aGIoQY/IrNTRwuMuPoxue5Q1XZdKyMt/cW0mi1AzBvRAy3zxsWsC+7/VF/6MGRr7h+ZtBruX3eMO64YBhBWg2Himr4+X8Pc7K0698IuqLRYudQYQ1bT1VQUNmAzR7YSLuq3sL+gmq2n6rwW3DTYLHxu43HOVlWR4heywOLR3U5uIkI0TM81rfMxEII4UmiycC0tCh02q4HJBpF4ZKx8fzymolcODIWBdBplCEV3PQX0oPj5x6cJqudr044e2/OVDXw1y9OU1zThFZRuOeiTGZkdJzO21+0GoWECAOJJgNRRr1fenWarHaKzU2cNTfS0Gz3QyvPq2t2Bjd5FQ2EBmlZceloMmK6FqhotQpzMmNa63gJIURPNFhs7MuvpsHS/fe7nPJ6YsOCWnvxC6oaOHy2hoVj4vvV/El/6w89ODIHJ4BSo4w8cuU4XtqWx6GzZkbE9d6wid2hcra6kbPVjeh1GmJCg4gKDcIUoic0SOtTwNNss1PTaMPcaKG8zkJdky1g7dVpFPQaDeEGHSsuHU1aVNcT841PipDgRgjhN8YgHTMzozlYaKaiztL5AR5ktutRfmdvIfvPmPnkcAlXTErigpEx3a4wLjomPTgB7MFpoaoq5XUWl3wseRX1Xe6h8BeNxjmUZtBrCdJqWqvaOlQVm13FYnf0yYSyRosdc6O1W8vCU6NDGJsoS8KFEP6nqiqnyurJLfdejdzX82w5VcF7+89SWe8MmEKDtCwYE88lY+MxhQR2rmZv6g89OBLg9EKA097e/Cr+vOkU80bEcNPM9CHb63C0uIaTpXVcNTm5R+eJCNEzIyOqT1eRCSEGv9LaJg6fdSYv7Qmr3cFXJ8r5+HAJZXXOFVA6jcJlExK5ZlqKP5ra5/pDgCNDVH2guKYJBdh6qoIjRTUsn5PB5NTIvm5Wr1FVlc+PlbFuVwF2VSXRZOj23CS9TsPkVJMEN0KIgIsPNxCWqeNgYQ01jd1PiaHXalg4Np6LR8ext6Cajw8Xc6qsnnDD+Y/kZqsdi90R8BW4g5kEOH3g8olJjIgL4x9bcymrbeYPn51kdmY0356ZNuh/ma12B6/syG9dRj87M5op3QzuFMWZe8LQjTw5QgjRHcYgHTMyojhVVkdeRfeSArbQaBSmZ0Qx/dz5UtqsGt2RW8krO/KZlGIiKz2SyamRhAXLR3ZXyL9WHxmdEM7jy8bz7r6zfHKkhB05lRw6W8MdFwzr9gd+f1dS08RzX54mr6IBRYFvZaWyZHxCt1d4jYoPJzo0yM+tFEKIjmk0CqMSnO8/h4tqaLb2fL5i+0UoueX12B0q+wqq2VdQjUaBMQnhTEuPYlKKidiwoF7NeTYQSYDTh4J1Wm6YkcaMYVH8c2sehdWNaAfpL+yu3ErWbs2l2ebAGKTlu/OHMzHF1O3zJUeGkB7T9ZVWQgjhLzFhwcwZHsPxklqKqv2TD6zFrXOHsWhsArvzKsnOr6awupEjxbUcKa5Fq1H4w7entq6+qm+2YfRxdexQIgFOPzA8NoyfXTmOPflVLh/6h8/WkBYdMiiGrYJ1GpptDkYnhHH3hcN71PMSFapnbGK4H1snhBDdo9dqmJBsIiHCwNGiWpqs/ssRlhIVQkpUCldPTaGkpom9+dXsP1ONTqO4LC3/9UfHMDdaSY82khFjJCPaSJIphLjw4F7NtWOzO6hssFBea8EYrA3IJOOukFVUfbCKyhfmRiuPvHMQgMsmJrJobPyAmmuiqiolNc0uS74PFpoZnxTRownBxmAtM4dFo5c6U0KIfsZmd5BTXk9+ZYPHApT+4lDV1szIVruDH72+F6uXlV2TUkzcv2hU68+bj5dh0GuJCNFh0DtrVQXrnClDgvUal/fWBosNi+1cXSqrgyabnUarndomG+EGXet0CqvdwU/fPkhVo6X1dY+MC2Xj/y7w+2uXVVSDQH2zjdiwIAqqGnl7byGfHC5h6YQEFo7p/4FOTnk9b+wuoKCqgZ9/Y2Jrb01PhqTAWURuWlqUBDdCiH5Jp9UwKiGcpMgQjhXXUFXf8+LDnrQt+6DXavjDt6dRWNVIXmUDeRXOAKukpplGq92lWLFDVXl5Rx4OL8HX5FQTP7rkfDC04o392LzsPCEpojXA0Ws1WOwOVBWCtBpiwoJINHWtzE4gSIDTTyVHhvCzK8ezI7eS/+4/S0ltM+uzC/n4cAlLxiewYHR8v8ufU1bbzNt7C9mZWwk4f9HzKur9MhFYq1WYmhbZ716zEEK0FxasY3pGNKU1TZwsretRqQdf6LUahsWGMiw2FIgDnL3o9c3OpeYtrHYHWelR1DRZqWmy0Wy102xzYLE5PAYyigIKzi+XwTotBp0GQ5CWcIOOzHaJav93yWgiDHoiDDoURXFZ8t5XZIiqnw5RtWV3qOzIqeA/XxdRVtuMVlF4+puTiDT2jxVEBVUNfHiwmJ25laiq8w9i7ogYrpma4p/gRqMwLT2y37xeIYTwlcOhUljdSE55PZZezg7fFXaHikNVXXrIrXYHOo3SrcnLkuhP+ESrUZg3IpbZmTFsP11BeV2zy4f9v7bnkRoZwszM6F7Pk9BosfPkB0db/3AnJkdw3bRUv61w0mic3aYS3AghBiKNRiEt2khyZAgFlQ3kVTb0ehkcX2g1ClpcA5mBPh1AApwBRKtRuGBkrMu2kpomvjheBsDruwoYlRDG1LRIJqeaiAsL9uuywWarnSPFtRwrruWGGakoikJIkJaLRsVS02jjsgmJfl267QxuIokJC+58ZyGE6Me0GoVhsaGkRRvPzZep90v+HOGdBDgDXFjw/2/vXmObLP8+gH/vnre168a6Q8eGjOl/E4ExQNwQ1AgpahR94YFgCInJFCMSNMYM1Ki8AROjMSj4qMQXhmQmjBmMSBgyNg1Mn8kUAZmEDdn+UMZ4tq5bux6v58Vcsa6wdq6nu99Pcifu7nV3V3/56X5evQ4qPLmoCMfPX0N3vxNnrXactdpR97/dyEpT47HK6Vj6V1EkhAi74PH7BfodbnT3O9HZN4TOq8M4f3UoMFO/ata0wGGhTy0qnvL9F8aKGxOLGyKSEaVCwoycdBRlp+GKfQQXrzlgH/HGu1uyxAInyWVoVbDMLoBldgF67SOBXS/PXx3GgNMD3d/2QDh9aRD/09IJY7oaWWlqZGhUo8OSCgl+IbBy9vURmO/O9uLLtu5xv8+k12BeUVbQSq6pLm6USgkVRVncpZiIZEuhkGA2psFsTMOAw42efid67SPwc1BnyrDAkZE8gy5Q7Li8PnT1DaM4+/pXRv8dcMLp8cFp88FqG7/rZmVxVqDAyTVooVRIyDdoMStXj1mmDJTm6VFo1EV1t0y1SoH5xVkwpiX/5oZEROHIStcgK10Dt9eAK4MjuDTg5KjOFOAqqiRYRTVVXF4frg25MTjigc3hgcPtg08IeH0CkgRUFGUFNubz+QUkIKandKdrlJg/IwvpGtbdRJTahl1eWAdHcGVwBA5XdJeZRwNXUVFMaVVKFGaloRATb8CkjGFhA4wevzB3elZMtxUnIkpUGVoVSnP1KM3VY8jlxVW7C31DLtgc0dk8UI5Y4FDcFU1Lw3/yDDEdLSIiShZ6rQp6rQolpgy4vX70O9y4NuTG/w27p/TsK7lhgTPFdGol7po1DZ1Xh3HV7op3dxKaUiGh3GyAOQG29CYiSgYalQL5mTrkZ45OJxjx+NDvcGPA4cGg04Mhlzeq52AlExY4UWDQqVFRnAX7iAcX+hy4Mjh+Qm+q0+tUmDvdiIwYb0xIRCQnOrUysBoLGJ0/OTTihd3lgX3Ei2GXF0MuL7w3OIxTzvjXJYoMOjXmFhlR6s7AhT4HrIPOlF8CKEnALTnpmGXS8yspIqIpplRIMKarYUwPXonq8vrgcPng8PjgdPsw4hm9nB4f3F6/LEd9WODEQLpGhdmFmSjNy0BPvxP/7Xcm9Jkk0aLXqXC7OZNLwImIYkyrUkKrUiI7xGtCCLh9o4duur1+eHwCHp8fbp8fPv/oP/v8InBelc8/ejK5Xwjgr8JorD4a+9/WRDgYmQVODGlVSpTm6lGSk4Feuws9/Q4MpMCMeJVSQmmuHkXZaVHdQ4eIiCInSVKgAJITFjhxoFBIKDDqUGDUYcjlxaUBJy7bRhLyALZ/Q6EAirLTUWLKSPpD24iIKLmwwIkzvVaF/+QbcGuuHteG3bgyOIKrdhd8/uT9QlSpkDA9Ow0zpqUHHelAREQUKyxwEoRCISHXoEWuQQufX+DakAu9f23slCyz39M0SkzPSsP07DSO2BARUVyxwElASoWEvEwd8jJ1EELA5vSgb8iNfocbg05PQs12VyklmPRamI06TMvQcI4NERElBBY4CU6SpMBBbADg9flhc3ow4PTA5hzd2CnWIzwZWhWmZWhg0muQna7hcm8iIko4LHCSjEqpQI5eixy9NnBvxOMLbOg07PbC6R7d28Dl+XeTlhWK0U2kMjQqGHQqGHRqGNPUPC+KiIgSXlQLnP7+fmzcuBH79+8HAKxatQo7duxAVlZWyPYejwevv/46Dhw4gM7OThiNRqxYsQLbt29HYWFhoN19992H5ubmoGefeuop1NXVRe2zJDKdWgmdWolcgzbovt8/ureBy+uHx+eH1yfg9fvh/2sPg7FxH4UEKCQJKqUEtVIBtVIBrWr04ldORESUjKJa4KxZswY9PT04ePAgAODZZ5/F2rVr8fXXX4ds73A4cOLECbzxxhuoqKhAf38/Nm3ahFWrVqGtrS2obU1NDbZu3Rr4OS2N5xn9k0IhQadQciUTERGlnKgVOL///jsOHjyI1tZW3HXXXQCATz/9FNXV1ejo6EBZWdm4Z4xGIxobG4Pu7dixA4sXL8bFixcxY8aMwP309HQUFBREq/tERESUxKI2meL48eMwGo2B4gYAqqqqYDQacezYsbDfx2azjU60/cfXWnv27IHJZMIdd9yBV155BXa7/Ybv4XK5MDg4GHQRERGRfEVtBMdqtSIvL2/c/by8PFit1rDeY2RkBLW1tVizZg0yMzMD959++mmUlJSgoKAAp06dwubNm/Hrr7+OG/0Zs23bNrz99tuT+yBERESUdCIewXnrrbcgSdJNr7H5MqEmqAohwpq46vF4sHr1avj9fuzcuTPotZqaGqxYsQJz5szB6tWrsXfvXhw+fBgnTpwI+V6bN2+GzWYLXN3d3ZF+bCIiIkoiEY/gbNiwAatXr75pm5kzZ+LkyZO4cuXKuNeuXr2K/Pz8mz7v8Xjw5JNPoqurC0eOHAkavQllwYIFUKvVOHfuHBYsWDDuda1WC61WG+JJIiIikqOICxyTyQSTyTRhu+rqathsNvz0009YvHgxAODHH3+EzWbDkiVLbvjcWHFz7tw5NDU1IScnZ8Lfdfr0aXg8HpjN5vA/CBEREclW1CYZ33777XjggQdQU1OD1tZWtLa2oqamBg8//HDQCqry8nI0NDQAALxeLx5//HG0tbVhz5498Pl8sFqtsFqtcLvdAIDz589j69ataGtrw4ULF3DgwAE88cQTqKysxN133x2tj0NERERJJKpb0u7Zswdz586FxWKBxWLBvHnz8MUXXwS16ejogM1mAwD09PRg//796Onpwfz582E2mwPX2MorjUaD7777DitXrkRZWRk2btwIi8WCw4cPQ6nkfi9EREQESEIk0tGNsTE4OAij0QibzTbh/B4iIiJKDJH8/eahQkRERCQ7LHCIiIhIdljgEBERkeywwCEiIiLZYYFDREREshO1s6gS2djCMR66SURElDzG/m6HswA8JQucsZPHi4uL49wTIiIiipTdbofRaLxpm5TcB8fv9+PSpUswGAxhHfwZicHBQRQXF6O7u5t77EyAsQofYxU+xip8jFVkGK/wRStWQgjY7XYUFhZCobj5LJuUHMFRKBQoKiqK6u/IzMzkvwBhYqzCx1iFj7EKH2MVGcYrfNGI1UQjN2M4yZiIiIhkhwUOERERyQ4LnCmm1Wrx5ptvQqvVxrsrCY+xCh9jFT7GKnyMVWQYr/AlQqxScpIxERERyRtHcIiIiEh2WOAQERGR7LDAISIiItlhgUNERESywwKHiIiIZIcFziTs3LkTJSUl0Ol0WLhwIb7//vubtm9ubsbChQuh0+kwa9YsfPzxxzHqafxFEqujR49CkqRx19mzZ2PY4/hoaWnBI488gsLCQkiShK+++mrCZ1I1ryKNVarm1bZt23DnnXfCYDAgLy8Pjz32GDo6OiZ8LlXzajLxStXc2rVrF+bNmxfYpbi6uhrffvvtTZ+JR16xwInQl19+iU2bNuG1115De3s7li1bhgcffBAXL14M2b6rqwsPPfQQli1bhvb2dmzZsgUbN25EfX19jHsee5HGakxHRwcuX74cuG677bYY9Th+hoeHUVFRgQ8//DCs9qmcV5HGakyq5VVzczNeeOEFtLa2orGxEV6vFxaLBcPDwzd8JpXzajLxGpNquVVUVITt27ejra0NbW1tuP/++/Hoo4/i9OnTIdvHLa8ERWTx4sVi/fr1QffKy8tFbW1tyPavvvqqKC8vD7r33HPPiaqqqqj1MVFEGqumpiYBQPT398egd4kLgGhoaLhpm1TOq78LJ1bMq1G9vb0CgGhubr5hG+bVdeHEi7l1XXZ2tvjss89CvhavvOIITgTcbjd+/vlnWCyWoPsWiwXHjh0L+czx48fHtV+5ciXa2trg8Xii1td4m0ysxlRWVsJsNmP58uVoamqKZjeTVqrm1b+R6nlls9kAANOmTbthG+bVdeHEa0wq55bP50NdXR2Gh4dRXV0dsk288ooFTgT6+vrg8/mQn58fdD8/Px9WqzXkM1arNWR7r9eLvr6+qPU13iYTK7PZjE8++QT19fXYt28fysrKsHz5crS0tMSiy0klVfNqMphXgBACL7/8MpYuXYo5c+bcsB3zalS48Url3Prtt9+g1+uh1Wqxfv16NDQ0YPbs2SHbxiuvVFF7ZxmTJCnoZyHEuHsTtQ91X44iiVVZWRnKysoCP1dXV6O7uxvvvvsu7rnnnqj2Mxmlcl5FgnkFbNiwASdPnsQPP/wwYVvmVfjxSuXcKisrwy+//IKBgQHU19dj3bp1aG5uvmGRE4+84ghOBEwmE5RK5bgRiN7e3nHV6ZiCgoKQ7VUqFXJycqLW13ibTKxCqaqqwrlz56a6e0kvVfNqqqRSXr344ovYv38/mpqaUFRUdNO2zKvI4hVKquSWRqPBrbfeikWLFmHbtm2oqKjABx98ELJtvPKKBU4ENBoNFi5ciMbGxqD7jY2NWLJkSchnqqurx7U/dOgQFi1aBLVaHbW+xttkYhVKe3s7zGbzVHcv6aVqXk2VVMgrIQQ2bNiAffv24ciRIygpKZnwmVTOq8nEK5RUyK1QhBBwuVwhX4tbXkV1CrMM1dXVCbVaLXbv3i3OnDkjNm3aJDIyMsSFCxeEEELU1taKtWvXBtp3dnaK9PR08dJLL4kzZ86I3bt3C7VaLfbu3RuvjxAzkcbq/fffFw0NDeKPP/4Qp06dErW1tQKAqK+vj9dHiBm73S7a29tFe3u7ACDee+890d7eLv78808hBPPq7yKNVarm1fPPPy+MRqM4evSouHz5cuByOByBNsyr6yYTr1TNrc2bN4uWlhbR1dUlTp48KbZs2SIUCoU4dOiQECJx8ooFziR89NFH4pZbbhEajUYsWLAgaBnhunXrxL333hvU/ujRo6KyslJoNBoxc+ZMsWvXrhj3OH4iidU777wjSktLhU6nE9nZ2WLp0qXim2++iUOvY29suek/r3Xr1gkhmFd/F2msUjWvQsUIgPj8888DbZhX100mXqmaW88880zgv+u5ubli+fLlgeJGiMTJK0mIv2b6EBEREckE5+AQERGR7LDAISIiItlhgUNERESywwKHiIiIZIcFDhEREckOCxwiIiKSHRY4REREJDsscIiIiEh2WOAQERGR7LDAISIiItlhgUNERESy8/8YDqehEJwBgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred, logk_1_pred = model.predict(np.concatenate([x_test, t_test], axis=-1), samples, processes, pde_fn=None,)\n",
    "\n",
    "plots(\n",
    "    logk_1_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc7a6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting backend tensorflow.compat.v1\n",
      "\n",
      "Compiling a Ensemble method\n",
      "\n",
      "Generating 0th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  1.6903431\n",
      "Iteration:  100 , loss:  0.06321212\n",
      "Iteration:  200 , loss:  0.05014824\n",
      "Iteration:  300 , loss:  0.040975276\n",
      "Iteration:  400 , loss:  0.035215195\n",
      "Iteration:  500 , loss:  0.031886823\n",
      "Iteration:  600 , loss:  0.029616797\n",
      "Iteration:  700 , loss:  0.027913962\n",
      "Iteration:  800 , loss:  0.026583005\n",
      "Iteration:  900 , loss:  0.025565375\n",
      "Iteration:  1000 , loss:  0.024818514\n",
      "Iteration:  1100 , loss:  0.024243686\n",
      "Iteration:  1200 , loss:  0.023775585\n",
      "Iteration:  1300 , loss:  0.023379058\n",
      "Iteration:  1400 , loss:  0.02303269\n",
      "Iteration:  1500 , loss:  0.022721902\n",
      "Iteration:  1600 , loss:  0.02243602\n",
      "Iteration:  1700 , loss:  0.02216661\n",
      "Iteration:  1800 , loss:  0.021906372\n",
      "Iteration:  1900 , loss:  0.021648567\n",
      "Iteration:  2000 , loss:  0.02138667\n",
      "Iteration:  2100 , loss:  0.02111438\n",
      "Iteration:  2200 , loss:  0.020825699\n",
      "Iteration:  2300 , loss:  0.020515233\n",
      "Iteration:  2400 , loss:  0.020179207\n",
      "Iteration:  2500 , loss:  0.019817544\n",
      "Iteration:  2600 , loss:  0.019436076\n",
      "Iteration:  2700 , loss:  0.019046752\n",
      "Iteration:  2800 , loss:  0.018664246\n",
      "Iteration:  2900 , loss:  0.01829922\n",
      "Iteration:  3000 , loss:  0.017952595\n",
      "Iteration:  3100 , loss:  0.017610874\n",
      "Iteration:  3200 , loss:  0.017250331\n",
      "Iteration:  3300 , loss:  0.016855236\n",
      "Iteration:  3400 , loss:  0.01641987\n",
      "Iteration:  3500 , loss:  0.01592983\n",
      "Iteration:  3600 , loss:  0.015375465\n",
      "Iteration:  3700 , loss:  0.014781108\n",
      "Iteration:  3800 , loss:  0.014192007\n",
      "Iteration:  3900 , loss:  0.013632915\n",
      "Iteration:  4000 , loss:  0.013099405\n",
      "Iteration:  4100 , loss:  0.012582928\n",
      "Iteration:  4200 , loss:  0.0120990295\n",
      "Iteration:  4300 , loss:  0.011649632\n",
      "Iteration:  4400 , loss:  0.011222523\n",
      "Iteration:  4500 , loss:  0.010822326\n",
      "Iteration:  4600 , loss:  0.010455346\n",
      "Iteration:  4700 , loss:  0.010106435\n",
      "Iteration:  4800 , loss:  0.009760971\n",
      "Iteration:  4900 , loss:  0.009425719\n",
      "Iteration:  5000 , loss:  0.009116205\n",
      "Iteration:  5100 , loss:  0.008826065\n",
      "Iteration:  5200 , loss:  0.008553185\n",
      "Iteration:  5300 , loss:  0.008292395\n",
      "Iteration:  5400 , loss:  0.008047835\n",
      "Iteration:  5500 , loss:  0.007823025\n",
      "Iteration:  5600 , loss:  0.0075905425\n",
      "Iteration:  5700 , loss:  0.0073718415\n",
      "Iteration:  5800 , loss:  0.0071584987\n",
      "Iteration:  5900 , loss:  0.0069716885\n",
      "Iteration:  6000 , loss:  0.0067409975\n",
      "Iteration:  6100 , loss:  0.006548483\n",
      "Iteration:  6200 , loss:  0.006333609\n",
      "Iteration:  6300 , loss:  0.006136621\n",
      "Iteration:  6400 , loss:  0.005926727\n",
      "Iteration:  6500 , loss:  0.005721259\n",
      "Iteration:  6600 , loss:  0.005523518\n",
      "Iteration:  6700 , loss:  0.005325381\n",
      "Iteration:  6800 , loss:  0.005133975\n",
      "Iteration:  6900 , loss:  0.004934148\n",
      "Iteration:  7000 , loss:  0.004743597\n",
      "Iteration:  7100 , loss:  0.0045675943\n",
      "Iteration:  7200 , loss:  0.004393828\n",
      "Iteration:  7300 , loss:  0.004403921\n",
      "Iteration:  7400 , loss:  0.004073315\n",
      "Iteration:  7500 , loss:  0.0039762165\n",
      "Iteration:  7600 , loss:  0.0037860775\n",
      "Iteration:  7700 , loss:  0.0038766577\n",
      "Iteration:  7800 , loss:  0.0035256306\n",
      "Iteration:  7900 , loss:  0.0034073046\n",
      "Iteration:  8000 , loss:  0.0033725582\n",
      "Iteration:  8100 , loss:  0.0031838696\n",
      "Iteration:  8200 , loss:  0.0030824894\n",
      "Iteration:  8300 , loss:  0.0029797342\n",
      "Iteration:  8400 , loss:  0.0028748952\n",
      "Iteration:  8500 , loss:  0.0030388338\n",
      "Iteration:  8600 , loss:  0.002673442\n",
      "Iteration:  8700 , loss:  0.0026745563\n",
      "Iteration:  8800 , loss:  0.0024748717\n",
      "Iteration:  8900 , loss:  0.0023802943\n",
      "Iteration:  9000 , loss:  0.002331367\n",
      "Iteration:  9100 , loss:  0.002201055\n",
      "Iteration:  9200 , loss:  0.0021173449\n",
      "Iteration:  9300 , loss:  0.002041046\n",
      "Iteration:  9400 , loss:  0.001970394\n",
      "Iteration:  9500 , loss:  0.0019472277\n",
      "Iteration:  9600 , loss:  0.00184984\n",
      "Iteration:  9700 , loss:  0.0017899034\n",
      "Iteration:  9800 , loss:  0.0017423615\n",
      "Iteration:  9900 , loss:  0.0017275531\n",
      "Iteration:  10000 , loss:  0.0016581797\n",
      "Iteration:  10100 , loss:  0.0016603139\n",
      "Iteration:  10200 , loss:  0.0015562272\n",
      "Iteration:  10300 , loss:  0.0015156498\n",
      "Iteration:  10400 , loss:  0.0014761221\n",
      "Iteration:  10500 , loss:  0.0014437194\n",
      "Iteration:  10600 , loss:  0.001399537\n",
      "Iteration:  10700 , loss:  0.0013648527\n",
      "Iteration:  10800 , loss:  0.0013321349\n",
      "Iteration:  10900 , loss:  0.0012995191\n",
      "Iteration:  11000 , loss:  0.001270243\n",
      "Iteration:  11100 , loss:  0.001245847\n",
      "Iteration:  11200 , loss:  0.0012798547\n",
      "Iteration:  11300 , loss:  0.0011888758\n",
      "Iteration:  11400 , loss:  0.0015778518\n",
      "Iteration:  11500 , loss:  0.0011486488\n",
      "Iteration:  11600 , loss:  0.0011212133\n",
      "Iteration:  11700 , loss:  0.0011013923\n",
      "Iteration:  11800 , loss:  0.0010819545\n",
      "Iteration:  11900 , loss:  0.0010623104\n",
      "Iteration:  12000 , loss:  0.0010461197\n",
      "Iteration:  12100 , loss:  0.0011550623\n",
      "Iteration:  12200 , loss:  0.0010097801\n",
      "Iteration:  12300 , loss:  0.0012933007\n",
      "Iteration:  12400 , loss:  0.0009781711\n",
      "Iteration:  12500 , loss:  0.0009621922\n",
      "Iteration:  12600 , loss:  0.000953029\n",
      "Iteration:  12700 , loss:  0.00093219243\n",
      "Iteration:  12800 , loss:  0.0009180313\n",
      "Iteration:  12900 , loss:  0.00091958675\n",
      "Iteration:  13000 , loss:  0.00089866755\n",
      "Iteration:  13100 , loss:  0.00087914325\n",
      "Iteration:  13200 , loss:  0.0008696262\n",
      "Iteration:  13300 , loss:  0.0010938445\n",
      "Iteration:  13400 , loss:  0.0012597018\n",
      "Iteration:  13500 , loss:  0.00083918916\n",
      "Iteration:  13600 , loss:  0.0008104801\n",
      "Iteration:  13700 , loss:  0.00079600856\n",
      "Iteration:  13800 , loss:  0.0007846894\n",
      "Iteration:  13900 , loss:  0.0008029338\n",
      "Iteration:  14000 , loss:  0.0007619099\n",
      "Iteration:  14100 , loss:  0.00074661325\n",
      "Iteration:  14200 , loss:  0.00073439535\n",
      "Iteration:  14300 , loss:  0.00088157697\n",
      "Iteration:  14400 , loss:  0.0007686378\n",
      "Iteration:  14500 , loss:  0.0007029631\n",
      "Iteration:  14600 , loss:  0.00068633934\n",
      "Iteration:  14700 , loss:  0.00067439006\n",
      "Iteration:  14800 , loss:  0.000663836\n",
      "Iteration:  14900 , loss:  0.00067355245\n",
      "Iteration:  15000 , loss:  0.0006405323\n",
      "Iteration:  15100 , loss:  0.0006315663\n",
      "Iteration:  15200 , loss:  0.0006162499\n",
      "Iteration:  15300 , loss:  0.0006050302\n",
      "Iteration:  15400 , loss:  0.00059642387\n",
      "Iteration:  15500 , loss:  0.00059677346\n",
      "Iteration:  15600 , loss:  0.00058818504\n",
      "Iteration:  15700 , loss:  0.0005614305\n",
      "Iteration:  15800 , loss:  0.0005519851\n",
      "Iteration:  15900 , loss:  0.00054089545\n",
      "Iteration:  16000 , loss:  0.00053248624\n",
      "Iteration:  16100 , loss:  0.0005598682\n",
      "Iteration:  16200 , loss:  0.00051090436\n",
      "Iteration:  16300 , loss:  0.00050186255\n",
      "Iteration:  16400 , loss:  0.00049963244\n",
      "Iteration:  16500 , loss:  0.00048763692\n",
      "Iteration:  16600 , loss:  0.0006316901\n",
      "Iteration:  16700 , loss:  0.0005805032\n",
      "Iteration:  16800 , loss:  0.0004919031\n",
      "Iteration:  16900 , loss:  0.000447097\n",
      "Iteration:  17000 , loss:  0.00043956866\n",
      "Iteration:  17100 , loss:  0.00043195384\n",
      "Iteration:  17200 , loss:  0.00042351198\n",
      "Iteration:  17300 , loss:  0.00043764157\n",
      "Iteration:  17400 , loss:  0.0004066689\n",
      "Iteration:  17500 , loss:  0.0004000539\n",
      "Iteration:  17600 , loss:  0.0004190023\n",
      "Iteration:  17700 , loss:  0.00038607488\n",
      "Iteration:  17800 , loss:  0.0003915188\n",
      "Iteration:  17900 , loss:  0.00048165984\n",
      "Iteration:  18000 , loss:  0.00076796126\n",
      "Iteration:  18100 , loss:  0.0003645228\n",
      "Iteration:  18200 , loss:  0.00036809428\n",
      "Iteration:  18300 , loss:  0.0003636179\n",
      "Iteration:  18400 , loss:  0.0003618803\n",
      "Iteration:  18500 , loss:  0.00044135132\n",
      "Iteration:  18600 , loss:  0.0003380892\n",
      "Iteration:  18700 , loss:  0.00038080997\n",
      "Iteration:  18800 , loss:  0.00033168987\n",
      "Iteration:  18900 , loss:  0.0003379079\n",
      "Iteration:  19000 , loss:  0.00031808362\n",
      "Iteration:  19100 , loss:  0.00031261414\n",
      "Iteration:  19200 , loss:  0.00030700574\n",
      "Iteration:  19300 , loss:  0.00030591738\n",
      "Iteration:  19400 , loss:  0.00029990208\n",
      "Iteration:  19500 , loss:  0.0005730848\n",
      "Iteration:  19600 , loss:  0.0002915541\n",
      "Iteration:  19700 , loss:  0.00035076358\n",
      "Iteration:  19800 , loss:  0.0002865026\n",
      "Iteration:  19900 , loss:  0.00028766913\n",
      "Generating 1th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.08936088\n",
      "Iteration:  100 , loss:  0.027549712\n",
      "Iteration:  200 , loss:  0.02332984\n",
      "Iteration:  300 , loss:  0.022008166\n",
      "Iteration:  400 , loss:  0.021071795\n",
      "Iteration:  500 , loss:  0.020153662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  600 , loss:  0.018992634\n",
      "Iteration:  700 , loss:  0.017736087\n",
      "Iteration:  800 , loss:  0.016956672\n",
      "Iteration:  900 , loss:  0.016358517\n",
      "Iteration:  1000 , loss:  0.015667751\n",
      "Iteration:  1100 , loss:  0.0147988945\n",
      "Iteration:  1200 , loss:  0.014043124\n",
      "Iteration:  1300 , loss:  0.0133367255\n",
      "Iteration:  1400 , loss:  0.012740905\n",
      "Iteration:  1500 , loss:  0.012161693\n",
      "Iteration:  1600 , loss:  0.011713923\n",
      "Iteration:  1700 , loss:  0.011347998\n",
      "Iteration:  1800 , loss:  0.011076996\n",
      "Iteration:  1900 , loss:  0.010721256\n",
      "Iteration:  2000 , loss:  0.01180246\n",
      "Iteration:  2100 , loss:  0.010160143\n",
      "Iteration:  2200 , loss:  0.0099018235\n",
      "Iteration:  2300 , loss:  0.009675066\n",
      "Iteration:  2400 , loss:  0.009455245\n",
      "Iteration:  2500 , loss:  0.009252191\n",
      "Iteration:  2600 , loss:  0.009066023\n",
      "Iteration:  2700 , loss:  0.0088739805\n",
      "Iteration:  2800 , loss:  0.008682806\n",
      "Iteration:  2900 , loss:  0.008482921\n",
      "Iteration:  3000 , loss:  0.008271169\n",
      "Iteration:  3100 , loss:  0.008068932\n",
      "Iteration:  3200 , loss:  0.007839385\n",
      "Iteration:  3300 , loss:  0.007603536\n",
      "Iteration:  3400 , loss:  0.007368058\n",
      "Iteration:  3500 , loss:  0.0071297847\n",
      "Iteration:  3600 , loss:  0.006892775\n",
      "Iteration:  3700 , loss:  0.006685834\n",
      "Iteration:  3800 , loss:  0.0064863884\n",
      "Iteration:  3900 , loss:  0.006288479\n",
      "Iteration:  4000 , loss:  0.0060808985\n",
      "Iteration:  4100 , loss:  0.0058669285\n",
      "Iteration:  4200 , loss:  0.005631442\n",
      "Iteration:  4300 , loss:  0.0053730546\n",
      "Iteration:  4400 , loss:  0.0051393462\n",
      "Iteration:  4500 , loss:  0.0049245255\n",
      "Iteration:  4600 , loss:  0.0047359983\n",
      "Iteration:  4700 , loss:  0.004577803\n",
      "Iteration:  4800 , loss:  0.0044250875\n",
      "Iteration:  4900 , loss:  0.0042925077\n",
      "Iteration:  5000 , loss:  0.004161979\n",
      "Iteration:  5100 , loss:  0.004045381\n",
      "Iteration:  5200 , loss:  0.003913289\n",
      "Iteration:  5300 , loss:  0.0038515383\n",
      "Iteration:  5400 , loss:  0.0036737137\n",
      "Iteration:  5500 , loss:  0.0035557596\n",
      "Iteration:  5600 , loss:  0.0034393598\n",
      "Iteration:  5700 , loss:  0.00333347\n",
      "Iteration:  5800 , loss:  0.003829538\n",
      "Iteration:  5900 , loss:  0.0030945\n",
      "Iteration:  6000 , loss:  0.0029866253\n",
      "Iteration:  6100 , loss:  0.0029135265\n",
      "Iteration:  6200 , loss:  0.0027835418\n",
      "Iteration:  6300 , loss:  0.0026947148\n",
      "Iteration:  6400 , loss:  0.002624508\n",
      "Iteration:  6500 , loss:  0.0025308565\n",
      "Iteration:  6600 , loss:  0.002460988\n",
      "Iteration:  6700 , loss:  0.0023946583\n",
      "Iteration:  6800 , loss:  0.0023379587\n",
      "Iteration:  6900 , loss:  0.0022794623\n",
      "Iteration:  7000 , loss:  0.0022306903\n",
      "Iteration:  7100 , loss:  0.0021816292\n",
      "Iteration:  7200 , loss:  0.002137619\n",
      "Iteration:  7300 , loss:  0.0020978579\n",
      "Iteration:  7400 , loss:  0.00208417\n",
      "Iteration:  7500 , loss:  0.0020159218\n",
      "Iteration:  7600 , loss:  0.0019835962\n",
      "Iteration:  7700 , loss:  0.001945336\n",
      "Iteration:  7800 , loss:  0.0019556072\n",
      "Iteration:  7900 , loss:  0.0018780835\n",
      "Iteration:  8000 , loss:  0.0018741236\n",
      "Iteration:  8100 , loss:  0.0018113387\n",
      "Iteration:  8200 , loss:  0.0017772238\n",
      "Iteration:  8300 , loss:  0.0017443942\n",
      "Iteration:  8400 , loss:  0.0017126531\n",
      "Iteration:  8500 , loss:  0.0017282154\n",
      "Iteration:  8600 , loss:  0.0016439201\n",
      "Iteration:  8700 , loss:  0.002158287\n",
      "Iteration:  8800 , loss:  0.0015763588\n",
      "Iteration:  8900 , loss:  0.0015491918\n",
      "Iteration:  9000 , loss:  0.0015092902\n",
      "Iteration:  9100 , loss:  0.0014876788\n",
      "Iteration:  9200 , loss:  0.0014413225\n",
      "Iteration:  9300 , loss:  0.001447976\n",
      "Iteration:  9400 , loss:  0.0016472287\n",
      "Iteration:  9500 , loss:  0.0013395727\n",
      "Iteration:  9600 , loss:  0.0013164638\n",
      "Iteration:  9700 , loss:  0.0015887751\n",
      "Iteration:  9800 , loss:  0.0012434267\n",
      "Iteration:  9900 , loss:  0.0012167995\n",
      "Iteration:  10000 , loss:  0.0026427996\n",
      "Iteration:  10100 , loss:  0.0011565025\n",
      "Iteration:  10200 , loss:  0.0012997519\n",
      "Iteration:  10300 , loss:  0.0011027169\n",
      "Iteration:  10400 , loss:  0.0010788757\n",
      "Iteration:  10500 , loss:  0.001138383\n",
      "Iteration:  10600 , loss:  0.0010285788\n",
      "Iteration:  10700 , loss:  0.0010064001\n",
      "Iteration:  10800 , loss:  0.0014886183\n",
      "Iteration:  10900 , loss:  0.0010538788\n",
      "Iteration:  11000 , loss:  0.0009406426\n",
      "Iteration:  11100 , loss:  0.0009981361\n",
      "Iteration:  11200 , loss:  0.00090205297\n",
      "Iteration:  11300 , loss:  0.0008848043\n",
      "Iteration:  11400 , loss:  0.00089064246\n",
      "Iteration:  11500 , loss:  0.0010761372\n",
      "Iteration:  11600 , loss:  0.00083331385\n",
      "Iteration:  11700 , loss:  0.00083087437\n",
      "Iteration:  11800 , loss:  0.00081432884\n",
      "Iteration:  11900 , loss:  0.00078517577\n",
      "Iteration:  12000 , loss:  0.0007708486\n",
      "Iteration:  12100 , loss:  0.00075861707\n",
      "Iteration:  12200 , loss:  0.0007530326\n",
      "Iteration:  12300 , loss:  0.00080954714\n",
      "Iteration:  12400 , loss:  0.0007210668\n",
      "Iteration:  12500 , loss:  0.0007102644\n",
      "Iteration:  12600 , loss:  0.00075100025\n",
      "Iteration:  12700 , loss:  0.00069558073\n",
      "Iteration:  12800 , loss:  0.0006914553\n",
      "Iteration:  12900 , loss:  0.0006709108\n",
      "Iteration:  13000 , loss:  0.00068959536\n",
      "Iteration:  13100 , loss:  0.0006745314\n",
      "Iteration:  13200 , loss:  0.00065303926\n",
      "Iteration:  13300 , loss:  0.000632466\n",
      "Iteration:  13400 , loss:  0.0006235752\n",
      "Iteration:  13500 , loss:  0.00081553316\n",
      "Iteration:  13600 , loss:  0.0006641706\n",
      "Iteration:  13700 , loss:  0.0006332852\n",
      "Iteration:  13800 , loss:  0.0005962781\n",
      "Iteration:  13900 , loss:  0.00079861213\n",
      "Iteration:  14000 , loss:  0.00057706865\n",
      "Iteration:  14100 , loss:  0.00060107716\n",
      "Iteration:  14200 , loss:  0.0005720645\n",
      "Iteration:  14300 , loss:  0.00055634906\n",
      "Iteration:  14400 , loss:  0.00055582315\n",
      "Iteration:  14500 , loss:  0.00054631225\n",
      "Iteration:  14600 , loss:  0.00056166924\n",
      "Iteration:  14700 , loss:  0.00093625236\n",
      "Iteration:  14800 , loss:  0.0005281614\n",
      "Iteration:  14900 , loss:  0.0005670645\n",
      "Iteration:  15000 , loss:  0.0005931357\n",
      "Iteration:  15100 , loss:  0.0005087016\n",
      "Iteration:  15200 , loss:  0.0005073215\n",
      "Iteration:  15300 , loss:  0.0008056698\n",
      "Iteration:  15400 , loss:  0.0007780532\n",
      "Iteration:  15500 , loss:  0.00048786055\n",
      "Iteration:  15600 , loss:  0.0008369592\n",
      "Iteration:  15700 , loss:  0.0008863176\n",
      "Iteration:  15800 , loss:  0.00047499556\n",
      "Iteration:  15900 , loss:  0.00046589907\n",
      "Iteration:  16000 , loss:  0.0004931642\n",
      "Iteration:  16100 , loss:  0.00046576853\n",
      "Iteration:  16200 , loss:  0.00045665182\n",
      "Iteration:  16300 , loss:  0.0006041361\n",
      "Iteration:  16400 , loss:  0.00044891416\n",
      "Iteration:  16500 , loss:  0.00043919188\n",
      "Iteration:  16600 , loss:  0.00045303226\n",
      "Iteration:  16700 , loss:  0.0004423606\n",
      "Iteration:  16800 , loss:  0.00048632955\n",
      "Iteration:  16900 , loss:  0.00041923427\n",
      "Iteration:  17000 , loss:  0.00041803982\n",
      "Iteration:  17100 , loss:  0.00041359168\n",
      "Iteration:  17200 , loss:  0.00043529322\n",
      "Iteration:  17300 , loss:  0.0004026486\n",
      "Iteration:  17400 , loss:  0.00039993305\n",
      "Iteration:  17500 , loss:  0.00039508392\n",
      "Iteration:  17600 , loss:  0.00039200336\n",
      "Iteration:  17700 , loss:  0.00040882124\n",
      "Iteration:  17800 , loss:  0.00038421448\n",
      "Iteration:  17900 , loss:  0.00038297742\n",
      "Iteration:  18000 , loss:  0.00042168284\n",
      "Iteration:  18100 , loss:  0.00065545965\n",
      "Iteration:  18200 , loss:  0.0003723591\n",
      "Iteration:  18300 , loss:  0.00065939786\n",
      "Iteration:  18400 , loss:  0.00036350073\n",
      "Iteration:  18500 , loss:  0.00036322183\n",
      "Iteration:  18600 , loss:  0.00038102118\n",
      "Iteration:  18700 , loss:  0.0012587473\n",
      "Iteration:  18800 , loss:  0.00069823745\n",
      "Iteration:  18900 , loss:  0.00039906322\n",
      "Iteration:  19000 , loss:  0.00037078038\n",
      "Iteration:  19100 , loss:  0.0003578767\n",
      "Iteration:  19200 , loss:  0.00046468107\n",
      "Iteration:  19300 , loss:  0.00041783554\n",
      "Iteration:  19400 , loss:  0.00033802752\n",
      "Iteration:  19500 , loss:  0.00038890657\n",
      "Iteration:  19600 , loss:  0.00041510357\n",
      "Iteration:  19700 , loss:  0.00046929374\n",
      "Iteration:  19800 , loss:  0.0003223358\n",
      "Iteration:  19900 , loss:  0.00032047473\n",
      "Generating 2th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.17782886\n",
      "Iteration:  100 , loss:  0.039634902\n",
      "Iteration:  200 , loss:  0.029894479\n",
      "Iteration:  300 , loss:  0.026633725\n",
      "Iteration:  400 , loss:  0.024670592\n",
      "Iteration:  500 , loss:  0.02331626\n",
      "Iteration:  600 , loss:  0.02230508\n",
      "Iteration:  700 , loss:  0.021533623\n",
      "Iteration:  800 , loss:  0.020850869\n",
      "Iteration:  900 , loss:  0.020126728\n",
      "Iteration:  1000 , loss:  0.019223116\n",
      "Iteration:  1100 , loss:  0.018169336\n",
      "Iteration:  1200 , loss:  0.017444396\n",
      "Iteration:  1300 , loss:  0.016848158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1400 , loss:  0.01619676\n",
      "Iteration:  1500 , loss:  0.015526457\n",
      "Iteration:  1600 , loss:  0.014901133\n",
      "Iteration:  1700 , loss:  0.014304925\n",
      "Iteration:  1800 , loss:  0.013752513\n",
      "Iteration:  1900 , loss:  0.013261049\n",
      "Iteration:  2000 , loss:  0.012826694\n",
      "Iteration:  2100 , loss:  0.012405409\n",
      "Iteration:  2200 , loss:  0.012020014\n",
      "Iteration:  2300 , loss:  0.011629162\n",
      "Iteration:  2400 , loss:  0.0112426095\n",
      "Iteration:  2500 , loss:  0.01086267\n",
      "Iteration:  2600 , loss:  0.010614219\n",
      "Iteration:  2700 , loss:  0.010156071\n",
      "Iteration:  2800 , loss:  0.009848236\n",
      "Iteration:  2900 , loss:  0.009512834\n",
      "Iteration:  3000 , loss:  0.009275046\n",
      "Iteration:  3100 , loss:  0.008949612\n",
      "Iteration:  3200 , loss:  0.009228597\n",
      "Iteration:  3300 , loss:  0.0084509235\n",
      "Iteration:  3400 , loss:  0.008202721\n",
      "Iteration:  3500 , loss:  0.007963017\n",
      "Iteration:  3600 , loss:  0.0077116974\n",
      "Iteration:  3700 , loss:  0.0082584955\n",
      "Iteration:  3800 , loss:  0.0072048493\n",
      "Iteration:  3900 , loss:  0.0069643087\n",
      "Iteration:  4000 , loss:  0.0067431917\n",
      "Iteration:  4100 , loss:  0.0066152113\n",
      "Iteration:  4200 , loss:  0.006352691\n",
      "Iteration:  4300 , loss:  0.0061843535\n",
      "Iteration:  4400 , loss:  0.0062491912\n",
      "Iteration:  4500 , loss:  0.0058807298\n",
      "Iteration:  4600 , loss:  0.005991957\n",
      "Iteration:  4700 , loss:  0.0056071603\n",
      "Iteration:  4800 , loss:  0.005471229\n",
      "Iteration:  4900 , loss:  0.005341178\n",
      "Iteration:  5000 , loss:  0.0052103214\n",
      "Iteration:  5100 , loss:  0.005071749\n",
      "Iteration:  5200 , loss:  0.0049283155\n",
      "Iteration:  5300 , loss:  0.004779019\n",
      "Iteration:  5400 , loss:  0.0046274206\n",
      "Iteration:  5500 , loss:  0.004478768\n",
      "Iteration:  5600 , loss:  0.004407344\n",
      "Iteration:  5700 , loss:  0.0041891825\n",
      "Iteration:  5800 , loss:  0.0040488117\n",
      "Iteration:  5900 , loss:  0.00391173\n",
      "Iteration:  6000 , loss:  0.0037821915\n",
      "Iteration:  6100 , loss:  0.0037038897\n",
      "Iteration:  6200 , loss:  0.0036215978\n",
      "Iteration:  6300 , loss:  0.0034271125\n",
      "Iteration:  6400 , loss:  0.0033098478\n",
      "Iteration:  6500 , loss:  0.003205707\n",
      "Iteration:  6600 , loss:  0.0031019012\n",
      "Iteration:  6700 , loss:  0.0030194144\n",
      "Iteration:  6800 , loss:  0.002917283\n",
      "Iteration:  6900 , loss:  0.0028429953\n",
      "Iteration:  7000 , loss:  0.0027679089\n",
      "Iteration:  7100 , loss:  0.0026885737\n",
      "Iteration:  7200 , loss:  0.0026245709\n",
      "Iteration:  7300 , loss:  0.0025830523\n",
      "Iteration:  7400 , loss:  0.0025113812\n",
      "Iteration:  7500 , loss:  0.002452902\n",
      "Iteration:  7600 , loss:  0.0024026893\n",
      "Iteration:  7700 , loss:  0.0023683384\n",
      "Iteration:  7800 , loss:  0.0023081885\n",
      "Iteration:  7900 , loss:  0.0023103599\n",
      "Iteration:  8000 , loss:  0.0022251264\n",
      "Iteration:  8100 , loss:  0.0022377216\n",
      "Iteration:  8200 , loss:  0.0021267051\n",
      "Iteration:  8300 , loss:  0.002077519\n",
      "Iteration:  8400 , loss:  0.0020279833\n",
      "Iteration:  8500 , loss:  0.0019818086\n",
      "Iteration:  8600 , loss:  0.0021192518\n",
      "Iteration:  8700 , loss:  0.0018865117\n",
      "Iteration:  8800 , loss:  0.0018485435\n",
      "Iteration:  8900 , loss:  0.0018021956\n",
      "Iteration:  9000 , loss:  0.0017631759\n",
      "Iteration:  9100 , loss:  0.0017288781\n",
      "Iteration:  9200 , loss:  0.0020885507\n",
      "Iteration:  9300 , loss:  0.0016510494\n",
      "Iteration:  9400 , loss:  0.0016164931\n",
      "Iteration:  9500 , loss:  0.001589562\n",
      "Iteration:  9600 , loss:  0.0015490656\n",
      "Iteration:  9700 , loss:  0.0015185489\n",
      "Iteration:  9800 , loss:  0.0014942936\n",
      "Iteration:  9900 , loss:  0.0014518545\n",
      "Iteration:  10000 , loss:  0.0014222984\n",
      "Iteration:  10100 , loss:  0.0013920644\n",
      "Iteration:  10200 , loss:  0.0014126303\n",
      "Iteration:  10300 , loss:  0.0013407605\n",
      "Iteration:  10400 , loss:  0.0013072107\n",
      "Iteration:  10500 , loss:  0.0012808428\n",
      "Iteration:  10600 , loss:  0.0013178762\n",
      "Iteration:  10700 , loss:  0.0012302912\n",
      "Iteration:  10800 , loss:  0.001282937\n",
      "Iteration:  10900 , loss:  0.0011815962\n",
      "Iteration:  11000 , loss:  0.0011594165\n",
      "Iteration:  11100 , loss:  0.0011862621\n",
      "Iteration:  11200 , loss:  0.0011760271\n",
      "Iteration:  11300 , loss:  0.0014113521\n",
      "Iteration:  11400 , loss:  0.0012321246\n",
      "Iteration:  11500 , loss:  0.0010457987\n",
      "Iteration:  11600 , loss:  0.0010304078\n",
      "Iteration:  11700 , loss:  0.0010025274\n",
      "Iteration:  11800 , loss:  0.0009827818\n",
      "Iteration:  11900 , loss:  0.0009633476\n",
      "Iteration:  12000 , loss:  0.0009452583\n",
      "Iteration:  12100 , loss:  0.000937237\n",
      "Iteration:  12200 , loss:  0.0010024419\n",
      "Iteration:  12300 , loss:  0.00088867487\n",
      "Iteration:  12400 , loss:  0.0009628803\n",
      "Iteration:  12500 , loss:  0.0008662453\n",
      "Iteration:  12600 , loss:  0.00084616855\n",
      "Iteration:  12700 , loss:  0.0013307225\n",
      "Iteration:  12800 , loss:  0.00080138363\n",
      "Iteration:  12900 , loss:  0.0008327989\n",
      "Iteration:  13000 , loss:  0.00077072554\n",
      "Iteration:  13100 , loss:  0.00087696646\n",
      "Iteration:  13200 , loss:  0.00089472474\n",
      "Iteration:  13300 , loss:  0.00073175435\n",
      "Iteration:  13400 , loss:  0.00072730123\n",
      "Iteration:  13500 , loss:  0.0007706864\n",
      "Iteration:  13600 , loss:  0.0008908838\n",
      "Iteration:  13700 , loss:  0.0006890762\n",
      "Iteration:  13800 , loss:  0.0006628892\n",
      "Iteration:  13900 , loss:  0.00067154854\n",
      "Iteration:  14000 , loss:  0.0008175266\n",
      "Iteration:  14100 , loss:  0.00063065963\n",
      "Iteration:  14200 , loss:  0.0006201939\n",
      "Iteration:  14300 , loss:  0.0006053954\n",
      "Iteration:  14400 , loss:  0.00062744133\n",
      "Iteration:  14500 , loss:  0.00067177194\n",
      "Iteration:  14600 , loss:  0.00058589835\n",
      "Iteration:  14700 , loss:  0.0011160121\n",
      "Iteration:  14800 , loss:  0.0005568729\n",
      "Iteration:  14900 , loss:  0.00055980944\n",
      "Iteration:  15000 , loss:  0.0005411144\n",
      "Iteration:  15100 , loss:  0.00053162506\n",
      "Iteration:  15200 , loss:  0.0005331107\n",
      "Iteration:  15300 , loss:  0.00054445345\n",
      "Iteration:  15400 , loss:  0.0007761298\n",
      "Iteration:  15500 , loss:  0.00053673604\n",
      "Iteration:  15600 , loss:  0.000544296\n",
      "Iteration:  15700 , loss:  0.0005563606\n",
      "Iteration:  15800 , loss:  0.00048412997\n",
      "Iteration:  15900 , loss:  0.00048404082\n",
      "Iteration:  16000 , loss:  0.0004750279\n",
      "Iteration:  16100 , loss:  0.000489364\n",
      "Iteration:  16200 , loss:  0.00048603409\n",
      "Iteration:  16300 , loss:  0.0004608702\n",
      "Iteration:  16400 , loss:  0.0004898942\n",
      "Iteration:  16500 , loss:  0.00046964426\n",
      "Iteration:  16600 , loss:  0.00043976857\n",
      "Iteration:  16700 , loss:  0.0004612678\n",
      "Iteration:  16800 , loss:  0.0008496292\n",
      "Iteration:  16900 , loss:  0.00044011296\n",
      "Iteration:  17000 , loss:  0.00047032686\n",
      "Iteration:  17100 , loss:  0.00042356175\n",
      "Iteration:  17200 , loss:  0.0004121227\n",
      "Iteration:  17300 , loss:  0.0004131732\n",
      "Iteration:  17400 , loss:  0.0004210403\n",
      "Iteration:  17500 , loss:  0.00042905082\n",
      "Iteration:  17600 , loss:  0.0004492735\n",
      "Iteration:  17700 , loss:  0.0004037649\n",
      "Iteration:  17800 , loss:  0.0003911067\n",
      "Iteration:  17900 , loss:  0.000385503\n",
      "Iteration:  18000 , loss:  0.00038274896\n",
      "Iteration:  18100 , loss:  0.00038664084\n",
      "Iteration:  18200 , loss:  0.00042563467\n",
      "Iteration:  18300 , loss:  0.00049522356\n",
      "Iteration:  18400 , loss:  0.00038276063\n",
      "Iteration:  18500 , loss:  0.00042100585\n",
      "Iteration:  18600 , loss:  0.0003927903\n",
      "Iteration:  18700 , loss:  0.00048748188\n",
      "Iteration:  18800 , loss:  0.0004649236\n",
      "Iteration:  18900 , loss:  0.00043161414\n",
      "Iteration:  19000 , loss:  0.00040981703\n",
      "Iteration:  19100 , loss:  0.00036447265\n",
      "Iteration:  19200 , loss:  0.000419802\n",
      "Iteration:  19300 , loss:  0.00035668793\n",
      "Iteration:  19400 , loss:  0.00036124123\n",
      "Iteration:  19500 , loss:  0.0003788498\n",
      "Iteration:  19600 , loss:  0.00037550222\n",
      "Iteration:  19700 , loss:  0.00066758005\n",
      "Iteration:  19800 , loss:  0.0004416104\n",
      "Iteration:  19900 , loss:  0.0005397709\n",
      "Generating 3th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.06892365\n",
      "Iteration:  100 , loss:  0.025539758\n",
      "Iteration:  200 , loss:  0.02308442\n",
      "Iteration:  300 , loss:  0.022050668\n",
      "Iteration:  400 , loss:  0.021122431\n",
      "Iteration:  500 , loss:  0.019875664\n",
      "Iteration:  600 , loss:  0.018881734\n",
      "Iteration:  700 , loss:  0.018039841\n",
      "Iteration:  800 , loss:  0.01679159\n",
      "Iteration:  900 , loss:  0.015542736\n",
      "Iteration:  1000 , loss:  0.01477409\n",
      "Iteration:  1100 , loss:  0.01420835\n",
      "Iteration:  1200 , loss:  0.013606732\n",
      "Iteration:  1300 , loss:  0.013081071\n",
      "Iteration:  1400 , loss:  0.012718856\n",
      "Iteration:  1500 , loss:  0.0123903835\n",
      "Iteration:  1600 , loss:  0.012111992\n",
      "Iteration:  1700 , loss:  0.011846799\n",
      "Iteration:  1800 , loss:  0.011619308\n",
      "Iteration:  1900 , loss:  0.011408707\n",
      "Iteration:  2000 , loss:  0.011216184\n",
      "Iteration:  2100 , loss:  0.011046957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2200 , loss:  0.010876682\n",
      "Iteration:  2300 , loss:  0.010988297\n",
      "Iteration:  2400 , loss:  0.010512112\n",
      "Iteration:  2500 , loss:  0.01028388\n",
      "Iteration:  2600 , loss:  0.0102096265\n",
      "Iteration:  2700 , loss:  0.00986499\n",
      "Iteration:  2800 , loss:  0.009653796\n",
      "Iteration:  2900 , loss:  0.00943476\n",
      "Iteration:  3000 , loss:  0.009196382\n",
      "Iteration:  3100 , loss:  0.008917805\n",
      "Iteration:  3200 , loss:  0.0085926065\n",
      "Iteration:  3300 , loss:  0.008183861\n",
      "Iteration:  3400 , loss:  0.008409624\n",
      "Iteration:  3500 , loss:  0.007209765\n",
      "Iteration:  3600 , loss:  0.0067766556\n",
      "Iteration:  3700 , loss:  0.006463924\n",
      "Iteration:  3800 , loss:  0.0061902\n",
      "Iteration:  3900 , loss:  0.0060002757\n",
      "Iteration:  4000 , loss:  0.005936388\n",
      "Iteration:  4100 , loss:  0.0057262103\n",
      "Iteration:  4200 , loss:  0.00561349\n",
      "Iteration:  4300 , loss:  0.00566523\n",
      "Iteration:  4400 , loss:  0.0054149604\n",
      "Iteration:  4500 , loss:  0.0053177555\n",
      "Iteration:  4600 , loss:  0.00522737\n",
      "Iteration:  4700 , loss:  0.0051324195\n",
      "Iteration:  4800 , loss:  0.005101067\n",
      "Iteration:  4900 , loss:  0.0049673645\n",
      "Iteration:  5000 , loss:  0.004885052\n",
      "Iteration:  5100 , loss:  0.0048212907\n",
      "Iteration:  5200 , loss:  0.0047096773\n",
      "Iteration:  5300 , loss:  0.0045998744\n",
      "Iteration:  5400 , loss:  0.004486072\n",
      "Iteration:  5500 , loss:  0.00435847\n",
      "Iteration:  5600 , loss:  0.0045546135\n",
      "Iteration:  5700 , loss:  0.004097346\n",
      "Iteration:  5800 , loss:  0.0039694444\n",
      "Iteration:  5900 , loss:  0.0038535742\n",
      "Iteration:  6000 , loss:  0.003736114\n",
      "Iteration:  6100 , loss:  0.0036228609\n",
      "Iteration:  6200 , loss:  0.0035118442\n",
      "Iteration:  6300 , loss:  0.00340919\n",
      "Iteration:  6400 , loss:  0.0033060606\n",
      "Iteration:  6500 , loss:  0.0032187058\n",
      "Iteration:  6600 , loss:  0.0031203763\n",
      "Iteration:  6700 , loss:  0.0030308343\n",
      "Iteration:  6800 , loss:  0.0029508155\n",
      "Iteration:  6900 , loss:  0.0028719504\n",
      "Iteration:  7000 , loss:  0.0028052183\n",
      "Iteration:  7100 , loss:  0.0027297325\n",
      "Iteration:  7200 , loss:  0.0026626862\n",
      "Iteration:  7300 , loss:  0.0026393924\n",
      "Iteration:  7400 , loss:  0.0025394543\n",
      "Iteration:  7500 , loss:  0.0025038563\n",
      "Iteration:  7600 , loss:  0.0024305815\n",
      "Iteration:  7700 , loss:  0.0023805774\n",
      "Iteration:  7800 , loss:  0.0031687787\n",
      "Iteration:  7900 , loss:  0.0022878593\n",
      "Iteration:  8000 , loss:  0.0022938135\n",
      "Iteration:  8100 , loss:  0.0022046433\n",
      "Iteration:  8200 , loss:  0.0021653662\n",
      "Iteration:  8300 , loss:  0.0021279913\n",
      "Iteration:  8400 , loss:  0.002210931\n",
      "Iteration:  8500 , loss:  0.002055377\n",
      "Iteration:  8600 , loss:  0.0020231428\n",
      "Iteration:  8700 , loss:  0.0019864526\n",
      "Iteration:  8800 , loss:  0.0019512008\n",
      "Iteration:  8900 , loss:  0.0020238203\n",
      "Iteration:  9000 , loss:  0.0018821795\n",
      "Iteration:  9100 , loss:  0.001854538\n",
      "Iteration:  9200 , loss:  0.001818377\n",
      "Iteration:  9300 , loss:  0.0017818003\n",
      "Iteration:  9400 , loss:  0.0017506293\n",
      "Iteration:  9500 , loss:  0.0017181074\n",
      "Iteration:  9600 , loss:  0.0016938861\n",
      "Iteration:  9700 , loss:  0.0016619859\n",
      "Iteration:  9800 , loss:  0.0016301684\n",
      "Iteration:  9900 , loss:  0.0016039682\n",
      "Iteration:  10000 , loss:  0.0015812018\n",
      "Iteration:  10100 , loss:  0.0015543444\n",
      "Iteration:  10200 , loss:  0.001541114\n",
      "Iteration:  10300 , loss:  0.0015721257\n",
      "Iteration:  10400 , loss:  0.001487826\n",
      "Iteration:  10500 , loss:  0.0024423627\n",
      "Iteration:  10600 , loss:  0.0014478364\n",
      "Iteration:  10700 , loss:  0.0020723315\n",
      "Iteration:  10800 , loss:  0.0014105609\n",
      "Iteration:  10900 , loss:  0.0013943693\n",
      "Iteration:  11000 , loss:  0.0022908258\n",
      "Iteration:  11100 , loss:  0.0013598455\n",
      "Iteration:  11200 , loss:  0.0015675074\n",
      "Iteration:  11300 , loss:  0.0013281405\n",
      "Iteration:  11400 , loss:  0.0022876102\n",
      "Iteration:  11500 , loss:  0.0012977314\n",
      "Iteration:  11600 , loss:  0.001429877\n",
      "Iteration:  11700 , loss:  0.001343723\n",
      "Iteration:  11800 , loss:  0.0012541509\n",
      "Iteration:  11900 , loss:  0.0012398951\n",
      "Iteration:  12000 , loss:  0.0012402586\n",
      "Iteration:  12100 , loss:  0.0012120384\n",
      "Iteration:  12200 , loss:  0.0012019278\n",
      "Iteration:  12300 , loss:  0.001185928\n",
      "Iteration:  12400 , loss:  0.0011930267\n",
      "Iteration:  12500 , loss:  0.0011597102\n",
      "Iteration:  12600 , loss:  0.0011569825\n",
      "Iteration:  12700 , loss:  0.0011374509\n",
      "Iteration:  12800 , loss:  0.0011236325\n",
      "Iteration:  12900 , loss:  0.0011384019\n",
      "Iteration:  13000 , loss:  0.001115902\n",
      "Iteration:  13100 , loss:  0.0010911907\n",
      "Iteration:  13200 , loss:  0.0011494837\n",
      "Iteration:  13300 , loss:  0.0010608034\n",
      "Iteration:  13400 , loss:  0.0010676923\n",
      "Iteration:  13500 , loss:  0.0010368295\n",
      "Iteration:  13600 , loss:  0.001101837\n",
      "Iteration:  13700 , loss:  0.0010109267\n",
      "Iteration:  13800 , loss:  0.0010004219\n",
      "Iteration:  13900 , loss:  0.0010138801\n",
      "Iteration:  14000 , loss:  0.001015464\n",
      "Iteration:  14100 , loss:  0.00096573005\n",
      "Iteration:  14200 , loss:  0.00095512473\n",
      "Iteration:  14300 , loss:  0.0009745262\n",
      "Iteration:  14400 , loss:  0.0009340977\n",
      "Iteration:  14500 , loss:  0.0009600055\n",
      "Iteration:  14600 , loss:  0.00093881594\n",
      "Iteration:  14700 , loss:  0.0009577492\n",
      "Iteration:  14800 , loss:  0.00090332516\n",
      "Iteration:  14900 , loss:  0.000886947\n",
      "Iteration:  15000 , loss:  0.0008789509\n",
      "Iteration:  15100 , loss:  0.0008809427\n",
      "Iteration:  15200 , loss:  0.0008725859\n",
      "Iteration:  15300 , loss:  0.0008551993\n",
      "Iteration:  15400 , loss:  0.00084144087\n",
      "Iteration:  15500 , loss:  0.0008992453\n",
      "Iteration:  15600 , loss:  0.000842897\n",
      "Iteration:  15700 , loss:  0.0008408713\n",
      "Iteration:  15800 , loss:  0.0008063575\n",
      "Iteration:  15900 , loss:  0.00080345053\n",
      "Iteration:  16000 , loss:  0.0007887325\n",
      "Iteration:  16100 , loss:  0.0007820256\n",
      "Iteration:  16200 , loss:  0.00077214383\n",
      "Iteration:  16300 , loss:  0.00085582543\n",
      "Iteration:  16400 , loss:  0.001032219\n",
      "Iteration:  16500 , loss:  0.0007481278\n",
      "Iteration:  16600 , loss:  0.0007393574\n",
      "Iteration:  16700 , loss:  0.0007325749\n",
      "Iteration:  16800 , loss:  0.0007238424\n",
      "Iteration:  16900 , loss:  0.000716311\n",
      "Iteration:  17000 , loss:  0.00070871913\n",
      "Iteration:  17100 , loss:  0.0007228875\n",
      "Iteration:  17200 , loss:  0.0006937013\n",
      "Iteration:  17300 , loss:  0.00070009555\n",
      "Iteration:  17400 , loss:  0.00067857385\n",
      "Iteration:  17500 , loss:  0.0008526186\n",
      "Iteration:  17600 , loss:  0.00074592227\n",
      "Iteration:  17700 , loss:  0.0006765681\n",
      "Iteration:  17800 , loss:  0.0006620948\n",
      "Iteration:  17900 , loss:  0.00064179767\n",
      "Iteration:  18000 , loss:  0.0006360038\n",
      "Iteration:  18100 , loss:  0.0006773907\n",
      "Iteration:  18200 , loss:  0.000641248\n",
      "Iteration:  18300 , loss:  0.0006311239\n",
      "Iteration:  18400 , loss:  0.0007171517\n",
      "Iteration:  18500 , loss:  0.0006338706\n",
      "Iteration:  18600 , loss:  0.0011037248\n",
      "Iteration:  18700 , loss:  0.0005939231\n",
      "Iteration:  18800 , loss:  0.00058455183\n",
      "Iteration:  18900 , loss:  0.0005749618\n",
      "Iteration:  19000 , loss:  0.0005778114\n",
      "Iteration:  19100 , loss:  0.00058725924\n",
      "Iteration:  19200 , loss:  0.00055706524\n",
      "Iteration:  19300 , loss:  0.00056615914\n",
      "Iteration:  19400 , loss:  0.0008941023\n",
      "Iteration:  19500 , loss:  0.0010127948\n",
      "Iteration:  19600 , loss:  0.0005939404\n",
      "Iteration:  19700 , loss:  0.000529377\n",
      "Iteration:  19800 , loss:  0.00069258024\n",
      "Iteration:  19900 , loss:  0.0005912774\n",
      "Generating 4th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  1.0444293\n",
      "Iteration:  100 , loss:  0.06094914\n",
      "Iteration:  200 , loss:  0.051408216\n",
      "Iteration:  300 , loss:  0.04263503\n",
      "Iteration:  400 , loss:  0.036172338\n",
      "Iteration:  500 , loss:  0.031585712\n",
      "Iteration:  600 , loss:  0.028772574\n",
      "Iteration:  700 , loss:  0.026998345\n",
      "Iteration:  800 , loss:  0.025780786\n",
      "Iteration:  900 , loss:  0.024887607\n",
      "Iteration:  1000 , loss:  0.024204902\n",
      "Iteration:  1100 , loss:  0.023666188\n",
      "Iteration:  1200 , loss:  0.023225864\n",
      "Iteration:  1300 , loss:  0.022848748\n",
      "Iteration:  1400 , loss:  0.022507682\n",
      "Iteration:  1500 , loss:  0.022185085\n",
      "Iteration:  1600 , loss:  0.021871813\n",
      "Iteration:  1700 , loss:  0.021563549\n",
      "Iteration:  1800 , loss:  0.021257551\n",
      "Iteration:  1900 , loss:  0.02095095\n",
      "Iteration:  2000 , loss:  0.020640384\n",
      "Iteration:  2100 , loss:  0.020322662\n",
      "Iteration:  2200 , loss:  0.01999636\n",
      "Iteration:  2300 , loss:  0.019663583\n",
      "Iteration:  2400 , loss:  0.019330494\n",
      "Iteration:  2500 , loss:  0.019004647\n",
      "Iteration:  2600 , loss:  0.018689303\n",
      "Iteration:  2700 , loss:  0.018379638\n",
      "Iteration:  2800 , loss:  0.018065397\n",
      "Iteration:  2900 , loss:  0.017737601\n",
      "Iteration:  3000 , loss:  0.017394342\n",
      "Iteration:  3100 , loss:  0.01704025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3200 , loss:  0.01667982\n",
      "Iteration:  3300 , loss:  0.016313305\n",
      "Iteration:  3400 , loss:  0.015939739\n",
      "Iteration:  3500 , loss:  0.015562877\n",
      "Iteration:  3600 , loss:  0.015188986\n",
      "Iteration:  3700 , loss:  0.014819482\n",
      "Iteration:  3800 , loss:  0.014418298\n",
      "Iteration:  3900 , loss:  0.013890927\n",
      "Iteration:  4000 , loss:  0.013369089\n",
      "Iteration:  4100 , loss:  0.012975194\n",
      "Iteration:  4200 , loss:  0.01265706\n",
      "Iteration:  4300 , loss:  0.012383336\n",
      "Iteration:  4400 , loss:  0.012144388\n",
      "Iteration:  4500 , loss:  0.011930311\n",
      "Iteration:  4600 , loss:  0.0117382035\n",
      "Iteration:  4700 , loss:  0.011564621\n",
      "Iteration:  4800 , loss:  0.011404826\n",
      "Iteration:  4900 , loss:  0.0113592595\n",
      "Iteration:  5000 , loss:  0.011116245\n",
      "Iteration:  5100 , loss:  0.010981315\n",
      "Iteration:  5200 , loss:  0.010853851\n",
      "Iteration:  5300 , loss:  0.010725524\n",
      "Iteration:  5400 , loss:  0.010728506\n",
      "Iteration:  5500 , loss:  0.010457502\n",
      "Iteration:  5600 , loss:  0.010298611\n",
      "Iteration:  5700 , loss:  0.010113322\n",
      "Iteration:  5800 , loss:  0.009897359\n",
      "Iteration:  5900 , loss:  0.010070573\n",
      "Iteration:  6000 , loss:  0.009422687\n",
      "Iteration:  6100 , loss:  0.009189816\n",
      "Iteration:  6200 , loss:  0.008985065\n",
      "Iteration:  6300 , loss:  0.008782577\n",
      "Iteration:  6400 , loss:  0.008632501\n",
      "Iteration:  6500 , loss:  0.008436387\n",
      "Iteration:  6600 , loss:  0.008271326\n",
      "Iteration:  6700 , loss:  0.008124607\n",
      "Iteration:  6800 , loss:  0.007948437\n",
      "Iteration:  6900 , loss:  0.007781311\n",
      "Iteration:  7000 , loss:  0.007620696\n",
      "Iteration:  7100 , loss:  0.0074546933\n",
      "Iteration:  7200 , loss:  0.0072913575\n",
      "Iteration:  7300 , loss:  0.007138981\n",
      "Iteration:  7400 , loss:  0.0069814883\n",
      "Iteration:  7500 , loss:  0.007090575\n",
      "Iteration:  7600 , loss:  0.006651917\n",
      "Iteration:  7700 , loss:  0.00646587\n",
      "Iteration:  7800 , loss:  0.0062717185\n",
      "Iteration:  7900 , loss:  0.0060793553\n",
      "Iteration:  8000 , loss:  0.00590113\n",
      "Iteration:  8100 , loss:  0.005745237\n",
      "Iteration:  8200 , loss:  0.0056002154\n",
      "Iteration:  8300 , loss:  0.005463564\n",
      "Iteration:  8400 , loss:  0.0053431652\n",
      "Iteration:  8500 , loss:  0.00522637\n",
      "Iteration:  8600 , loss:  0.005119496\n",
      "Iteration:  8700 , loss:  0.00500442\n",
      "Iteration:  8800 , loss:  0.0048960885\n",
      "Iteration:  8900 , loss:  0.0047920803\n",
      "Iteration:  9000 , loss:  0.0046792626\n",
      "Iteration:  9100 , loss:  0.00458479\n",
      "Iteration:  9200 , loss:  0.004460628\n",
      "Iteration:  9300 , loss:  0.0043594586\n",
      "Iteration:  9400 , loss:  0.004248082\n",
      "Iteration:  9500 , loss:  0.004189179\n",
      "Iteration:  9600 , loss:  0.004043989\n",
      "Iteration:  9700 , loss:  0.0039605023\n",
      "Iteration:  9800 , loss:  0.0038475618\n",
      "Iteration:  9900 , loss:  0.0037913767\n",
      "Iteration:  10000 , loss:  0.0036554832\n",
      "Iteration:  10100 , loss:  0.003566381\n",
      "Iteration:  10200 , loss:  0.0034712486\n",
      "Iteration:  10300 , loss:  0.0033851182\n",
      "Iteration:  10400 , loss:  0.0033234963\n",
      "Iteration:  10500 , loss:  0.0032241398\n",
      "Iteration:  10600 , loss:  0.00315298\n",
      "Iteration:  10700 , loss:  0.00320774\n",
      "Iteration:  10800 , loss:  0.0030219832\n",
      "Iteration:  10900 , loss:  0.003015982\n",
      "Iteration:  11000 , loss:  0.0029065532\n",
      "Iteration:  11100 , loss:  0.0028616977\n",
      "Iteration:  11200 , loss:  0.00280283\n",
      "Iteration:  11300 , loss:  0.0027568815\n",
      "Iteration:  11400 , loss:  0.0035111797\n",
      "Iteration:  11500 , loss:  0.0026669365\n",
      "Iteration:  11600 , loss:  0.0031517753\n",
      "Iteration:  11700 , loss:  0.0025839333\n",
      "Iteration:  11800 , loss:  0.0032001531\n",
      "Iteration:  11900 , loss:  0.002506589\n",
      "Iteration:  12000 , loss:  0.0024804436\n",
      "Iteration:  12100 , loss:  0.002435029\n",
      "Iteration:  12200 , loss:  0.0023991016\n",
      "Iteration:  12300 , loss:  0.002387025\n",
      "Iteration:  12400 , loss:  0.0023336743\n",
      "Iteration:  12500 , loss:  0.0027530573\n",
      "Iteration:  12600 , loss:  0.0022733572\n",
      "Iteration:  12700 , loss:  0.002242765\n",
      "Iteration:  12800 , loss:  0.0022278116\n",
      "Iteration:  12900 , loss:  0.002189828\n",
      "Iteration:  13000 , loss:  0.0021623627\n",
      "Iteration:  13100 , loss:  0.0021383283\n",
      "Iteration:  13200 , loss:  0.0025043115\n",
      "Iteration:  13300 , loss:  0.002091005\n",
      "Iteration:  13400 , loss:  0.002969276\n",
      "Iteration:  13500 , loss:  0.002047522\n",
      "Iteration:  13600 , loss:  0.0020251328\n",
      "Iteration:  13700 , loss:  0.0021281634\n",
      "Iteration:  13800 , loss:  0.0019848624\n",
      "Iteration:  13900 , loss:  0.0028874092\n",
      "Iteration:  14000 , loss:  0.0019463494\n",
      "Iteration:  14100 , loss:  0.0021256465\n",
      "Iteration:  14200 , loss:  0.0019081484\n",
      "Iteration:  14300 , loss:  0.0018912764\n",
      "Iteration:  14400 , loss:  0.0018717763\n",
      "Iteration:  14500 , loss:  0.0018565076\n",
      "Iteration:  14600 , loss:  0.0018351895\n",
      "Iteration:  14700 , loss:  0.00189183\n",
      "Iteration:  14800 , loss:  0.0018167773\n",
      "Iteration:  14900 , loss:  0.0017822939\n",
      "Iteration:  15000 , loss:  0.0017679561\n",
      "Iteration:  15100 , loss:  0.0017470781\n",
      "Iteration:  15200 , loss:  0.0017323925\n",
      "Iteration:  15300 , loss:  0.0017139958\n",
      "Iteration:  15400 , loss:  0.001698069\n",
      "Iteration:  15500 , loss:  0.0016834994\n",
      "Iteration:  15600 , loss:  0.0018172833\n",
      "Iteration:  15700 , loss:  0.0016508353\n",
      "Iteration:  15800 , loss:  0.0016383948\n",
      "Iteration:  15900 , loss:  0.0017169899\n",
      "Iteration:  16000 , loss:  0.001597722\n",
      "Iteration:  16100 , loss:  0.0015872413\n",
      "Iteration:  16200 , loss:  0.0015642281\n",
      "Iteration:  16300 , loss:  0.001549098\n",
      "Iteration:  16400 , loss:  0.0015318049\n",
      "Iteration:  16500 , loss:  0.0015171289\n",
      "Iteration:  16600 , loss:  0.0015199234\n",
      "Iteration:  16700 , loss:  0.0014955408\n",
      "Iteration:  16800 , loss:  0.0014727552\n",
      "Iteration:  16900 , loss:  0.0014518219\n",
      "Iteration:  17000 , loss:  0.0014348858\n",
      "Iteration:  17100 , loss:  0.0014185095\n",
      "Iteration:  17200 , loss:  0.0015709538\n",
      "Iteration:  17300 , loss:  0.0013852204\n",
      "Iteration:  17400 , loss:  0.0013727751\n",
      "Iteration:  17500 , loss:  0.0013521728\n",
      "Iteration:  17600 , loss:  0.0013469656\n",
      "Iteration:  17700 , loss:  0.0013201196\n",
      "Iteration:  17800 , loss:  0.0013728568\n",
      "Iteration:  17900 , loss:  0.0012886062\n",
      "Iteration:  18000 , loss:  0.0012723473\n",
      "Iteration:  18100 , loss:  0.0012580311\n",
      "Iteration:  18200 , loss:  0.0012415745\n",
      "Iteration:  18300 , loss:  0.0012481323\n",
      "Iteration:  18400 , loss:  0.0012119277\n",
      "Iteration:  18500 , loss:  0.0011960276\n",
      "Iteration:  18600 , loss:  0.0021887345\n",
      "Iteration:  18700 , loss:  0.0011666077\n",
      "Iteration:  18800 , loss:  0.0011646213\n",
      "Iteration:  18900 , loss:  0.0011387785\n",
      "Iteration:  19000 , loss:  0.0011281912\n",
      "Iteration:  19100 , loss:  0.0011127135\n",
      "Iteration:  19200 , loss:  0.0011394803\n",
      "Iteration:  19300 , loss:  0.0010867437\n",
      "Iteration:  19400 , loss:  0.0010762054\n",
      "Iteration:  19500 , loss:  0.0010847913\n",
      "Iteration:  19600 , loss:  0.001050836\n",
      "Iteration:  19700 , loss:  0.0011756751\n",
      "Iteration:  19800 , loss:  0.0010275454\n",
      "Iteration:  19900 , loss:  0.0010170982\n",
      "Generating 5th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.07479051\n",
      "Iteration:  100 , loss:  0.027518678\n",
      "Iteration:  200 , loss:  0.02324101\n",
      "Iteration:  300 , loss:  0.022025365\n",
      "Iteration:  400 , loss:  0.021176198\n",
      "Iteration:  500 , loss:  0.020336784\n",
      "Iteration:  600 , loss:  0.019358607\n",
      "Iteration:  700 , loss:  0.018150713\n",
      "Iteration:  800 , loss:  0.017158631\n",
      "Iteration:  900 , loss:  0.016288124\n",
      "Iteration:  1000 , loss:  0.015792677\n",
      "Iteration:  1100 , loss:  0.014838723\n",
      "Iteration:  1200 , loss:  0.014217844\n",
      "Iteration:  1300 , loss:  0.013696059\n",
      "Iteration:  1400 , loss:  0.013257433\n",
      "Iteration:  1500 , loss:  0.012795636\n",
      "Iteration:  1600 , loss:  0.012418607\n",
      "Iteration:  1700 , loss:  0.012080498\n",
      "Iteration:  1800 , loss:  0.011788212\n",
      "Iteration:  1900 , loss:  0.011517532\n",
      "Iteration:  2000 , loss:  0.011266872\n",
      "Iteration:  2100 , loss:  0.011019912\n",
      "Iteration:  2200 , loss:  0.010783844\n",
      "Iteration:  2300 , loss:  0.010542809\n",
      "Iteration:  2400 , loss:  0.010309605\n",
      "Iteration:  2500 , loss:  0.0100541925\n",
      "Iteration:  2600 , loss:  0.00978892\n",
      "Iteration:  2700 , loss:  0.0095228255\n",
      "Iteration:  2800 , loss:  0.009226653\n",
      "Iteration:  2900 , loss:  0.008966791\n",
      "Iteration:  3000 , loss:  0.008567965\n",
      "Iteration:  3100 , loss:  0.008207683\n",
      "Iteration:  3200 , loss:  0.007868835\n",
      "Iteration:  3300 , loss:  0.007558598\n",
      "Iteration:  3400 , loss:  0.00727067\n",
      "Iteration:  3500 , loss:  0.0070263585\n",
      "Iteration:  3600 , loss:  0.0067966315\n",
      "Iteration:  3700 , loss:  0.006602602\n",
      "Iteration:  3800 , loss:  0.006389235\n",
      "Iteration:  3900 , loss:  0.006200752\n",
      "Iteration:  4000 , loss:  0.0060271733\n",
      "Iteration:  4100 , loss:  0.005862608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4200 , loss:  0.0057007084\n",
      "Iteration:  4300 , loss:  0.0055536246\n",
      "Iteration:  4400 , loss:  0.005411294\n",
      "Iteration:  4500 , loss:  0.005268321\n",
      "Iteration:  4600 , loss:  0.0051385094\n",
      "Iteration:  4700 , loss:  0.0050027682\n",
      "Iteration:  4800 , loss:  0.0048672743\n",
      "Iteration:  4900 , loss:  0.0047349874\n",
      "Iteration:  5000 , loss:  0.004599258\n",
      "Iteration:  5100 , loss:  0.004463795\n",
      "Iteration:  5200 , loss:  0.0043338547\n",
      "Iteration:  5300 , loss:  0.0044906475\n",
      "Iteration:  5400 , loss:  0.0040824683\n",
      "Iteration:  5500 , loss:  0.003957545\n",
      "Iteration:  5600 , loss:  0.0038396458\n",
      "Iteration:  5700 , loss:  0.0037221597\n",
      "Iteration:  5800 , loss:  0.0036199724\n",
      "Iteration:  5900 , loss:  0.0035205183\n",
      "Iteration:  6000 , loss:  0.0036460566\n",
      "Iteration:  6100 , loss:  0.0033459319\n",
      "Iteration:  6200 , loss:  0.003265362\n",
      "Iteration:  6300 , loss:  0.003195139\n",
      "Iteration:  6400 , loss:  0.0031229614\n",
      "Iteration:  6500 , loss:  0.0030526873\n",
      "Iteration:  6600 , loss:  0.0029877233\n",
      "Iteration:  6700 , loss:  0.0029248816\n",
      "Iteration:  6800 , loss:  0.0028627007\n",
      "Iteration:  6900 , loss:  0.0028463323\n",
      "Iteration:  7000 , loss:  0.00274296\n",
      "Iteration:  7100 , loss:  0.0026842793\n",
      "Iteration:  7200 , loss:  0.0026260444\n",
      "Iteration:  7300 , loss:  0.0026060645\n",
      "Iteration:  7400 , loss:  0.0030018468\n",
      "Iteration:  7500 , loss:  0.0024564494\n",
      "Iteration:  7600 , loss:  0.0029073046\n",
      "Iteration:  7700 , loss:  0.0023462095\n",
      "Iteration:  7800 , loss:  0.0022939374\n",
      "Iteration:  7900 , loss:  0.0022397903\n",
      "Iteration:  8000 , loss:  0.0021868679\n",
      "Iteration:  8100 , loss:  0.0021352526\n",
      "Iteration:  8200 , loss:  0.0020870361\n",
      "Iteration:  8300 , loss:  0.0021883922\n",
      "Iteration:  8400 , loss:  0.0019919383\n",
      "Iteration:  8500 , loss:  0.0019477627\n",
      "Iteration:  8600 , loss:  0.0018942952\n",
      "Iteration:  8700 , loss:  0.0018452292\n",
      "Iteration:  8800 , loss:  0.0018469637\n",
      "Iteration:  8900 , loss:  0.001782062\n",
      "Iteration:  9000 , loss:  0.001716264\n",
      "Iteration:  9100 , loss:  0.0016771501\n",
      "Iteration:  9200 , loss:  0.0016395033\n",
      "Iteration:  9300 , loss:  0.001599962\n",
      "Iteration:  9400 , loss:  0.0015735889\n",
      "Iteration:  9500 , loss:  0.0015706166\n",
      "Iteration:  9600 , loss:  0.0015925863\n",
      "Iteration:  9700 , loss:  0.0014663809\n",
      "Iteration:  9800 , loss:  0.0014302882\n",
      "Iteration:  9900 , loss:  0.0015584918\n",
      "Iteration:  10000 , loss:  0.0013687965\n",
      "Iteration:  10100 , loss:  0.0013394463\n",
      "Iteration:  10200 , loss:  0.0018262302\n",
      "Iteration:  10300 , loss:  0.0012867489\n",
      "Iteration:  10400 , loss:  0.0012614058\n",
      "Iteration:  10500 , loss:  0.0012504347\n",
      "Iteration:  10600 , loss:  0.0012302656\n",
      "Iteration:  10700 , loss:  0.0012863185\n",
      "Iteration:  10800 , loss:  0.0011921887\n",
      "Iteration:  10900 , loss:  0.0011844165\n",
      "Iteration:  11000 , loss:  0.0011272378\n",
      "Iteration:  11100 , loss:  0.0011072042\n",
      "Iteration:  11200 , loss:  0.0010936628\n",
      "Iteration:  11300 , loss:  0.0010833956\n",
      "Iteration:  11400 , loss:  0.0019169813\n",
      "Iteration:  11500 , loss:  0.0010328522\n",
      "Iteration:  11600 , loss:  0.0010222025\n",
      "Iteration:  11700 , loss:  0.0010098002\n",
      "Iteration:  11800 , loss:  0.0009826854\n",
      "Iteration:  11900 , loss:  0.0009833517\n",
      "Iteration:  12000 , loss:  0.0009534344\n",
      "Iteration:  12100 , loss:  0.00093923724\n",
      "Iteration:  12200 , loss:  0.0009236096\n",
      "Iteration:  12300 , loss:  0.0018096493\n",
      "Iteration:  12400 , loss:  0.0008964897\n",
      "Iteration:  12500 , loss:  0.00088977\n",
      "Iteration:  12600 , loss:  0.0011585095\n",
      "Iteration:  12700 , loss:  0.0008599974\n",
      "Iteration:  12800 , loss:  0.00085193734\n",
      "Iteration:  12900 , loss:  0.0015517222\n",
      "Iteration:  13000 , loss:  0.00082708057\n",
      "Iteration:  13100 , loss:  0.0008195821\n",
      "Iteration:  13200 , loss:  0.00080647593\n",
      "Iteration:  13300 , loss:  0.0010231942\n",
      "Iteration:  13400 , loss:  0.00093110104\n",
      "Iteration:  13500 , loss:  0.0007779291\n",
      "Iteration:  13600 , loss:  0.00078315113\n",
      "Iteration:  13700 , loss:  0.00076060154\n",
      "Iteration:  13800 , loss:  0.00075201\n",
      "Iteration:  13900 , loss:  0.0008588541\n",
      "Iteration:  14000 , loss:  0.0007351351\n",
      "Iteration:  14100 , loss:  0.0007342015\n",
      "Iteration:  14200 , loss:  0.0010191662\n",
      "Iteration:  14300 , loss:  0.0008981817\n",
      "Iteration:  14400 , loss:  0.0011030405\n",
      "Iteration:  14500 , loss:  0.0007131192\n",
      "Iteration:  14600 , loss:  0.00069858594\n",
      "Iteration:  14700 , loss:  0.0006857702\n",
      "Iteration:  14800 , loss:  0.00068740867\n",
      "Iteration:  14900 , loss:  0.00067778036\n",
      "Iteration:  15000 , loss:  0.0009753731\n",
      "Iteration:  15100 , loss:  0.0006575631\n",
      "Iteration:  15200 , loss:  0.0006582022\n",
      "Iteration:  15300 , loss:  0.000878274\n",
      "Iteration:  15400 , loss:  0.0007781666\n",
      "Iteration:  15500 , loss:  0.0006335965\n",
      "Iteration:  15600 , loss:  0.00062901666\n",
      "Iteration:  15700 , loss:  0.000625159\n",
      "Iteration:  15800 , loss:  0.00068434037\n",
      "Iteration:  15900 , loss:  0.0008630769\n",
      "Iteration:  16000 , loss:  0.0007373044\n",
      "Iteration:  16100 , loss:  0.0011341677\n",
      "Iteration:  16200 , loss:  0.0005950837\n",
      "Iteration:  16300 , loss:  0.00059027714\n",
      "Iteration:  16400 , loss:  0.00059248006\n",
      "Iteration:  16500 , loss:  0.0005798843\n",
      "Iteration:  16600 , loss:  0.0005760009\n",
      "Iteration:  16700 , loss:  0.0006073412\n",
      "Iteration:  16800 , loss:  0.0005703122\n",
      "Iteration:  16900 , loss:  0.00056238\n",
      "Iteration:  17000 , loss:  0.00055548025\n",
      "Iteration:  17100 , loss:  0.0005512021\n",
      "Iteration:  17200 , loss:  0.0005467529\n",
      "Iteration:  17300 , loss:  0.00056734774\n",
      "Iteration:  17400 , loss:  0.0005400413\n",
      "Iteration:  17500 , loss:  0.00054135994\n",
      "Iteration:  17600 , loss:  0.0005323195\n",
      "Iteration:  17700 , loss:  0.0005303052\n",
      "Iteration:  17800 , loss:  0.00052164204\n",
      "Iteration:  17900 , loss:  0.0008265093\n",
      "Iteration:  18000 , loss:  0.0005135012\n",
      "Iteration:  18100 , loss:  0.00069924083\n",
      "Iteration:  18200 , loss:  0.000662077\n",
      "Iteration:  18300 , loss:  0.00050569297\n",
      "Iteration:  18400 , loss:  0.0005037676\n",
      "Iteration:  18500 , loss:  0.0008657966\n",
      "Iteration:  18600 , loss:  0.0006747731\n",
      "Iteration:  18700 , loss:  0.00048634212\n",
      "Iteration:  18800 , loss:  0.0004786242\n",
      "Iteration:  18900 , loss:  0.00047641102\n",
      "Iteration:  19000 , loss:  0.00054710184\n",
      "Iteration:  19100 , loss:  0.0005508303\n",
      "Iteration:  19200 , loss:  0.00046388683\n",
      "Iteration:  19300 , loss:  0.00046061308\n",
      "Iteration:  19400 , loss:  0.00045624445\n",
      "Iteration:  19500 , loss:  0.000452667\n",
      "Iteration:  19600 , loss:  0.00044893567\n",
      "Iteration:  19700 , loss:  0.00044696144\n",
      "Iteration:  19800 , loss:  0.0009621526\n",
      "Iteration:  19900 , loss:  0.0004380989\n",
      "Generating 6th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.12630811\n",
      "Iteration:  100 , loss:  0.038432766\n",
      "Iteration:  200 , loss:  0.025378551\n",
      "Iteration:  300 , loss:  0.023274958\n",
      "Iteration:  400 , loss:  0.022210654\n",
      "Iteration:  500 , loss:  0.021453943\n",
      "Iteration:  600 , loss:  0.020818438\n",
      "Iteration:  700 , loss:  0.020234276\n",
      "Iteration:  800 , loss:  0.01960646\n",
      "Iteration:  900 , loss:  0.018821867\n",
      "Iteration:  1000 , loss:  0.018172724\n",
      "Iteration:  1100 , loss:  0.017665949\n",
      "Iteration:  1200 , loss:  0.017131431\n",
      "Iteration:  1300 , loss:  0.016477924\n",
      "Iteration:  1400 , loss:  0.015657647\n",
      "Iteration:  1500 , loss:  0.014569008\n",
      "Iteration:  1600 , loss:  0.013723444\n",
      "Iteration:  1700 , loss:  0.0130740525\n",
      "Iteration:  1800 , loss:  0.012607746\n",
      "Iteration:  1900 , loss:  0.012221923\n",
      "Iteration:  2000 , loss:  0.011847264\n",
      "Iteration:  2100 , loss:  0.011544261\n",
      "Iteration:  2200 , loss:  0.011268912\n",
      "Iteration:  2300 , loss:  0.011030877\n",
      "Iteration:  2400 , loss:  0.010808185\n",
      "Iteration:  2500 , loss:  0.010606193\n",
      "Iteration:  2600 , loss:  0.01040831\n",
      "Iteration:  2700 , loss:  0.010218748\n",
      "Iteration:  2800 , loss:  0.010027628\n",
      "Iteration:  2900 , loss:  0.0098336665\n",
      "Iteration:  3000 , loss:  0.00964524\n",
      "Iteration:  3100 , loss:  0.009442097\n",
      "Iteration:  3200 , loss:  0.00920877\n",
      "Iteration:  3300 , loss:  0.008964646\n",
      "Iteration:  3400 , loss:  0.008635145\n",
      "Iteration:  3500 , loss:  0.0083021745\n",
      "Iteration:  3600 , loss:  0.008078644\n",
      "Iteration:  3700 , loss:  0.007759065\n",
      "Iteration:  3800 , loss:  0.0076723467\n",
      "Iteration:  3900 , loss:  0.0073860986\n",
      "Iteration:  4000 , loss:  0.0072309\n",
      "Iteration:  4100 , loss:  0.007103729\n",
      "Iteration:  4200 , loss:  0.0069575245\n",
      "Iteration:  4300 , loss:  0.0068350607\n",
      "Iteration:  4400 , loss:  0.006712724\n",
      "Iteration:  4500 , loss:  0.006598281\n",
      "Iteration:  4600 , loss:  0.006480155\n",
      "Iteration:  4700 , loss:  0.0063728346\n",
      "Iteration:  4800 , loss:  0.0062649203\n",
      "Iteration:  4900 , loss:  0.0061594993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5000 , loss:  0.006059157\n",
      "Iteration:  5100 , loss:  0.0059461463\n",
      "Iteration:  5200 , loss:  0.005828434\n",
      "Iteration:  5300 , loss:  0.00573937\n",
      "Iteration:  5400 , loss:  0.0056541273\n",
      "Iteration:  5500 , loss:  0.005567756\n",
      "Iteration:  5600 , loss:  0.0054872325\n",
      "Iteration:  5700 , loss:  0.0054018972\n",
      "Iteration:  5800 , loss:  0.0055476427\n",
      "Iteration:  5900 , loss:  0.00523521\n",
      "Iteration:  6000 , loss:  0.0051509584\n",
      "Iteration:  6100 , loss:  0.00530416\n",
      "Iteration:  6200 , loss:  0.004977551\n",
      "Iteration:  6300 , loss:  0.0048824945\n",
      "Iteration:  6400 , loss:  0.004789302\n",
      "Iteration:  6500 , loss:  0.0046771867\n",
      "Iteration:  6600 , loss:  0.004558361\n",
      "Iteration:  6700 , loss:  0.004440368\n",
      "Iteration:  6800 , loss:  0.0043149507\n",
      "Iteration:  6900 , loss:  0.0042047095\n",
      "Iteration:  7000 , loss:  0.004069228\n",
      "Iteration:  7100 , loss:  0.003943564\n",
      "Iteration:  7200 , loss:  0.0038288927\n",
      "Iteration:  7300 , loss:  0.0037092636\n",
      "Iteration:  7400 , loss:  0.0036242125\n",
      "Iteration:  7500 , loss:  0.0034723475\n",
      "Iteration:  7600 , loss:  0.0033467964\n",
      "Iteration:  7700 , loss:  0.0032275296\n",
      "Iteration:  7800 , loss:  0.003108017\n",
      "Iteration:  7900 , loss:  0.003075198\n",
      "Iteration:  8000 , loss:  0.0028960265\n",
      "Iteration:  8100 , loss:  0.0028006467\n",
      "Iteration:  8200 , loss:  0.0027192081\n",
      "Iteration:  8300 , loss:  0.0026370117\n",
      "Iteration:  8400 , loss:  0.003675023\n",
      "Iteration:  8500 , loss:  0.0024831092\n",
      "Iteration:  8600 , loss:  0.0024085355\n",
      "Iteration:  8700 , loss:  0.0023427745\n",
      "Iteration:  8800 , loss:  0.0022738313\n",
      "Iteration:  8900 , loss:  0.0028500708\n",
      "Iteration:  9000 , loss:  0.002149478\n",
      "Iteration:  9100 , loss:  0.0021137905\n",
      "Iteration:  9200 , loss:  0.00203665\n",
      "Iteration:  9300 , loss:  0.0019817255\n",
      "Iteration:  9400 , loss:  0.001933189\n",
      "Iteration:  9500 , loss:  0.0018834084\n",
      "Iteration:  9600 , loss:  0.0018379961\n",
      "Iteration:  9700 , loss:  0.0017918395\n",
      "Iteration:  9800 , loss:  0.001756103\n",
      "Iteration:  9900 , loss:  0.0017088582\n",
      "Iteration:  10000 , loss:  0.0024956134\n",
      "Iteration:  10100 , loss:  0.0016316992\n",
      "Iteration:  10200 , loss:  0.0015939358\n",
      "Iteration:  10300 , loss:  0.0015618756\n",
      "Iteration:  10400 , loss:  0.0016279898\n",
      "Iteration:  10500 , loss:  0.0014927278\n",
      "Iteration:  10600 , loss:  0.001478357\n",
      "Iteration:  10700 , loss:  0.0014306571\n",
      "Iteration:  10800 , loss:  0.0014064728\n",
      "Iteration:  10900 , loss:  0.0014162575\n",
      "Iteration:  11000 , loss:  0.0013519458\n",
      "Iteration:  11100 , loss:  0.0013202368\n",
      "Iteration:  11200 , loss:  0.001304497\n",
      "Iteration:  11300 , loss:  0.0015312776\n",
      "Iteration:  11400 , loss:  0.0012466357\n",
      "Iteration:  11500 , loss:  0.0012282568\n",
      "Iteration:  11600 , loss:  0.0015966882\n",
      "Iteration:  11700 , loss:  0.0011799161\n",
      "Iteration:  11800 , loss:  0.0011709122\n",
      "Iteration:  11900 , loss:  0.0011378082\n",
      "Iteration:  12000 , loss:  0.0011217414\n",
      "Iteration:  12100 , loss:  0.0011031982\n",
      "Iteration:  12200 , loss:  0.0010932174\n",
      "Iteration:  12300 , loss:  0.001059355\n",
      "Iteration:  12400 , loss:  0.001041826\n",
      "Iteration:  12500 , loss:  0.0010222767\n",
      "Iteration:  12600 , loss:  0.0010965165\n",
      "Iteration:  12700 , loss:  0.000988519\n",
      "Iteration:  12800 , loss:  0.0009754248\n",
      "Iteration:  12900 , loss:  0.0009522609\n",
      "Iteration:  13000 , loss:  0.0009344664\n",
      "Iteration:  13100 , loss:  0.0009484944\n",
      "Iteration:  13200 , loss:  0.00090225716\n",
      "Iteration:  13300 , loss:  0.000888377\n",
      "Iteration:  13400 , loss:  0.00090771914\n",
      "Iteration:  13500 , loss:  0.0008577696\n",
      "Iteration:  13600 , loss:  0.0009108431\n",
      "Iteration:  13700 , loss:  0.0008251304\n",
      "Iteration:  13800 , loss:  0.0008186543\n",
      "Iteration:  13900 , loss:  0.00079669454\n",
      "Iteration:  14000 , loss:  0.00079474546\n",
      "Iteration:  14100 , loss:  0.00087555556\n",
      "Iteration:  14200 , loss:  0.00076578744\n",
      "Iteration:  14300 , loss:  0.00074804144\n",
      "Iteration:  14400 , loss:  0.0007429445\n",
      "Iteration:  14500 , loss:  0.00071843737\n",
      "Iteration:  14600 , loss:  0.0007739759\n",
      "Iteration:  14700 , loss:  0.0006920957\n",
      "Iteration:  14800 , loss:  0.0006809422\n",
      "Iteration:  14900 , loss:  0.00072732836\n",
      "Iteration:  15000 , loss:  0.0010738818\n",
      "Iteration:  15100 , loss:  0.00064603443\n",
      "Iteration:  15200 , loss:  0.00063798355\n",
      "Iteration:  15300 , loss:  0.0006538489\n",
      "Iteration:  15400 , loss:  0.0007053114\n",
      "Iteration:  15500 , loss:  0.0006038405\n",
      "Iteration:  15600 , loss:  0.0006504233\n",
      "Iteration:  15700 , loss:  0.0011606517\n",
      "Iteration:  15800 , loss:  0.00057537155\n",
      "Iteration:  15900 , loss:  0.00056512415\n",
      "Iteration:  16000 , loss:  0.00055695965\n",
      "Iteration:  16100 , loss:  0.0012814619\n",
      "Iteration:  16200 , loss:  0.00054332253\n",
      "Iteration:  16300 , loss:  0.0005349639\n",
      "Iteration:  16400 , loss:  0.0011355814\n",
      "Iteration:  16500 , loss:  0.0011382182\n",
      "Iteration:  16600 , loss:  0.0005048012\n",
      "Iteration:  16700 , loss:  0.00049740326\n",
      "Iteration:  16800 , loss:  0.00049316714\n",
      "Iteration:  16900 , loss:  0.00049388694\n",
      "Iteration:  17000 , loss:  0.0004746031\n",
      "Iteration:  17100 , loss:  0.00052442023\n",
      "Iteration:  17200 , loss:  0.00073915627\n",
      "Iteration:  17300 , loss:  0.00045469857\n",
      "Iteration:  17400 , loss:  0.00044813185\n",
      "Iteration:  17500 , loss:  0.0004419636\n",
      "Iteration:  17600 , loss:  0.00043546798\n",
      "Iteration:  17700 , loss:  0.00046563815\n",
      "Iteration:  17800 , loss:  0.00042570784\n",
      "Iteration:  17900 , loss:  0.0006524065\n",
      "Iteration:  18000 , loss:  0.00041659572\n",
      "Iteration:  18100 , loss:  0.0011747044\n",
      "Iteration:  18200 , loss:  0.00040207675\n",
      "Iteration:  18300 , loss:  0.0005285969\n",
      "Iteration:  18400 , loss:  0.00042683195\n",
      "Iteration:  18500 , loss:  0.00038759157\n",
      "Iteration:  18600 , loss:  0.00038457007\n",
      "Iteration:  18700 , loss:  0.00037947792\n",
      "Iteration:  18800 , loss:  0.00048240914\n",
      "Iteration:  18900 , loss:  0.00037017046\n",
      "Iteration:  19000 , loss:  0.00037651908\n",
      "Iteration:  19100 , loss:  0.00038379873\n",
      "Iteration:  19200 , loss:  0.0006156693\n",
      "Iteration:  19300 , loss:  0.0003543183\n",
      "Iteration:  19400 , loss:  0.000803776\n",
      "Iteration:  19500 , loss:  0.0003545782\n",
      "Iteration:  19600 , loss:  0.00034328524\n",
      "Iteration:  19700 , loss:  0.00036212293\n",
      "Iteration:  19800 , loss:  0.0003914364\n",
      "Iteration:  19900 , loss:  0.0003328251\n",
      "Generating 7th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.5724067\n",
      "Iteration:  100 , loss:  0.0584784\n",
      "Iteration:  200 , loss:  0.038122095\n",
      "Iteration:  300 , loss:  0.032057535\n",
      "Iteration:  400 , loss:  0.028963318\n",
      "Iteration:  500 , loss:  0.026632104\n",
      "Iteration:  600 , loss:  0.024845535\n",
      "Iteration:  700 , loss:  0.023185767\n",
      "Iteration:  800 , loss:  0.021448607\n",
      "Iteration:  900 , loss:  0.020671088\n",
      "Iteration:  1000 , loss:  0.020437539\n",
      "Iteration:  1100 , loss:  0.020238373\n",
      "Iteration:  1200 , loss:  0.020042779\n",
      "Iteration:  1300 , loss:  0.019844972\n",
      "Iteration:  1400 , loss:  0.019640781\n",
      "Iteration:  1500 , loss:  0.019426547\n",
      "Iteration:  1600 , loss:  0.019198846\n",
      "Iteration:  1700 , loss:  0.018954823\n",
      "Iteration:  1800 , loss:  0.018692795\n",
      "Iteration:  1900 , loss:  0.01841321\n",
      "Iteration:  2000 , loss:  0.018120073\n",
      "Iteration:  2100 , loss:  0.017821983\n",
      "Iteration:  2200 , loss:  0.017529959\n",
      "Iteration:  2300 , loss:  0.017249372\n",
      "Iteration:  2400 , loss:  0.016972318\n",
      "Iteration:  2500 , loss:  0.016682182\n",
      "Iteration:  2600 , loss:  0.016362447\n",
      "Iteration:  2700 , loss:  0.016012467\n",
      "Iteration:  2800 , loss:  0.015652712\n",
      "Iteration:  2900 , loss:  0.01530457\n",
      "Iteration:  3000 , loss:  0.014975142\n",
      "Iteration:  3100 , loss:  0.014660953\n",
      "Iteration:  3200 , loss:  0.014386317\n",
      "Iteration:  3300 , loss:  0.014059644\n",
      "Iteration:  3400 , loss:  0.013786579\n",
      "Iteration:  3500 , loss:  0.013535079\n",
      "Iteration:  3600 , loss:  0.013302369\n",
      "Iteration:  3700 , loss:  0.013085714\n",
      "Iteration:  3800 , loss:  0.01288164\n",
      "Iteration:  3900 , loss:  0.012717213\n",
      "Iteration:  4000 , loss:  0.0125124\n",
      "Iteration:  4100 , loss:  0.012338653\n",
      "Iteration:  4200 , loss:  0.012175868\n",
      "Iteration:  4300 , loss:  0.012605818\n",
      "Iteration:  4400 , loss:  0.011866583\n",
      "Iteration:  4500 , loss:  0.011723395\n",
      "Iteration:  4600 , loss:  0.011571692\n",
      "Iteration:  4700 , loss:  0.011431057\n",
      "Iteration:  4800 , loss:  0.011285065\n",
      "Iteration:  4900 , loss:  0.011143837\n",
      "Iteration:  5000 , loss:  0.010996454\n",
      "Iteration:  5100 , loss:  0.01085151\n",
      "Iteration:  5200 , loss:  0.010700518\n",
      "Iteration:  5300 , loss:  0.010703872\n",
      "Iteration:  5400 , loss:  0.0103853755\n",
      "Iteration:  5500 , loss:  0.01021472\n",
      "Iteration:  5600 , loss:  0.010049598\n",
      "Iteration:  5700 , loss:  0.009876173\n",
      "Iteration:  5800 , loss:  0.009689132\n",
      "Iteration:  5900 , loss:  0.00950978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6000 , loss:  0.009337017\n",
      "Iteration:  6100 , loss:  0.009471865\n",
      "Iteration:  6200 , loss:  0.0090419175\n",
      "Iteration:  6300 , loss:  0.008907716\n",
      "Iteration:  6400 , loss:  0.0087890215\n",
      "Iteration:  6500 , loss:  0.008658695\n",
      "Iteration:  6600 , loss:  0.008524545\n",
      "Iteration:  6700 , loss:  0.008388726\n",
      "Iteration:  6800 , loss:  0.008247917\n",
      "Iteration:  6900 , loss:  0.008103681\n",
      "Iteration:  7000 , loss:  0.007974283\n",
      "Iteration:  7100 , loss:  0.007832085\n",
      "Iteration:  7200 , loss:  0.007692657\n",
      "Iteration:  7300 , loss:  0.0076408475\n",
      "Iteration:  7400 , loss:  0.007415048\n",
      "Iteration:  7500 , loss:  0.007283035\n",
      "Iteration:  7600 , loss:  0.00724372\n",
      "Iteration:  7700 , loss:  0.007090941\n",
      "Iteration:  7800 , loss:  0.007024632\n",
      "Iteration:  7900 , loss:  0.0070052743\n",
      "Iteration:  8000 , loss:  0.006917352\n",
      "Iteration:  8100 , loss:  0.0068669836\n",
      "Iteration:  8200 , loss:  0.007030422\n",
      "Iteration:  8300 , loss:  0.0067689223\n",
      "Iteration:  8400 , loss:  0.0067195795\n",
      "Iteration:  8500 , loss:  0.0066814637\n",
      "Iteration:  8600 , loss:  0.0066215764\n",
      "Iteration:  8700 , loss:  0.006570913\n",
      "Iteration:  8800 , loss:  0.00652121\n",
      "Iteration:  8900 , loss:  0.0064668083\n",
      "Iteration:  9000 , loss:  0.006489077\n",
      "Iteration:  9100 , loss:  0.006355489\n",
      "Iteration:  9200 , loss:  0.007362446\n",
      "Iteration:  9300 , loss:  0.0062346244\n",
      "Iteration:  9400 , loss:  0.0063548866\n",
      "Iteration:  9500 , loss:  0.006101552\n",
      "Iteration:  9600 , loss:  0.0060303644\n",
      "Iteration:  9700 , loss:  0.005957741\n",
      "Iteration:  9800 , loss:  0.0058818213\n",
      "Iteration:  9900 , loss:  0.005804946\n",
      "Iteration:  10000 , loss:  0.0057268413\n",
      "Iteration:  10100 , loss:  0.0060123643\n",
      "Iteration:  10200 , loss:  0.0055713286\n",
      "Iteration:  10300 , loss:  0.005496676\n",
      "Iteration:  10400 , loss:  0.005522235\n",
      "Iteration:  10500 , loss:  0.0053430623\n",
      "Iteration:  10600 , loss:  0.005273799\n",
      "Iteration:  10700 , loss:  0.0051950933\n",
      "Iteration:  10800 , loss:  0.005124334\n",
      "Iteration:  10900 , loss:  0.005049664\n",
      "Iteration:  11000 , loss:  0.0057102563\n",
      "Iteration:  11100 , loss:  0.0049538985\n",
      "Iteration:  11200 , loss:  0.004831739\n",
      "Iteration:  11300 , loss:  0.0048353104\n",
      "Iteration:  11400 , loss:  0.0049372427\n",
      "Iteration:  11500 , loss:  0.0047175367\n",
      "Iteration:  11600 , loss:  0.0045195213\n",
      "Iteration:  11700 , loss:  0.0044875843\n",
      "Iteration:  11800 , loss:  0.004367103\n",
      "Iteration:  11900 , loss:  0.004779436\n",
      "Iteration:  12000 , loss:  0.004213185\n",
      "Iteration:  12100 , loss:  0.004132121\n",
      "Iteration:  12200 , loss:  0.004201168\n",
      "Iteration:  12300 , loss:  0.0039908323\n",
      "Iteration:  12400 , loss:  0.0038903574\n",
      "Iteration:  12500 , loss:  0.0038100178\n",
      "Iteration:  12600 , loss:  0.0037296114\n",
      "Iteration:  12700 , loss:  0.0037078436\n",
      "Iteration:  12800 , loss:  0.0036388715\n",
      "Iteration:  12900 , loss:  0.0034908236\n",
      "Iteration:  13000 , loss:  0.0034021926\n",
      "Iteration:  13100 , loss:  0.0033158995\n",
      "Iteration:  13200 , loss:  0.0032408203\n",
      "Iteration:  13300 , loss:  0.003172785\n",
      "Iteration:  13400 , loss:  0.0030790637\n",
      "Iteration:  13500 , loss:  0.003007135\n",
      "Iteration:  13600 , loss:  0.0029342854\n",
      "Iteration:  13700 , loss:  0.0028586686\n",
      "Iteration:  13800 , loss:  0.002790819\n",
      "Iteration:  13900 , loss:  0.003166055\n",
      "Iteration:  14000 , loss:  0.002669149\n",
      "Iteration:  14100 , loss:  0.0026108678\n",
      "Iteration:  14200 , loss:  0.0028383094\n",
      "Iteration:  14300 , loss:  0.0024968544\n",
      "Iteration:  14400 , loss:  0.0024440638\n",
      "Iteration:  14500 , loss:  0.0024021121\n",
      "Iteration:  14600 , loss:  0.0023608273\n",
      "Iteration:  14700 , loss:  0.0023076604\n",
      "Iteration:  14800 , loss:  0.0022662168\n",
      "Iteration:  14900 , loss:  0.0024467935\n",
      "Iteration:  15000 , loss:  0.002213375\n",
      "Iteration:  15100 , loss:  0.0021654116\n",
      "Iteration:  15200 , loss:  0.0022004494\n",
      "Iteration:  15300 , loss:  0.002083322\n",
      "Iteration:  15400 , loss:  0.0020684728\n",
      "Iteration:  15500 , loss:  0.00202296\n",
      "Iteration:  15600 , loss:  0.0019953933\n",
      "Iteration:  15700 , loss:  0.00220786\n",
      "Iteration:  15800 , loss:  0.002361215\n",
      "Iteration:  15900 , loss:  0.0019184626\n",
      "Iteration:  16000 , loss:  0.0018884544\n",
      "Iteration:  16100 , loss:  0.0021170056\n",
      "Iteration:  16200 , loss:  0.0018413019\n",
      "Iteration:  16300 , loss:  0.0020137965\n",
      "Iteration:  16400 , loss:  0.0017978123\n",
      "Iteration:  16500 , loss:  0.0019815727\n",
      "Iteration:  16600 , loss:  0.001825917\n",
      "Iteration:  16700 , loss:  0.0017589615\n",
      "Iteration:  16800 , loss:  0.0018210558\n",
      "Iteration:  16900 , loss:  0.0017714868\n",
      "Iteration:  17000 , loss:  0.0016865007\n",
      "Iteration:  17100 , loss:  0.0018241503\n",
      "Iteration:  17200 , loss:  0.0016435371\n",
      "Iteration:  17300 , loss:  0.0016324794\n",
      "Iteration:  17400 , loss:  0.0019048161\n",
      "Iteration:  17500 , loss:  0.0016545756\n",
      "Iteration:  17600 , loss:  0.0015833009\n",
      "Iteration:  17700 , loss:  0.0019391595\n",
      "Iteration:  17800 , loss:  0.0021745304\n",
      "Iteration:  17900 , loss:  0.0016020715\n",
      "Iteration:  18000 , loss:  0.001512328\n",
      "Iteration:  18100 , loss:  0.0014884913\n",
      "Iteration:  18200 , loss:  0.0014713499\n",
      "Iteration:  18300 , loss:  0.0018114412\n",
      "Iteration:  18400 , loss:  0.0016435576\n",
      "Iteration:  18500 , loss:  0.0014311771\n",
      "Iteration:  18600 , loss:  0.0014115984\n",
      "Iteration:  18700 , loss:  0.0013969748\n",
      "Iteration:  18800 , loss:  0.0019031304\n",
      "Iteration:  18900 , loss:  0.001366498\n",
      "Iteration:  19000 , loss:  0.0013504468\n",
      "Iteration:  19100 , loss:  0.0013346281\n",
      "Iteration:  19200 , loss:  0.0013199188\n",
      "Iteration:  19300 , loss:  0.0013059559\n",
      "Iteration:  19400 , loss:  0.0013430383\n",
      "Iteration:  19500 , loss:  0.0013724251\n",
      "Iteration:  19600 , loss:  0.0013116325\n",
      "Iteration:  19700 , loss:  0.0013076724\n",
      "Iteration:  19800 , loss:  0.0012948877\n",
      "Iteration:  19900 , loss:  0.0012366631\n",
      "Generating 8th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.15139134\n",
      "Iteration:  100 , loss:  0.026814453\n",
      "Iteration:  200 , loss:  0.02342705\n",
      "Iteration:  300 , loss:  0.022123845\n",
      "Iteration:  400 , loss:  0.021064658\n",
      "Iteration:  500 , loss:  0.02016222\n",
      "Iteration:  600 , loss:  0.019370032\n",
      "Iteration:  700 , loss:  0.018592726\n",
      "Iteration:  800 , loss:  0.017225858\n",
      "Iteration:  900 , loss:  0.016324699\n",
      "Iteration:  1000 , loss:  0.015699327\n",
      "Iteration:  1100 , loss:  0.015029179\n",
      "Iteration:  1200 , loss:  0.014327152\n",
      "Iteration:  1300 , loss:  0.013580957\n",
      "Iteration:  1400 , loss:  0.012875307\n",
      "Iteration:  1500 , loss:  0.012276984\n",
      "Iteration:  1600 , loss:  0.011773346\n",
      "Iteration:  1700 , loss:  0.011339766\n",
      "Iteration:  1800 , loss:  0.010943798\n",
      "Iteration:  1900 , loss:  0.01058402\n",
      "Iteration:  2000 , loss:  0.010252141\n",
      "Iteration:  2100 , loss:  0.009950962\n",
      "Iteration:  2200 , loss:  0.009662812\n",
      "Iteration:  2300 , loss:  0.009421664\n",
      "Iteration:  2400 , loss:  0.009147536\n",
      "Iteration:  2500 , loss:  0.00890504\n",
      "Iteration:  2600 , loss:  0.008675581\n",
      "Iteration:  2700 , loss:  0.008456103\n",
      "Iteration:  2800 , loss:  0.008242439\n",
      "Iteration:  2900 , loss:  0.00804241\n",
      "Iteration:  3000 , loss:  0.007843945\n",
      "Iteration:  3100 , loss:  0.0076622837\n",
      "Iteration:  3200 , loss:  0.007457006\n",
      "Iteration:  3300 , loss:  0.0072547193\n",
      "Iteration:  3400 , loss:  0.0070562535\n",
      "Iteration:  3500 , loss:  0.006848474\n",
      "Iteration:  3600 , loss:  0.008008495\n",
      "Iteration:  3700 , loss:  0.00643073\n",
      "Iteration:  3800 , loss:  0.0062203133\n",
      "Iteration:  3900 , loss:  0.006020844\n",
      "Iteration:  4000 , loss:  0.005804392\n",
      "Iteration:  4100 , loss:  0.005618629\n",
      "Iteration:  4200 , loss:  0.005464689\n",
      "Iteration:  4300 , loss:  0.00530681\n",
      "Iteration:  4400 , loss:  0.005155433\n",
      "Iteration:  4500 , loss:  0.0050148806\n",
      "Iteration:  4600 , loss:  0.0048704618\n",
      "Iteration:  4700 , loss:  0.004752072\n",
      "Iteration:  4800 , loss:  0.004584059\n",
      "Iteration:  4900 , loss:  0.004439674\n",
      "Iteration:  5000 , loss:  0.004304791\n",
      "Iteration:  5100 , loss:  0.004168338\n",
      "Iteration:  5200 , loss:  0.004098166\n",
      "Iteration:  5300 , loss:  0.0039179022\n",
      "Iteration:  5400 , loss:  0.0037983095\n",
      "Iteration:  5500 , loss:  0.003691781\n",
      "Iteration:  5600 , loss:  0.0035876965\n",
      "Iteration:  5700 , loss:  0.003490349\n",
      "Iteration:  5800 , loss:  0.0033940773\n",
      "Iteration:  5900 , loss:  0.0033035383\n",
      "Iteration:  6000 , loss:  0.0032160066\n",
      "Iteration:  6100 , loss:  0.0033933267\n",
      "Iteration:  6200 , loss:  0.0031145774\n",
      "Iteration:  6300 , loss:  0.002984318\n",
      "Iteration:  6400 , loss:  0.002949869\n",
      "Iteration:  6500 , loss:  0.0028240718\n",
      "Iteration:  6600 , loss:  0.0028146335\n",
      "Iteration:  6700 , loss:  0.0027658306\n",
      "Iteration:  6800 , loss:  0.0025907294\n",
      "Iteration:  6900 , loss:  0.0027184663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7000 , loss:  0.0027061338\n",
      "Iteration:  7100 , loss:  0.0023781867\n",
      "Iteration:  7200 , loss:  0.0023162244\n",
      "Iteration:  7300 , loss:  0.0033742827\n",
      "Iteration:  7400 , loss:  0.0021949862\n",
      "Iteration:  7500 , loss:  0.0021391697\n",
      "Iteration:  7600 , loss:  0.0020857856\n",
      "Iteration:  7700 , loss:  0.0020437916\n",
      "Iteration:  7800 , loss:  0.0019876724\n",
      "Iteration:  7900 , loss:  0.0019486963\n",
      "Iteration:  8000 , loss:  0.00209033\n",
      "Iteration:  8100 , loss:  0.0018526528\n",
      "Iteration:  8200 , loss:  0.0018181009\n",
      "Iteration:  8300 , loss:  0.0017745938\n",
      "Iteration:  8400 , loss:  0.0017715949\n",
      "Iteration:  8500 , loss:  0.0017838676\n",
      "Iteration:  8600 , loss:  0.0016731883\n",
      "Iteration:  8700 , loss:  0.0016443453\n",
      "Iteration:  8800 , loss:  0.0016200156\n",
      "Iteration:  8900 , loss:  0.0017388857\n",
      "Iteration:  9000 , loss:  0.0018356652\n",
      "Iteration:  9100 , loss:  0.0015554426\n",
      "Iteration:  9200 , loss:  0.0015151731\n",
      "Iteration:  9300 , loss:  0.00149799\n",
      "Iteration:  9400 , loss:  0.0014704961\n",
      "Iteration:  9500 , loss:  0.001451538\n",
      "Iteration:  9600 , loss:  0.0014275692\n",
      "Iteration:  9700 , loss:  0.0014070855\n",
      "Iteration:  9800 , loss:  0.0013862158\n",
      "Iteration:  9900 , loss:  0.0014270837\n",
      "Iteration:  10000 , loss:  0.0013456406\n",
      "Iteration:  10100 , loss:  0.0013273361\n",
      "Iteration:  10200 , loss:  0.0013184643\n",
      "Iteration:  10300 , loss:  0.0012945209\n",
      "Iteration:  10400 , loss:  0.0012823897\n",
      "Iteration:  10500 , loss:  0.0013252208\n",
      "Iteration:  10600 , loss:  0.0015719242\n",
      "Iteration:  10700 , loss:  0.0013925885\n",
      "Iteration:  10800 , loss:  0.0012055511\n",
      "Iteration:  10900 , loss:  0.0011752514\n",
      "Iteration:  11000 , loss:  0.0011565036\n",
      "Iteration:  11100 , loss:  0.0011434247\n",
      "Iteration:  11200 , loss:  0.0016337733\n",
      "Iteration:  11300 , loss:  0.0011077562\n",
      "Iteration:  11400 , loss:  0.001092476\n",
      "Iteration:  11500 , loss:  0.001429362\n",
      "Iteration:  11600 , loss:  0.0010642785\n",
      "Iteration:  11700 , loss:  0.0010480961\n",
      "Iteration:  11800 , loss:  0.0010399815\n",
      "Iteration:  11900 , loss:  0.001021691\n",
      "Iteration:  12000 , loss:  0.001040682\n",
      "Iteration:  12100 , loss:  0.0010201824\n",
      "Iteration:  12200 , loss:  0.0011173626\n",
      "Iteration:  12300 , loss:  0.00096993725\n",
      "Iteration:  12400 , loss:  0.0009562199\n",
      "Iteration:  12500 , loss:  0.0009995823\n",
      "Iteration:  12600 , loss:  0.0009324201\n",
      "Iteration:  12700 , loss:  0.00092145253\n",
      "Iteration:  12800 , loss:  0.0015476107\n",
      "Iteration:  12900 , loss:  0.0008988998\n",
      "Iteration:  13000 , loss:  0.00089025125\n",
      "Iteration:  13100 , loss:  0.0010959968\n",
      "Iteration:  13200 , loss:  0.0010504258\n",
      "Iteration:  13300 , loss:  0.00085629005\n",
      "Iteration:  13400 , loss:  0.0008470261\n",
      "Iteration:  13500 , loss:  0.00087283633\n",
      "Iteration:  13600 , loss:  0.0008272759\n",
      "Iteration:  13700 , loss:  0.00081692165\n",
      "Iteration:  13800 , loss:  0.0008086188\n",
      "Iteration:  13900 , loss:  0.000799973\n",
      "Iteration:  14000 , loss:  0.0007889082\n",
      "Iteration:  14100 , loss:  0.00085798657\n",
      "Iteration:  14200 , loss:  0.0007706302\n",
      "Iteration:  14300 , loss:  0.0007847326\n",
      "Iteration:  14400 , loss:  0.00075988815\n",
      "Iteration:  14500 , loss:  0.0007444494\n",
      "Iteration:  14600 , loss:  0.00074976956\n",
      "Iteration:  14700 , loss:  0.0009179118\n",
      "Iteration:  14800 , loss:  0.00071888906\n",
      "Iteration:  14900 , loss:  0.00071824004\n",
      "Iteration:  15000 , loss:  0.0017926903\n",
      "Iteration:  15100 , loss:  0.0006948583\n",
      "Iteration:  15200 , loss:  0.0006917617\n",
      "Iteration:  15300 , loss:  0.0008373102\n",
      "Iteration:  15400 , loss:  0.00067490205\n",
      "Iteration:  15500 , loss:  0.0006638294\n",
      "Iteration:  15600 , loss:  0.0006596839\n",
      "Iteration:  15700 , loss:  0.0006533191\n",
      "Iteration:  15800 , loss:  0.0006554689\n",
      "Iteration:  15900 , loss:  0.0006341195\n",
      "Iteration:  16000 , loss:  0.0006286744\n",
      "Iteration:  16100 , loss:  0.00065750483\n",
      "Iteration:  16200 , loss:  0.0006133907\n",
      "Iteration:  16300 , loss:  0.0006076048\n",
      "Iteration:  16400 , loss:  0.00063301227\n",
      "Iteration:  16500 , loss:  0.0008234207\n",
      "Iteration:  16600 , loss:  0.000586921\n",
      "Iteration:  16700 , loss:  0.00059017906\n",
      "Iteration:  16800 , loss:  0.0005769867\n",
      "Iteration:  16900 , loss:  0.00056831725\n",
      "Iteration:  17000 , loss:  0.000562108\n",
      "Iteration:  17100 , loss:  0.0005660133\n",
      "Iteration:  17200 , loss:  0.00055027177\n",
      "Iteration:  17300 , loss:  0.0005662243\n",
      "Iteration:  17400 , loss:  0.00081959995\n",
      "Iteration:  17500 , loss:  0.0005442866\n",
      "Iteration:  17600 , loss:  0.0008887376\n",
      "Iteration:  17700 , loss:  0.0005256203\n",
      "Iteration:  17800 , loss:  0.0012741665\n",
      "Iteration:  17900 , loss:  0.0005103923\n",
      "Iteration:  18000 , loss:  0.00050594273\n",
      "Iteration:  18100 , loss:  0.0005007812\n",
      "Iteration:  18200 , loss:  0.0005042171\n",
      "Iteration:  18300 , loss:  0.0004896207\n",
      "Iteration:  18400 , loss:  0.0004851238\n",
      "Iteration:  18500 , loss:  0.00049635704\n",
      "Iteration:  18600 , loss:  0.00047535045\n",
      "Iteration:  18700 , loss:  0.00047101118\n",
      "Iteration:  18800 , loss:  0.00048298453\n",
      "Iteration:  18900 , loss:  0.0005222721\n",
      "Iteration:  19000 , loss:  0.00045709847\n",
      "Iteration:  19100 , loss:  0.0004536046\n",
      "Iteration:  19200 , loss:  0.00044975185\n",
      "Iteration:  19300 , loss:  0.00048559182\n",
      "Iteration:  19400 , loss:  0.0004704321\n",
      "Iteration:  19500 , loss:  0.00047580968\n",
      "Iteration:  19600 , loss:  0.00075095665\n",
      "Iteration:  19700 , loss:  0.0005288125\n",
      "Iteration:  19800 , loss:  0.00053627155\n",
      "Iteration:  19900 , loss:  0.00042074127\n",
      "Generating 9th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.06817409\n",
      "Iteration:  100 , loss:  0.027614417\n",
      "Iteration:  200 , loss:  0.023471808\n",
      "Iteration:  300 , loss:  0.022104926\n",
      "Iteration:  400 , loss:  0.021097986\n",
      "Iteration:  500 , loss:  0.020141859\n",
      "Iteration:  600 , loss:  0.01902571\n",
      "Iteration:  700 , loss:  0.017689243\n",
      "Iteration:  800 , loss:  0.016422374\n",
      "Iteration:  900 , loss:  0.015063655\n",
      "Iteration:  1000 , loss:  0.0142668355\n",
      "Iteration:  1100 , loss:  0.013725556\n",
      "Iteration:  1200 , loss:  0.013511794\n",
      "Iteration:  1300 , loss:  0.012775909\n",
      "Iteration:  1400 , loss:  0.012378393\n",
      "Iteration:  1500 , loss:  0.011987444\n",
      "Iteration:  1600 , loss:  0.011632318\n",
      "Iteration:  1700 , loss:  0.011291931\n",
      "Iteration:  1800 , loss:  0.01098069\n",
      "Iteration:  1900 , loss:  0.01067132\n",
      "Iteration:  2000 , loss:  0.010374883\n",
      "Iteration:  2100 , loss:  0.010063381\n",
      "Iteration:  2200 , loss:  0.009752457\n",
      "Iteration:  2300 , loss:  0.009461239\n",
      "Iteration:  2400 , loss:  0.0093387\n",
      "Iteration:  2500 , loss:  0.008943484\n",
      "Iteration:  2600 , loss:  0.008682112\n",
      "Iteration:  2700 , loss:  0.00842468\n",
      "Iteration:  2800 , loss:  0.008157244\n",
      "Iteration:  2900 , loss:  0.007875634\n",
      "Iteration:  3000 , loss:  0.0076032653\n",
      "Iteration:  3100 , loss:  0.0073243687\n",
      "Iteration:  3200 , loss:  0.007068346\n",
      "Iteration:  3300 , loss:  0.0069608777\n",
      "Iteration:  3400 , loss:  0.006618521\n",
      "Iteration:  3500 , loss:  0.0064214664\n",
      "Iteration:  3600 , loss:  0.0062070284\n",
      "Iteration:  3700 , loss:  0.0060355556\n",
      "Iteration:  3800 , loss:  0.005833641\n",
      "Iteration:  3900 , loss:  0.0056546363\n",
      "Iteration:  4000 , loss:  0.0054918174\n",
      "Iteration:  4100 , loss:  0.005329512\n",
      "Iteration:  4200 , loss:  0.0051696575\n",
      "Iteration:  4300 , loss:  0.00503052\n",
      "Iteration:  4400 , loss:  0.00489384\n",
      "Iteration:  4500 , loss:  0.005339096\n",
      "Iteration:  4600 , loss:  0.004643918\n",
      "Iteration:  4700 , loss:  0.0045274156\n",
      "Iteration:  4800 , loss:  0.004414952\n",
      "Iteration:  4900 , loss:  0.004312297\n",
      "Iteration:  5000 , loss:  0.0041999384\n",
      "Iteration:  5100 , loss:  0.004401099\n",
      "Iteration:  5200 , loss:  0.004066826\n",
      "Iteration:  5300 , loss:  0.003923782\n",
      "Iteration:  5400 , loss:  0.0038053954\n",
      "Iteration:  5500 , loss:  0.0037253085\n",
      "Iteration:  5600 , loss:  0.0036729877\n",
      "Iteration:  5700 , loss:  0.0035811667\n",
      "Iteration:  5800 , loss:  0.003517208\n",
      "Iteration:  5900 , loss:  0.0036457917\n",
      "Iteration:  6000 , loss:  0.0033887\n",
      "Iteration:  6100 , loss:  0.0033695581\n",
      "Iteration:  6200 , loss:  0.003263152\n",
      "Iteration:  6300 , loss:  0.0031998989\n",
      "Iteration:  6400 , loss:  0.003129581\n",
      "Iteration:  6500 , loss:  0.003057788\n",
      "Iteration:  6600 , loss:  0.0044312347\n",
      "Iteration:  6700 , loss:  0.002908298\n",
      "Iteration:  6800 , loss:  0.0028351175\n",
      "Iteration:  6900 , loss:  0.0027670888\n",
      "Iteration:  7000 , loss:  0.0026991554\n",
      "Iteration:  7100 , loss:  0.00264074\n",
      "Iteration:  7200 , loss:  0.0025735034\n",
      "Iteration:  7300 , loss:  0.00251246\n",
      "Iteration:  7400 , loss:  0.0024560015\n",
      "Iteration:  7500 , loss:  0.0024145048\n",
      "Iteration:  7600 , loss:  0.0023481187\n",
      "Iteration:  7700 , loss:  0.0023046243\n",
      "Iteration:  7800 , loss:  0.0022481545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7900 , loss:  0.0022154255\n",
      "Iteration:  8000 , loss:  0.0021568504\n",
      "Iteration:  8100 , loss:  0.0021356656\n",
      "Iteration:  8200 , loss:  0.0020731443\n",
      "Iteration:  8300 , loss:  0.0020428395\n",
      "Iteration:  8400 , loss:  0.0019963477\n",
      "Iteration:  8500 , loss:  0.0019585679\n",
      "Iteration:  8600 , loss:  0.0019259148\n",
      "Iteration:  8700 , loss:  0.0018917423\n",
      "Iteration:  8800 , loss:  0.0020452833\n",
      "Iteration:  8900 , loss:  0.0018272072\n",
      "Iteration:  9000 , loss:  0.0017952838\n",
      "Iteration:  9100 , loss:  0.0017676849\n",
      "Iteration:  9200 , loss:  0.0017371115\n",
      "Iteration:  9300 , loss:  0.0018888741\n",
      "Iteration:  9400 , loss:  0.0016818001\n",
      "Iteration:  9500 , loss:  0.002712031\n",
      "Iteration:  9600 , loss:  0.0016299776\n",
      "Iteration:  9700 , loss:  0.0016037311\n",
      "Iteration:  9800 , loss:  0.0015831861\n",
      "Iteration:  9900 , loss:  0.0015566536\n",
      "Iteration:  10000 , loss:  0.0015441115\n",
      "Iteration:  10100 , loss:  0.0015127391\n",
      "Iteration:  10200 , loss:  0.0021522902\n",
      "Iteration:  10300 , loss:  0.0014706437\n",
      "Iteration:  10400 , loss:  0.0014492446\n",
      "Iteration:  10500 , loss:  0.0014301123\n",
      "Iteration:  10600 , loss:  0.0015226912\n",
      "Iteration:  10700 , loss:  0.0013918485\n",
      "Iteration:  10800 , loss:  0.0013756062\n",
      "Iteration:  10900 , loss:  0.0015370862\n",
      "Iteration:  11000 , loss:  0.0013393429\n",
      "Iteration:  11100 , loss:  0.0013346527\n",
      "Iteration:  11200 , loss:  0.0013075348\n",
      "Iteration:  11300 , loss:  0.0012969865\n",
      "Iteration:  11400 , loss:  0.0012782463\n",
      "Iteration:  11500 , loss:  0.0014333585\n",
      "Iteration:  11600 , loss:  0.001277002\n",
      "Iteration:  11700 , loss:  0.0012358684\n",
      "Iteration:  11800 , loss:  0.0012561036\n",
      "Iteration:  11900 , loss:  0.0012152842\n",
      "Iteration:  12000 , loss:  0.0011974676\n",
      "Iteration:  12100 , loss:  0.0011843459\n",
      "Iteration:  12200 , loss:  0.0011814175\n",
      "Iteration:  12300 , loss:  0.0011760178\n",
      "Iteration:  12400 , loss:  0.0011632555\n",
      "Iteration:  12500 , loss:  0.001137219\n",
      "Iteration:  12600 , loss:  0.0011295518\n",
      "Iteration:  12700 , loss:  0.0011186628\n",
      "Iteration:  12800 , loss:  0.0011056449\n",
      "Iteration:  12900 , loss:  0.0010942197\n",
      "Iteration:  13000 , loss:  0.0011669017\n",
      "Iteration:  13100 , loss:  0.0010725927\n",
      "Iteration:  13200 , loss:  0.00108174\n",
      "Iteration:  13300 , loss:  0.0010516252\n",
      "Iteration:  13400 , loss:  0.0012153107\n",
      "Iteration:  13500 , loss:  0.0010340485\n",
      "Iteration:  13600 , loss:  0.001081768\n",
      "Iteration:  13700 , loss:  0.0018973954\n",
      "Iteration:  13800 , loss:  0.0010004686\n",
      "Iteration:  13900 , loss:  0.0009921837\n",
      "Iteration:  14000 , loss:  0.0023440362\n",
      "Iteration:  14100 , loss:  0.0009704374\n",
      "Iteration:  14200 , loss:  0.0010270767\n",
      "Iteration:  14300 , loss:  0.0011641971\n",
      "Iteration:  14400 , loss:  0.0009407331\n",
      "Iteration:  14500 , loss:  0.00096671376\n",
      "Iteration:  14600 , loss:  0.0009213299\n",
      "Iteration:  14700 , loss:  0.00094179565\n",
      "Iteration:  14800 , loss:  0.0010499761\n",
      "Iteration:  14900 , loss:  0.0008928318\n",
      "Iteration:  15000 , loss:  0.00090572913\n",
      "Iteration:  15100 , loss:  0.0008739078\n",
      "Iteration:  15200 , loss:  0.00086944835\n",
      "Iteration:  15300 , loss:  0.00085547206\n",
      "Iteration:  15400 , loss:  0.0008502741\n",
      "Iteration:  15500 , loss:  0.00083708233\n",
      "Iteration:  15600 , loss:  0.0008292202\n",
      "Iteration:  15700 , loss:  0.000937994\n",
      "Iteration:  15800 , loss:  0.00081006106\n",
      "Iteration:  15900 , loss:  0.000979793\n",
      "Iteration:  16000 , loss:  0.0007927793\n",
      "Iteration:  16100 , loss:  0.00078442873\n",
      "Iteration:  16200 , loss:  0.00090420217\n",
      "Iteration:  16300 , loss:  0.0007672105\n",
      "Iteration:  16400 , loss:  0.00079634215\n",
      "Iteration:  16500 , loss:  0.000782791\n",
      "Iteration:  16600 , loss:  0.0015160334\n",
      "Iteration:  16700 , loss:  0.00073446333\n",
      "Iteration:  16800 , loss:  0.0007368497\n",
      "Iteration:  16900 , loss:  0.0007780156\n",
      "Iteration:  17000 , loss:  0.00071257935\n",
      "Iteration:  17100 , loss:  0.0007028775\n",
      "Iteration:  17200 , loss:  0.0006998692\n",
      "Iteration:  17300 , loss:  0.0006880668\n",
      "Iteration:  17400 , loss:  0.0006802396\n",
      "Iteration:  17500 , loss:  0.0010673134\n",
      "Iteration:  17600 , loss:  0.00066667143\n",
      "Iteration:  17700 , loss:  0.0006591185\n",
      "Iteration:  17800 , loss:  0.0006610169\n",
      "Iteration:  17900 , loss:  0.00064453506\n",
      "Iteration:  18000 , loss:  0.0006387012\n",
      "Iteration:  18100 , loss:  0.000966097\n",
      "Iteration:  18200 , loss:  0.0006311489\n",
      "Iteration:  18300 , loss:  0.0006263858\n",
      "Iteration:  18400 , loss:  0.00085820945\n",
      "Iteration:  18500 , loss:  0.0006056596\n",
      "Iteration:  18600 , loss:  0.00060696324\n",
      "Iteration:  18700 , loss:  0.00069119903\n",
      "Iteration:  18800 , loss:  0.0005906899\n",
      "Iteration:  18900 , loss:  0.00058156054\n",
      "Iteration:  19000 , loss:  0.00057911326\n",
      "Iteration:  19100 , loss:  0.0006833039\n",
      "Iteration:  19200 , loss:  0.00056838617\n",
      "Iteration:  19300 , loss:  0.00069840945\n",
      "Iteration:  19400 , loss:  0.0006000638\n",
      "Iteration:  19500 , loss:  0.0005606002\n",
      "Iteration:  19600 , loss:  0.0006994251\n",
      "Iteration:  19700 , loss:  0.00056118524\n",
      "Iteration:  19800 , loss:  0.0005321974\n",
      "Iteration:  19900 , loss:  0.00065484946\n",
      "Generating 10th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.075178765\n",
      "Iteration:  100 , loss:  0.024704259\n",
      "Iteration:  200 , loss:  0.022414451\n",
      "Iteration:  300 , loss:  0.021285664\n",
      "Iteration:  400 , loss:  0.020371515\n",
      "Iteration:  500 , loss:  0.019511582\n",
      "Iteration:  600 , loss:  0.018668758\n",
      "Iteration:  700 , loss:  0.017723108\n",
      "Iteration:  800 , loss:  0.016528975\n",
      "Iteration:  900 , loss:  0.015337251\n",
      "Iteration:  1000 , loss:  0.014457838\n",
      "Iteration:  1100 , loss:  0.013839386\n",
      "Iteration:  1200 , loss:  0.013383299\n",
      "Iteration:  1300 , loss:  0.012960538\n",
      "Iteration:  1400 , loss:  0.01251938\n",
      "Iteration:  1500 , loss:  0.012110352\n",
      "Iteration:  1600 , loss:  0.011686669\n",
      "Iteration:  1700 , loss:  0.011275952\n",
      "Iteration:  1800 , loss:  0.010915496\n",
      "Iteration:  1900 , loss:  0.010650059\n",
      "Iteration:  2000 , loss:  0.01041425\n",
      "Iteration:  2100 , loss:  0.010195129\n",
      "Iteration:  2200 , loss:  0.00997258\n",
      "Iteration:  2300 , loss:  0.009734112\n",
      "Iteration:  2400 , loss:  0.009512621\n",
      "Iteration:  2500 , loss:  0.009279869\n",
      "Iteration:  2600 , loss:  0.00903718\n",
      "Iteration:  2700 , loss:  0.008812353\n",
      "Iteration:  2800 , loss:  0.008570653\n",
      "Iteration:  2900 , loss:  0.008295687\n",
      "Iteration:  3000 , loss:  0.008016171\n",
      "Iteration:  3100 , loss:  0.007742061\n",
      "Iteration:  3200 , loss:  0.0074990033\n",
      "Iteration:  3300 , loss:  0.007263841\n",
      "Iteration:  3400 , loss:  0.007053029\n",
      "Iteration:  3500 , loss:  0.006868914\n",
      "Iteration:  3600 , loss:  0.0066820565\n",
      "Iteration:  3700 , loss:  0.006496164\n",
      "Iteration:  3800 , loss:  0.006319646\n",
      "Iteration:  3900 , loss:  0.006138291\n",
      "Iteration:  4000 , loss:  0.0059560686\n",
      "Iteration:  4100 , loss:  0.005793214\n",
      "Iteration:  4200 , loss:  0.0056428136\n",
      "Iteration:  4300 , loss:  0.0055141104\n",
      "Iteration:  4400 , loss:  0.0053902725\n",
      "Iteration:  4500 , loss:  0.0052806195\n",
      "Iteration:  4600 , loss:  0.0051830555\n",
      "Iteration:  4700 , loss:  0.0050910516\n",
      "Iteration:  4800 , loss:  0.0049991426\n",
      "Iteration:  4900 , loss:  0.0049728225\n",
      "Iteration:  5000 , loss:  0.0048373854\n",
      "Iteration:  5100 , loss:  0.0047792033\n",
      "Iteration:  5200 , loss:  0.004689754\n",
      "Iteration:  5300 , loss:  0.0046197698\n",
      "Iteration:  5400 , loss:  0.005020355\n",
      "Iteration:  5500 , loss:  0.004489578\n",
      "Iteration:  5600 , loss:  0.0044283504\n",
      "Iteration:  5700 , loss:  0.0043661646\n",
      "Iteration:  5800 , loss:  0.0043220036\n",
      "Iteration:  5900 , loss:  0.005256151\n",
      "Iteration:  6000 , loss:  0.0041892314\n",
      "Iteration:  6100 , loss:  0.00415817\n",
      "Iteration:  6200 , loss:  0.004130078\n",
      "Iteration:  6300 , loss:  0.004266764\n",
      "Iteration:  6400 , loss:  0.003948898\n",
      "Iteration:  6500 , loss:  0.003886858\n",
      "Iteration:  6600 , loss:  0.0038246738\n",
      "Iteration:  6700 , loss:  0.003797126\n",
      "Iteration:  6800 , loss:  0.0038321894\n",
      "Iteration:  6900 , loss:  0.0036301734\n",
      "Iteration:  7000 , loss:  0.003566323\n",
      "Iteration:  7100 , loss:  0.0045202347\n",
      "Iteration:  7200 , loss:  0.0034312857\n",
      "Iteration:  7300 , loss:  0.00343147\n",
      "Iteration:  7400 , loss:  0.0032958104\n",
      "Iteration:  7500 , loss:  0.0032285908\n",
      "Iteration:  7600 , loss:  0.0031617382\n",
      "Iteration:  7700 , loss:  0.003106363\n",
      "Iteration:  7800 , loss:  0.0030329865\n",
      "Iteration:  7900 , loss:  0.002971687\n",
      "Iteration:  8000 , loss:  0.00291131\n",
      "Iteration:  8100 , loss:  0.002907185\n",
      "Iteration:  8200 , loss:  0.0027944325\n",
      "Iteration:  8300 , loss:  0.0027393221\n",
      "Iteration:  8400 , loss:  0.0026831806\n",
      "Iteration:  8500 , loss:  0.0026312992\n",
      "Iteration:  8600 , loss:  0.0026497853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  8700 , loss:  0.0025290484\n",
      "Iteration:  8800 , loss:  0.0024828368\n",
      "Iteration:  8900 , loss:  0.002432134\n",
      "Iteration:  9000 , loss:  0.00238644\n",
      "Iteration:  9100 , loss:  0.0023410085\n",
      "Iteration:  9200 , loss:  0.0022946424\n",
      "Iteration:  9300 , loss:  0.0022568656\n",
      "Iteration:  9400 , loss:  0.0023585414\n",
      "Iteration:  9500 , loss:  0.0021633827\n",
      "Iteration:  9600 , loss:  0.00215575\n",
      "Iteration:  9700 , loss:  0.0020832203\n",
      "Iteration:  9800 , loss:  0.0020442964\n",
      "Iteration:  9900 , loss:  0.0020218815\n",
      "Iteration:  10000 , loss:  0.0020573263\n",
      "Iteration:  10100 , loss:  0.0019353598\n",
      "Iteration:  10200 , loss:  0.0020865742\n",
      "Iteration:  10300 , loss:  0.0018647755\n",
      "Iteration:  10400 , loss:  0.0018467051\n",
      "Iteration:  10500 , loss:  0.0018023246\n",
      "Iteration:  10600 , loss:  0.0017779206\n",
      "Iteration:  10700 , loss:  0.0017730693\n",
      "Iteration:  10800 , loss:  0.0017755302\n",
      "Iteration:  10900 , loss:  0.0016850422\n",
      "Iteration:  11000 , loss:  0.001661001\n",
      "Iteration:  11100 , loss:  0.0017833229\n",
      "Iteration:  11200 , loss:  0.0016796719\n",
      "Iteration:  11300 , loss:  0.0015844896\n",
      "Iteration:  11400 , loss:  0.0015601148\n",
      "Iteration:  11500 , loss:  0.0015387452\n",
      "Iteration:  11600 , loss:  0.0015597186\n",
      "Iteration:  11700 , loss:  0.0015534362\n",
      "Iteration:  11800 , loss:  0.0014723056\n",
      "Iteration:  11900 , loss:  0.0014687369\n",
      "Iteration:  12000 , loss:  0.0014582659\n",
      "Iteration:  12100 , loss:  0.0014118874\n",
      "Iteration:  12200 , loss:  0.001397759\n",
      "Iteration:  12300 , loss:  0.001503383\n",
      "Iteration:  12400 , loss:  0.0013570172\n",
      "Iteration:  12500 , loss:  0.0013384277\n",
      "Iteration:  12600 , loss:  0.001343061\n",
      "Iteration:  12700 , loss:  0.001302015\n",
      "Iteration:  12800 , loss:  0.0013011848\n",
      "Iteration:  12900 , loss:  0.0012709427\n",
      "Iteration:  13000 , loss:  0.0012571359\n",
      "Iteration:  13100 , loss:  0.0012377754\n",
      "Iteration:  13200 , loss:  0.001223073\n",
      "Iteration:  13300 , loss:  0.0012060021\n",
      "Iteration:  13400 , loss:  0.0011939271\n",
      "Iteration:  13500 , loss:  0.001176928\n",
      "Iteration:  13600 , loss:  0.0011627942\n",
      "Iteration:  13700 , loss:  0.0011486878\n",
      "Iteration:  13800 , loss:  0.0011319943\n",
      "Iteration:  13900 , loss:  0.0011185589\n",
      "Iteration:  14000 , loss:  0.0011077162\n",
      "Iteration:  14100 , loss:  0.0010971149\n",
      "Iteration:  14200 , loss:  0.0011006518\n",
      "Iteration:  14300 , loss:  0.0011522371\n",
      "Iteration:  14400 , loss:  0.0011686374\n",
      "Iteration:  14500 , loss:  0.0011432801\n",
      "Iteration:  14600 , loss:  0.0010342275\n",
      "Iteration:  14700 , loss:  0.0010402797\n",
      "Iteration:  14800 , loss:  0.0012610598\n",
      "Iteration:  14900 , loss:  0.0010009755\n",
      "Iteration:  15000 , loss:  0.0011904942\n",
      "Iteration:  15100 , loss:  0.0010600593\n",
      "Iteration:  15200 , loss:  0.0009836945\n",
      "Iteration:  15300 , loss:  0.0011335812\n",
      "Iteration:  15400 , loss:  0.0010509425\n",
      "Iteration:  15500 , loss:  0.0017003259\n",
      "Iteration:  15600 , loss:  0.00093704235\n",
      "Iteration:  15700 , loss:  0.0009231642\n",
      "Iteration:  15800 , loss:  0.00091419945\n",
      "Iteration:  15900 , loss:  0.0009064814\n",
      "Iteration:  16000 , loss:  0.00091000495\n",
      "Iteration:  16100 , loss:  0.0008930539\n",
      "Iteration:  16200 , loss:  0.0009105519\n",
      "Iteration:  16300 , loss:  0.000957869\n",
      "Iteration:  16400 , loss:  0.00093227753\n",
      "Iteration:  16500 , loss:  0.00090431026\n",
      "Iteration:  16600 , loss:  0.0009441281\n",
      "Iteration:  16700 , loss:  0.0010940374\n",
      "Iteration:  16800 , loss:  0.001843512\n",
      "Iteration:  16900 , loss:  0.0008295504\n",
      "Iteration:  17000 , loss:  0.00082127313\n",
      "Iteration:  17100 , loss:  0.0008344396\n",
      "Iteration:  17200 , loss:  0.0011724164\n",
      "Iteration:  17300 , loss:  0.0008011291\n",
      "Iteration:  17400 , loss:  0.000795478\n",
      "Iteration:  17500 , loss:  0.0007953228\n",
      "Iteration:  17600 , loss:  0.00079025025\n",
      "Iteration:  17700 , loss:  0.0007952519\n",
      "Iteration:  17800 , loss:  0.0007807381\n",
      "Iteration:  17900 , loss:  0.001033492\n",
      "Iteration:  18000 , loss:  0.0010711098\n",
      "Iteration:  18100 , loss:  0.0008913668\n",
      "Iteration:  18200 , loss:  0.00074895297\n",
      "Iteration:  18300 , loss:  0.0007420725\n",
      "Iteration:  18400 , loss:  0.0007872346\n",
      "Iteration:  18500 , loss:  0.00082272897\n",
      "Iteration:  18600 , loss:  0.00076103857\n",
      "Iteration:  18700 , loss:  0.00071987044\n",
      "Iteration:  18800 , loss:  0.00073214207\n",
      "Iteration:  18900 , loss:  0.0007110037\n",
      "Iteration:  19000 , loss:  0.0009300056\n",
      "Iteration:  19100 , loss:  0.0007678064\n",
      "Iteration:  19200 , loss:  0.00069856487\n",
      "Iteration:  19300 , loss:  0.00071886386\n",
      "Iteration:  19400 , loss:  0.0013988728\n",
      "Iteration:  19500 , loss:  0.00071437156\n",
      "Iteration:  19600 , loss:  0.00077657454\n",
      "Iteration:  19700 , loss:  0.00085630093\n",
      "Iteration:  19800 , loss:  0.0007000533\n",
      "Iteration:  19900 , loss:  0.0006666039\n",
      "Generating 11th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.09360398\n",
      "Iteration:  100 , loss:  0.025258739\n",
      "Iteration:  200 , loss:  0.0227338\n",
      "Iteration:  300 , loss:  0.02157284\n",
      "Iteration:  400 , loss:  0.020651598\n",
      "Iteration:  500 , loss:  0.019835273\n",
      "Iteration:  600 , loss:  0.019041779\n",
      "Iteration:  700 , loss:  0.018208085\n",
      "Iteration:  800 , loss:  0.017293304\n",
      "Iteration:  900 , loss:  0.01647858\n",
      "Iteration:  1000 , loss:  0.015919965\n",
      "Iteration:  1100 , loss:  0.015374562\n",
      "Iteration:  1200 , loss:  0.014729187\n",
      "Iteration:  1300 , loss:  0.014109494\n",
      "Iteration:  1400 , loss:  0.013937142\n",
      "Iteration:  1500 , loss:  0.013157764\n",
      "Iteration:  1600 , loss:  0.012759188\n",
      "Iteration:  1700 , loss:  0.012396042\n",
      "Iteration:  1800 , loss:  0.012224412\n",
      "Iteration:  1900 , loss:  0.011727783\n",
      "Iteration:  2000 , loss:  0.011628882\n",
      "Iteration:  2100 , loss:  0.011114398\n",
      "Iteration:  2200 , loss:  0.010838509\n",
      "Iteration:  2300 , loss:  0.010593375\n",
      "Iteration:  2400 , loss:  0.010370461\n",
      "Iteration:  2500 , loss:  0.010165183\n",
      "Iteration:  2600 , loss:  0.009982172\n",
      "Iteration:  2700 , loss:  0.009792866\n",
      "Iteration:  2800 , loss:  0.009606162\n",
      "Iteration:  2900 , loss:  0.009424985\n",
      "Iteration:  3000 , loss:  0.009238496\n",
      "Iteration:  3100 , loss:  0.0090603735\n",
      "Iteration:  3200 , loss:  0.00887626\n",
      "Iteration:  3300 , loss:  0.008690124\n",
      "Iteration:  3400 , loss:  0.008498577\n",
      "Iteration:  3500 , loss:  0.008301777\n",
      "Iteration:  3600 , loss:  0.009014299\n",
      "Iteration:  3700 , loss:  0.007894015\n",
      "Iteration:  3800 , loss:  0.007680506\n",
      "Iteration:  3900 , loss:  0.0074562505\n",
      "Iteration:  4000 , loss:  0.0072311647\n",
      "Iteration:  4100 , loss:  0.0069948705\n",
      "Iteration:  4200 , loss:  0.0067789205\n",
      "Iteration:  4300 , loss:  0.0065707667\n",
      "Iteration:  4400 , loss:  0.0064126044\n",
      "Iteration:  4500 , loss:  0.0061969534\n",
      "Iteration:  4600 , loss:  0.0060216524\n",
      "Iteration:  4700 , loss:  0.0058657946\n",
      "Iteration:  4800 , loss:  0.0061350353\n",
      "Iteration:  4900 , loss:  0.0055711283\n",
      "Iteration:  5000 , loss:  0.00549003\n",
      "Iteration:  5100 , loss:  0.0055520716\n",
      "Iteration:  5200 , loss:  0.0051528467\n",
      "Iteration:  5300 , loss:  0.0050216643\n",
      "Iteration:  5400 , loss:  0.00489093\n",
      "Iteration:  5500 , loss:  0.0048421463\n",
      "Iteration:  5600 , loss:  0.0046231574\n",
      "Iteration:  5700 , loss:  0.0044890153\n",
      "Iteration:  5800 , loss:  0.004360658\n",
      "Iteration:  5900 , loss:  0.0054355543\n",
      "Iteration:  6000 , loss:  0.004079374\n",
      "Iteration:  6100 , loss:  0.003939257\n",
      "Iteration:  6200 , loss:  0.0038018099\n",
      "Iteration:  6300 , loss:  0.0036577426\n",
      "Iteration:  6400 , loss:  0.0035132074\n",
      "Iteration:  6500 , loss:  0.0033625546\n",
      "Iteration:  6600 , loss:  0.0032121527\n",
      "Iteration:  6700 , loss:  0.0030569786\n",
      "Iteration:  6800 , loss:  0.0029093972\n",
      "Iteration:  6900 , loss:  0.0027640068\n",
      "Iteration:  7000 , loss:  0.0026318408\n",
      "Iteration:  7100 , loss:  0.0025071749\n",
      "Iteration:  7200 , loss:  0.0026570002\n",
      "Iteration:  7300 , loss:  0.0022988867\n",
      "Iteration:  7400 , loss:  0.002208496\n",
      "Iteration:  7500 , loss:  0.0021308735\n",
      "Iteration:  7600 , loss:  0.002056373\n",
      "Iteration:  7700 , loss:  0.0019968057\n",
      "Iteration:  7800 , loss:  0.001922065\n",
      "Iteration:  7900 , loss:  0.0019451967\n",
      "Iteration:  8000 , loss:  0.0018411507\n",
      "Iteration:  8100 , loss:  0.0017650628\n",
      "Iteration:  8200 , loss:  0.0017029789\n",
      "Iteration:  8300 , loss:  0.001755769\n",
      "Iteration:  8400 , loss:  0.0016155103\n",
      "Iteration:  8500 , loss:  0.0015844124\n",
      "Iteration:  8600 , loss:  0.0015968883\n",
      "Iteration:  8700 , loss:  0.0015007488\n",
      "Iteration:  8800 , loss:  0.001472489\n",
      "Iteration:  8900 , loss:  0.001436065\n",
      "Iteration:  9000 , loss:  0.0014209287\n",
      "Iteration:  9100 , loss:  0.0013734848\n",
      "Iteration:  9200 , loss:  0.0013525456\n",
      "Iteration:  9300 , loss:  0.0013317785\n",
      "Iteration:  9400 , loss:  0.0013143781\n",
      "Iteration:  9500 , loss:  0.0012631152\n",
      "Iteration:  9600 , loss:  0.0012316667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  9700 , loss:  0.0012049702\n",
      "Iteration:  9800 , loss:  0.00118038\n",
      "Iteration:  9900 , loss:  0.0011718092\n",
      "Iteration:  10000 , loss:  0.0011417916\n",
      "Iteration:  10100 , loss:  0.0013256102\n",
      "Iteration:  10200 , loss:  0.0010987438\n",
      "Iteration:  10300 , loss:  0.0010986163\n",
      "Iteration:  10400 , loss:  0.0010471275\n",
      "Iteration:  10500 , loss:  0.001034203\n",
      "Iteration:  10600 , loss:  0.0011651935\n",
      "Iteration:  10700 , loss:  0.0010036078\n",
      "Iteration:  10800 , loss:  0.0009812503\n",
      "Iteration:  10900 , loss:  0.0009593505\n",
      "Iteration:  11000 , loss:  0.0010061046\n",
      "Iteration:  11100 , loss:  0.00093109347\n",
      "Iteration:  11200 , loss:  0.0009773023\n",
      "Iteration:  11300 , loss:  0.0009330884\n",
      "Iteration:  11400 , loss:  0.000992139\n",
      "Iteration:  11500 , loss:  0.00085399864\n",
      "Iteration:  11600 , loss:  0.00086022203\n",
      "Iteration:  11700 , loss:  0.0009355347\n",
      "Iteration:  11800 , loss:  0.00082871766\n",
      "Iteration:  11900 , loss:  0.0008037317\n",
      "Iteration:  12000 , loss:  0.001386658\n",
      "Iteration:  12100 , loss:  0.00077660935\n",
      "Iteration:  12200 , loss:  0.0008002168\n",
      "Iteration:  12300 , loss:  0.0010972719\n",
      "Iteration:  12400 , loss:  0.0007639225\n",
      "Iteration:  12500 , loss:  0.00087161415\n",
      "Iteration:  12600 , loss:  0.00072302483\n",
      "Iteration:  12700 , loss:  0.0007245282\n",
      "Iteration:  12800 , loss:  0.00071276625\n",
      "Iteration:  12900 , loss:  0.00070653064\n",
      "Iteration:  13000 , loss:  0.0007003\n",
      "Iteration:  13100 , loss:  0.0006906496\n",
      "Iteration:  13200 , loss:  0.00069578865\n",
      "Iteration:  13300 , loss:  0.0006724365\n",
      "Iteration:  13400 , loss:  0.000838048\n",
      "Iteration:  13500 , loss:  0.00064482715\n",
      "Iteration:  13600 , loss:  0.00063082005\n",
      "Iteration:  13700 , loss:  0.00062385935\n",
      "Iteration:  13800 , loss:  0.00061650964\n",
      "Iteration:  13900 , loss:  0.00061881274\n",
      "Iteration:  14000 , loss:  0.00059933745\n",
      "Iteration:  14100 , loss:  0.0006128547\n",
      "Iteration:  14200 , loss:  0.00069238676\n",
      "Iteration:  14300 , loss:  0.00058898376\n",
      "Iteration:  14400 , loss:  0.0007163171\n",
      "Iteration:  14500 , loss:  0.0005695577\n",
      "Iteration:  14600 , loss:  0.00058250077\n",
      "Iteration:  14700 , loss:  0.00065099617\n",
      "Iteration:  14800 , loss:  0.00053896813\n",
      "Iteration:  14900 , loss:  0.0005897031\n",
      "Iteration:  15000 , loss:  0.00064281694\n",
      "Iteration:  15100 , loss:  0.0005262928\n",
      "Iteration:  15200 , loss:  0.0005130464\n",
      "Iteration:  15300 , loss:  0.0007700033\n",
      "Iteration:  15400 , loss:  0.00050329603\n",
      "Iteration:  15500 , loss:  0.00070973777\n",
      "Iteration:  15600 , loss:  0.00053158763\n",
      "Iteration:  15700 , loss:  0.0011555094\n",
      "Iteration:  15800 , loss:  0.00077455543\n",
      "Iteration:  15900 , loss:  0.0004894941\n",
      "Iteration:  16000 , loss:  0.00049302814\n",
      "Iteration:  16100 , loss:  0.0005267874\n",
      "Iteration:  16200 , loss:  0.0005010691\n",
      "Iteration:  16300 , loss:  0.0004494596\n",
      "Iteration:  16400 , loss:  0.0005415591\n",
      "Iteration:  16500 , loss:  0.00047334627\n",
      "Iteration:  16600 , loss:  0.00046551507\n",
      "Iteration:  16700 , loss:  0.0004267886\n",
      "Iteration:  16800 , loss:  0.0005272617\n",
      "Iteration:  16900 , loss:  0.0004150344\n",
      "Iteration:  17000 , loss:  0.0004280827\n",
      "Iteration:  17100 , loss:  0.00040087625\n",
      "Iteration:  17200 , loss:  0.00039421045\n",
      "Iteration:  17300 , loss:  0.00038959266\n",
      "Iteration:  17400 , loss:  0.00038586216\n",
      "Iteration:  17500 , loss:  0.00048586496\n",
      "Iteration:  17600 , loss:  0.0003957942\n",
      "Iteration:  17700 , loss:  0.00039005\n",
      "Iteration:  17800 , loss:  0.00036493153\n",
      "Iteration:  17900 , loss:  0.00038728485\n",
      "Iteration:  18000 , loss:  0.00036091896\n",
      "Iteration:  18100 , loss:  0.000352886\n",
      "Iteration:  18200 , loss:  0.00035772298\n",
      "Iteration:  18300 , loss:  0.00034369755\n",
      "Iteration:  18400 , loss:  0.00034007267\n",
      "Iteration:  18500 , loss:  0.0003321988\n",
      "Iteration:  18600 , loss:  0.00033121466\n",
      "Iteration:  18700 , loss:  0.0003347127\n",
      "Iteration:  18800 , loss:  0.00033434047\n",
      "Iteration:  18900 , loss:  0.00035978178\n",
      "Iteration:  19000 , loss:  0.00031282706\n",
      "Iteration:  19100 , loss:  0.00030953882\n",
      "Iteration:  19200 , loss:  0.00031143607\n",
      "Iteration:  19300 , loss:  0.0003060242\n",
      "Iteration:  19400 , loss:  0.00051048934\n",
      "Iteration:  19500 , loss:  0.00033362687\n",
      "Iteration:  19600 , loss:  0.00028788697\n",
      "Iteration:  19700 , loss:  0.0002837111\n",
      "Iteration:  19800 , loss:  0.0003259746\n",
      "Iteration:  19900 , loss:  0.00027773948\n",
      "Generating 12th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.21242109\n",
      "Iteration:  100 , loss:  0.049232148\n",
      "Iteration:  200 , loss:  0.03104432\n",
      "Iteration:  300 , loss:  0.025719974\n",
      "Iteration:  400 , loss:  0.02340017\n",
      "Iteration:  500 , loss:  0.021963112\n",
      "Iteration:  600 , loss:  0.020730536\n",
      "Iteration:  700 , loss:  0.01944666\n",
      "Iteration:  800 , loss:  0.01875001\n",
      "Iteration:  900 , loss:  0.01830713\n",
      "Iteration:  1000 , loss:  0.017896762\n",
      "Iteration:  1100 , loss:  0.017481992\n",
      "Iteration:  1200 , loss:  0.017056815\n",
      "Iteration:  1300 , loss:  0.016628344\n",
      "Iteration:  1400 , loss:  0.01620486\n",
      "Iteration:  1500 , loss:  0.015788212\n",
      "Iteration:  1600 , loss:  0.015371962\n",
      "Iteration:  1700 , loss:  0.014923231\n",
      "Iteration:  1800 , loss:  0.014276537\n",
      "Iteration:  1900 , loss:  0.013402835\n",
      "Iteration:  2000 , loss:  0.012790995\n",
      "Iteration:  2100 , loss:  0.012311557\n",
      "Iteration:  2200 , loss:  0.011892534\n",
      "Iteration:  2300 , loss:  0.011514802\n",
      "Iteration:  2400 , loss:  0.011179953\n",
      "Iteration:  2500 , loss:  0.010874672\n",
      "Iteration:  2600 , loss:  0.010590325\n",
      "Iteration:  2700 , loss:  0.010318044\n",
      "Iteration:  2800 , loss:  0.010058761\n",
      "Iteration:  2900 , loss:  0.009802387\n",
      "Iteration:  3000 , loss:  0.00954153\n",
      "Iteration:  3100 , loss:  0.009271046\n",
      "Iteration:  3200 , loss:  0.009009764\n",
      "Iteration:  3300 , loss:  0.008748901\n",
      "Iteration:  3400 , loss:  0.008473382\n",
      "Iteration:  3500 , loss:  0.008190236\n",
      "Iteration:  3600 , loss:  0.007916201\n",
      "Iteration:  3700 , loss:  0.007665066\n",
      "Iteration:  3800 , loss:  0.007462922\n",
      "Iteration:  3900 , loss:  0.007201079\n",
      "Iteration:  4000 , loss:  0.0069942707\n",
      "Iteration:  4100 , loss:  0.006824362\n",
      "Iteration:  4200 , loss:  0.006590011\n",
      "Iteration:  4300 , loss:  0.006399209\n",
      "Iteration:  4400 , loss:  0.0062103183\n",
      "Iteration:  4500 , loss:  0.0060317433\n",
      "Iteration:  4600 , loss:  0.0058486266\n",
      "Iteration:  4700 , loss:  0.0056855455\n",
      "Iteration:  4800 , loss:  0.00548246\n",
      "Iteration:  4900 , loss:  0.0054854024\n",
      "Iteration:  5000 , loss:  0.0051228376\n",
      "Iteration:  5100 , loss:  0.004973693\n",
      "Iteration:  5200 , loss:  0.004876763\n",
      "Iteration:  5300 , loss:  0.0046506883\n",
      "Iteration:  5400 , loss:  0.004515606\n",
      "Iteration:  5500 , loss:  0.0047348184\n",
      "Iteration:  5600 , loss:  0.0042492826\n",
      "Iteration:  5700 , loss:  0.004107859\n",
      "Iteration:  5800 , loss:  0.004004059\n",
      "Iteration:  5900 , loss:  0.0038888413\n",
      "Iteration:  6000 , loss:  0.0037895355\n",
      "Iteration:  6100 , loss:  0.0036947841\n",
      "Iteration:  6200 , loss:  0.0036009876\n",
      "Iteration:  6300 , loss:  0.0035327165\n",
      "Iteration:  6400 , loss:  0.0034280648\n",
      "Iteration:  6500 , loss:  0.0033453342\n",
      "Iteration:  6600 , loss:  0.0032715092\n",
      "Iteration:  6700 , loss:  0.00320844\n",
      "Iteration:  6800 , loss:  0.003119505\n",
      "Iteration:  6900 , loss:  0.003052114\n",
      "Iteration:  7000 , loss:  0.0029800814\n",
      "Iteration:  7100 , loss:  0.0029164266\n",
      "Iteration:  7200 , loss:  0.00284894\n",
      "Iteration:  7300 , loss:  0.00279297\n",
      "Iteration:  7400 , loss:  0.0027245986\n",
      "Iteration:  7500 , loss:  0.0035743841\n",
      "Iteration:  7600 , loss:  0.0026060434\n",
      "Iteration:  7700 , loss:  0.0034925856\n",
      "Iteration:  7800 , loss:  0.00249554\n",
      "Iteration:  7900 , loss:  0.0024412367\n",
      "Iteration:  8000 , loss:  0.002392674\n",
      "Iteration:  8100 , loss:  0.0023420155\n",
      "Iteration:  8200 , loss:  0.002301466\n",
      "Iteration:  8300 , loss:  0.0022487342\n",
      "Iteration:  8400 , loss:  0.0022054103\n",
      "Iteration:  8500 , loss:  0.002161013\n",
      "Iteration:  8600 , loss:  0.0021205044\n",
      "Iteration:  8700 , loss:  0.0020791877\n",
      "Iteration:  8800 , loss:  0.0020443965\n",
      "Iteration:  8900 , loss:  0.0020023512\n",
      "Iteration:  9000 , loss:  0.0019710762\n",
      "Iteration:  9100 , loss:  0.0019299737\n",
      "Iteration:  9200 , loss:  0.0019082981\n",
      "Iteration:  9300 , loss:  0.0018611391\n",
      "Iteration:  9400 , loss:  0.0018483007\n",
      "Iteration:  9500 , loss:  0.0017960886\n",
      "Iteration:  9600 , loss:  0.001782037\n",
      "Iteration:  9700 , loss:  0.0017345496\n",
      "Iteration:  9800 , loss:  0.0019831643\n",
      "Iteration:  9900 , loss:  0.0016755951\n",
      "Iteration:  10000 , loss:  0.0027031377\n",
      "Iteration:  10100 , loss:  0.0016196411\n",
      "Iteration:  10200 , loss:  0.0015918439\n",
      "Iteration:  10300 , loss:  0.0015688025\n",
      "Iteration:  10400 , loss:  0.0015402032\n",
      "Iteration:  10500 , loss:  0.002197674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10600 , loss:  0.0014900045\n",
      "Iteration:  10700 , loss:  0.0014645857\n",
      "Iteration:  10800 , loss:  0.0014413984\n",
      "Iteration:  10900 , loss:  0.0014167094\n",
      "Iteration:  11000 , loss:  0.001401886\n",
      "Iteration:  11100 , loss:  0.0013708721\n",
      "Iteration:  11200 , loss:  0.0015419333\n",
      "Iteration:  11300 , loss:  0.0013264469\n",
      "Iteration:  11400 , loss:  0.0013040454\n",
      "Iteration:  11500 , loss:  0.0012847838\n",
      "Iteration:  11600 , loss:  0.0012638773\n",
      "Iteration:  11700 , loss:  0.0014000922\n",
      "Iteration:  11800 , loss:  0.0012255781\n",
      "Iteration:  11900 , loss:  0.0012067673\n",
      "Iteration:  12000 , loss:  0.0012422894\n",
      "Iteration:  12100 , loss:  0.0011724477\n",
      "Iteration:  12200 , loss:  0.0011553372\n",
      "Iteration:  12300 , loss:  0.0011405931\n",
      "Iteration:  12400 , loss:  0.0011248826\n",
      "Iteration:  12500 , loss:  0.0017511273\n",
      "Iteration:  12600 , loss:  0.0010964385\n",
      "Iteration:  12700 , loss:  0.0010823181\n",
      "Iteration:  12800 , loss:  0.0010707937\n",
      "Iteration:  12900 , loss:  0.0010565877\n",
      "Iteration:  13000 , loss:  0.0011180693\n",
      "Iteration:  13100 , loss:  0.0010318368\n",
      "Iteration:  13200 , loss:  0.0014594356\n",
      "Iteration:  13300 , loss:  0.0010085383\n",
      "Iteration:  13400 , loss:  0.0009967922\n",
      "Iteration:  13500 , loss:  0.0010608105\n",
      "Iteration:  13600 , loss:  0.0009771206\n",
      "Iteration:  13700 , loss:  0.000967679\n",
      "Iteration:  13800 , loss:  0.001200472\n",
      "Iteration:  13900 , loss:  0.00095070235\n",
      "Iteration:  14000 , loss:  0.0009420678\n",
      "Iteration:  14100 , loss:  0.0009996739\n",
      "Iteration:  14200 , loss:  0.00092616276\n",
      "Iteration:  14300 , loss:  0.00091809634\n",
      "Iteration:  14400 , loss:  0.0009110186\n",
      "Iteration:  14500 , loss:  0.0009030786\n",
      "Iteration:  14600 , loss:  0.0008970272\n",
      "Iteration:  14700 , loss:  0.00088917767\n",
      "Iteration:  14800 , loss:  0.0017821431\n",
      "Iteration:  14900 , loss:  0.0008755726\n",
      "Iteration:  15000 , loss:  0.0018611448\n",
      "Iteration:  15100 , loss:  0.00086286664\n",
      "Iteration:  15200 , loss:  0.0008561328\n",
      "Iteration:  15300 , loss:  0.00087328424\n",
      "Iteration:  15400 , loss:  0.00084347016\n",
      "Iteration:  15500 , loss:  0.000860685\n",
      "Iteration:  15600 , loss:  0.00083339633\n",
      "Iteration:  15700 , loss:  0.0009654791\n",
      "Iteration:  15800 , loss:  0.0008182329\n",
      "Iteration:  15900 , loss:  0.0009478215\n",
      "Iteration:  16000 , loss:  0.0008194044\n",
      "Iteration:  16100 , loss:  0.00080044876\n",
      "Iteration:  16200 , loss:  0.0008158964\n",
      "Iteration:  16300 , loss:  0.00078889856\n",
      "Iteration:  16400 , loss:  0.0007944902\n",
      "Iteration:  16500 , loss:  0.0007778716\n",
      "Iteration:  16600 , loss:  0.00079076993\n",
      "Iteration:  16700 , loss:  0.00076716236\n",
      "Iteration:  16800 , loss:  0.0011343823\n",
      "Iteration:  16900 , loss:  0.0007871435\n",
      "Iteration:  17000 , loss:  0.00075144775\n",
      "Iteration:  17100 , loss:  0.00076571223\n",
      "Iteration:  17200 , loss:  0.0007412772\n",
      "Iteration:  17300 , loss:  0.0007574634\n",
      "Iteration:  17400 , loss:  0.0007316545\n",
      "Iteration:  17500 , loss:  0.0011620279\n",
      "Iteration:  17600 , loss:  0.00072675094\n",
      "Iteration:  17700 , loss:  0.00071777543\n",
      "Iteration:  17800 , loss:  0.0007249603\n",
      "Iteration:  17900 , loss:  0.00070836657\n",
      "Iteration:  18000 , loss:  0.00072765636\n",
      "Iteration:  18100 , loss:  0.00069957774\n",
      "Iteration:  18200 , loss:  0.0006965359\n",
      "Iteration:  18300 , loss:  0.0006911239\n",
      "Iteration:  18400 , loss:  0.00068797485\n",
      "Iteration:  18500 , loss:  0.0006905774\n",
      "Iteration:  18600 , loss:  0.0006786707\n",
      "Iteration:  18700 , loss:  0.0006760392\n",
      "Iteration:  18800 , loss:  0.001117388\n",
      "Iteration:  18900 , loss:  0.00066683686\n",
      "Iteration:  19000 , loss:  0.0007287505\n",
      "Iteration:  19100 , loss:  0.0014962745\n",
      "Iteration:  19200 , loss:  0.00065517396\n",
      "Iteration:  19300 , loss:  0.0006804962\n",
      "Iteration:  19400 , loss:  0.0006478436\n",
      "Iteration:  19500 , loss:  0.0008399218\n",
      "Iteration:  19600 , loss:  0.000792937\n",
      "Iteration:  19700 , loss:  0.00063640234\n",
      "Iteration:  19800 , loss:  0.0006335145\n",
      "Iteration:  19900 , loss:  0.0006302812\n",
      "Generating 13th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.13410217\n",
      "Iteration:  100 , loss:  0.027651513\n",
      "Iteration:  200 , loss:  0.02338593\n",
      "Iteration:  300 , loss:  0.022204962\n",
      "Iteration:  400 , loss:  0.021402959\n",
      "Iteration:  500 , loss:  0.020720202\n",
      "Iteration:  600 , loss:  0.020092638\n",
      "Iteration:  700 , loss:  0.01948614\n",
      "Iteration:  800 , loss:  0.018871577\n",
      "Iteration:  900 , loss:  0.018220622\n",
      "Iteration:  1000 , loss:  0.017525747\n",
      "Iteration:  1100 , loss:  0.016838063\n",
      "Iteration:  1200 , loss:  0.016156029\n",
      "Iteration:  1300 , loss:  0.015513537\n",
      "Iteration:  1400 , loss:  0.014649071\n",
      "Iteration:  1500 , loss:  0.013522773\n",
      "Iteration:  1600 , loss:  0.012795671\n",
      "Iteration:  1700 , loss:  0.01230786\n",
      "Iteration:  1800 , loss:  0.01193814\n",
      "Iteration:  1900 , loss:  0.011637369\n",
      "Iteration:  2000 , loss:  0.011397413\n",
      "Iteration:  2100 , loss:  0.011186659\n",
      "Iteration:  2200 , loss:  0.0110212825\n",
      "Iteration:  2300 , loss:  0.010838694\n",
      "Iteration:  2400 , loss:  0.010680101\n",
      "Iteration:  2500 , loss:  0.010540895\n",
      "Iteration:  2600 , loss:  0.010404976\n",
      "Iteration:  2700 , loss:  0.01051075\n",
      "Iteration:  2800 , loss:  0.010158952\n",
      "Iteration:  2900 , loss:  0.0100425305\n",
      "Iteration:  3000 , loss:  0.009943695\n",
      "Iteration:  3100 , loss:  0.009833284\n",
      "Iteration:  3200 , loss:  0.009729667\n",
      "Iteration:  3300 , loss:  0.00963778\n",
      "Iteration:  3400 , loss:  0.009533294\n",
      "Iteration:  3500 , loss:  0.009429544\n",
      "Iteration:  3600 , loss:  0.00933478\n",
      "Iteration:  3700 , loss:  0.009227771\n",
      "Iteration:  3800 , loss:  0.009120455\n",
      "Iteration:  3900 , loss:  0.009019612\n",
      "Iteration:  4000 , loss:  0.008913616\n",
      "Iteration:  4100 , loss:  0.010383856\n",
      "Iteration:  4200 , loss:  0.008700933\n",
      "Iteration:  4300 , loss:  0.008590523\n",
      "Iteration:  4400 , loss:  0.008473061\n",
      "Iteration:  4500 , loss:  0.008358911\n",
      "Iteration:  4600 , loss:  0.008235646\n",
      "Iteration:  4700 , loss:  0.008103316\n",
      "Iteration:  4800 , loss:  0.007972198\n",
      "Iteration:  4900 , loss:  0.00783356\n",
      "Iteration:  5000 , loss:  0.0076863733\n",
      "Iteration:  5100 , loss:  0.0075434702\n",
      "Iteration:  5200 , loss:  0.007392342\n",
      "Iteration:  5300 , loss:  0.0072326576\n",
      "Iteration:  5400 , loss:  0.007078586\n",
      "Iteration:  5500 , loss:  0.0069215605\n",
      "Iteration:  5600 , loss:  0.006762234\n",
      "Iteration:  5700 , loss:  0.0066109467\n",
      "Iteration:  5800 , loss:  0.0064582815\n",
      "Iteration:  5900 , loss:  0.006301921\n",
      "Iteration:  6000 , loss:  0.0061546233\n",
      "Iteration:  6100 , loss:  0.006006664\n",
      "Iteration:  6200 , loss:  0.0058565573\n",
      "Iteration:  6300 , loss:  0.005716561\n",
      "Iteration:  6400 , loss:  0.005574117\n",
      "Iteration:  6500 , loss:  0.005499549\n",
      "Iteration:  6600 , loss:  0.005296531\n",
      "Iteration:  6700 , loss:  0.005151486\n",
      "Iteration:  6800 , loss:  0.0050166\n",
      "Iteration:  6900 , loss:  0.004877985\n",
      "Iteration:  7000 , loss:  0.004771567\n",
      "Iteration:  7100 , loss:  0.0046202214\n",
      "Iteration:  7200 , loss:  0.0044937986\n",
      "Iteration:  7300 , loss:  0.004623407\n",
      "Iteration:  7400 , loss:  0.004250055\n",
      "Iteration:  7500 , loss:  0.0041280533\n",
      "Iteration:  7600 , loss:  0.0040180413\n",
      "Iteration:  7700 , loss:  0.0039053233\n",
      "Iteration:  7800 , loss:  0.0040695635\n",
      "Iteration:  7900 , loss:  0.0036902414\n",
      "Iteration:  8000 , loss:  0.0039115557\n",
      "Iteration:  8100 , loss:  0.0034933314\n",
      "Iteration:  8200 , loss:  0.0033985632\n",
      "Iteration:  8300 , loss:  0.003314686\n",
      "Iteration:  8400 , loss:  0.0032295045\n",
      "Iteration:  8500 , loss:  0.003169922\n",
      "Iteration:  8600 , loss:  0.0030733538\n",
      "Iteration:  8700 , loss:  0.0047811833\n",
      "Iteration:  8800 , loss:  0.0029285876\n",
      "Iteration:  8900 , loss:  0.002857789\n",
      "Iteration:  9000 , loss:  0.0027941186\n",
      "Iteration:  9100 , loss:  0.0027283346\n",
      "Iteration:  9200 , loss:  0.002697197\n",
      "Iteration:  9300 , loss:  0.0026109798\n",
      "Iteration:  9400 , loss:  0.0025531806\n",
      "Iteration:  9500 , loss:  0.0025037355\n",
      "Iteration:  9600 , loss:  0.0024488904\n",
      "Iteration:  9700 , loss:  0.0024458712\n",
      "Iteration:  9800 , loss:  0.002349809\n",
      "Iteration:  9900 , loss:  0.0023009612\n",
      "Iteration:  10000 , loss:  0.0022576854\n",
      "Iteration:  10100 , loss:  0.0022125181\n",
      "Iteration:  10200 , loss:  0.0022554412\n",
      "Iteration:  10300 , loss:  0.0021286637\n",
      "Iteration:  10400 , loss:  0.002086163\n",
      "Iteration:  10500 , loss:  0.0020480854\n",
      "Iteration:  10600 , loss:  0.0020078889\n",
      "Iteration:  10700 , loss:  0.0020113739\n",
      "Iteration:  10800 , loss:  0.0019326917\n",
      "Iteration:  10900 , loss:  0.0019234222\n",
      "Iteration:  11000 , loss:  0.0018607883\n",
      "Iteration:  11100 , loss:  0.0018247268\n",
      "Iteration:  11200 , loss:  0.0017919438\n",
      "Iteration:  11300 , loss:  0.0017860995\n",
      "Iteration:  11400 , loss:  0.0017242782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  11500 , loss:  0.0016930026\n",
      "Iteration:  11600 , loss:  0.0016744562\n",
      "Iteration:  11700 , loss:  0.0016318827\n",
      "Iteration:  11800 , loss:  0.0016005569\n",
      "Iteration:  11900 , loss:  0.0015727087\n",
      "Iteration:  12000 , loss:  0.0015425917\n",
      "Iteration:  12100 , loss:  0.0015136446\n",
      "Iteration:  12200 , loss:  0.0014862398\n",
      "Iteration:  12300 , loss:  0.0014581643\n",
      "Iteration:  12400 , loss:  0.0028316262\n",
      "Iteration:  12500 , loss:  0.001403922\n",
      "Iteration:  12600 , loss:  0.0013849074\n",
      "Iteration:  12700 , loss:  0.0013527822\n",
      "Iteration:  12800 , loss:  0.0013271302\n",
      "Iteration:  12900 , loss:  0.0013937831\n",
      "Iteration:  13000 , loss:  0.0012785498\n",
      "Iteration:  13100 , loss:  0.0012536566\n",
      "Iteration:  13200 , loss:  0.0012330747\n",
      "Iteration:  13300 , loss:  0.0012078871\n",
      "Iteration:  13400 , loss:  0.0011867634\n",
      "Iteration:  13500 , loss:  0.0011633763\n",
      "Iteration:  13600 , loss:  0.0011657567\n",
      "Iteration:  13700 , loss:  0.0013149979\n",
      "Iteration:  13800 , loss:  0.0010994667\n",
      "Iteration:  13900 , loss:  0.001079042\n",
      "Iteration:  14000 , loss:  0.0011771144\n",
      "Iteration:  14100 , loss:  0.0010419032\n",
      "Iteration:  14200 , loss:  0.0010212015\n",
      "Iteration:  14300 , loss:  0.0012171188\n",
      "Iteration:  14400 , loss:  0.000999888\n",
      "Iteration:  14500 , loss:  0.0009678351\n",
      "Iteration:  14600 , loss:  0.0010465458\n",
      "Iteration:  14700 , loss:  0.0009348692\n",
      "Iteration:  14800 , loss:  0.0009255774\n",
      "Iteration:  14900 , loss:  0.000904141\n",
      "Iteration:  15000 , loss:  0.0008905664\n",
      "Iteration:  15100 , loss:  0.00088115834\n",
      "Iteration:  15200 , loss:  0.0012330392\n",
      "Iteration:  15300 , loss:  0.000847971\n",
      "Iteration:  15400 , loss:  0.00083766074\n",
      "Iteration:  15500 , loss:  0.00082487805\n",
      "Iteration:  15600 , loss:  0.0008969046\n",
      "Iteration:  15700 , loss:  0.00079934223\n",
      "Iteration:  15800 , loss:  0.0007955474\n",
      "Iteration:  15900 , loss:  0.00077791093\n",
      "Iteration:  16000 , loss:  0.00080548116\n",
      "Iteration:  16100 , loss:  0.0007565208\n",
      "Iteration:  16200 , loss:  0.000748412\n",
      "Iteration:  16300 , loss:  0.00073725905\n",
      "Iteration:  16400 , loss:  0.00072754675\n",
      "Iteration:  16500 , loss:  0.0007206733\n",
      "Iteration:  16600 , loss:  0.00070960406\n",
      "Iteration:  16700 , loss:  0.000716104\n",
      "Iteration:  16800 , loss:  0.00069245696\n",
      "Iteration:  16900 , loss:  0.00068507134\n",
      "Iteration:  17000 , loss:  0.00067615125\n",
      "Iteration:  17100 , loss:  0.0006747053\n",
      "Iteration:  17200 , loss:  0.0015592568\n",
      "Iteration:  17300 , loss:  0.00065295567\n",
      "Iteration:  17400 , loss:  0.00069642096\n",
      "Iteration:  17500 , loss:  0.00063808594\n",
      "Iteration:  17600 , loss:  0.0011209572\n",
      "Iteration:  17700 , loss:  0.00062377646\n",
      "Iteration:  17800 , loss:  0.0012735301\n",
      "Iteration:  17900 , loss:  0.00060984545\n",
      "Iteration:  18000 , loss:  0.00060735736\n",
      "Iteration:  18100 , loss:  0.0005962259\n",
      "Iteration:  18200 , loss:  0.00059087656\n",
      "Iteration:  18300 , loss:  0.00058278604\n",
      "Iteration:  18400 , loss:  0.00057559257\n",
      "Iteration:  18500 , loss:  0.0005713448\n",
      "Iteration:  18600 , loss:  0.0005622222\n",
      "Iteration:  18700 , loss:  0.00055629807\n",
      "Iteration:  18800 , loss:  0.0005490414\n",
      "Iteration:  18900 , loss:  0.0005450636\n",
      "Iteration:  19000 , loss:  0.0005357593\n",
      "Iteration:  19100 , loss:  0.00054524967\n",
      "Iteration:  19200 , loss:  0.00052235834\n",
      "Iteration:  19300 , loss:  0.0005161319\n",
      "Iteration:  19400 , loss:  0.0005086412\n",
      "Iteration:  19500 , loss:  0.00050266646\n",
      "Iteration:  19600 , loss:  0.0006385214\n",
      "Iteration:  19700 , loss:  0.0004884602\n",
      "Iteration:  19800 , loss:  0.00048849144\n",
      "Iteration:  19900 , loss:  0.0004756762\n",
      "Generating 14th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.1547717\n",
      "Iteration:  100 , loss:  0.029363517\n",
      "Iteration:  200 , loss:  0.02461771\n",
      "Iteration:  300 , loss:  0.022743255\n",
      "Iteration:  400 , loss:  0.021659475\n",
      "Iteration:  500 , loss:  0.020834029\n",
      "Iteration:  600 , loss:  0.020126414\n",
      "Iteration:  700 , loss:  0.01949015\n",
      "Iteration:  800 , loss:  0.018899588\n",
      "Iteration:  900 , loss:  0.018337935\n",
      "Iteration:  1000 , loss:  0.017797794\n",
      "Iteration:  1100 , loss:  0.017281864\n",
      "Iteration:  1200 , loss:  0.016801955\n",
      "Iteration:  1300 , loss:  0.016282177\n",
      "Iteration:  1400 , loss:  0.015785582\n",
      "Iteration:  1500 , loss:  0.015314003\n",
      "Iteration:  1600 , loss:  0.0149149215\n",
      "Iteration:  1700 , loss:  0.014448838\n",
      "Iteration:  1800 , loss:  0.014049518\n",
      "Iteration:  1900 , loss:  0.013697041\n",
      "Iteration:  2000 , loss:  0.0132831875\n",
      "Iteration:  2100 , loss:  0.012943024\n",
      "Iteration:  2200 , loss:  0.012632415\n",
      "Iteration:  2300 , loss:  0.012357222\n",
      "Iteration:  2400 , loss:  0.012094206\n",
      "Iteration:  2500 , loss:  0.012058233\n",
      "Iteration:  2600 , loss:  0.011603835\n",
      "Iteration:  2700 , loss:  0.011373492\n",
      "Iteration:  2800 , loss:  0.011168897\n",
      "Iteration:  2900 , loss:  0.010973378\n",
      "Iteration:  3000 , loss:  0.010784196\n",
      "Iteration:  3100 , loss:  0.010611434\n",
      "Iteration:  3200 , loss:  0.010436455\n",
      "Iteration:  3300 , loss:  0.010256544\n",
      "Iteration:  3400 , loss:  0.010088649\n",
      "Iteration:  3500 , loss:  0.009915354\n",
      "Iteration:  3600 , loss:  0.0097386595\n",
      "Iteration:  3700 , loss:  0.009562991\n",
      "Iteration:  3800 , loss:  0.009365482\n",
      "Iteration:  3900 , loss:  0.012089591\n",
      "Iteration:  4000 , loss:  0.008955518\n",
      "Iteration:  4100 , loss:  0.008778553\n",
      "Iteration:  4200 , loss:  0.008612366\n",
      "Iteration:  4300 , loss:  0.008453536\n",
      "Iteration:  4400 , loss:  0.008282054\n",
      "Iteration:  4500 , loss:  0.009052799\n",
      "Iteration:  4600 , loss:  0.007913254\n",
      "Iteration:  4700 , loss:  0.0077137435\n",
      "Iteration:  4800 , loss:  0.007513776\n",
      "Iteration:  4900 , loss:  0.0073406324\n",
      "Iteration:  5000 , loss:  0.0071674893\n",
      "Iteration:  5100 , loss:  0.0070047877\n",
      "Iteration:  5200 , loss:  0.0068522086\n",
      "Iteration:  5300 , loss:  0.006700406\n",
      "Iteration:  5400 , loss:  0.0065549584\n",
      "Iteration:  5500 , loss:  0.0064059217\n",
      "Iteration:  5600 , loss:  0.0062639434\n",
      "Iteration:  5700 , loss:  0.0061234687\n",
      "Iteration:  5800 , loss:  0.0059938245\n",
      "Iteration:  5900 , loss:  0.0058638393\n",
      "Iteration:  6000 , loss:  0.0057300404\n",
      "Iteration:  6100 , loss:  0.005596745\n",
      "Iteration:  6200 , loss:  0.0054562804\n",
      "Iteration:  6300 , loss:  0.005886545\n",
      "Iteration:  6400 , loss:  0.0051650223\n",
      "Iteration:  6500 , loss:  0.0050150603\n",
      "Iteration:  6600 , loss:  0.004875401\n",
      "Iteration:  6700 , loss:  0.0047197784\n",
      "Iteration:  6800 , loss:  0.004566861\n",
      "Iteration:  6900 , loss:  0.0044177305\n",
      "Iteration:  7000 , loss:  0.004270193\n",
      "Iteration:  7100 , loss:  0.004119956\n",
      "Iteration:  7200 , loss:  0.0039802776\n",
      "Iteration:  7300 , loss:  0.0038429224\n",
      "Iteration:  7400 , loss:  0.0037362059\n",
      "Iteration:  7500 , loss:  0.0035867332\n",
      "Iteration:  7600 , loss:  0.0034681398\n",
      "Iteration:  7700 , loss:  0.0033592326\n",
      "Iteration:  7800 , loss:  0.003255512\n",
      "Iteration:  7900 , loss:  0.0031557675\n",
      "Iteration:  8000 , loss:  0.0030624615\n",
      "Iteration:  8100 , loss:  0.0030926906\n",
      "Iteration:  8200 , loss:  0.0029126918\n",
      "Iteration:  8300 , loss:  0.002811146\n",
      "Iteration:  8400 , loss:  0.0027288178\n",
      "Iteration:  8500 , loss:  0.0026528728\n",
      "Iteration:  8600 , loss:  0.002579373\n",
      "Iteration:  8700 , loss:  0.002514446\n",
      "Iteration:  8800 , loss:  0.0026485582\n",
      "Iteration:  8900 , loss:  0.0023711927\n",
      "Iteration:  9000 , loss:  0.0023101722\n",
      "Iteration:  9100 , loss:  0.0022501843\n",
      "Iteration:  9200 , loss:  0.002195194\n",
      "Iteration:  9300 , loss:  0.0023414216\n",
      "Iteration:  9400 , loss:  0.002137392\n",
      "Iteration:  9500 , loss:  0.0021867135\n",
      "Iteration:  9600 , loss:  0.001992284\n",
      "Iteration:  9700 , loss:  0.0019464333\n",
      "Iteration:  9800 , loss:  0.002088706\n",
      "Iteration:  9900 , loss:  0.0018601259\n",
      "Iteration:  10000 , loss:  0.0020067368\n",
      "Iteration:  10100 , loss:  0.0017740709\n",
      "Iteration:  10200 , loss:  0.0017346602\n",
      "Iteration:  10300 , loss:  0.0017062296\n",
      "Iteration:  10400 , loss:  0.0016579151\n",
      "Iteration:  10500 , loss:  0.0016544855\n",
      "Iteration:  10600 , loss:  0.0015946332\n",
      "Iteration:  10700 , loss:  0.0015508577\n",
      "Iteration:  10800 , loss:  0.0015516888\n",
      "Iteration:  10900 , loss:  0.0014932813\n",
      "Iteration:  11000 , loss:  0.001466926\n",
      "Iteration:  11100 , loss:  0.0014435517\n",
      "Iteration:  11200 , loss:  0.0014178911\n",
      "Iteration:  11300 , loss:  0.001380475\n",
      "Iteration:  11400 , loss:  0.0014876922\n",
      "Iteration:  11500 , loss:  0.0014956433\n",
      "Iteration:  11600 , loss:  0.0013236178\n",
      "Iteration:  11700 , loss:  0.0012908798\n",
      "Iteration:  11800 , loss:  0.0013135206\n",
      "Iteration:  11900 , loss:  0.0012583293\n",
      "Iteration:  12000 , loss:  0.0012331532\n",
      "Iteration:  12100 , loss:  0.0012362166\n",
      "Iteration:  12200 , loss:  0.0011901597\n",
      "Iteration:  12300 , loss:  0.0011728657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  12400 , loss:  0.0013443205\n",
      "Iteration:  12500 , loss:  0.0012023305\n",
      "Iteration:  12600 , loss:  0.0014641811\n",
      "Iteration:  12700 , loss:  0.0011091204\n",
      "Iteration:  12800 , loss:  0.0010953031\n",
      "Iteration:  12900 , loss:  0.0013140341\n",
      "Iteration:  13000 , loss:  0.0010678291\n",
      "Iteration:  13100 , loss:  0.0011374175\n",
      "Iteration:  13200 , loss:  0.001091185\n",
      "Iteration:  13300 , loss:  0.0010881855\n",
      "Iteration:  13400 , loss:  0.0010299953\n",
      "Iteration:  13500 , loss:  0.0009995163\n",
      "Iteration:  13600 , loss:  0.0010758518\n",
      "Iteration:  13700 , loss:  0.0009795028\n",
      "Iteration:  13800 , loss:  0.0009681593\n",
      "Iteration:  13900 , loss:  0.0009632003\n",
      "Iteration:  14000 , loss:  0.0009385339\n",
      "Iteration:  14100 , loss:  0.0009222765\n",
      "Iteration:  14200 , loss:  0.0010147151\n",
      "Iteration:  14300 , loss:  0.000986307\n",
      "Iteration:  14400 , loss:  0.0008900675\n",
      "Iteration:  14500 , loss:  0.000887763\n",
      "Iteration:  14600 , loss:  0.00089250633\n",
      "Iteration:  14700 , loss:  0.00087294274\n",
      "Iteration:  14800 , loss:  0.0008837661\n",
      "Iteration:  14900 , loss:  0.0008342497\n",
      "Iteration:  15000 , loss:  0.0009277252\n",
      "Iteration:  15100 , loss:  0.000809199\n",
      "Iteration:  15200 , loss:  0.00080061477\n",
      "Iteration:  15300 , loss:  0.0007911939\n",
      "Iteration:  15400 , loss:  0.00078095536\n",
      "Iteration:  15500 , loss:  0.0008345972\n",
      "Iteration:  15600 , loss:  0.000783489\n",
      "Iteration:  15700 , loss:  0.0007569491\n",
      "Iteration:  15800 , loss:  0.0007980056\n",
      "Iteration:  15900 , loss:  0.00081628514\n",
      "Iteration:  16000 , loss:  0.0008208907\n",
      "Iteration:  16100 , loss:  0.0010037035\n",
      "Iteration:  16200 , loss:  0.0007027939\n",
      "Iteration:  16300 , loss:  0.0007195546\n",
      "Iteration:  16400 , loss:  0.0007017567\n",
      "Iteration:  16500 , loss:  0.0007234968\n",
      "Iteration:  16600 , loss:  0.0007227139\n",
      "Iteration:  16700 , loss:  0.0006608329\n",
      "Iteration:  16800 , loss:  0.0006536019\n",
      "Iteration:  16900 , loss:  0.0006465438\n",
      "Iteration:  17000 , loss:  0.00063728704\n",
      "Iteration:  17100 , loss:  0.0006674248\n",
      "Iteration:  17200 , loss:  0.0006414815\n",
      "Iteration:  17300 , loss:  0.0008617082\n",
      "Iteration:  17400 , loss:  0.0006555785\n",
      "Iteration:  17500 , loss:  0.0009098367\n",
      "Iteration:  17600 , loss:  0.00059309846\n",
      "Iteration:  17700 , loss:  0.0005886125\n",
      "Iteration:  17800 , loss:  0.0005807404\n",
      "Iteration:  17900 , loss:  0.0005892782\n",
      "Iteration:  18000 , loss:  0.00057077187\n",
      "Iteration:  18100 , loss:  0.0005836061\n",
      "Iteration:  18200 , loss:  0.0005578897\n",
      "Iteration:  18300 , loss:  0.0006406985\n",
      "Iteration:  18400 , loss:  0.0005468811\n",
      "Iteration:  18500 , loss:  0.00057300925\n",
      "Iteration:  18600 , loss:  0.00053282303\n",
      "Iteration:  18700 , loss:  0.0005326476\n",
      "Iteration:  18800 , loss:  0.00051972974\n",
      "Iteration:  18900 , loss:  0.0005357586\n",
      "Iteration:  19000 , loss:  0.00079879485\n",
      "Iteration:  19100 , loss:  0.000715425\n",
      "Iteration:  19200 , loss:  0.0010901949\n",
      "Iteration:  19300 , loss:  0.00049472874\n",
      "Iteration:  19400 , loss:  0.00054227974\n",
      "Iteration:  19500 , loss:  0.0005037986\n",
      "Iteration:  19600 , loss:  0.0005634912\n",
      "Iteration:  19700 , loss:  0.00053630944\n",
      "Iteration:  19800 , loss:  0.0004732801\n",
      "Iteration:  19900 , loss:  0.0008540916\n",
      "Generating 15th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.09850967\n",
      "Iteration:  100 , loss:  0.026130231\n",
      "Iteration:  200 , loss:  0.023238556\n",
      "Iteration:  300 , loss:  0.021930162\n",
      "Iteration:  400 , loss:  0.020933164\n",
      "Iteration:  500 , loss:  0.020042207\n",
      "Iteration:  600 , loss:  0.019147234\n",
      "Iteration:  700 , loss:  0.01826533\n",
      "Iteration:  800 , loss:  0.017401744\n",
      "Iteration:  900 , loss:  0.016550371\n",
      "Iteration:  1000 , loss:  0.0157252\n",
      "Iteration:  1100 , loss:  0.015028947\n",
      "Iteration:  1200 , loss:  0.014309154\n",
      "Iteration:  1300 , loss:  0.013537213\n",
      "Iteration:  1400 , loss:  0.013829616\n",
      "Iteration:  1500 , loss:  0.012494128\n",
      "Iteration:  1600 , loss:  0.012135014\n",
      "Iteration:  1700 , loss:  0.01175167\n",
      "Iteration:  1800 , loss:  0.011567796\n",
      "Iteration:  1900 , loss:  0.01113525\n",
      "Iteration:  2000 , loss:  0.011174183\n",
      "Iteration:  2100 , loss:  0.0105668325\n",
      "Iteration:  2200 , loss:  0.010267811\n",
      "Iteration:  2300 , loss:  0.009965925\n",
      "Iteration:  2400 , loss:  0.00965205\n",
      "Iteration:  2500 , loss:  0.009328082\n",
      "Iteration:  2600 , loss:  0.009022849\n",
      "Iteration:  2700 , loss:  0.008724388\n",
      "Iteration:  2800 , loss:  0.008832626\n",
      "Iteration:  2900 , loss:  0.008210578\n",
      "Iteration:  3000 , loss:  0.007996614\n",
      "Iteration:  3100 , loss:  0.008022412\n",
      "Iteration:  3200 , loss:  0.007618946\n",
      "Iteration:  3300 , loss:  0.0074360226\n",
      "Iteration:  3400 , loss:  0.008182776\n",
      "Iteration:  3500 , loss:  0.007075396\n",
      "Iteration:  3600 , loss:  0.006895535\n",
      "Iteration:  3700 , loss:  0.0067256484\n",
      "Iteration:  3800 , loss:  0.006557828\n",
      "Iteration:  3900 , loss:  0.0063923257\n",
      "Iteration:  4000 , loss:  0.006240433\n",
      "Iteration:  4100 , loss:  0.006090166\n",
      "Iteration:  4200 , loss:  0.0059387553\n",
      "Iteration:  4300 , loss:  0.0057982393\n",
      "Iteration:  4400 , loss:  0.0056553986\n",
      "Iteration:  4500 , loss:  0.0055241473\n",
      "Iteration:  4600 , loss:  0.0053757015\n",
      "Iteration:  4700 , loss:  0.006196785\n",
      "Iteration:  4800 , loss:  0.0050946753\n",
      "Iteration:  4900 , loss:  0.004952943\n",
      "Iteration:  5000 , loss:  0.004867507\n",
      "Iteration:  5100 , loss:  0.004694063\n",
      "Iteration:  5200 , loss:  0.004570609\n",
      "Iteration:  5300 , loss:  0.0045487685\n",
      "Iteration:  5400 , loss:  0.004342195\n",
      "Iteration:  5500 , loss:  0.0042308196\n",
      "Iteration:  5600 , loss:  0.0041285916\n",
      "Iteration:  5700 , loss:  0.004028004\n",
      "Iteration:  5800 , loss:  0.004565031\n",
      "Iteration:  5900 , loss:  0.003847273\n",
      "Iteration:  6000 , loss:  0.003763751\n",
      "Iteration:  6100 , loss:  0.0044073733\n",
      "Iteration:  6200 , loss:  0.0036075606\n",
      "Iteration:  6300 , loss:  0.003532899\n",
      "Iteration:  6400 , loss:  0.0034666639\n",
      "Iteration:  6500 , loss:  0.0033977695\n",
      "Iteration:  6600 , loss:  0.0033511468\n",
      "Iteration:  6700 , loss:  0.0032703385\n",
      "Iteration:  6800 , loss:  0.0032076198\n",
      "Iteration:  6900 , loss:  0.0031522731\n",
      "Iteration:  7000 , loss:  0.0030868223\n",
      "Iteration:  7100 , loss:  0.0036093798\n",
      "Iteration:  7200 , loss:  0.0029662012\n",
      "Iteration:  7300 , loss:  0.002904444\n",
      "Iteration:  7400 , loss:  0.0028469963\n",
      "Iteration:  7500 , loss:  0.0027856866\n",
      "Iteration:  7600 , loss:  0.0028508229\n",
      "Iteration:  7700 , loss:  0.0026618012\n",
      "Iteration:  7800 , loss:  0.0026022051\n",
      "Iteration:  7900 , loss:  0.002650477\n",
      "Iteration:  8000 , loss:  0.0024794233\n",
      "Iteration:  8100 , loss:  0.0024210664\n",
      "Iteration:  8200 , loss:  0.0024305324\n",
      "Iteration:  8300 , loss:  0.0023195103\n",
      "Iteration:  8400 , loss:  0.0022478944\n",
      "Iteration:  8500 , loss:  0.0021950784\n",
      "Iteration:  8600 , loss:  0.0021411127\n",
      "Iteration:  8700 , loss:  0.0020909945\n",
      "Iteration:  8800 , loss:  0.002757765\n",
      "Iteration:  8900 , loss:  0.0019945155\n",
      "Iteration:  9000 , loss:  0.001978578\n",
      "Iteration:  9100 , loss:  0.0019065713\n",
      "Iteration:  9200 , loss:  0.0018668782\n",
      "Iteration:  9300 , loss:  0.0018259677\n",
      "Iteration:  9400 , loss:  0.0017866921\n",
      "Iteration:  9500 , loss:  0.001752633\n",
      "Iteration:  9600 , loss:  0.0017161699\n",
      "Iteration:  9700 , loss:  0.0016980775\n",
      "Iteration:  9800 , loss:  0.0016496442\n",
      "Iteration:  9900 , loss:  0.0022387707\n",
      "Iteration:  10000 , loss:  0.0015862563\n",
      "Iteration:  10100 , loss:  0.0015697693\n",
      "Iteration:  10200 , loss:  0.0015261972\n",
      "Iteration:  10300 , loss:  0.0015040124\n",
      "Iteration:  10400 , loss:  0.001476635\n",
      "Iteration:  10500 , loss:  0.0014405544\n",
      "Iteration:  10600 , loss:  0.0014598704\n",
      "Iteration:  10700 , loss:  0.0015148419\n",
      "Iteration:  10800 , loss:  0.0013600921\n",
      "Iteration:  10900 , loss:  0.0013369813\n",
      "Iteration:  11000 , loss:  0.0013089224\n",
      "Iteration:  11100 , loss:  0.0012857751\n",
      "Iteration:  11200 , loss:  0.001261187\n",
      "Iteration:  11300 , loss:  0.0012399491\n",
      "Iteration:  11400 , loss:  0.0012174678\n",
      "Iteration:  11500 , loss:  0.0012571672\n",
      "Iteration:  11600 , loss:  0.001180475\n",
      "Iteration:  11700 , loss:  0.0011578321\n",
      "Iteration:  11800 , loss:  0.001142501\n",
      "Iteration:  11900 , loss:  0.0020327393\n",
      "Iteration:  12000 , loss:  0.0011046677\n",
      "Iteration:  12100 , loss:  0.0011411585\n",
      "Iteration:  12200 , loss:  0.0010731864\n",
      "Iteration:  12300 , loss:  0.0014216364\n",
      "Iteration:  12400 , loss:  0.0010439301\n",
      "Iteration:  12500 , loss:  0.0010292353\n",
      "Iteration:  12600 , loss:  0.0010941371\n",
      "Iteration:  12700 , loss:  0.0018123828\n",
      "Iteration:  12800 , loss:  0.0009877235\n",
      "Iteration:  12900 , loss:  0.0009817942\n",
      "Iteration:  13000 , loss:  0.0012837179\n",
      "Iteration:  13100 , loss:  0.0009490814\n",
      "Iteration:  13200 , loss:  0.00094200124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  13300 , loss:  0.0009243384\n",
      "Iteration:  13400 , loss:  0.0009133456\n",
      "Iteration:  13500 , loss:  0.0009409039\n",
      "Iteration:  13600 , loss:  0.0008887979\n",
      "Iteration:  13700 , loss:  0.00087972387\n",
      "Iteration:  13800 , loss:  0.0020527365\n",
      "Iteration:  13900 , loss:  0.0008554232\n",
      "Iteration:  14000 , loss:  0.001080593\n",
      "Iteration:  14100 , loss:  0.00083343766\n",
      "Iteration:  14200 , loss:  0.000823743\n",
      "Iteration:  14300 , loss:  0.00081197807\n",
      "Iteration:  14400 , loss:  0.0008025111\n",
      "Iteration:  14500 , loss:  0.0007917887\n",
      "Iteration:  14600 , loss:  0.0007833286\n",
      "Iteration:  14700 , loss:  0.0007720755\n",
      "Iteration:  14800 , loss:  0.0007711469\n",
      "Iteration:  14900 , loss:  0.00075299444\n",
      "Iteration:  15000 , loss:  0.00083082425\n",
      "Iteration:  15100 , loss:  0.0007343419\n",
      "Iteration:  15200 , loss:  0.0007298066\n",
      "Iteration:  15300 , loss:  0.0007161314\n",
      "Iteration:  15400 , loss:  0.0007125052\n",
      "Iteration:  15500 , loss:  0.0007007627\n",
      "Iteration:  15600 , loss:  0.0010046607\n",
      "Iteration:  15700 , loss:  0.0006817943\n",
      "Iteration:  15800 , loss:  0.0007863005\n",
      "Iteration:  15900 , loss:  0.0006777181\n",
      "Iteration:  16000 , loss:  0.0006656668\n",
      "Iteration:  16100 , loss:  0.0006496223\n",
      "Iteration:  16200 , loss:  0.0006423814\n",
      "Iteration:  16300 , loss:  0.0006409924\n",
      "Iteration:  16400 , loss:  0.0006275691\n",
      "Iteration:  16500 , loss:  0.00062011596\n",
      "Iteration:  16600 , loss:  0.00061954535\n",
      "Iteration:  16700 , loss:  0.00060624204\n",
      "Iteration:  16800 , loss:  0.00060203136\n",
      "Iteration:  16900 , loss:  0.00059266976\n",
      "Iteration:  17000 , loss:  0.00058680994\n",
      "Iteration:  17100 , loss:  0.0005796063\n",
      "Iteration:  17200 , loss:  0.00057462667\n",
      "Iteration:  17300 , loss:  0.0016198182\n",
      "Iteration:  17400 , loss:  0.0005608266\n",
      "Iteration:  17500 , loss:  0.0005574871\n",
      "Iteration:  17600 , loss:  0.0005697106\n",
      "Iteration:  17700 , loss:  0.00054323976\n",
      "Iteration:  17800 , loss:  0.0005375384\n",
      "Iteration:  17900 , loss:  0.0005321466\n",
      "Iteration:  18000 , loss:  0.0006025062\n",
      "Iteration:  18100 , loss:  0.0005535837\n",
      "Iteration:  18200 , loss:  0.0006037988\n",
      "Iteration:  18300 , loss:  0.00052190135\n",
      "Iteration:  18400 , loss:  0.0005051601\n",
      "Iteration:  18500 , loss:  0.0005078454\n",
      "Iteration:  18600 , loss:  0.0004960639\n",
      "Iteration:  18700 , loss:  0.00050642324\n",
      "Iteration:  18800 , loss:  0.00049448584\n",
      "Iteration:  18900 , loss:  0.0005247075\n",
      "Iteration:  19000 , loss:  0.0004761875\n",
      "Iteration:  19100 , loss:  0.00047231442\n",
      "Iteration:  19200 , loss:  0.00046894595\n",
      "Iteration:  19300 , loss:  0.0004639856\n",
      "Iteration:  19400 , loss:  0.0004770212\n",
      "Iteration:  19500 , loss:  0.00050036586\n",
      "Iteration:  19600 , loss:  0.0005035936\n",
      "Iteration:  19700 , loss:  0.0007199469\n",
      "Iteration:  19800 , loss:  0.0004415975\n",
      "Iteration:  19900 , loss:  0.00043822816\n",
      "Generating 16th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.14178869\n",
      "Iteration:  100 , loss:  0.026421279\n",
      "Iteration:  200 , loss:  0.02288245\n",
      "Iteration:  300 , loss:  0.02177003\n",
      "Iteration:  400 , loss:  0.020895395\n",
      "Iteration:  500 , loss:  0.020128319\n",
      "Iteration:  600 , loss:  0.019446053\n",
      "Iteration:  700 , loss:  0.018802715\n",
      "Iteration:  800 , loss:  0.018087734\n",
      "Iteration:  900 , loss:  0.017253239\n",
      "Iteration:  1000 , loss:  0.01640044\n",
      "Iteration:  1100 , loss:  0.01590841\n",
      "Iteration:  1200 , loss:  0.0155700315\n",
      "Iteration:  1300 , loss:  0.015238576\n",
      "Iteration:  1400 , loss:  0.014898133\n",
      "Iteration:  1500 , loss:  0.014524026\n",
      "Iteration:  1600 , loss:  0.0140905585\n",
      "Iteration:  1700 , loss:  0.013618826\n",
      "Iteration:  1800 , loss:  0.013109631\n",
      "Iteration:  1900 , loss:  0.012619561\n",
      "Iteration:  2000 , loss:  0.012148177\n",
      "Iteration:  2100 , loss:  0.011821997\n",
      "Iteration:  2200 , loss:  0.01124461\n",
      "Iteration:  2300 , loss:  0.010837054\n",
      "Iteration:  2400 , loss:  0.010483174\n",
      "Iteration:  2500 , loss:  0.01012744\n",
      "Iteration:  2600 , loss:  0.009776423\n",
      "Iteration:  2700 , loss:  0.009435626\n",
      "Iteration:  2800 , loss:  0.009130508\n",
      "Iteration:  2900 , loss:  0.008868179\n",
      "Iteration:  3000 , loss:  0.008619154\n",
      "Iteration:  3100 , loss:  0.008390826\n",
      "Iteration:  3200 , loss:  0.0081636\n",
      "Iteration:  3300 , loss:  0.00793806\n",
      "Iteration:  3400 , loss:  0.0077087237\n",
      "Iteration:  3500 , loss:  0.0074680885\n",
      "Iteration:  3600 , loss:  0.007243472\n",
      "Iteration:  3700 , loss:  0.007029178\n",
      "Iteration:  3800 , loss:  0.0069706477\n",
      "Iteration:  3900 , loss:  0.0066360896\n",
      "Iteration:  4000 , loss:  0.006447538\n",
      "Iteration:  4100 , loss:  0.0062687057\n",
      "Iteration:  4200 , loss:  0.006093103\n",
      "Iteration:  4300 , loss:  0.005925858\n",
      "Iteration:  4400 , loss:  0.0057645394\n",
      "Iteration:  4500 , loss:  0.0056125335\n",
      "Iteration:  4600 , loss:  0.005480247\n",
      "Iteration:  4700 , loss:  0.0053365966\n",
      "Iteration:  4800 , loss:  0.0052030203\n",
      "Iteration:  4900 , loss:  0.0050751735\n",
      "Iteration:  5000 , loss:  0.004944316\n",
      "Iteration:  5100 , loss:  0.0048721465\n",
      "Iteration:  5200 , loss:  0.004689172\n",
      "Iteration:  5300 , loss:  0.004559198\n",
      "Iteration:  5400 , loss:  0.0044366214\n",
      "Iteration:  5500 , loss:  0.004299761\n",
      "Iteration:  5600 , loss:  0.0041667027\n",
      "Iteration:  5700 , loss:  0.004039363\n",
      "Iteration:  5800 , loss:  0.003909718\n",
      "Iteration:  5900 , loss:  0.003886222\n",
      "Iteration:  6000 , loss:  0.0036528918\n",
      "Iteration:  6100 , loss:  0.0035228867\n",
      "Iteration:  6200 , loss:  0.0034001605\n",
      "Iteration:  6300 , loss:  0.0032792594\n",
      "Iteration:  6400 , loss:  0.003164348\n",
      "Iteration:  6500 , loss:  0.0030512258\n",
      "Iteration:  6600 , loss:  0.002954168\n",
      "Iteration:  6700 , loss:  0.002843612\n",
      "Iteration:  6800 , loss:  0.0027461192\n",
      "Iteration:  6900 , loss:  0.0026564952\n",
      "Iteration:  7000 , loss:  0.0025784806\n",
      "Iteration:  7100 , loss:  0.0024960707\n",
      "Iteration:  7200 , loss:  0.0025478036\n",
      "Iteration:  7300 , loss:  0.0023404658\n",
      "Iteration:  7400 , loss:  0.0022701651\n",
      "Iteration:  7500 , loss:  0.0022033935\n",
      "Iteration:  7600 , loss:  0.0021587445\n",
      "Iteration:  7700 , loss:  0.0020808692\n",
      "Iteration:  7800 , loss:  0.0020468007\n",
      "Iteration:  7900 , loss:  0.002002092\n",
      "Iteration:  8000 , loss:  0.00207414\n",
      "Iteration:  8100 , loss:  0.0018613762\n",
      "Iteration:  8200 , loss:  0.0018091339\n",
      "Iteration:  8300 , loss:  0.0018313429\n",
      "Iteration:  8400 , loss:  0.001720621\n",
      "Iteration:  8500 , loss:  0.001669586\n",
      "Iteration:  8600 , loss:  0.001627687\n",
      "Iteration:  8700 , loss:  0.0015878162\n",
      "Iteration:  8800 , loss:  0.0015491153\n",
      "Iteration:  8900 , loss:  0.0016178893\n",
      "Iteration:  9000 , loss:  0.0014781632\n",
      "Iteration:  9100 , loss:  0.0017264405\n",
      "Iteration:  9200 , loss:  0.0014202992\n",
      "Iteration:  9300 , loss:  0.0013883817\n",
      "Iteration:  9400 , loss:  0.0014279621\n",
      "Iteration:  9500 , loss:  0.001335472\n",
      "Iteration:  9600 , loss:  0.00131573\n",
      "Iteration:  9700 , loss:  0.0012801866\n",
      "Iteration:  9800 , loss:  0.0012433997\n",
      "Iteration:  9900 , loss:  0.001486529\n",
      "Iteration:  10000 , loss:  0.0012058843\n",
      "Iteration:  10100 , loss:  0.0011722981\n",
      "Iteration:  10200 , loss:  0.0011461129\n",
      "Iteration:  10300 , loss:  0.0012682206\n",
      "Iteration:  10400 , loss:  0.0011777548\n",
      "Iteration:  10500 , loss:  0.0010788873\n",
      "Iteration:  10600 , loss:  0.0010627875\n",
      "Iteration:  10700 , loss:  0.0010382942\n",
      "Iteration:  10800 , loss:  0.0012164415\n",
      "Iteration:  10900 , loss:  0.0010122391\n",
      "Iteration:  11000 , loss:  0.0009813163\n",
      "Iteration:  11100 , loss:  0.0010680454\n",
      "Iteration:  11200 , loss:  0.0011099664\n",
      "Iteration:  11300 , loss:  0.0009593996\n",
      "Iteration:  11400 , loss:  0.00092996313\n",
      "Iteration:  11500 , loss:  0.00089741545\n",
      "Iteration:  11600 , loss:  0.0008773791\n",
      "Iteration:  11700 , loss:  0.00086021813\n",
      "Iteration:  11800 , loss:  0.00084647944\n",
      "Iteration:  11900 , loss:  0.0008291539\n",
      "Iteration:  12000 , loss:  0.0008217987\n",
      "Iteration:  12100 , loss:  0.0008022067\n",
      "Iteration:  12200 , loss:  0.0007868014\n",
      "Iteration:  12300 , loss:  0.000773163\n",
      "Iteration:  12400 , loss:  0.00075938646\n",
      "Iteration:  12500 , loss:  0.00079547573\n",
      "Iteration:  12600 , loss:  0.0007316827\n",
      "Iteration:  12700 , loss:  0.00072973006\n",
      "Iteration:  12800 , loss:  0.00070724334\n",
      "Iteration:  12900 , loss:  0.00080575055\n",
      "Iteration:  13000 , loss:  0.00068398507\n",
      "Iteration:  13100 , loss:  0.001138504\n",
      "Iteration:  13200 , loss:  0.0007776099\n",
      "Iteration:  13300 , loss:  0.00065234787\n",
      "Iteration:  13400 , loss:  0.0007418564\n",
      "Iteration:  13500 , loss:  0.0006328381\n",
      "Iteration:  13600 , loss:  0.0007606841\n",
      "Iteration:  13700 , loss:  0.00060827134\n",
      "Iteration:  13800 , loss:  0.0005995656\n",
      "Iteration:  13900 , loss:  0.00059645926\n",
      "Iteration:  14000 , loss:  0.00058044103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  14100 , loss:  0.00064696895\n",
      "Iteration:  14200 , loss:  0.0006704949\n",
      "Iteration:  14300 , loss:  0.00055933686\n",
      "Iteration:  14400 , loss:  0.00096319104\n",
      "Iteration:  14500 , loss:  0.000576565\n",
      "Iteration:  14600 , loss:  0.0005410894\n",
      "Iteration:  14700 , loss:  0.00055826944\n",
      "Iteration:  14800 , loss:  0.0005333365\n",
      "Iteration:  14900 , loss:  0.0007128986\n",
      "Iteration:  15000 , loss:  0.0006155635\n",
      "Iteration:  15100 , loss:  0.0005262374\n",
      "Iteration:  15200 , loss:  0.0004883711\n",
      "Iteration:  15300 , loss:  0.00056468335\n",
      "Iteration:  15400 , loss:  0.0005450204\n",
      "Iteration:  15500 , loss:  0.000505149\n",
      "Iteration:  15600 , loss:  0.0005269644\n",
      "Iteration:  15700 , loss:  0.0005240336\n",
      "Iteration:  15800 , loss:  0.000464031\n",
      "Iteration:  15900 , loss:  0.00044599743\n",
      "Iteration:  16000 , loss:  0.0004402589\n",
      "Iteration:  16100 , loss:  0.00043542945\n",
      "Iteration:  16200 , loss:  0.00062057487\n",
      "Iteration:  16300 , loss:  0.00042551855\n",
      "Iteration:  16400 , loss:  0.00045374632\n",
      "Iteration:  16500 , loss:  0.00041666222\n",
      "Iteration:  16600 , loss:  0.00041405577\n",
      "Iteration:  16700 , loss:  0.00040664722\n",
      "Iteration:  16800 , loss:  0.00041045036\n",
      "Iteration:  16900 , loss:  0.00042663154\n",
      "Iteration:  17000 , loss:  0.00039650334\n",
      "Iteration:  17100 , loss:  0.00041042338\n",
      "Iteration:  17200 , loss:  0.00039262505\n",
      "Iteration:  17300 , loss:  0.0004971021\n",
      "Iteration:  17400 , loss:  0.0003846896\n",
      "Iteration:  17500 , loss:  0.00037788376\n",
      "Iteration:  17600 , loss:  0.0003900168\n",
      "Iteration:  17700 , loss:  0.00039061753\n",
      "Iteration:  17800 , loss:  0.00047750186\n",
      "Iteration:  17900 , loss:  0.0003849205\n",
      "Iteration:  18000 , loss:  0.0003830461\n",
      "Iteration:  18100 , loss:  0.0003675532\n",
      "Iteration:  18200 , loss:  0.00040606086\n",
      "Iteration:  18300 , loss:  0.00034910865\n",
      "Iteration:  18400 , loss:  0.00041191236\n",
      "Iteration:  18500 , loss:  0.00037327255\n",
      "Iteration:  18600 , loss:  0.00034092125\n",
      "Iteration:  18700 , loss:  0.0003945599\n",
      "Iteration:  18800 , loss:  0.0003332267\n",
      "Iteration:  18900 , loss:  0.00033903954\n",
      "Iteration:  19000 , loss:  0.00033294377\n",
      "Iteration:  19100 , loss:  0.0003525775\n",
      "Iteration:  19200 , loss:  0.00035124907\n",
      "Iteration:  19300 , loss:  0.00032184328\n",
      "Iteration:  19400 , loss:  0.0003611932\n",
      "Iteration:  19500 , loss:  0.00033175616\n",
      "Iteration:  19600 , loss:  0.00033428302\n",
      "Iteration:  19700 , loss:  0.00040908923\n",
      "Iteration:  19800 , loss:  0.00030788386\n",
      "Iteration:  19900 , loss:  0.00040169383\n",
      "Generating 17th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.09059969\n",
      "Iteration:  100 , loss:  0.029674362\n",
      "Iteration:  200 , loss:  0.024315767\n",
      "Iteration:  300 , loss:  0.022717372\n",
      "Iteration:  400 , loss:  0.02178416\n",
      "Iteration:  500 , loss:  0.021021925\n",
      "Iteration:  600 , loss:  0.020268135\n",
      "Iteration:  700 , loss:  0.019537656\n",
      "Iteration:  800 , loss:  0.018824005\n",
      "Iteration:  900 , loss:  0.018121876\n",
      "Iteration:  1000 , loss:  0.017466405\n",
      "Iteration:  1100 , loss:  0.01679406\n",
      "Iteration:  1200 , loss:  0.01596614\n",
      "Iteration:  1300 , loss:  0.015093719\n",
      "Iteration:  1400 , loss:  0.014368185\n",
      "Iteration:  1500 , loss:  0.013821856\n",
      "Iteration:  1600 , loss:  0.013233833\n",
      "Iteration:  1700 , loss:  0.013060302\n",
      "Iteration:  1800 , loss:  0.012382898\n",
      "Iteration:  1900 , loss:  0.012014614\n",
      "Iteration:  2000 , loss:  0.011696079\n",
      "Iteration:  2100 , loss:  0.011379621\n",
      "Iteration:  2200 , loss:  0.011067054\n",
      "Iteration:  2300 , loss:  0.0107176425\n",
      "Iteration:  2400 , loss:  0.010447672\n",
      "Iteration:  2500 , loss:  0.010033658\n",
      "Iteration:  2600 , loss:  0.009716061\n",
      "Iteration:  2700 , loss:  0.009405547\n",
      "Iteration:  2800 , loss:  0.009090336\n",
      "Iteration:  2900 , loss:  0.008786562\n",
      "Iteration:  3000 , loss:  0.008516576\n",
      "Iteration:  3100 , loss:  0.008252474\n",
      "Iteration:  3200 , loss:  0.008639486\n",
      "Iteration:  3300 , loss:  0.007797801\n",
      "Iteration:  3400 , loss:  0.0075964793\n",
      "Iteration:  3500 , loss:  0.007410857\n",
      "Iteration:  3600 , loss:  0.0071978155\n",
      "Iteration:  3700 , loss:  0.00698968\n",
      "Iteration:  3800 , loss:  0.006789443\n",
      "Iteration:  3900 , loss:  0.0065816245\n",
      "Iteration:  4000 , loss:  0.0063808765\n",
      "Iteration:  4100 , loss:  0.006209531\n",
      "Iteration:  4200 , loss:  0.0060403966\n",
      "Iteration:  4300 , loss:  0.005889694\n",
      "Iteration:  4400 , loss:  0.0057336986\n",
      "Iteration:  4500 , loss:  0.005582601\n",
      "Iteration:  4600 , loss:  0.00543047\n",
      "Iteration:  4700 , loss:  0.005275685\n",
      "Iteration:  4800 , loss:  0.0051217442\n",
      "Iteration:  4900 , loss:  0.004986005\n",
      "Iteration:  5000 , loss:  0.004831192\n",
      "Iteration:  5100 , loss:  0.004690524\n",
      "Iteration:  5200 , loss:  0.0045601246\n",
      "Iteration:  5300 , loss:  0.0044298437\n",
      "Iteration:  5400 , loss:  0.004307919\n",
      "Iteration:  5500 , loss:  0.0041797967\n",
      "Iteration:  5600 , loss:  0.0040554553\n",
      "Iteration:  5700 , loss:  0.0042210603\n",
      "Iteration:  5800 , loss:  0.003808926\n",
      "Iteration:  5900 , loss:  0.0036871866\n",
      "Iteration:  6000 , loss:  0.0035853307\n",
      "Iteration:  6100 , loss:  0.0034515592\n",
      "Iteration:  6200 , loss:  0.0034255565\n",
      "Iteration:  6300 , loss:  0.003216491\n",
      "Iteration:  6400 , loss:  0.0031324336\n",
      "Iteration:  6500 , loss:  0.0030760972\n",
      "Iteration:  6600 , loss:  0.0029352126\n",
      "Iteration:  6700 , loss:  0.002759576\n",
      "Iteration:  6800 , loss:  0.002642573\n",
      "Iteration:  6900 , loss:  0.00255174\n",
      "Iteration:  7000 , loss:  0.00246927\n",
      "Iteration:  7100 , loss:  0.0023947563\n",
      "Iteration:  7200 , loss:  0.0023955822\n",
      "Iteration:  7300 , loss:  0.0025282693\n",
      "Iteration:  7400 , loss:  0.0022512726\n",
      "Iteration:  7500 , loss:  0.0021031876\n",
      "Iteration:  7600 , loss:  0.0020772137\n",
      "Iteration:  7700 , loss:  0.0019657188\n",
      "Iteration:  7800 , loss:  0.0019047898\n",
      "Iteration:  7900 , loss:  0.0018461853\n",
      "Iteration:  8000 , loss:  0.0017910785\n",
      "Iteration:  8100 , loss:  0.0017382894\n",
      "Iteration:  8200 , loss:  0.0019134504\n",
      "Iteration:  8300 , loss:  0.001634966\n",
      "Iteration:  8400 , loss:  0.0017661636\n",
      "Iteration:  8500 , loss:  0.0016600026\n",
      "Iteration:  8600 , loss:  0.0016054534\n",
      "Iteration:  8700 , loss:  0.0014765423\n",
      "Iteration:  8800 , loss:  0.0014146211\n",
      "Iteration:  8900 , loss:  0.0013743984\n",
      "Iteration:  9000 , loss:  0.0013535909\n",
      "Iteration:  9100 , loss:  0.0016084732\n",
      "Iteration:  9200 , loss:  0.001277586\n",
      "Iteration:  9300 , loss:  0.0012326615\n",
      "Iteration:  9400 , loss:  0.0011884641\n",
      "Iteration:  9500 , loss:  0.0011662932\n",
      "Iteration:  9600 , loss:  0.0011196968\n",
      "Iteration:  9700 , loss:  0.001088074\n",
      "Iteration:  9800 , loss:  0.001060797\n",
      "Iteration:  9900 , loss:  0.0010265089\n",
      "Iteration:  10000 , loss:  0.0010014726\n",
      "Iteration:  10100 , loss:  0.0010462042\n",
      "Iteration:  10200 , loss:  0.00094182836\n",
      "Iteration:  10300 , loss:  0.000915303\n",
      "Iteration:  10400 , loss:  0.0008869898\n",
      "Iteration:  10500 , loss:  0.00086516154\n",
      "Iteration:  10600 , loss:  0.00089936267\n",
      "Iteration:  10700 , loss:  0.0010727531\n",
      "Iteration:  10800 , loss:  0.0008396041\n",
      "Iteration:  10900 , loss:  0.0007855286\n",
      "Iteration:  11000 , loss:  0.00084712845\n",
      "Iteration:  11100 , loss:  0.00074929383\n",
      "Iteration:  11200 , loss:  0.0007278476\n",
      "Iteration:  11300 , loss:  0.0007206786\n",
      "Iteration:  11400 , loss:  0.0006967279\n",
      "Iteration:  11500 , loss:  0.0006783704\n",
      "Iteration:  11600 , loss:  0.0007773333\n",
      "Iteration:  11700 , loss:  0.0006506316\n",
      "Iteration:  11800 , loss:  0.0012963898\n",
      "Iteration:  11900 , loss:  0.00062492606\n",
      "Iteration:  12000 , loss:  0.0006189718\n",
      "Iteration:  12100 , loss:  0.00060154195\n",
      "Iteration:  12200 , loss:  0.00059681863\n",
      "Iteration:  12300 , loss:  0.0005820739\n",
      "Iteration:  12400 , loss:  0.0005759194\n",
      "Iteration:  12500 , loss:  0.0005599095\n",
      "Iteration:  12600 , loss:  0.00056527054\n",
      "Iteration:  12700 , loss:  0.000541158\n",
      "Iteration:  12800 , loss:  0.0008622296\n",
      "Iteration:  12900 , loss:  0.0005236754\n",
      "Iteration:  13000 , loss:  0.00052308873\n",
      "Iteration:  13100 , loss:  0.0005074657\n",
      "Iteration:  13200 , loss:  0.0005144435\n",
      "Iteration:  13300 , loss:  0.00050756737\n",
      "Iteration:  13400 , loss:  0.0005269348\n",
      "Iteration:  13500 , loss:  0.0004785073\n",
      "Iteration:  13600 , loss:  0.0004822985\n",
      "Iteration:  13700 , loss:  0.0004690869\n",
      "Iteration:  13800 , loss:  0.00047477303\n",
      "Iteration:  13900 , loss:  0.0004908625\n",
      "Iteration:  14000 , loss:  0.0004616955\n",
      "Iteration:  14100 , loss:  0.00050022407\n",
      "Iteration:  14200 , loss:  0.0006260559\n",
      "Iteration:  14300 , loss:  0.00052058976\n",
      "Iteration:  14400 , loss:  0.0007370662\n",
      "Iteration:  14500 , loss:  0.0004214775\n",
      "Iteration:  14600 , loss:  0.00041893878\n",
      "Iteration:  14700 , loss:  0.00041316677\n",
      "Iteration:  14800 , loss:  0.00040937695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  14900 , loss:  0.000404286\n",
      "Iteration:  15000 , loss:  0.00039678466\n",
      "Iteration:  15100 , loss:  0.00039381126\n",
      "Iteration:  15200 , loss:  0.00038784684\n",
      "Iteration:  15300 , loss:  0.00038483355\n",
      "Iteration:  15400 , loss:  0.0003795928\n",
      "Iteration:  15500 , loss:  0.0003900554\n",
      "Iteration:  15600 , loss:  0.0003743444\n",
      "Iteration:  15700 , loss:  0.00044073284\n",
      "Iteration:  15800 , loss:  0.0003735911\n",
      "Iteration:  15900 , loss:  0.00043904508\n",
      "Iteration:  16000 , loss:  0.00038827377\n",
      "Iteration:  16100 , loss:  0.00036159798\n",
      "Iteration:  16200 , loss:  0.00049107923\n",
      "Iteration:  16300 , loss:  0.00045186846\n",
      "Iteration:  16400 , loss:  0.0005199306\n",
      "Iteration:  16500 , loss:  0.00035022723\n",
      "Iteration:  16600 , loss:  0.00052065135\n",
      "Iteration:  16700 , loss:  0.00045682257\n",
      "Iteration:  16800 , loss:  0.0003565946\n",
      "Iteration:  16900 , loss:  0.00033562595\n",
      "Iteration:  17000 , loss:  0.00033164176\n",
      "Iteration:  17100 , loss:  0.0003823143\n",
      "Iteration:  17200 , loss:  0.00032136176\n",
      "Iteration:  17300 , loss:  0.00031753152\n",
      "Iteration:  17400 , loss:  0.00042902512\n",
      "Iteration:  17500 , loss:  0.0003130776\n",
      "Iteration:  17600 , loss:  0.00030791998\n",
      "Iteration:  17700 , loss:  0.00031304482\n",
      "Iteration:  17800 , loss:  0.00030337326\n",
      "Iteration:  17900 , loss:  0.0003498158\n",
      "Iteration:  18000 , loss:  0.0003013902\n",
      "Iteration:  18100 , loss:  0.000294355\n",
      "Iteration:  18200 , loss:  0.00029474302\n",
      "Iteration:  18300 , loss:  0.0005419436\n",
      "Iteration:  18400 , loss:  0.00049501297\n",
      "Iteration:  18500 , loss:  0.00031039873\n",
      "Iteration:  18600 , loss:  0.00048335962\n",
      "Iteration:  18700 , loss:  0.0005395749\n",
      "Iteration:  18800 , loss:  0.00028874696\n",
      "Iteration:  18900 , loss:  0.00029774787\n",
      "Iteration:  19000 , loss:  0.00078525755\n",
      "Iteration:  19100 , loss:  0.00031850146\n",
      "Iteration:  19200 , loss:  0.00027094947\n",
      "Iteration:  19300 , loss:  0.00030923026\n",
      "Iteration:  19400 , loss:  0.00026338396\n",
      "Iteration:  19500 , loss:  0.00026169096\n",
      "Iteration:  19600 , loss:  0.00025922284\n",
      "Iteration:  19700 , loss:  0.0002649903\n",
      "Iteration:  19800 , loss:  0.00025487682\n",
      "Iteration:  19900 , loss:  0.00025313004\n",
      "Generating 18th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  0.09135648\n",
      "Iteration:  100 , loss:  0.026482591\n",
      "Iteration:  200 , loss:  0.023058947\n",
      "Iteration:  300 , loss:  0.021617256\n",
      "Iteration:  400 , loss:  0.020615771\n",
      "Iteration:  500 , loss:  0.019743145\n",
      "Iteration:  600 , loss:  0.01880394\n",
      "Iteration:  700 , loss:  0.017516749\n",
      "Iteration:  800 , loss:  0.016610185\n",
      "Iteration:  900 , loss:  0.015832115\n",
      "Iteration:  1000 , loss:  0.014855645\n",
      "Iteration:  1100 , loss:  0.014025925\n",
      "Iteration:  1200 , loss:  0.013429809\n",
      "Iteration:  1300 , loss:  0.012912734\n",
      "Iteration:  1400 , loss:  0.012444661\n",
      "Iteration:  1500 , loss:  0.012030739\n",
      "Iteration:  1600 , loss:  0.011632383\n",
      "Iteration:  1700 , loss:  0.011326227\n",
      "Iteration:  1800 , loss:  0.010979134\n",
      "Iteration:  1900 , loss:  0.011584044\n",
      "Iteration:  2000 , loss:  0.010359585\n",
      "Iteration:  2100 , loss:  0.010013779\n",
      "Iteration:  2200 , loss:  0.010651087\n",
      "Iteration:  2300 , loss:  0.009440657\n",
      "Iteration:  2400 , loss:  0.009207243\n",
      "Iteration:  2500 , loss:  0.009000202\n",
      "Iteration:  2600 , loss:  0.008803674\n",
      "Iteration:  2700 , loss:  0.008623122\n",
      "Iteration:  2800 , loss:  0.008468121\n",
      "Iteration:  2900 , loss:  0.008302325\n",
      "Iteration:  3000 , loss:  0.008138256\n",
      "Iteration:  3100 , loss:  0.0079812845\n",
      "Iteration:  3200 , loss:  0.007813725\n",
      "Iteration:  3300 , loss:  0.0076277256\n",
      "Iteration:  3400 , loss:  0.007690665\n",
      "Iteration:  3500 , loss:  0.007205085\n",
      "Iteration:  3600 , loss:  0.0069751623\n",
      "Iteration:  3700 , loss:  0.0067608883\n",
      "Iteration:  3800 , loss:  0.0065323524\n",
      "Iteration:  3900 , loss:  0.0065362467\n",
      "Iteration:  4000 , loss:  0.006131681\n",
      "Iteration:  4100 , loss:  0.0059462246\n",
      "Iteration:  4200 , loss:  0.0061335647\n",
      "Iteration:  4300 , loss:  0.0055848667\n",
      "Iteration:  4400 , loss:  0.005396185\n",
      "Iteration:  4500 , loss:  0.0052136425\n",
      "Iteration:  4600 , loss:  0.0050419816\n",
      "Iteration:  4700 , loss:  0.0049354816\n",
      "Iteration:  4800 , loss:  0.004742284\n",
      "Iteration:  4900 , loss:  0.004615302\n",
      "Iteration:  5000 , loss:  0.004488386\n",
      "Iteration:  5100 , loss:  0.0043712957\n",
      "Iteration:  5200 , loss:  0.0042585353\n",
      "Iteration:  5300 , loss:  0.0044907406\n",
      "Iteration:  5400 , loss:  0.004044287\n",
      "Iteration:  5500 , loss:  0.00394314\n",
      "Iteration:  5600 , loss:  0.0038489597\n",
      "Iteration:  5700 , loss:  0.0037683644\n",
      "Iteration:  5800 , loss:  0.0036686885\n",
      "Iteration:  5900 , loss:  0.0036696657\n",
      "Iteration:  6000 , loss:  0.0035069683\n",
      "Iteration:  6100 , loss:  0.0034315302\n",
      "Iteration:  6200 , loss:  0.003340067\n",
      "Iteration:  6300 , loss:  0.0032668556\n",
      "Iteration:  6400 , loss:  0.0031894639\n",
      "Iteration:  6500 , loss:  0.0031817043\n",
      "Iteration:  6600 , loss:  0.0030369586\n",
      "Iteration:  6700 , loss:  0.0031457525\n",
      "Iteration:  6800 , loss:  0.0028884525\n",
      "Iteration:  6900 , loss:  0.0027985768\n",
      "Iteration:  7000 , loss:  0.0027145112\n",
      "Iteration:  7100 , loss:  0.0031884797\n",
      "Iteration:  7200 , loss:  0.002547865\n",
      "Iteration:  7300 , loss:  0.002465818\n",
      "Iteration:  7400 , loss:  0.0024822047\n",
      "Iteration:  7500 , loss:  0.0023024154\n",
      "Iteration:  7600 , loss:  0.002226611\n",
      "Iteration:  7700 , loss:  0.0021714086\n",
      "Iteration:  7800 , loss:  0.0020812266\n",
      "Iteration:  7900 , loss:  0.0020894082\n",
      "Iteration:  8000 , loss:  0.0019909623\n",
      "Iteration:  8100 , loss:  0.0018891864\n",
      "Iteration:  8200 , loss:  0.0019051782\n",
      "Iteration:  8300 , loss:  0.0017844168\n",
      "Iteration:  8400 , loss:  0.0017542853\n",
      "Iteration:  8500 , loss:  0.0016885737\n",
      "Iteration:  8600 , loss:  0.0016760932\n",
      "Iteration:  8700 , loss:  0.0016905259\n",
      "Iteration:  8800 , loss:  0.0017713625\n",
      "Iteration:  8900 , loss:  0.0015879949\n",
      "Iteration:  9000 , loss:  0.001522197\n",
      "Iteration:  9100 , loss:  0.0014589011\n",
      "Iteration:  9200 , loss:  0.0014158672\n",
      "Iteration:  9300 , loss:  0.0013901062\n",
      "Iteration:  9400 , loss:  0.0015337771\n",
      "Iteration:  9500 , loss:  0.0017904388\n",
      "Iteration:  9600 , loss:  0.0012809555\n",
      "Iteration:  9700 , loss:  0.0012733698\n",
      "Iteration:  9800 , loss:  0.0012299996\n",
      "Iteration:  9900 , loss:  0.0012931522\n",
      "Iteration:  10000 , loss:  0.0011979737\n",
      "Iteration:  10100 , loss:  0.0011686153\n",
      "Iteration:  10200 , loss:  0.0011357799\n",
      "Iteration:  10300 , loss:  0.0010667024\n",
      "Iteration:  10400 , loss:  0.0010383723\n",
      "Iteration:  10500 , loss:  0.0010366023\n",
      "Iteration:  10600 , loss:  0.0010084538\n",
      "Iteration:  10700 , loss:  0.0010859771\n",
      "Iteration:  10800 , loss:  0.0009399513\n",
      "Iteration:  10900 , loss:  0.0009085065\n",
      "Iteration:  11000 , loss:  0.0009416045\n",
      "Iteration:  11100 , loss:  0.0008853907\n",
      "Iteration:  11200 , loss:  0.000850546\n",
      "Iteration:  11300 , loss:  0.0008503219\n",
      "Iteration:  11400 , loss:  0.00088169647\n",
      "Iteration:  11500 , loss:  0.00086071424\n",
      "Iteration:  11600 , loss:  0.0008034421\n",
      "Iteration:  11700 , loss:  0.0007628023\n",
      "Iteration:  11800 , loss:  0.0007749574\n",
      "Iteration:  11900 , loss:  0.00085957354\n",
      "Iteration:  12000 , loss:  0.0008617592\n",
      "Iteration:  12100 , loss:  0.00071692927\n",
      "Iteration:  12200 , loss:  0.0007006314\n",
      "Iteration:  12300 , loss:  0.0007946513\n",
      "Iteration:  12400 , loss:  0.00067567296\n",
      "Iteration:  12500 , loss:  0.0006685592\n",
      "Iteration:  12600 , loss:  0.00066700776\n",
      "Iteration:  12700 , loss:  0.00065509725\n",
      "Iteration:  12800 , loss:  0.00067020644\n",
      "Iteration:  12900 , loss:  0.00081189524\n",
      "Iteration:  13000 , loss:  0.00062221795\n",
      "Iteration:  13100 , loss:  0.00063746824\n",
      "Iteration:  13200 , loss:  0.0006664087\n",
      "Iteration:  13300 , loss:  0.0006014061\n",
      "Iteration:  13400 , loss:  0.00061708153\n",
      "Iteration:  13500 , loss:  0.0006086879\n",
      "Iteration:  13600 , loss:  0.00072090747\n",
      "Iteration:  13700 , loss:  0.00058537483\n",
      "Iteration:  13800 , loss:  0.00071937504\n",
      "Iteration:  13900 , loss:  0.0005687911\n",
      "Iteration:  14000 , loss:  0.0005614074\n",
      "Iteration:  14100 , loss:  0.000542679\n",
      "Iteration:  14200 , loss:  0.00053700904\n",
      "Iteration:  14300 , loss:  0.0006656623\n",
      "Iteration:  14400 , loss:  0.00054783997\n",
      "Iteration:  14500 , loss:  0.00052644894\n",
      "Iteration:  14600 , loss:  0.00052611885\n",
      "Iteration:  14700 , loss:  0.00052433956\n",
      "Iteration:  14800 , loss:  0.0005034105\n",
      "Iteration:  14900 , loss:  0.0004977555\n",
      "Iteration:  15000 , loss:  0.0005591074\n",
      "Iteration:  15100 , loss:  0.00048489438\n",
      "Iteration:  15200 , loss:  0.0004850473\n",
      "Iteration:  15300 , loss:  0.0005338224\n",
      "Iteration:  15400 , loss:  0.00046836343\n",
      "Iteration:  15500 , loss:  0.00046413994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  15600 , loss:  0.00045860244\n",
      "Iteration:  15700 , loss:  0.0010259259\n",
      "Iteration:  15800 , loss:  0.0004490892\n",
      "Iteration:  15900 , loss:  0.00044433787\n",
      "Iteration:  16000 , loss:  0.00044008376\n",
      "Iteration:  16100 , loss:  0.00044226024\n",
      "Iteration:  16200 , loss:  0.00043331014\n",
      "Iteration:  16300 , loss:  0.00044067268\n",
      "Iteration:  16400 , loss:  0.0004262385\n",
      "Iteration:  16500 , loss:  0.00044105985\n",
      "Iteration:  16600 , loss:  0.0004247892\n",
      "Iteration:  16700 , loss:  0.00042023233\n",
      "Iteration:  16800 , loss:  0.00042757505\n",
      "Iteration:  16900 , loss:  0.00040353875\n",
      "Iteration:  17000 , loss:  0.00040085733\n",
      "Iteration:  17100 , loss:  0.00040022822\n",
      "Iteration:  17200 , loss:  0.00039457297\n",
      "Iteration:  17300 , loss:  0.00038843218\n",
      "Iteration:  17400 , loss:  0.00038964982\n",
      "Iteration:  17500 , loss:  0.0003814869\n",
      "Iteration:  17600 , loss:  0.0004026954\n",
      "Iteration:  17700 , loss:  0.000567297\n",
      "Iteration:  17800 , loss:  0.00043702364\n",
      "Iteration:  17900 , loss:  0.00036873226\n",
      "Iteration:  18000 , loss:  0.00048660848\n",
      "Iteration:  18100 , loss:  0.00038941915\n",
      "Iteration:  18200 , loss:  0.00039262587\n",
      "Iteration:  18300 , loss:  0.0006965955\n",
      "Iteration:  18400 , loss:  0.00038611647\n",
      "Iteration:  18500 , loss:  0.0003612583\n",
      "Iteration:  18600 , loss:  0.00035617006\n",
      "Iteration:  18700 , loss:  0.0003429791\n",
      "Iteration:  18800 , loss:  0.00034056377\n",
      "Iteration:  18900 , loss:  0.0003545253\n",
      "Iteration:  19000 , loss:  0.0003402671\n",
      "Iteration:  19100 , loss:  0.00040752935\n",
      "Iteration:  19200 , loss:  0.00047997897\n",
      "Iteration:  19300 , loss:  0.0003305358\n",
      "Iteration:  19400 , loss:  0.00059640536\n",
      "Iteration:  19500 , loss:  0.00032110568\n",
      "Iteration:  19600 , loss:  0.0005397674\n",
      "Iteration:  19700 , loss:  0.00033592654\n",
      "Iteration:  19800 , loss:  0.00034538587\n",
      "Iteration:  19900 , loss:  0.00031239653\n",
      "Generating 19th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  1.2764266\n",
      "Iteration:  100 , loss:  0.050357085\n",
      "Iteration:  200 , loss:  0.043209534\n",
      "Iteration:  300 , loss:  0.036857847\n",
      "Iteration:  400 , loss:  0.031916022\n",
      "Iteration:  500 , loss:  0.02871661\n",
      "Iteration:  600 , loss:  0.026644524\n",
      "Iteration:  700 , loss:  0.025410386\n",
      "Iteration:  800 , loss:  0.024612619\n",
      "Iteration:  900 , loss:  0.024030754\n",
      "Iteration:  1000 , loss:  0.023618445\n",
      "Iteration:  1100 , loss:  0.023295496\n",
      "Iteration:  1200 , loss:  0.023016084\n",
      "Iteration:  1300 , loss:  0.02275868\n",
      "Iteration:  1400 , loss:  0.022511847\n",
      "Iteration:  1500 , loss:  0.022268318\n",
      "Iteration:  1600 , loss:  0.022022683\n",
      "Iteration:  1700 , loss:  0.021770615\n",
      "Iteration:  1800 , loss:  0.021508493\n",
      "Iteration:  1900 , loss:  0.021233084\n",
      "Iteration:  2000 , loss:  0.020940498\n",
      "Iteration:  2100 , loss:  0.020623492\n",
      "Iteration:  2200 , loss:  0.020264609\n",
      "Iteration:  2300 , loss:  0.019814309\n",
      "Iteration:  2400 , loss:  0.01913321\n",
      "Iteration:  2500 , loss:  0.0182142\n",
      "Iteration:  2600 , loss:  0.017636446\n",
      "Iteration:  2700 , loss:  0.017194442\n",
      "Iteration:  2800 , loss:  0.01677773\n",
      "Iteration:  2900 , loss:  0.01638573\n",
      "Iteration:  3000 , loss:  0.016000528\n",
      "Iteration:  3100 , loss:  0.015605602\n",
      "Iteration:  3200 , loss:  0.015196327\n",
      "Iteration:  3300 , loss:  0.014774993\n",
      "Iteration:  3400 , loss:  0.014351783\n",
      "Iteration:  3500 , loss:  0.013942984\n",
      "Iteration:  3600 , loss:  0.013554658\n",
      "Iteration:  3700 , loss:  0.013184522\n",
      "Iteration:  3800 , loss:  0.012833885\n",
      "Iteration:  3900 , loss:  0.012496959\n",
      "Iteration:  4000 , loss:  0.012212561\n",
      "Iteration:  4100 , loss:  0.011870338\n",
      "Iteration:  4200 , loss:  0.011574918\n",
      "Iteration:  4300 , loss:  0.011285272\n",
      "Iteration:  4400 , loss:  0.01101217\n",
      "Iteration:  4500 , loss:  0.010712352\n",
      "Iteration:  4600 , loss:  0.010431938\n",
      "Iteration:  4700 , loss:  0.010165696\n",
      "Iteration:  4800 , loss:  0.009899944\n",
      "Iteration:  4900 , loss:  0.009654202\n",
      "Iteration:  5000 , loss:  0.009475115\n",
      "Iteration:  5100 , loss:  0.009200188\n",
      "Iteration:  5200 , loss:  0.008992797\n",
      "Iteration:  5300 , loss:  0.008794194\n",
      "Iteration:  5400 , loss:  0.008607096\n",
      "Iteration:  5500 , loss:  0.008426345\n",
      "Iteration:  5600 , loss:  0.0082539\n",
      "Iteration:  5700 , loss:  0.008081499\n",
      "Iteration:  5800 , loss:  0.007915524\n",
      "Iteration:  5900 , loss:  0.007755194\n",
      "Iteration:  6000 , loss:  0.007876948\n",
      "Iteration:  6100 , loss:  0.007457519\n",
      "Iteration:  6200 , loss:  0.0073184776\n",
      "Iteration:  6300 , loss:  0.0071902685\n",
      "Iteration:  6400 , loss:  0.00705812\n",
      "Iteration:  6500 , loss:  0.006923726\n",
      "Iteration:  6600 , loss:  0.00679544\n",
      "Iteration:  6700 , loss:  0.006657737\n",
      "Iteration:  6800 , loss:  0.0065098936\n",
      "Iteration:  6900 , loss:  0.0064796037\n",
      "Iteration:  7000 , loss:  0.0062041\n",
      "Iteration:  7100 , loss:  0.0060426923\n",
      "Iteration:  7200 , loss:  0.0058898623\n",
      "Iteration:  7300 , loss:  0.0057369135\n",
      "Iteration:  7400 , loss:  0.006827448\n",
      "Iteration:  7500 , loss:  0.0054333787\n",
      "Iteration:  7600 , loss:  0.0052762874\n",
      "Iteration:  7700 , loss:  0.005129312\n",
      "Iteration:  7800 , loss:  0.004969965\n",
      "Iteration:  7900 , loss:  0.004814314\n",
      "Iteration:  8000 , loss:  0.0046744607\n",
      "Iteration:  8100 , loss:  0.004535386\n",
      "Iteration:  8200 , loss:  0.0044235904\n",
      "Iteration:  8300 , loss:  0.004274444\n",
      "Iteration:  8400 , loss:  0.004285913\n",
      "Iteration:  8500 , loss:  0.004023766\n",
      "Iteration:  8600 , loss:  0.0038990641\n",
      "Iteration:  8700 , loss:  0.0037827354\n",
      "Iteration:  8800 , loss:  0.0036660053\n",
      "Iteration:  8900 , loss:  0.003681079\n",
      "Iteration:  9000 , loss:  0.0040116236\n",
      "Iteration:  9100 , loss:  0.003418674\n",
      "Iteration:  9200 , loss:  0.003241289\n",
      "Iteration:  9300 , loss:  0.0031485048\n",
      "Iteration:  9400 , loss:  0.0030599833\n",
      "Iteration:  9500 , loss:  0.0030850703\n",
      "Iteration:  9600 , loss:  0.0030195813\n",
      "Iteration:  9700 , loss:  0.0028631764\n",
      "Iteration:  9800 , loss:  0.0027492219\n",
      "Iteration:  9900 , loss:  0.0026905322\n",
      "Iteration:  10000 , loss:  0.0027354925\n",
      "Iteration:  10100 , loss:  0.0025550178\n",
      "Iteration:  10200 , loss:  0.0025125204\n",
      "Iteration:  10300 , loss:  0.002425638\n",
      "Iteration:  10400 , loss:  0.002370066\n",
      "Iteration:  10500 , loss:  0.0024126496\n",
      "Iteration:  10600 , loss:  0.0022650654\n",
      "Iteration:  10700 , loss:  0.0022106138\n",
      "Iteration:  10800 , loss:  0.0021599703\n",
      "Iteration:  10900 , loss:  0.002293637\n",
      "Iteration:  11000 , loss:  0.0020632795\n",
      "Iteration:  11100 , loss:  0.0020174088\n",
      "Iteration:  11200 , loss:  0.0019995184\n",
      "Iteration:  11300 , loss:  0.002503004\n",
      "Iteration:  11400 , loss:  0.0018797012\n",
      "Iteration:  11500 , loss:  0.0018563662\n",
      "Iteration:  11600 , loss:  0.0017917295\n",
      "Iteration:  11700 , loss:  0.002542554\n",
      "Iteration:  11800 , loss:  0.0017194072\n",
      "Iteration:  11900 , loss:  0.0019822079\n",
      "Iteration:  12000 , loss:  0.0016432095\n",
      "Iteration:  12100 , loss:  0.0017636011\n",
      "Iteration:  12200 , loss:  0.001546609\n",
      "Iteration:  12300 , loss:  0.0016309505\n",
      "Iteration:  12400 , loss:  0.0014712416\n",
      "Iteration:  12500 , loss:  0.0014662332\n",
      "Iteration:  12600 , loss:  0.002095934\n",
      "Iteration:  12700 , loss:  0.0013631209\n",
      "Iteration:  12800 , loss:  0.0013290683\n",
      "Iteration:  12900 , loss:  0.0012977808\n",
      "Iteration:  13000 , loss:  0.0012837596\n",
      "Iteration:  13100 , loss:  0.0012356157\n",
      "Iteration:  13200 , loss:  0.0019928338\n",
      "Iteration:  13300 , loss:  0.0012441438\n",
      "Iteration:  13400 , loss:  0.0011577936\n",
      "Iteration:  13500 , loss:  0.0011643661\n",
      "Iteration:  13600 , loss:  0.0011153726\n",
      "Iteration:  13700 , loss:  0.0010911023\n",
      "Iteration:  13800 , loss:  0.0011869959\n",
      "Iteration:  13900 , loss:  0.0010614664\n",
      "Iteration:  14000 , loss:  0.0010318753\n",
      "Iteration:  14100 , loss:  0.0010150142\n",
      "Iteration:  14200 , loss:  0.0010004538\n",
      "Iteration:  14300 , loss:  0.0009845651\n",
      "Iteration:  14400 , loss:  0.000987473\n",
      "Iteration:  14500 , loss:  0.0009784024\n",
      "Iteration:  14600 , loss:  0.0009454596\n",
      "Iteration:  14700 , loss:  0.0009352445\n",
      "Iteration:  14800 , loss:  0.0009208297\n",
      "Iteration:  14900 , loss:  0.000923928\n",
      "Iteration:  15000 , loss:  0.0009405729\n",
      "Iteration:  15100 , loss:  0.0009363127\n",
      "Iteration:  15200 , loss:  0.00087768375\n",
      "Iteration:  15300 , loss:  0.00086580217\n",
      "Iteration:  15400 , loss:  0.00088901754\n",
      "Iteration:  15500 , loss:  0.000845737\n",
      "Iteration:  15600 , loss:  0.0008372038\n",
      "Iteration:  15700 , loss:  0.00082724285\n",
      "Iteration:  15800 , loss:  0.00092020567\n",
      "Iteration:  15900 , loss:  0.0008091\n",
      "Iteration:  16000 , loss:  0.0008019386\n",
      "Iteration:  16100 , loss:  0.000838045\n",
      "Iteration:  16200 , loss:  0.00087354775\n",
      "Iteration:  16300 , loss:  0.00082585623\n",
      "Iteration:  16400 , loss:  0.0007812385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  16500 , loss:  0.0007583092\n",
      "Iteration:  16600 , loss:  0.00074995385\n",
      "Iteration:  16700 , loss:  0.000742904\n",
      "Iteration:  16800 , loss:  0.0007397602\n",
      "Iteration:  16900 , loss:  0.0007605792\n",
      "Iteration:  17000 , loss:  0.00079727726\n",
      "Iteration:  17100 , loss:  0.0010430713\n",
      "Iteration:  17200 , loss:  0.000768065\n",
      "Iteration:  17300 , loss:  0.0007483771\n",
      "Iteration:  17400 , loss:  0.0006939643\n",
      "Iteration:  17500 , loss:  0.0007272843\n",
      "Iteration:  17600 , loss:  0.00067529955\n",
      "Iteration:  17700 , loss:  0.0006738291\n",
      "Iteration:  17800 , loss:  0.00067440665\n",
      "Iteration:  17900 , loss:  0.0010250625\n",
      "Iteration:  18000 , loss:  0.0006480704\n",
      "Iteration:  18100 , loss:  0.00069670513\n",
      "Iteration:  18200 , loss:  0.0011455964\n",
      "Iteration:  18300 , loss:  0.00083492603\n",
      "Iteration:  18400 , loss:  0.0006245448\n",
      "Iteration:  18500 , loss:  0.00092045375\n",
      "Iteration:  18600 , loss:  0.00069186516\n",
      "Iteration:  18700 , loss:  0.00062143645\n",
      "Iteration:  18800 , loss:  0.0005998558\n",
      "Iteration:  18900 , loss:  0.00059501943\n",
      "Iteration:  19000 , loss:  0.0006190101\n",
      "Iteration:  19100 , loss:  0.0005958171\n",
      "Iteration:  19200 , loss:  0.0005876261\n",
      "Iteration:  19300 , loss:  0.00060792844\n",
      "Iteration:  19400 , loss:  0.0005688314\n",
      "Iteration:  19500 , loss:  0.00062608876\n",
      "Iteration:  19600 , loss:  0.0005927281\n",
      "Iteration:  19700 , loss:  0.00056672964\n",
      "Iteration:  19800 , loss:  0.00073408114\n",
      "Iteration:  19900 , loss:  0.00063760206\n",
      "Execution time for 'Trainable' function is: 611.647 s, 10.194 mins\n"
     ]
    }
   ],
   "source": [
    "#processes, samples, model = Samplable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)\n",
    "\n",
    "processes, samples, model = Trainable(x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2e63fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean & Std of k1 are -0.815, 0.025\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGxCAYAAACwbLZkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVCUlEQVR4nOzdd3hUVfrA8e/0Se+9F0ILvQgIAhYUERXrqosVV+zKLtZd6yrqWve3K/a1rIW164oFBQtN6b0GQjrpk2Qm0+/vj0iWSIBMS30/zzPPo3fuufdMEmbeOec971EpiqIghBBCCNFF1F3dASGEEEL0bRKMCCGEEKJLSTAihBBCiC4lwYgQQgghupQEI0IIIYToUhKMCCGEEKJLSTAihBBCiC4lwYgQQgghupQEI0IIIYToUhKMiF5r5cqVPPDAA9TX1/vtmt9++y3jx48nODiY2NhYrrzySiorKzvc/r333mP48OEYjUaSk5O57bbbaGpqavfc5cuXc+aZZxIVFUVQUBD9+vXj4YcfbnOOSqU66mPAgAGt573++uvHPPexxx5rc92vv/6aE088kaCgICIiIpg5cybbtm1rt59ms5n77ruPvLw8DAYDMTExTJ06lT179hxx7tatW7nwwguJi4vDYDCQmZnJDTfc0Oacbdu2ccMNNzB+/HhCQkJQqVR8//33Pv1MGxsbueOOO5g2bRpxcXGoVCoeeOCBo17T4XDw9NNPM2TIEIKCgoiMjGTChAmsXLmyzXnl5eVceeWVxMfHYzQaGTp0KK+++upRr3vIn//8Z1QqFfn5+Uc8Z7fbue+++8jKykKv15ORkcHdd99Nc3Nzu9c566yzSElJQaVSceWVV7Z7vwceeKDd37vRaDzi3Dlz5pCfn09kZCRBQUHk5eUxf/58qqurj/u6hPCWtqs7IESgrFy5kgcffJArr7ySyMhIn6/3ww8/MH36dGbMmMGnn35KZWUld955J6eccgpr167FYDAcs/3bb7/N73//e+bMmcMzzzzD7t27ufPOO9m+fTvffPNNm3PfeecdZs+ezUUXXcSbb75JaGgoBQUFlJWVtTlv1apVR9zn559/5rbbbmPWrFmtx2bMmNHuuffddx9Llixpc+6nn37KrFmzOOecc/jwww8xmUw8+OCDTJo0iTVr1pCTk9N6blNTE1OnTqWsrIy77rqLoUOHYjKZWLlyJRaLpc29li1bxowZM5g0aRIvvPACsbGxFBUVsWHDhjbnrV27lk8++YQRI0Zwyimn8Pnnn/v8M62pqeGll15i2LBhnHvuubzyyitHvabL5WLWrFksX76cO+64gwkTJmA2m1m3bh1ms7n1PJPJxMSJE7Hb7TzxxBMkJSXx7rvvMmfOHEwmE/PmzWv3+hs3buTJJ58kISGh3ecvueQSFi9ezH333ceYMWNYtWoVf/3rX9m2bRufffZZm3OfeeYZhg4dytlnn81rr7121Nd0yFdffUVERETr/6vVR34fNZvN/OEPfyA3Nxej0cjatWt55JFHWLx4MRs2bECv1x/3PkJ4TBGil/rb3/6mAMr+/fv9cr0xY8YogwYNUhwOR+uxFStWKIDy/PPPH7Ot0+lUkpKSlGnTprU5/vbbbyuAsnjx4tZjJSUlSkhIiHL99dd71c8rr7xSUalUyp49e455XlNTkxIaGqpMnDixzfH+/fsrQ4cOVdxud+uxwsJCRa/XK5deemmbc2+99VYlJCREKSgoOOa9zGazkpSUpMyYMaPNddvjcrla//v9999XAGXZsmVHnOfJz9Ttdrfet6qqSgGU+++/v937P/PMM4parVZWrVp1zH4uWLBAAZS1a9e2OT5t2jQlJCREqaurO6KNw+FQhg8frtxyyy3K5MmTlcGDB7d5ftWqVQqgPPXUU22OP/roowqgfPPNN22OH/6zCgkJUa644op2+3r//fcrgFJVVXXM13Q0zz//vAIo3333nVfthTgemaYRvdIDDzzA/PnzAcjKymodlj7WcP+xlJaWsmbNGmbPno1W+78BxQkTJpCXl8fHH398zParV6+mvLycq666qs3xCy+8kNDQ0DbtX3nlFcxmM3feeafH/WxsbOT9999n8uTJ5ObmHvPcRYsW0dTUxJw5c1qP1dTUsGvXLqZPn45KpWo9npGRQX5+Pp988gkulwsAi8XCK6+8woUXXkh2dvYx7/X+++9TXl7O/Pnz21y3Pe19W2+PJz/TQ7//jnjuuec46aSTGDdu3DHPW7FiBQkJCYwaNarN8bPOOguz2cxXX311RJvHHnuM2tpaHnnkkaNeE+DMM8884poAH374YZvjHf1Z+SouLg6gzd++EP4kwYjolebMmcPNN98MwEcffcSqVatYtWoVI0eOxO1243Q6j/s49KELLbkOAEOHDj3iXkOHDm19/miO1l6n0zFgwIA27X/88Ueio6PZuXMnw4cPR6vVEh8fz9y5c2loaDjmfd577z3MZnObAONoXn31VcLDw7nwwgtbj9ntdoB2p5wMBgMWi4WCggKA1mmLfv36cf311xMVFYVer2f06NF88cUXbdr++OOPQMsUyMSJE9Hr9URFRXHJJZccMfXUUZ78TDuquLiYwsJChgwZwj333ENCQgJarZbBgwfzxhtvtDnXbrcf9ecEsHnz5jbHt2/fzl//+lcWLlxIaGhou/c/2s//aNf01JAhQ9BoNCQkJHD55ZdTVFR01HOdTidms5kVK1bwl7/8hYkTJ3LiiSf6dH8hjkaCEdErpaamkp6eDsCIESMYN24c48aNIzw8nKuvvhqdTnfcxymnnNJ6vZqaGgCio6OPuFd0dHTr80fjSfvS0lIsFgsXXnghF198Md9++y3z58/nzTff5Mwzz0RRlKPe59VXXyUyMpLzzz//mP3ZuXMnK1eu5JJLLiE4OLj1eEJCAtHR0a3f0A+pr69v/XA/1NfS0lIAHn/8cbZs2cKbb77Jxx9/THh4ODNnzuTrr79u85oAzj//fE488US+/vprHnvsMZYsWcLkyZOPyC/pCF9/J+051M833niDTz/9lH/84x8sXryYQYMGceWVV/Lyyy+3njto0CBKSkqO+EBfvnx5m/4BuN1urr76as4777wjRj0ON2jQIIAjfv7tXdMTOTk5PPLII7z22mt8++23zJs3jy+++IKxY8e2vubDrV69Gp1OR2hoKBMnTiQ7O5vFixej0Wi8ur8QxyNjbqLPeeCBB7jpppuOe15YWNgRx4421N/RKYCOtHe73VitVu6//37uuusuAKZMmYJer+e2227ju+++49RTTz3iGtu2bePnn3/mxhtvbHeVxOEOrfj47QiKWq3mxhtv5OGHH+bhhx/muuuuo6Ghgdtuu601YDg0NeB2uwHQ6/V8+eWXrT+vqVOntq78Of3009uce/HFF/P444+3npeYmMi5557LO++806HRnPb4+js53KF+Wq1WFi9eTEZGBgCnnXYao0eP5qGHHuLaa68F4A9/+AMLFy7ksssu44UXXiAxMZH33nuPRYsWAW2nUJ5++mn27NlzRALqb02fPp3c3FzuvPNOEhISGDNmDKtXr+aee+5Bo9F4PS0ze/bsNv8/depUpk6dyvjx43niiSd47rnn2jw/ZMgQ1qxZg8ViYePGjTz22GOcdtppLF26tE3wKoS/yMiI6HPS09MZPnz4cR+H51zExMQA7X8zra2tbffb+eE8aX/o3EMf5IdMnz4dgPXr17d7j6MFGL/lcDh48803GTZsGKNHjz7i+fvuu4/bb7+dv/71ryQkJNCvXz+A1tyMlJSUNv2cMGFCm8AtODiYyZMnt+nn0V7T6aefjkqlOuprOhZffyfHuuaAAQNaAxFoCWxOP/10SkpKWpdyDxw4kI8//pgDBw6Qn59PbGwsjz/+OE899RTwv59TUVER9913H/fffz96vZ76+nrq6+txOp243W7q6+tbl+0eCuzS09OZNm0aUVFRXHDBBdxzzz1ERUW1XtMfxo4dS15eHqtXrz7iuZCQEEaPHs1JJ53ELbfcwscff8zPP//Miy++6Lf7C3E4CUZEn+PNNM2hehBbtmw54npbtmxpt17E4YYMGdJue6fTyc6dO9u0by8vBWidnmnv27Hdbuett95i1KhRDB8+/Jh9+e9//0tlZeVRgxatVsvTTz9NTU0NmzdvpqysjP/+978UFRWRlZVFamrqMft5qK+H9/NY5x7tNR2PJz/TjsrJyTnqN//2fv7Tp0/nwIED7N69m+3bt7N///7WgOakk04CYN++fTQ3N3PrrbcSFRXV+lixYgU7duwgKiqKu+++u/Waubm5rFq1ipKSEjZv3kxlZSUXXngh1dXVrdf0l9/+no5m9OjRqNVqdu/e7df7C3GIBCOi1zqU9PfbYlEPPPAAa9asOe7j8G+BKSkpjB07ln//+99tEltXr17Nrl27OO+8847ZlxNOOIGkpCRef/31Nsc/+OADmpqa2rQ/lO/x5Zdftjl38eLFAO2u8vjss8+orq7mmmuuOWY/oGUExWg0ctlllx3zvNDQUIYMGUJSUhLr16/nu+++49Zbb219PikpifHjx7NixYo2ibUWi4UffvihTT9nzZqFSqU64jV9+eWXKIpy3JUr7fHkZ9pRWq2Wc845hx07dlBYWNh6XFEUvvrqK3JycoiNjW3TRqVS0a9fPwYOHIjL5eK5555j+PDhrYHD8OHDWbZs2RGPYcOGkZmZybJly9qdNkxJSWHIkCEEBwfzt7/9jZCQkA79fjtq9erV7Nmzp0M/+x9++AG3233cFVpCeK0LlxULEVDLli1TAOW6665TVq5cqaxZs0ZpaGjw6XparVaZNWuWsmTJEuXtt99W0tLSlPz8fMVqtbaeV1hYqGg0GuXqq69u0/6tt95SAOUPf/iDsmzZMuWll15SIiMjldNOO+2Ie82cOVMxGAzKww8/rCxZskRZsGCBYjQalbPOOqvdvp1xxhlKUFCQUl9ff8zXUFpaqmg0miPqhfz2dT7xxBPKV199pXz55ZfKgw8+qAQHByszZsxQnE5nm3NXrFih6PV6Zdy4ccrHH3+sfPLJJ8qkSZMUnU6nrFy5ss25N910k6JWq5V58+YpS5YsUf75z38qUVFRyogRIxSbzdZ6ntlsVt5//33l/fffV/74xz8qgPLAAw8o77//fpvaIZ7+TBcvXqy8//77ymuvvaYAyoUXXth6H7PZ3Hre3r17lcjISKV///7Ku+++q3zxxRfKrFmzFJVKpbz//vtHvKYPPvhAWbZsmfLqq68qw4YNU2JiYpStW7ce8/egKEq7dUYURVEef/xx5Y033lCWLVumvPfee8p5552nqNVq5e233z7i3O+//771NRiNRmXKlCmt/19ZWdl63tChQ5UnnnhC+fzzz5UlS5YojzzyiBIZGakkJycrZWVlred9/vnnytlnn6288sorypIlS5TFixcrDz30kBIdHa3k5uYe9+9LCG9JMCJ6tbvvvltJTk5W1Gr1UYtneeKbb75Rxo0bpxiNRiU6Olq5/PLLlYMHD7Y5Z//+/QrQbgGqd955Rxk6dKii1+uVxMRE5ZZbblEaGxuPOM9isSh33nmnkpaWpmi1WiU9PV25++672wQ9hxQVFSlqtVq5/PLLj9v/Rx55RAGUpUuXHvWcFStWKCeccIISHh6uGAwGJT8/X3nyyScVu93e7vk//fSTMnnyZCU4OFgJDg5WTj75ZGXFihVHnOd0OpXHHntMyc3NVXQ6nZKUlKRcf/31RxQHO/Tza++RkZFxxHU7+jPNyMg46nV/Wxhvy5YtyowZM5SwsDDFaDQq48aNUz7//PMjrnnOOecoSUlJik6nUxITE5Urr7xSKSwsPOrP9nBHC0YefPBBJScnRzEYDEpkZKRyxhlnKD/++ONRr3G013T43/rvfvc7JTc3VwkJCVF0Op2SkZGhzJ07t00goiiKsmPHDuWCCy5QMjIyFKPRqBiNRmXAgAHK/PnzlZqamg69LiG8oVKUY6wTFEIIIYQIMMkZEUIIIUSXkmBECCGEEF1KghEhhBBCdCkJRoQQQgjRpSQYEUIIIUSXkmBECCGEEF2qR2yU53a7KSsrIywszKvNr4QQQgjR+RRFobGxkeTk5GNuPdAjgpGysjLS0tK6uhtCCCGE8EJxcXHrvlbt6RHByKEdQYuLiwkPD+/i3gghhBCiIxoaGkhLS2uzs3d7ekQwcmhqJjw8XIIRIYQQooc5XoqFJLAKIYQQoktJMCKEEEKILiXBiBBCCCG6VI/IGRFCCNE1XC4XDoejq7shuimNRoNWq/W57IYEI0IIIdrV1NRESUkJiqJ0dVdENxYcHExSUhJ6vd7ra0gwIoQQ4ggul4uSkhKCg4OJi4uTgpPiCIqiYLfbqaqqYv/+/fTr1++Yhc2ORYIRIYQQR3A4HCiKQlxcHEFBQV3dHdFNBQUFodPpOHDgAHa7HaPR6NV1JIFVCCHEUcmIiDgeb0dD2lzDD/0QQgghhPCaBCNCCCGE6FISjAghhBCiS0kwIoQQQoguJcGIEEIIIbqUBCNCCL9yuxUarA4qTFYO1JjZW9nE3som9lU1UVxrobLRitnmlEJaPZTF7jzqw+pw+f1cT02ZMoWbb76Z2267jaioKBISEnjppZcwm81cddVVhIWFkZOTw5dfftnaZvv27Zx55pmEhoaSkJDA7Nmzqa6ubn3+q6++YuLEiURGRhITE8NZZ51FQUFB6/OFhYWoVCo++ugjpk6dSnBwMMOGDWPVqlUe97+vkjojQgif2Z1uDjZYqWqyUW+x43Yfv41GrSI8SEd0iJ6YUD3hRl3gOyp8Nui+r4/63NT+cfzrqrGt/z/q4W9p/k3QccgJWdEsum586/9PfHwZtWb7EecVPjbD4z6+8cYb3HHHHfzyyy8sWrSI66+/nk8++YRZs2Zxzz338MwzzzB79myKioowmUxMnjyZa6+9lqeffprm5mbuvPNOLrroIpYuXQqA2Wxm3rx5DBkyBLPZzH333cesWbPYuHFjm2Wt9957L08++ST9+vXj3nvv5ZJLLmHv3r1otfJRezzyExJCeK3J5qSw2kxlo7VDAcjhXG6FOrOdOrOdgkoI0mtICDeSHGkkWC9vTcJ7w4YN489//jMAd999N4899hixsbFce+21ANx3330sXLiQzZs3s3jxYkaOHMmjjz7a2v61114jLS2N3bt3k5eXx/nnn9/m+q+++irx8fFs376d/Pz81uN/+tOfmDGjJXh68MEHGTx4MHv37mXAgAGBfsk9nvyLF0J4zOZ0sbeyifJ6q9+u2Wx3UVhtprDaTHSonrSoYGJD9VJ0q5vZ/tDpR31O/Zvf1bq/nNrhc5ffOdW3jh1m6NChrf+t0WiIiYlhyJAhrccSEhIAqKysZN26dSxbtozQ0NAjrlNQUEBeXh4FBQX85S9/YfXq1VRXV+P+NfIuKipqE4wcft+kpKTWe0gwcnwSjAghPFJuamZXRSNOV+ByPmqb7NQ22QkxaMmKDSEh3CBBSTfhyahVoM49Hp2u7ZSfSqVqc+zQ35Lb7cbtdjNz5kwef/zxI65zKKCYOXMmaWlpvPzyyyQnJ+N2u8nPz8dubzutdLR7iOOTYEQI0SFOl5udFY1UmPw3GnI8ZpuTraUm9lVryI0LJT7cu30vhDiakSNH8uGHH5KZmdlubkdNTQ07duzgxRdfZNKkSQAsX768s7vZ68lqGiHEcTXbXaw9UNepgcjhLDYXm0tMrC2spcHq6JI+iN7pxhtvpLa2lksuuYRffvmFffv28c0333D11VfjcrmIiooiJiaGl156ib1797J06VLmzZvX1d3udSQYEUIcU6PVwZrCWpqsni+z9Ld6i4Nf9tWyo7wBh0uGv4XvkpOTWbFiBS6Xi9NPP538/HxuvfVWIiIiUKvVqNVq3nvvPdatW0d+fj633347f/vb37q6272OSukBi/0bGhqIiIjAZDIRHh7e1d0Ros8wWRysL67DFcD8EG/ptWoGJIbJ1E2AWK1W9u/fT1ZWltfbwou+4Vh/Kx39/JaRESFEu0zN3TcQgZbaJptLTGwpMWF3yiiJED2ZBCNCiCOYbU42FHXfQORwBxus/Ly/hpomW1d3RQjhJQlGhBBtWB0uNhTVB3Tprr/ZHG42FNWzt7JJyswL0QNJMCKEaOVyK2wuMR2xb0hPUVhtZn1RPTZnz+y/EH2VBCNCiFY7yhtoaO7ZS2frzHbW7K+jUZYAC9FjSDAihACguNbSZXVE/M3qcLG2sI6qRskjEaInkGBECIGp2cGeysau7oZftUw51VNca+nqrgghjkOCESH6OKfLzbZSk8e77vYEigK7KhopqGrq6q4IIY5BghEh+rhdBxux2Ht3wuf+KjO7D/aukR8hehMJRoTowyobrZTX9448keMpqrGws6Khq7shuiFFUfjDH/5AdHQ0KpWKjRs3dnWX+hzZtVeIPsrudLOzvG+NFpTUNgMwIFG2lRD/89VXX/H666/z/fffk52dTWxsbFd3qc+RYESIPmr3wcY+WUa9pLYZjUpFv4Swru6K6AR2ux29Xn/McwoKCkhKSmLChAle30dRFFwuF1qtfKx6Q6ZphOiDappsvWYZrzcO1FgorDZ3dTd6FkUBu7lrHh5U1Z0yZQo33XQT8+bNIzY2ltNOO43t27dz5plnEhoaSkJCArNnz6a6uhqAK6+8kptvvpmioiJUKhWZmZm/vlyFJ554guzsbIKCghg2bBgffPBB632+//57VCoVX3/9NaNHj8ZgMPDTTz91uN13333H6NGjCQ4OZsKECezatavN6/jss88YPXo0RqOR2NhYzjvvvNbn7HY7d9xxBykpKYSEhHDCCSfw/fffe/FL7T4khBOij3G5FXZW9K3pmfbsrWxCr1WTHBnU1V3pGRwWeDS5a+59TxnoQzp8+htvvMH111/PihUrqK2tZfLkyVx77bU8/fTTNDc3c+edd3LRRRexdOlSnnvuOXJycnjppZdYs2YNGo0GgD//+c989NFHLFy4kH79+vHjjz/y+9//nri4OCZPntx6rzvuuIMnn3yS7OxsIiMjO9zu3nvv5amnniIuLo65c+dy9dVXs2LFCgC++OILzjvvPO69917eeust7HY7X3zxRWvbq666isLCQt577z2Sk5P5+OOPOeOMM9iyZQv9+vXz9afdJVRKD9jIoaNbEAshjq+gqon9VTIqAKBSwYj0KKJDjj2M3xcdsS283dwjgpEpU6ZgMpnYsGEDAPfddx8///wzX3/9des5JSUlpKWlsWvXLvLy8nj22Wd59tlnKSwsBMBsNhMbG8vSpUsZP358a7s5c+ZgsVh45513+P7775k6dSqffPIJ55xzjsftvv32W0455RQAFi9ezIwZM2hubsZoNDJhwgSys7P597//fcTrKygooF+/fpSUlJCc/L/fx6mnnsrYsWN59NFHO/hD9Z8j/lYO09HPbxkZEaIPsdidHKiRQOQQRYHNJfWMyYwmxCBvh8ekC24JCrrq3h4YPXp063+vW7eOZcuWERoaesR5BQUF5OXlHXF8+/btWK1WTjvttDbH7XY7I0aMOOq9PGk3dOjQ1v9OSkoCoLKykvT0dDZu3Mi1117b7mtbv349iqIc0W+bzUZMTEy7bXoC+dcnRB+y52BTryxu5gunS2FTcT1jsqLRaSSN7qhUKo+mSrpSSMj/+ul2u5k5cyaPP/74EecdCgJ+y/3rP5IvvviClJSUNs8ZDIZj3quj7XQ6Xet/q1SqNu2Dgo4+deh2u9FoNKxbt651SumQ9gKunkKCESH6iJomm+zVchQWu4stpSZGpEW2fjCI3mHkyJF8+OGHZGZmdnily6BBgzAYDBQVFbXJ8whUu98aOnQo3333HVddddURz40YMQKXy0VlZSWTJk3y+h7djQQjQvQBiqKwp1JKoh9LbZOdgiozufE999ulONKNN97Iyy+/zCWXXML8+fOJjY1l7969vPfee7z88stHjC4AhIWF8ac//Ynbb78dt9vNxIkTaWhoYOXKlYSGhnLFFVe0ey9v2/3W/fffzymnnEJOTg6/+93vcDqdfPnll9xxxx3k5eVx2WWXcfnll/PUU08xYsQIqqurWbp0KUOGDOHMM8/06efVVSQYEaIPKDNZabI6u7ob3V5htZmIIB1xYYbjnyx6hOTkZFasWMGdd97J6aefjs1mIyMjgzPOOAO1+ujTcg8//DDx8fEsWLCAffv2ERkZyciRI7nnnnuOeT9v2x1uypQpvP/++zz88MM89thjhIeHc9JJJ7U+/69//Yu//vWv/PGPf6S0tJSYmBjGjx/fYwMRkNU0QvR6LrfCyoJqbA5JFukIrUbFuOwYjLojvzH3JcdaISHE4fyxmkaytYTo5YpqLRKIeMDpUthaaqIHfE8ToteQYESIXszhcstSXi/UWxwU1li6uhtC9BkSjAjRix2oMeN0yTd8b+yrasLU7OjqbgjRJ0gwIkQvZXO6KP51l1rhOUWBbWUmXG4J5oQINAlGhOilDtRY5IPURxabi4IqWRItRKB5FYw8//zzrVmzo0aN4qeffjrm+W+//TbDhg0jODiYpKQkrrrqKmpqarzqsBDi+KwOFyV1kvPgD0U1FkwWma4RIpA8DkYWLVrEbbfdxr333suGDRuYNGkS06dPp6ioqN3zly9fzuWXX84111zDtm3beP/991mzZg1z5szxufNCiPYdqLFI2Xc/2lZuwi2jTEIEjMfByNNPP80111zDnDlzGDhwIM8++yxpaWksXLiw3fNXr15NZmYmt9xyC1lZWUycOJHrrruOtWvX+tx5IcSRrA4XpfUyKuJPFpuL/bIqSYiA8SgYsdvtrFu3jmnTprU5Pm3aNFauXNlumwkTJlBSUsLixYtRFIWDBw/ywQcfMGPGjKPex2az0dDQ0OYhhOiYoloZFQmEAzVmzDapYitEIHgUjFRXV+NyuUhISGhzPCEhgYqKinbbTJgwgbfffpuLL74YvV5PYmIikZGR/N///d9R77NgwQIiIiJaH2lpaZ50U4g+y+Z0UVonK2gCwe2GnRWNXd2NHsfldrGmYg2L9y1mTcUaXG5Xl/bn+++/R6VSUV9f36X98Kcrr7ySc889t6u74ROvElh/u6uloihH3ely+/bt3HLLLdx3332sW7eOr776iv379zN37tyjXv/uu+/GZDK1PoqLi73pphB9TnFts6ygCaA6s52DDdau7kaP8e2Bbzn9w9O5+uurufOnO7n666s5/cPT+fbAt13dtR6psLAQlUrFxo0b2xx/7rnneP3117ukT/7i0UZ5sbGxaDSaI0ZBKisrjxgtOWTBggWceOKJzJ8/H2jZGjkkJIRJkybx17/+laSkpCPaGAwGDAbZqEoITzhcboplBU3A7T7YSEyIHq1GKiMcy7cHvmXe9/NQaBscV1oqmff9PJ6e8jSnZpzaRb3rXHa7Hb1eH7DrR0REBOzancWjf016vZ5Ro0axZMmSNseXLFnChAkT2m1jsViO2Bnx0JbNsveDEP5TWteMS6qtBpzN4ZZS8cfhcrt47JfHjghEgNZjj//yeMCmbGw2G7fccgvx8fEYjUYmTpzImjVr2pyzYsUKhg0bhtFo5IQTTmDLli2tzx04cICZM2cSFRVFSEgIgwcPZvHixa3Pb9++nTPPPJPQ0FASEhKYPXs21dXVrc9PmTKFm266iXnz5hEbG8tpp53GJZdcwu9+97s2fXA4HMTGxvKvf/0LgK+++oqJEycSGRlJTEwMZ511FgUFBa3nZ2VlATBixAhUKhVTpkwBjpymOd7rPzRV9d133zF69GiCg4OZMGECu3btaj1n06ZNTJ06lbCwMMLDwxk1alRAF554HNrPmzePV155hddee40dO3Zw++23U1RU1Drtcvfdd3P55Ze3nj9z5kw++ugjFi5cyL59+1ixYgW33HILY8eOJTk52X+vRIg+zO1WKKqVD8jOUlRrptnetbkP3dn6yvUctBw86vMKChWWCtZXrg/I/e+44w4+/PBD3njjDdavX09ubi6nn346tbW1refMnz+fJ598kjVr1hAfH8/ZZ5+Nw9FST+bGG2/EZrPx448/smXLFh5//HFCQ0MBKC8vZ/LkyQwfPpy1a9fy1VdfcfDgQS666KI2fXjjjTfQarWsWLGCF198kcsuu4zPPvuMpqb/FdH7+uuvMZvNnH/++QCYzWbmzZvHmjVr+O6771Cr1cyaNQv3rxnpv/zyCwDffvst5eXlfPTRR16/foB7772Xp556irVr16LVarn66qtbn7vssstITU1lzZo1rFu3jrvuugudTufV76MjPJqmAbj44oupqanhoYceory8nPz8fBYvXkxGRgbQ8os6vObIlVdeSWNjI//4xz/44x//SGRkJCeffDKPP/64/16FEH1cmakZu7OHLKFR3OhsdRiaD2KwVqFxNuPWGHBpDDj0kVjCsnFru/eW9W437KlsZGhqZFd3pVuqslT59TxPmM1mFi5cyOuvv8706dMBePnll1myZAmvvvoqY8aMAeD+++/ntNNOA1oCh9TUVD7++GMuuugiioqKOP/88xkyZAgA2dnZrddfuHAhI0eO5NFHH2099tprr5GWlsbu3bvJy8sDIDc3lyeeeKL1nJycHEJCQvj444+ZPXs2AO+88w4zZ84kPDwcoDUoOeTVV18lPj6e7du3k5+fT1xcHAAxMTEkJiZ69foPpUwAPPLII0yePBmAu+66ixkzZmC1WjEajRQVFTF//nwGDBgAQL9+/Tr4G/COx8EIwA033MANN9zQ7nPtJdHcfPPN3Hzzzd7cSghxHIqiUNSdpw0UhbD67URXrCCyeh2RNevR2U1HP12lpjkkjcbIQVQnT6Y6cQoOY3QndrhjKhts1FvsRAYHLhegp4oLjvPreZ4oKCjA4XBw4oknth7T6XSMHTuWHTt2tAYj48ePb30+Ojqa/v37s2PHDgBuueUWrr/+er755htOPfVUzj//fIYOHQrAunXrWLZsWetIyW/vfSgYGT16dJvndDodF154IW+//TazZ8/GbDbz6aef8s4777Rp/5e//IXVq1dTXV3dOiJSVFREfn6+X17/4Q69JqA1f7OyspL09HTmzZvHnDlzeOuttzj11FO58MILycnJ6VAfvOFVMCKE6D6qGm1YuuGUgcFSQeKBT0k68CmhDXvbPKegokETSZ06GgtGtG47BpWDGHcNoe5GgpsOENx0gISSL1FQUR87ipLcy6hMnYaiDtxQsaf2VDYxJrP7BUpdbWT8SBKCE6i0VLabN6JCRUJwAiPjR/r93odyET1Z9dnar1+fnzNnDqeffjpffPEF33zzDQsWLOCpp57i5ptvxu12M3PmzHZH9w9fkBESEnLE85dddhmTJ0+msrKSJUuWYDQaW0cvoCWtIS0tjZdffpnk5GTcbjf5+fnY7faAvP7Dp10OPXcoAHrggQe49NJL+eKLL/jyyy+5//77ee+995g1a1aH++IJCUaE6OEOdLNcEaO5lMwdL5Jc+CFqd8scvEOlpzphEo0JY6mPG8UHpZH8Z0NlO60V4jBx92iF4e7txJYtI7x+O1HVa4mqXos1KJ6S3N9T1O9y3Nrgzn1h7TBZHFQ2WIkP797TSp1No9Zw19i7mPf9PFSo2gQkKlo+9O4ceycatcbv987NzUWv17N8+XIuvfRSoCVRdO3atdx2222t561evZr09HQA6urq2L17d+uUBEBaWhpz585l7ty53H333bz88svcfPPNjBw5kg8//JDMzEy0Ws8+QidMmEBaWhqLFi3iyy+/5MILL2xdZVNTU8OOHTt48cUXmTRpEtCyncrhDp3rch39y0dHX39H5OXlkZeXx+23384ll1zCv/71LwlGhBBHqrfYu80mblq7iZwtz5Cy//3WIGS7diCvN0/kS9cJXJw6mHHZMQDkuc2cZlURZtQSpNOg16ppdrgw25yYmuNQ56Syz3Aa+/JvZcnqdSTte5/LNN8R11xJ7panSd37bwry51GeeS6ounaJ7d7KJuLCDMf91t3XnJpxKk9PeZrHfnmsTTJrQnACd469M2DLekNCQrj++uuZP38+0dHRpKen88QTT2CxWLjmmmvYtGkTAA899BAxMTEkJCRw7733Ehsb27oi5bbbbmP69Onk5eVRV1fH0qVLGThwINCS3Pryyy9zySWXMH/+fGJjY9m7dy/vvfceL7/8cutq0faoVCouvfRSXnjhBXbv3s2yZctan4uKiiImJoaXXnqJpKQkioqKuOuuu9q0j4+PJygoiK+++orU1FSMRuMRy3qP9/o7orm5mfnz53PBBReQlZVFSUkJa9asOSKnxZ8kGBGiB+sWK2gUhYTiL8jb8AgGW8tu3GvVQ3ii+Vx+sQ5EBeTGhxKk/9+bdGZsCJmxRw5jt8cZmsybhkt53nwOZ6lXcbv2Q9KaKxm85i7S9r7F9jGP0hQ5MBCvrEMsdhdlJispkUFd1ofu6tSMU5maNpX1leupslQRFxzHyPiRARkROdxjjz2G2+1m9uzZNDY2Mnr0aL7++muioqLanHPrrbeyZ88ehg0bxmeffdZm5OHGG2+kpKSE8PBwzjjjDJ555hkAkpOTWbFiBXfeeSenn346NpuNjIwMzjjjjCPKWLTnsssu49FHHyUjI6NNXodarea9997jlltuIT8/n/79+/P3v/+9dfkugFar5e9//zsPPfQQ9913H5MmTeL777/36vUfi0ajoaamhssvv5yDBw8SGxvLeeedx4MPPtih9t5QKT2g2EdDQwMRERGYTKbWrGMh+jqL3cnKvTVd2gedtYbBv9xJbMWPABSpU7nTegWr3IMxaNVMzI3llIHxxIf5No2hKAp7Kpv4ZttBdpRUcoXma27SfkK4qhm3SkdB/i0c6D8HAvwhdzQGnZoTc2JRq3vP6IjVamX//v1kZWVhNMo0lDi6Y/2tdPTzW0ZGhOihimu7dg+aqMqfyV/9RwzWSlxqPYWDbuCPpZPZarUyY0gipw9OIFjvn7cYlUpFXkIYeQlhVJhS+e+WRE7edxKvRr/FMMtK+m15irjyZWwZ9yy24PaXPAaSzeGmpK6Z9Jiuz2MRoieSYESIHsjhclNm6qJgRFHI3PECOdueQ6W4aQzLYeuEv2OO6MfFaTYuUUFMaOC2c0iMMDJnYjb7+sdTFD4Zbdln9N/wMJHV6xm95Dy2nvhPTLEjAnb/oymsMZMSFYSmF42OCNFZZHMFIXqg8nprl5R+V7nsDPrlTnK3PoNKcfOh6yRuC3sac0RLQaS4MENAA5HDZceFEmTQUp51HitP/ZR96gyCbNWMWPZ7kve93yl9OJzd6aZE9gYSwisSjAjRwyiK0iUb4mntDYz4aQ7JBz7BhZp7HNfwR8dcqmxanK6urf5ao0/i5uDH+dI1Bq3iYNDae8na8nfo5JS4whqL7JoshBckGBGih6lqsnX6vih6azWjll1GdOVqLARxjf1PvOM6hXOHJ3PzybldvoNtmFHHLWeM4PO8BTznPA+AnB3/IGvdw6B0XqDk6IWjIz1gjYPoYv74G5FgRIgeprMTV/XNVYz8fjZhpl1UE8UFtr+wSj2SG6fkcNbQ5G5TX0OjVnHeqHTM4+/gIdeVAOTs+zc5q+5E5XZ2Wj8O9JLRkUP1Mjyp/in6JoulJQD3ZSM9SWAVogdptDqoM3feh4O+uZJR319OSOM+KlUxXGi9l3pjGned0o+06O65cmRsVjRFEbfx5+9CecD9PFkln2JYq2b7mAWdUiDN7nRTVt/cbX8+HaXVagkODqaqqgqdTtehGhqib1EUBYvFQmVlJZGRkccs+HY8EowI0YN05qiIzlrbGohYg5P4avBC7Jvd3DE1l4RuXv48PTqYkOnXseD7MO5tfoLkwo9xaYLYNfJ+6ISRnMIaMymRQT267ohKpSIpKYn9+/dz4MCBru6O6MYiIyOPuotwR0nRMyF6CIfLzfI91Z0yBaBxmBn5w+VE1G7BGpzEuilv0Ryajsut9Lilq4kHPmPwz/NRoVDQ72r2D7+zUwKSgcnhvaIqq9vtlqkacVQ6ne6YIyJS9EyIXqasvrlTAhGV28GQVbcQUbsFkyqMpcOfJyy0ZUOxnhaIAFRknI3a2cygdX8hZ89r1KiiaBh+XcDve6DaTHKEsdvk1HhLrVZLBVYRcDIJKEQPoCgKJXWdMEWjKAxacw+xFT/RjIErrPN5ZqOqx6+oKMm+iBcNVwEwevfTaHb9N+D3tNhdVDXaAn4fIXoDCUaE6AGqm+ydspw3c8cLJB34FBdqrrffyj7DAK47Kbvnf7tXqUg8/U98rD0DNQrjNt0FpesCft/Cmt61zFeIQJFgRIgeoDNqV8SVLiF3a8vOpH92XMUq9UhuPzWv2yerdlSIUYfqjMdZqR5JEHZGrpiLUl8U0Hs2NHfu6icheioJRoTo5ix2JzVNgf1AC63fyeCf5wPwunMa77lP4bqTsnv88tTfCg0OouzU59lJBtGYSP/uetz2wE5/FdaYA3p9IXoDCUaE6OZKA5wrorXVM2zFDWidFpa7BvOwczYXj05jaGpkQO/bVSIjo9k04XnqlFD6u/YQ+cO9Ab1fTZOdJlvnFV0ToieSYESIbszlViitD2AworgZ/MudBJlLaApO4x/R93JS/0ROGRAfuHt2AzGp/ViW/xhu1Iyt+y/JBYsCer8iyR0R4pgkGBGiGzvYYMUZwN15M3a9Rlz5MlxqPdtO/D+uPm0UvxuT3uMTVjsifPA0CobcDsCADQ8RVrslYPeqaGjG5uzc/YSE6EkkGBGiGwvkct6IqrXkbHkKgN0j/kxj1CDUalWPrCXirQMD/kBlyqmo3Q4yv7+F2rqagNzH7Q7s71KInk6CESG6KVOzg4ZmR0CurbPVMWT17agVFx+7TuSxynE9vpaIV1Qqto9ZQLUmngRnKeFL78LuDMwuvyV1zbh7wQZ6QgSCBCNCdFMBW86rKAxc+xeMzQcpUJK513EN8eE9v1Kot5z6CLac8CRO1Jzh+oGi718LyH0cTjcVDdaAXFuInk6CESG6IYfLTWVDYKp3JhV+RHzpNzjRcIv9RrJT4pk2KCEg9+opXKnjWJP+BwBm1zzH7u0bA3KfolpJZBWiPRKMCNENlddbA7IPTVBTEf03/BWApxwXUmTox1UTsvrsqMjhzGNvZU/QMEJUNsZt+TMH6/1fH6TJ6pQiaEK0Q4IRIbqhknr/f4NWuZ0M/nk+WqeZn90DeNF1FtecmEVEkM7v9+qR1BrKpzyDmSBGqnZjWvoMDpf/80eKO6GarhA9jQQjQnQzdWY7Fpv/l4Gm7/4XkTUbaCSIefbrOXlgIvkpEX6/T09mD0tlx9C7AZjjeIfmEv8v961qtGF1yDJfIQ4nwYgQ3UwgloAGNxSQvfU5AFbl/onwpGzOH5nq9/v0BvX9L6YwehJ6lZNTd92Pyu3fFU2K0jl7DQnRk0gwIkQ3YnO6qGry84oLt4tBa+5B47ZTnTgJ9Yjf88fT+qPTyD//dqlUFJ34GHZ9JOH128nc+bLfb1Fab5VlvkIcRt6NhOhGyuutuP2cppC+5w0iazbg0IawY/RfQZJVj8seFMeuEX8BIGPb83y/cqVfr+9wujnYKMt8hThEghEhuglF8f8+NEFNReRsfRaAh+2Xsrra6Nfr92YH08+iPPZEtIqdGQeeYHNxnV+vX1wrFVmFOESCESG6iRqznWa7HxMbFYX+6x9E47KywjWYtxxTiAzW++/6vZ1KRcHYh7CpDIzXbMe0+g2//n4amh2YAlRhV4ieRoIRIbqJUj8nrsaXfE1sxU/Y0fJn59VM7Z9AVmyIX+/R21lD09g3+BYAbne/wddr/Lu6RhJZhWghwYgQ3YDV4aK6yX8VVzWOJvI2thQ3W+g8mzpjOrOGp/jt+n1J2YCrqArJI1Jl5tSiZ9lV0ei3ax9ssAaklokQPY0EI0J0A2X1zfhzn7qcrc9hbK7kgJLA886zuWRsOkF6jf9u0Icoai37xi/AjZpzNSvZteJjbE7/TNe43S1Jy0L0dRKMCNHFFEWhzI8fSGF120jb8xYAf3ZcRf/UOEamR/rt+n1RY/QQ9ufMBuBPjhfZXFjht2uX1Fn65o7JQhxGghEhulh1k91/FTndLgasuw8Vbn4JmcpazQguG5sue8/4QdHQ22jUx5OuruIi+6d+u67F7qJW9qsRfZwEI0J0MX8u503Zt4iI2i04daFYT36YBecNISbU4Lfr92UuXQiFI+8CIHPHCxjMZX67tr+XdAvR00gwIkQXsjpc1PgpcVVrq2+tKbI3/3bsQfGEGrR+ubZocTBtBnVxY9C4rGStX+C3ZFbZr0b0dRKMCNGFSv2YuJq97f/Q2+vZr8lkdfQ5/rmoaEulYteIP+NGTWr516z94VOarE6fL6soUG6SRFbRd0kwIkQXaUlc9c/wfIhpD6kF7wBwT/NlfLGtyi/XFUdqihxIcc7vALhT+Refbijyy3VL65olkVX0WRKMCNFFqpps2Bx+qDGhKORtXIBacfG1azRrVflcIDvyBtT+/NuwaiMYoC4mY9+77K82+3xNq8NFjSSyij5KghEhuoi/lvPGln9PzMHl2NHyiPMyzhicKEmrAeY0RLJ/6DwAbte+z39Xb8bth1ENf1fhFaKnkGBEiC7gr8RVlctOv40LAHjNOZ3GoFTOyE/0+bri+EqzL6IufCARKgvnN/yb5Xuqfb5mdZMksoq+SVLthegC/kpcTdv7FiFNhVQpEfzDeQ6Xjk/DoO15lVaDDRqiQ/REBOkI1mnRa9Wo1S2JnXaXG4vNRaPVQY3Z7peEUb9Qa9g38h5GfT+bSzXfMWvDmYzOPJ1gvfdvq4rSUo03Oy7Ujx0VovuTYESITuavxFWdtZbs7f8E4AnnxSTFxzMmM8rn63YWnVZNSqSRpIggQo6xBNmo0xBu1JEYYaQf0Gx3UWZqprSuGbuza/d1qYs/gcqkqcSXL+PBoPcp4XSfr1lWbyUrNkQK1Yk+RYIRITqZvxJXs7b/E62jCVPkIPRpv+d38WE94gNMr1WTFRtCcmQQGrXn/Q3Sa8iJCyUzJoSy+mb2VZtxdGFQsnfYfGIrfmRk80rc9eupjx/r0/VaNk20ExcmeT+i75CcESE6mT+SFIOaikjd9x4Ae4fdwdSBiWTEhPh83UBSqyEzNoQJOTGkRQd7FYgcTqNWkRYdzIScGFKjg/zUS89ZwnMpy74IgH6bHgPF98DIX0u+hegpJBgRohO1JK76vnwzZ8vTqN0OqhImUpcwwQ89C6yIYB0nZMWQGx+KVuPftx2dRs2AxHBGZURh1HVNvsy+wTfj1IYQUbeVdYtfZU+lb5VZJZFV9DUSjAjRifyxB0l47WYSixfjRsVtNbMoqrX4oWeBoVJBdlwIozOijpkX4g9RIXpOyI4mtgumN+zGWA4MuBaAy5r+xcdr9vm01Fcqsoq+RoIRITqJXxJXFYXcTX8D4GPXRDbYU4kO0fuhd/6n16oZkR5Fdlxop+Wy6DRqhqVGkBXX+VNWB/KuotkYT6qqmsn1H7Nmf61P15OKrKIvkWBEiE7ij8TVmIofiK76GRs6nnJcyIwhSd1yM7wwo5axWdFdEiipVCpy4kIZnBJOZ+bzurVB7BvSUgjtJu0nfLNul0+rfawOF7VSkVX0ERKMCNFJfE5cdbvot/lJAF53TsMakszJA+L90DP/igszMDozusvyNw5JighiWFqkz4mynijPOIfG8H5EqCxc5PiIb3cc9Ol6/pjWE6InkGBEiE7gj8TVpAOfEmraTb0Swj+d5zBreAo6PyeD+io1OoihqRGdGgAcS2yogeGdGZCoNewbcjsAV2m+Zu22nZht3hdpq2q0YXNKIqvo/brXO5kQvZSv33BVLjvZ2/4OwD+d5xARFccJ2dH+6JrfZMWFMCAxvNvVOokK0TMivfMCkqrkU6iPHk6wysY17g9YtqvS62spCpT7aQ8jIbozCUaECDB/JK6m7PsPQZYyatQxvOmaxqwRKai70Yd+v4RQcrpxCfPIYD1DUyNQd8Y7nkpFwa+b6F2mW8asTN/K15fVSyKr6P0kGBEiwHxNXFU7m8nasRCAyuE388fpQxmSEuGv7vmsf2JYty+4BhATaiA/OaJTklrr4sdRk3AiWsVJvx3/8OlaFruLOovDTz0TonvyKhh5/vnnycrKwmg0MmrUKH766adjnm+z2bj33nvJyMjAYDCQk5PDa6+95lWHhehpfE1cTS14B4O1iuaQVMqyLujUpbLHk5cQRlp0cFd3o8Piw430TwzrlHsV/Jo7knTgU4x1u2jyIXdEKrKK3s7jYGTRokXcdttt3HvvvWzYsIFJkyYxffp0ioqKjtrmoosu4rvvvuPVV19l165dvPvuuwwYMMCnjgvREzTbfUtc1TiayNz5EgDb+81F0XSfmiK58aGkx/ScQOSQ1KhgMmMD3++G6KFUpkxDhYLz24d55+ejv0ceT2Wjtcs3BRQikDwORp5++mmuueYa5syZw8CBA3n22WdJS0tj4cKF7Z7/1Vdf8cMPP7B48WJOPfVUMjMzGTt2LBMmdP8S1kL4ytfE1fQ9b6K31bHPncTstVnUWbpH3YnM2BAyY7v/1MzR5MSFEh8e+Eqte4fchhs1U5RfsB/4haIa76rlut1QIRVZRS/mUTBit9tZt24d06ZNa3N82rRprFy5st02n332GaNHj+aJJ54gJSWFvLw8/vSnP9HcfPQ3aZvNRkNDQ5uHED2N2+1b4qrWbiJ916sAPOM8n5yESKKCu35kJDU6iNz47pus2hEqlYrByRGEGQNbMM4SnktF5rkA3K79gA83lHh9rZL67lv2XwhfeRSMVFdX43K5SEhIaHM8ISGBioqKdtvs27eP5cuXs3XrVj7++GOeffZZPvjgA2688caj3mfBggVERES0PtLS0jzpphDdQnWTzaeh9Yxdr6FzNLLTncZ/3eM4d3iyH3vnnYRwI/0TOifnItA0ahXD0iLRawObx79/0A24VVomazZjKF/r9SZ6FpuL+m4yMiaEv3n1r/C3yXOKohw1oc7tdqNSqXj77bcZO3YsZ555Jk8//TSvv/76UUdH7r77bkwmU+ujuLjYm24K0aVKfBgV0VlrSdvzBgBPOy9gZHpMl69YiQrRMzi5+9UR8YVRp2FISmBX2DSHplP+6+jIbdoP+WxjmdfXKvG1iq8Q3ZRHwUhsbCwajeaIUZDKysojRksOSUpKIiUlhYiI/y1FHDhwIIqiUFLS/pClwWAgPDy8zUOInsRid1LrQ+Jq5s6X0DotbHZnscQ9mnO6eFQk1Kj9tU5H7wlEDokK0dMvPrCjPYdGR07SbCH44Fp2H/RudKSy0YrDJYmsovfxKBjR6/WMGjWKJUuWtDm+ZMmSoyaknnjiiZSVldHU1NR6bPfu3ajValJTU73oshDdny+5Ivrmg6QWvA3AU86LGJcdS3JkkL+65jGDTs3wtMhuV3ren9JjgkkINwbs+taQVMqyzgNackc2FNd7dR23Wyqyit7J43eXefPm8corr/Daa6+xY8cObr/9doqKipg7dy7QMsVy+eWXt55/6aWXEhMTw1VXXcX27dv58ccfmT9/PldffTVBQV33BitEoLQkrnr/gZG14wU0Lhu7DYNZpR7OzGFJfuydZzQaFcPTIrt807vOMDApjGB94F5n4cDrcam0TNRs4w/p7efYdYRsnid6I4+DkYsvvphnn32Whx56iOHDh/Pjjz+yePFiMjIyACgvL29TcyQ0NJQlS5ZQX1/P6NGjueyyy5g5cyZ///vf/fcqhOhGqnxIXDVYKkjZ9x8AGsffyZMXDCM+LHDf2I9FpYIhKRGEGXVdcv/OptWoGRLAkvHWkBTKsy4AIGf7/3l9HbPNKYmsotdRKT1g04OGhgYiIiIwmUySPyK6vXUH6qgze/dhkbf+YdL3vkVd3BjWTX3bzz3zTP/EnlVd1V9K6izsLPcup+N4DOYyTvzyNNRuBz9NeIPCsOEkRXg+QpwYYSS/G20JIMTRdPTzu/dOAgvRBcw2p9eBiL75ICn7FgGwKvUaf3bLY6nRQX0yEIGWCq2BKohmC0mmNOtCAPQrHuNfKwq92gRPEllFbyPBiBB+5Mt8fubOV9G47axx53Hz6nBMzV2zOVp0qL7X1BLx1sCk8IDlyRQOvA6XWscJqh0k1P7CtjLPizpKIqvobSQYEcJPfKm4qm+uImXfuwD83XkeJ2THEBHU+bkawfpDdTd63xJeT+g0agYnB2ZK2BacRNmvoyO3aT/k802lXo2OSEVW0ZtIMCKEnxxstOJ0eZeClbHrVTQuG+vduaxQhjBjSOevoNFoWiqS9uYlvJ6ICtEHbP+dwoFzW0ZH1DtJqP2FXV7UHbHYXF5PCQrR3ci7jhB+UupldUydtYbUgsNGRbJiA1rz4mjykyMIMQR2r5aeJjs2hPAAjFDZghMpy74YgFu0H/PF5nKvriPLfEVvIcGIEH7QaHVQb/EuxyNj12toXM1sdGfzgzKMGUM7f1QkJz6UuLDA72Lb06jVKgYnh6MJQOXZwgF/wKXSMk69g9CDayioajp+o9+obLT6tP+REN2FBCNC+IG331B1ttrWaqt/d57H2MwYEjt5VCQ+3EBWgKYjeoMQgzYguxTbghMpzzofgJt1n3CgxvMcELfbt2q/QnQXEowI4SOny025ybuVDem7X0frtFBqzGODYSxndfKoSIhBy6Akqd1zPKlRQUSH6v1+3QMDrsWt0nCSejPnxntXlbW0vtmrBFghuhMJRoTwUUWDFZcXiataWz1pe94CoHrUbTx2/jCvCmB5S6tRMSwtAq0krB6XSqViUFI4Wo1/p2uaQ9OpSJ8JQOb2hd5dw+6iVhJZRQ8n70JC+Mjbbd3T97yB1mmmMXIAVcmnBCQv4VgGJ0cQrJeE1Y4y6jT0T/R//ZXCgdehoCK+7DvMRRuparR5fA1v/waF6C4kGBHCByaLgyar0+N2GkcTaXveBODrmMvxckWw17LiQiRh1QtJEUF+/7lZwnM4mHYGAOoVT/PJxlKPr1HdZMPqcPm1X0J0JglGhPBBcZ13hadS976DztHIHncK87elU2bqvG+20aF6siVh1WsDksL8Pl1TOPB6AGaof6b6wFYONniWg6QoMjoiejYJRoTwkt3pprLR88RVtdNK+u5/AbDQOZP8lCjSojpnHxijTkN+slRY9YVBq2FAon+Tfpt+napTqxSu13zGl1s9T2Ytq2/G7ZZEVtEzSTAihJfKTc24vSjxkLz/Awy2GkqUWD5zT+DMIYn+71w71GoYkhqBXiv/7H2VGGH0+3TN/kEtoyPnqpdTXLCDmibPckdagmPP802E6A7kXUkILyiK4tWwuMrtIGPXqwC84JxJdkIk/eI7Z1O6fvFhXbLfTW/l7+mahuihVCdOQqty8wfNZ3y1zfPRkRIvpw2F6GoSjAjhhRqznWa75wmDiUX/JchSSrUSwfuuyZyZ3zl1RRIjjKRFd85UUF9h0Pp/dc3+X3NHLtD8wN69u2m0elbVt97i8LiNEN2BBCNCeMGrZEHFTcbOlwB4xTmdhOjIgO0Me7hgg4YBAViSKlpW18T6cbrGFDea2rixGFRO/qD7wqtiepLIKnoiCUaE8FCz3UW1F3PzcaXfEtpQgE0Tysqoc5kxJCngiaQatYqhqZFS2CyABiSGofHjdE3hr7kjl2qWkh/h+d9ZhcmKwyX71YieRd6hhPBQab0X8/KKQuaOFwAoy5vNLWeOZGR6pH871o7+iWGEyk68AWXUachL8N/IU238BEzRw9C4/rfqyhMut0J5vXfbEwjRVSQYEcIDbrdCqRdv9NEHVxJRtxWXxkhRvysAAj4qkhRpJDmy88rL92UpkUFEhfhp7xqViv2DbgAgde/b7Nx3AKeHy7ZK6iyyX43oUSQYEcIDBxutOLzYsj1z54sA/Bg2gzo6K09ENsDrTIOSwv1W0r86aQqNkQPQOi3YV73IL/trPWpvsbuokf1qRA8iwYgQHvAmOTCiegPRlatxoOWeiin8UujZB4un1GoYkhLR6Xvd9HVBeg05caH+uZhKxf6BcwG4SvsVP2zdj9vDkY7iWlnmK3oOCUaE6CBTswOTxfNlk4dGRT5yTqTJmMDE3Fh/d62NvIQwwoxST6QrpEUHEe6nWi6VKafTFJpJlKqJqU2L2VJq8qh9TZMdi93zfZOE6AoSjAjRQd4UlAqp30Vc2VLcqHjBNZNpgxICWgE1IdxIaieVlhdHUqlUDEoOR+2PX7Faw4GB1wFwrfYLvt1c5PElimtlma/oGSQYEaID7E63x5uXAWT+WldksWssFdpUpuTF+7trrYw6DQOSpJ5IVws1aMmI8c9GhBXpM7EYE0lQ1TOybjF7Khs9al9mapZlvqJHkGBEiA4orfd8H5qgpiISi74AYKHzHE4eEE+QXhOA3oFKBfkp4eiknki3kBUTQrDB99+1otFTPHAOAHM1n/PNllKP2rtcssxX9AzyziXEcSiKQqkXiasZO19BhZtlrmHsUWdz6sDAjYpkxYYQGeynpaXCZ2q1ikFJ/lnNVJp1Ec36aNLUVYxuWordw9VcxbLMV/QAEowIcRxVjTasDs/2odE3HyS58EMAlideztQBcQFLKo0M1pEV659pAeE/kcF6UqN9r/Pi1hop6X8VALca/oung2vNdhdVHu4ALERnk2BEiOMo9iJxNX3366jdDupiRzF+6kwuGJkagJ6BRqMiPyUi4AXUhHdy40Ix6Hx/my3JuRSHLozQhr3ElX7rcXtJZBXdnQQjQhxDo9VBndmz5bxaWz2pBe8CUPhrrYhABQsDE8Mx6gKThyJ8p9Wo/bKzr0sfRnHubAAytr/AnooGj9rXme2ym6/o1iQYEeIYvPlGmbb3LbROC/u1OWw0jA5Ar1okRhhJjDAG7PrCP+LDjMSH+76zb3He5TjURiLrt7Lu+488njoskiJoohuTYESIo7A73VQ0eBaMaBxm0va8BcCTlhl8saUiEF3DqNP45Ru36Bx5CWFofdzZ12GIpiz7YgDm8DEr9lZ71P5ggxWb07MARojOIsGIEEfhzXLelH2L0Nvr2e9O5Ev3WGYMSQpI3wYlyzLensSo05Ab73up+KIB1+BUaRmn3kHl9h9wuzu+Ssbt9m47AyE6g7ybCdEOt1vxuOKqymUnffdrACx0zSQ/JYq0aP9XQ02PCSbaXzvEik6TEhlEZLBvK6pswYmUZcwC4DL7B6wvrvOofUlds0cBjBCdRYIRIdpR2WjD5vBsWCSp8GOMzZWUK9F87JrEmQEYFQk2+HEzNtGpVCoVA5J8LxVfPPAPuFFzsmYjBZtXeVRDxOF0U+5FJWEhAk2CESHacaDG7NH5KreTzF0vA/CScwZZCZF+GZZvcw8VDE6W3Xh7Mn+Uim8Oy6AkZToA5zQtYm9Vk0fti2okkVV0PxKMCPEbLcsgPdvtNL7kK4KbiqhTwnjPNTUguSKZsSFE+GlHWNF1smJCCPZxW4DSwS1Lxs9U/0xT6Q6P2pptTmqkCJroZiQYEeI3PF4CqShk7ngRgNXxF9EvJcFvpcAPCTVqyfLT5muia6nVLdM1vjBH9qc0YSpqlcJljo89bn9AlvmKbkaCESEOY7E7qWr07FtjbPn3hJl24dSGEHTiXG45pZ9fi5yp1TA4ORy1TM/0GtEhep9rxJTm3wBA4oFPMZjLPGpb2yRF0ET3IsGIEIfxblTkBaClZLdTH+H3PmXGhARsXxvRdfolhPpUe6QhZhg18eNRK07itrxIk82zqUUpgia6EwlGhPiV3en2eLv1yKo1RNZswI6Oz4PPxe3n3VFDjVoyZXqmVzJofa89cmi7gcwDH7B2206P2h5ssHpcxVWIQJFgRIhfldRZcHlYgyHr11GR95xTeH1zs1+DkZbVMzI905ulRAYR4UPtkbr4cZSGDMaocpC5900cro4vR5ciaKI7kWBECMDlVij28I05rHYrMQeX40TNS66zOGNwIlpfi0gcJkOmZ3o9lUrFgMQwvE4xUqmoGHYjABcrX7Nh936PmnsTgAsRCBKMCAGU1TfjcHpW5CxzZ8sKmk9dE2gwJHFibqzf+hNs0JAdK9MzfUGYUedTpd66lJMpN2QTpmomZvubHo3OOV0KZfUyOiK6ngQjos9TFMXjZL7ghgLiS74BYKHzbE4blIBe679/ToOSZHqmL8mODcGg8/LvR6WmbEjLypoLnZ+zs8izzRmLai0eVXEVIhAkGBF93sEGG812zxL5Mne+hAqFr12jKdNlMCUv3m/9SYsOJjJY9p7pS7QaNf3ivd+FuS5zBge1KUSrmjBsetOjts12l8fL2YXwNwlGRJ9X6GHpd6O5hMQDnwHwT+c5nDwgniAfK2oeYtCpyYmT6Zm+KDHCSFSIlzlCag1FA68F4NzmjzCbPfubLpQS8aKLSTAi+rTqJhtNHpZ+z9j1KmrFRWHEWGzxwzllgP9GRQYkhqPVyD/Lvqp/YrjXyawNeRfQqI8nQVVHv4r/eta22UG9xe7djYXwA3nXE31aYbVn3yD1zVUk73sfgJoRNzP/9P5+W/ESH24gLszgl2uJninUoPU6mVXR6Ckb1DI6krnzJVRuz4LsAzI6IrqQBCOiz6oz26m3eFYSO33P62jcdupjRlAXN9ZvfdFoVOQleJ8zIHqPrNgQr5OhS7MvxG6IIthcjHH3px61rWq0YfawiqsQ/iLBiOiz9nuYK6K1m0jd+w4A7wddhMWP1Stz40Ix6vyTdyJ6Np1G7XVlVrc2mF0ZvwcgbtPzWO2eBdsyOiK6igQjok8yWRzUNnk2R5629220TjM73Ok8WpDu8V4gRxMepCM1Ksgv1xK9Q1KEkfAg76b/qgZcThPB5KmKqdvwmUdtKxqasTmlRLzofBKMiD5pX3WTR+ernRbSdr8OwPPOsxmbGUN8mG+7rkJLyfcBSWF+3eVX9HwqlYr+Xk7buY0RrI07H4ARRa/h9rBEfHGtFEETnU+CEdHnmJod1Hg4KpJasAi9vZ797gS+cI/jzPwkv/QlNSqYcCn5LtoREawjMcK7gNcx5jqaFT35yh7qtn/rUduSOgtODwIYIfxBghHR5+yr8mxUROWyk777VQBecJ3NsLRoUvwwraLXqsmWmiLiGHLjQ9F4UYlXFRrP6sizAMjb/aJHbZ0uhXKTZ7tXC+ErCUZEn2KyeD4qklT4McbmSsqVaD52TeTMIf4ZFclLCEMnNUXEMRh1GtJjvFvqaxl9PQ5FwwjXFswFKz1qKyXiRWeTd0LRpxR4mCuicjvJ3PUyAC87Z5CbFEOWHzawiwrxfghe9C0Z0cFeLfU1xGSwPORUADJ3eDY60mx3USkl4kUnkmBE9Bl1ZrvHK2jiS74iuKkIqy6SgrTzmeGHURGVqqXSphAdodWoyfFyqa9p5I24UTPMsorQ+p0etfW0IKAQvpBgRPQZBR7miqC4ydrxAgCl/a9k9kmD6J/oe2GytOhgQg1an68j+o7kCCMhXvzNhCYPoDLtDMDz0ZFGq5Nas5SIF53Dq2Dk+eefJysrC6PRyKhRo/jpp5861G7FihVotVqGDx/uzW2F8Fp1k83jaqux5d8TatqNUxtCce5lfumHXqsm2w/TPKJvUalU9EvwbnSkcOB1ACQUf4mmvsCjtgc8LAwohLc8DkYWLVrEbbfdxr333suGDRuYNGkS06dPp6io6JjtTCYTl19+OaeccorXnRXCG4qisLfS01ERhaztCwH4wjiDEqt/9ozplxAqG+EJr8SGGogK0XvcrilyIDvCJqDCTciaf3jUtqbJTqPVsyBeCG94/K749NNPc8011zBnzhwGDhzIs88+S1paGgsXLjxmu+uuu45LL72U8ePHe91ZIbxR0WD1eGfeqKqfiajdhFXR8XD1VErqfC+THRmsIylCKq0K73lbJv6nxCsAGFH3NbqmMo/aSol40Rk8Ckbsdjvr1q1j2rRpbY5PmzaNlSuPvnTsX//6FwUFBdx///0duo/NZqOhoaHNQwhvuN0KBZWeDzVn/porssg1BW1EAiPTo3zuS54f8k1E3xYRpCM+3PNRutQhk/lFGYwOJ8Hrjv3F8bcONlix+nEfJiHa41EwUl1djcvlIiEhoc3xhIQEKioq2m2zZ88e7rrrLt5++2202o4lYC1YsICIiIjWR1pamifdFKJVcZ3F4zfS8JpNxBxciQMNLznPYnp+Imofy7WnRAVJpVXhFzlxoXj656jXqvkl9SoAhhz8GG1zdYfbKgoU18roiAgsryavf7uPhqIo7e6t4XK5uPTSS3nwwQfJy8vr8PXvvvtuTCZT66O4uNibboo+zu50s9+L5YlZO1q+OX7qOhFbaAonZEX71A+tRkVOnHfD60L8VohB69V0X/KIM9jkzsGInbBNr3jUtqS+GYeUiBcB5FEwEhsbi0ajOWIUpLKy8ojREoDGxkbWrl3LTTfdhFarRavV8tBDD7Fp0ya0Wi1Lly5t9z4Gg4Hw8PA2DyE8tb/ajNPlWRXJsLrtxJUtxYWafzrP4fTBiWjVviWcZseGelW0SoijyY4LwdM/y/BgPcvifg/AgOL30No7Pv3tcimU1csGeiJwPPpz1uv1jBo1iiVLlrQ5vmTJEiZMmHDE+eHh4WzZsoWNGze2PubOnUv//v3ZuHEjJ5xwgm+9F+IozDanV0mnWdv/CcDnrnHUGtOZmBvrUz+CDRpS/bCPjRCHM+o0pER6XiY+euS57HKnEqJYiN35lkdti2otuN1SIl4EhsdVdObNm8fs2bMZPXo048eP56WXXqKoqIi5c+cCLVMspaWlvPnmm6jVavLz89u0j4+Px2g0HnFcCH/afbART7fWCK3fSXzpEhRU7Mj9A2dHJPu8d0z/hDDUXmx0JsTxZMYGU1bfjMuDACE5KoSNGVfTv/gh8va/SeWgq3FrOxYs2xxuKhqsJEdKcC38z+Ng5OKLL6ampoaHHnqI8vJy8vPzWbx4MRkZGQCUl5cft+aIEIFU1WjzeDM8oLWuyMG0Mxgz5siRPk/FhhmICfVPfRIhfsugbRl183TpbewJv8NS+y+CzcWk7PsPxXlXdLjtgRqLBCMiIFRKD9iasaGhgYiICEwmk+SPiGNyuxVW76vBYvdsBU2IaS/jvp6BCoVV0z7HHNnfp36oVDA+J4ZgvZR9F4Fjd7pZsbfao9ERgJSC9xi47j6ajQmsnPEdiqbjxdSGp0cSK0G26KCOfn5LVp3oVQ7UWjwORAAydyxEhcKPmvH8Ykn0uR9p0cESiIiA02vVXuUk7UyYSa06miDrQeL3f+JRWymCJgJBghHRa1gdLq92Gg1u2Edi0RcAPG6Z6fObrU6rJkv2nxGdJD0mGI2HeUnGoCBec58FQPK2F1C5O16huM5sp0FKxAs/k2BE9Bq7Kho9Hq6GlmqrKtwscY1kvy6Hqf3jfepHdmyIz4mvQnTUodwRT+g0aqr6X0KtEkqMrYS44q88an+gWkZHhH/JO6boFaoabVQ12jxuF9R4gMSizwH4P+cspg1KIEiv8bofIQatLOUVnS49JtjjuiPj+2fwpns6AMlbn8eT5WeVjVaavZgOFeJoJBgRPZ7T5WZXRaNXbTN3vohacbHMNYy9ujxOHuDbqEheQmi71YiFCCSD1vO6I6FGLbszLqFRCSLWvJfY8mUdbqsoLXVHhPAXCUZEj7ev2uzVRl5GcwlJhZ8ALaMipw5M8CnpNCZUL0t5RZfJ8GJ0ZEJ+Lv92nQpAypZ/ejQ6UlbfjN0pJeKFf0gwIno0U7PD6028Mne8hFpx8qNrCDu0Azl1oPejIioV5CXIrryi6xh1GhLDPZsiTAw3sjr+d1gVHXGmLUQfPPru67/lciuUSol44ScSjIgey+1W2FHe4HGlVQCDpZzkwg8BKMq/kQtGpfo0KpISFUSIQZbyiq6VGRvs8Y6+E4YNZG3suQBkb/u7R6MjxVIiXviJBCOixyqsMdNk7fiSxMNl7nwJtdtBbdwJJA45mcl5cV73Q6tRkR0ru/KKrhes15IQbvSoTU5cKO4Jt+LSGIis2UD0weUdbmt3uikzyeiI8J0EI6JHarQ6KKzxvKYIgMFSQfK+9wHYP/hGn/uSFRsiu/KKbiMjxvMN9OxB8ZTkXApAzpbnPBodKaqx0AMKeYtuTt5BRY/jditsL2vA7WXuXNaOhWjcdtYykI9qs3zqS5BeQ1qU52/+QgRKmFFHTGjHy7sf8t/QC7GiJ6JuMzEVP3S4ncXuoqrJ82X1QhxOghHR4xTWmGn0cnrGaC4hed8HAPzNdgG1Ft8qSfaLD5VdeUW3kxnjeQXg/dZQXndOAyB7q2e5I1IiXvhKghHRozRYHez3ouT7IVnbn0etOFjuGsxGzWCmDUrw+lqRwTriPZyfF6IzRIXoiQjWedTmpLxYXudszIqBiLqtHtUdMVkc1Fs83ylbiEMkGBE9hsutsLXU5NXqGWiptppU+DEATzsv5JSB8YQZPXvDPly/eFnKK7qvjGjPpg+D9Vry+2Xzhut0QEZHROeSYET0GAVVTVhs3pegzt7+j9Zqqzu0Azl9kPe78yZGGD3+5ilEZ4oLMxDs4dYGpwxI4GXXDJoUI+H124kr+7bDbasabZht3k2fCiHBiOgRappsFPnwzSu4oYDEAy170DztvJBpgxO8rguiVrcshxSiO1OpVKR7uLImLsxAdno6/3KdARwaHel4priMjghvSTAiuj270822sgafrpG97R+/7sw7iv36PE4d4H2uSFpUsE+b6QnRWZIigtB5uOx82qAEXnGeSaMSRJhpF/El33S4bUVDMzanbKAnPCfBiOj2tpc3+LQHRohpNwnFiwEwT7iDK8ZneB1M6LRqMmM9X6kgRFfQqFWkebiLdE5cKKMHZLM17TIAsrf9X4dHR9xuKK6VImjCcxKMiG6tuNZCdaNvNQxytv4dFQoHU88gNGMEI9KjvL5WdmwIOo38sxE9R2qU5xvoXTI2HdvouTh0YYQ27CGh6IsOty2ps+B0yQZ6wjPyriq6rUargz2VjT5dI6xuO/Gl36CgYt/gm326VrBeQ0qkZ98yhehqeq2apAjP/26d+nAO9J8DQM6251C5O1aTx+lSKKu3enw/0bdJMCK6JZdbYUupyesqq4dkb/s7AJ+7xvPOft8qpeZKgTPRQ6V7uMwXoNnuYqH1NOpUEQQ3FbUWC+yIItlAT3hIghHRLe2saPBpGS9ARPV64sqW4kLFs87ziAjyfimuFDgTPVmIQUtsmMGjNioVLN7VyLP2cwHI3v5P1M6O5YNYHS4qfZxeFX2LBCOi2ymrb6bc12FeRSF385MAvO+cTENIJhNzY72+XG68LOUVPZunoyNGnYaT8mJ513UyFap4DNZK0vb+u8Ptvd3IUvRNEoyIbqXJ5mRXhW95IgAxFT8QVb0Wm6LjWef5nDU0Ga2Xiafx4QYigz3feEyI7iQ6RE+o0bPaOqcMSMCl0vM323kAZO58Ca29Y8vsm6xOamQDPdFBEoyIbsPpcrO5pB6Xr3PNipvczU8B8LprGkp4MuOzY7y6lEoloyKi9/B0dCQ6RM/ozCg+dk+kWJuOzm4iY9crHW5fKEXQRAdJMCK6jZ0VjT7niQAkFn1OmGkXDUowzzvP4bwRqWi8TDxNjQomWO9dpVYhupvEcCN6D4ugnTYoATdqHmm+AID03W+gb67qUNs6s50Gq287Y4u+QYIR0S0U11qoMPm+HFDlspOz9TkAXlHOJiY2gZHpkV5dS6NRkRnr2wocIboTtVpFiodF0DJjQshLCOUr1yj2GQaicTWTtWNhh9sfqJbREXF8EoyILmdq9r2eyCGpBe8RZC7BZown96w/cfWJWahU3o2KZMaEYNBK2XfRu6RGBXlcBO2MwYlMyo1jb/7tAKTsW4SxqbhDbSsbrVjssoGeODYJRkSXsjvdbCnxvZ4IgMbRRNaO5wHYN/gmgkPDSYzwbjmuQaf2qjaDEN2dQashwcNl6kNTI7liQibqnCnUJExA7Xa0lInvAEVpqTsixLFIMCK6jKIobC0zYXX4Z2Ot9N3/Qm+rpc6YTlnW+T5dKys2xOs8EyG6uzQfAu2CIfMASDrwKSH1uzrUpqxeNtATxybBiOgyBVVN1DbZ/XItnbWGjF2vAvDnhnNZvL3a62sFG6Tsu+jdwo06okI8LwJYVGvhqW2h7Io+GRUK/TY/0aF2soGeOB4JRkSXqGywUujHxLasHQvROi1sdmfxDScwNjPa62vlxoV6nWciRE/hzejIugN1/Ly/loetF+FW6Yit+InoiuUdaisb6IljkWBEdDqzzcm28o4VTuqIoKYiUve+C8Djzt8xZUAiMaGelb4+JELKvos+Ii7UQJDeswTtkwfEo9OoWF4bzubklqW+/TY9Du7jT8E4XQql9TI6ItonwYjoVA6Xm00l9bhc/ttEK3fzk6gVBz+6hrBeM5wZ+UneXytOCpyJvkGlUpEW5dnoSESQrnVbhUeaZuLQhRNm2kVy4ccdai8b6ImjkWBEdBpFUdhe5vsGeIeLqF5HQslXuFDziPMypucnelzy+pCYUD1RIVL2XfQdSZFGjxO1Tx+ciFoFaw7Cuow5AORsfRa18/jTrjaHm/IG3+sJid5HghHRafZXm6ny506eipu8jQsA+I9zMgeNOZwyMN7ry0nZd9HX6DRqkiI9m5aMDTVwQlbL9gpPmSZjCUnFYK1sTSA/ngPVZhRFRkdEWxKMiE5R2WhlX5V/d/FMKF5MRO1m7Oog3jBcxqyRKV4XKUuMMBJm9Hx1gRA9nadTNQDT8xNRAWuKzazJuQWAzJ2voG+uPG5bi91FpT+/lIheQYIREXBmm5NtZf5LWAVQu2ytm+EVD7qOW8+d6PVmeGo15EiuiOijQgxaYkI9m55MjgzipLw4zh+ZQkPWWdTHDEfjam7diuF4Cqv9+8VE9HwSjIiAcrjcbCr2b8IqQNruNwiylGINSuBA3lXoNGrUXi7HTY4M8nhVgRC9iTfVhmePy2B6fhJBBi17ht0FQHLhhx0qhNZodVLTJKMj4n8kGBEBoygKW0pNWOz+rbyos9aQtfMFAD6PnYNd7d0yXgCNWkVWbIi/uiZEjxQTaiDE4P3u1KbYkRxMPQOV4u5wIbTCGhkdEf8jwYgImL2V/quwericrc+hdTSxxZ3J3QWDqDV7f4+06GDZDE8IIC3a86rDiqKw7kAdj325kw15t+JWtxRCiyn/4bht68wO6i3+f38QPZMEIyIgyk3NHKjx/+ZYYXXbSdm3CICHHbOZOiCR+DDvipRpNSoyYmQzPCEAkiKC0Go8n+r8elsFe6ua+OSAgeLc2QDkbXwUlev4gcZ+yR0Rv5JgRPidyeJghx8rrLZSFPI2PIwKhc9c49muH8LMod4XOMuICUGnkX8CQkDLlGVqlGejIyqVijOHtPwb/H53Jdv6zcVmjCWkcT9pe946bvuaJjsNVodX/RW9i7wTC7+yOlxsLq3HHYAtKBKK/ktU9TosioEFjks5e1gywXrv5rn1WjVpHr7xCtHbpUYF42ke+NDUCFIig7A63HxTYGHvkD8BkL39Hx1a6israwRIMCL8yOVW2FxiwubwfySicZjpt/lxAP7pPAdNVCqT8+K8vl5mTAhaGRURog2jTkOCh3szqVUqzhySCMC3OyrZnzITU/RQtE4zuVueOm77ygYbZpvTq/6K3kPejYXf7ChvoKE5MEOumTtewNhcSZESzyuuM7l0bLrHZawPMejUHg9HC9FXeLOb75iMaBLCDTTZnCzdVc2uEX8BILnwY8JrNh63veSOCAlGhF/sq2qiwhSYPSeCGg+Qsfs1AHYPu5sZI7LISwjz+npZsSGovQxkhOjtIoJ0RAR7Vo1YrVZx1pBkAL7ZfpDK8HzKMs8HoP/6h0A59mjpwQYrFruMjvRlEowIn1U2+L/U++HyNi1A7XZQkzAR+p/ZmjDnjSC9huQIGRUR4lgyvBgdGZsVzaiMKK6ckIlBq2bv0D/i1IUSUbeV5P0fHrOtokBhtf9X34meQ4IR4ZMGq8Pvpd4PF1u2lLiypbhVWnaNuBePs+t+IztORkWEOJ64MANGnWf1dzRqFddPzmF4WiQqlQq7MZZ9g24CIHfLk2ht9cdsX25qptnPBRJFzyHBiPCa1eFqKfXuDswOnGqnhf7rHwbgZcd0PinxrVJqsEFDoofJeUL0RSqVyqsS8YdTFIXifrNpCu+H3lZH7pYnj3O+VGXtyyQYEV4J5MqZQ7K3/5MgSymlSizPOmf5PL2SExeKyseRFSH6iuRIIxoviqA5XG4Wbynnvs+2YXWp2THqQQBS9/2HiOr1x2xbbmrG6pDRkb5IghHhMUVR2FZmCtjKGYAQ027Sd/0LgPscVzAgPZH8lAjvr2fQEh/m/R42QvQ1Wo2alEjPvwCoVSp+2lNNucnK97urMMWNpjTrAgAGrLsflfvo7xtut4yO9FUSjAiPFVSZqWwI4I6bipsB6+5HrTj5xjWK5eoxXDIm3adL5sSFyKiIEB5Kj/a8CJpGrWLGr5WRv9pWgc3hYu/QP2HXRxJm2kXa7jeP2b6sXkZH+iIJRoRHyk3NAa+YmFT4cWul1QccVzBrRArRIXqvrxdq1BInoyJCeMybImgA47KjiQs10Gh1smxXFQ5DNHuG3QlA9vb/w2AuO2pbt1vqjvRFEoyIDqu32AOz58xhdLZa+m1qqbT6jPN8dDHpnNw/3qdrZsuoiBBeS/diM0mtWs1Zw1pGR77cWo7F7qQ8cxZ1saPROi303/jXY7aX3JG+R4IR0SEWu5NNJaaA7DlzuH6bnkBvr6fckM176hlcPi7Dp6W4YUat17v6CiEg3KgjyouRyfFZMSRFGDHbXSzZfhBUanaOehC3Skt86bfElS45alu3m4DWLhLdjwQj4rgcLjcbi+pxOAMbiURX/ERy4UcoqCg58VEWXDCSjBjflvNmx4X6qXdC9F0ZXoyOqNUqzh2eAsB3OyuxOV2YI/pxoP81AAxY9yBa+9FHWqXuSN8iwYg4JrdbYXNJPZYAvyloHE0MXNuyn0Vxv9mYYkd6XHTpt8KDdJIrIoQfxIYaCDF4vkP2yPRIzhicyN3TB2DQtvx73j/4JsxhWRislfTb9NhR2yoK7Ktu8rrPomeRYEQc0/byBurMgVvCe0julqcJspRRRjxfxs/xyzWz43wbVRFC/E9mrOejIyqVigtGpZJ0WI0gt8bA9jGPoqAiZf8HRB9ccdT2FSar7OjbR3gVjDz//PNkZWVhNBoZNWoUP/3001HP/eijjzjttNOIi4sjPDyc8ePH8/XXX3vdYdF5Arn53eEiqtaSuvdtAO6wX8N3Bb7vURERrCM2VEZFhPCXhDAjBp1v318brS1fbEyxoyjJvQyAgWv/gsbRfn6IokjuSF/h8V/WokWLuO2227j33nvZsGEDkyZNYvr06RQVFbV7/o8//shpp53G4sWLWbduHVOnTmXmzJls2LDB586LwCk3NXfKm4DaZWPQ2ntRobDIOYVN+hFcMjbN5+tmxcqoiBD+pFaryIj27t+V0+XmtRX7uePDzVQ1ttQo2jvkjzQHpxBkLiFn6zNHbXuwwUqDNfCjs6JrqRRF8WhjkRNOOIGRI0eycOHC1mMDBw7k3HPPZcGCBR26xuDBg7n44ou57777OnR+Q0MDERERmEwmwsPDPemu8EKt2c7G4rqAr5wByNn8JFk7X+KgEslptr9x2eShjMqI8umaEcE6xmRG+6mHQohDnC43y/dW43R5vh/VM9/uZltZA+Oyo5kzMRuA6IrljPzxahRUrD35HUyxo9ptGxOqZ0S6b+8Lomt09PPbo5ERu93OunXrmDZtWpvj06ZNY+XKlR26htvtprGxkejoo39Y2Gw2Ghoa2jxE52iyOdlcUt8pgUh47WYydr0KwF8cV5GXkepzIAKQLaMiQgSEVqMmzcsN9GaNaFlZ8/O+WopqWqZiaxMnUpZ5HioUBq25B7Wzud22NU126sx27zotegSPgpHq6mpcLhcJCQltjickJFBRUdGhazz11FOYzWYuuuiio56zYMECIiIiWh9pab4P24vjszpcbCyq9+pbj6fUzmYG/zwfteLiM9d4VurGc+lY30q+Q8uoSIzkiggRMGlRwWi8qP2TGRPC2MxoFOA/64o5NCi/e/jdWIPiCWncT7/Nfztq+4IqWVnTm3mVjfTbapaKonSowuW7777LAw88wKJFi4iPP3pVzbvvvhuTydT6KC4u9qabwgNOl5tNxfWdVvUwd/OThDTup0Ydw18cV3Hp2HTCg3Q+X1dGRYQILL1WTWqUdztonzcyBa1axc6KRraUmgBw6iPYPqZlij9t77+Jrmh/dU29xUFlY+AT6kXX8CgYiY2NRaPRHDEKUllZecRoyW8tWrSIa665hv/85z+ceuqpxzzXYDAQHh7e5iECR1EUtpSaaLR2zhK66IoVpO99C4ADJz7O1aeOYEym79MzMioiROdIiw5G7cVX2dhQA6cMaPki+sH6ElzultGR2sRJFOdcCsCgNXehtZvabb+3sgkP0xxFD+HRn5Ner2fUqFEsWdK2jO+SJUuYMGHCUdu9++67XHnllbzzzjvMmDHDu56KgNlR3khNU+fMx2rtJgatuQuA4pxLqU06icHJEX7ZO0ZGRYToHEadhuRI70ZHzhySRLBeg8nioKLhfyMde4bdgTk0E2PzQfqvf6jdthabi7JOKDcgOp/Hse28efN45ZVXeO2119ixYwe33347RUVFzJ07F2iZYrn88stbz3/33Xe5/PLLeeqppxg3bhwVFRVUVFRgMrUf+YrOtb/aTFl9+0ljgdB//UMYmw9Spklh04B5fruujIoI0bkyY0K8Gh0JMWi5aWouC84bQsphAY1bG8y2E/6GolKTVPQ58cWL222/r6qpdURF9B4e/yldfPHFPPvsszz00EMMHz6cH3/8kcWLF5ORkQFAeXl5m5ojL774Ik6nkxtvvJGkpKTWx6233uq/VyG8UlbfTEFl5yWFJRR9QVLR5zhRc4PlOr7e0+i3a8uoiBCdy6jTkBju3ehIXkIYwfojy8s3xAxj/4CWL7YD192PwXLkwgibw82BGimE1tt4XGekK0idEf+rbrKxqbiezvrtG5uKOWHJuegcjTznnMV/Qi/nzzMGotP4viOB1BURoms0212sLKj2+n1EURQ2FteTFRtCZHDLzsAqt4Mx311EeN02auNOYP3k10Hddp8qjVrF+JwYn/evEoEXkDojoncwNTvYUmLqtEBE5XYwZPU8dI5G1rn7sdB9HtdOyvJLIAIyKiJEVwnSa9rsO+Opd38p5p/fF/DRhtLWY4pax9ZxT+PUBhNd9TNZOxYe0c7lVqRMfC8jwUgfY7E72VRc36lzrjlbniGidhMmJYRb7DdxzshMUqO8K5z0W5GSKyJEl8qKDcHb/PNx2S0jmisLatrUEbGEZbFz5AMAZG//B5GVvxzRtqy+uXWvG9HzSTDSh9icLUXN7M5OKK/6q5jyH8nc9QoAdziuJTY1l1MHHr3GjKdkDxohulaQ3vuVNdlxoZyYEwPAO78U4T7sS1JF5rmUZZyLSnGT//Mf0dlqj2i/+6D/8s5E15JgpI9wutxsLKrHYu+comYA+uaDDP7lDgDe43TWBU/k6hOz/LKMF2RURIjuIivWu5U1AOeNTCVIp+FAjYXlBdVtnts18n7MYVkYmw8y6Je7+e3ccp3ZQWWDLPXtDSQY6QPcboXNnVjUrOWmLvJ/no/eVktj5ACCZizg5qn9CDEcmUHvrey4UL9dSwjhPaNOQ0qkd1OvEUE6zh6WDMBH60sx2/73PuXShbBl/LO41HriypeRvvv1I9rvqZSlvr2BBCO9nKIobC9voLaTipodkrPtOaIrV+PUBrNl3LOEhISS4mUJ6fZEheiIDtH77XpCCN9kxnq3Zw3A1AFxJEcYabI5+XRTWZvnmiIHsmf43QDkbv4bEVVr2zzfbHfJUt9eQIKRXm73wSYqOrliYVzpErJ2vADAp2l3YAnP9vs9cmRURIhuxaDVkBbt3RcOrVrNJWPTSYowMjw18ojnS3IupSLtTNSKk6GrbkXfXNnm+cIaM82dOAUt/E+CkV5sf7WZ4lpLp94zuGEfg39uyRN51Tmdx0uG+D1hNjpU31qTQAjRfWTEhKDVeDc6MjApnAdnDmZQcju1KFQqto95lKaIPAzWKoauugWV63+jvW63JLP2dBKM9FIldZZOra4KoHE0MXTljWidZn52D+BpLuPGqbnotf79M8uJlVERIbojnUZNZoz3K9zUh03zOFxtv8S4tcFsmvAPnLpQIqvXk7fpsTbPVzXaqGq0eX1v0bUkGOmFKhus7Czv5G8JisKgNXcT2lBAhRLFTfZbuWpSXpu9J/whNsxARLDOr9cUQvhPWnQwBp33Hy0ut8LX2yq45+MtmJrb1hFpDstk6wlPttxn779JLPykzfO7DzZKMmsPJcFIL1PTZGNrWedvQpix82USSr7Grmi43n4bJw4fyPC0SL/fJztO6ooI0Z1p1Cqfc7p+3l9LncXBojXFRzxXnXwy+wbdCMDAdX8hrHZr63PNdhf7qyWZtSeSYKQXMVkcbC4x4e68mmYAxJV8Q+6WpwB40HkFmvSxzBiS5Pf7xIcbCDfKqIgQ3V1ShJFQo3fL+DVqFVeMz0Ctgl8Ka9lcUn/EOfsG30x10mQ0LhvDVsxts6HegRozTbZOLGMg/EKCkV6i0epgQ3Fdpw9RhtVuJf/nP6FC4YeIc/kp4myumpDpt8Jmh6hUUldEiJ5CpVLRL977f68ZMSGcNjABgH//XITV8ZuVMio1W054mqbwXIzNlQxbPheNo2VERFFgR3kDPWAPWHEYCUZ6AYvdyYaiepyuzv3HZ7BUMHz5XDQuK9WJk3Ce9ih3Tx+AIQA7aSZGGAn1Y8E0IURgxYQaiA3zvkLy2cOSiQ3VU2u28+nGsiOed+nD2DjxReyGaMLrtzP45z+BuyVoMVkclNQ1e31v0fkkGOnhrA4XGzp5vxkAjcPMsOXXYbBW0hiey5Zxz6KotX7bifdwajVkywoaIXqcvIRQrzfRM+g0/P6EDAC+3XmQfdVHrg60hqax6cSFuNR64su+I3fLk63P7a1sktojPYgEIz2YzelifVFd5/+Dc7vI//lPhNfvoEoJ5wblThy6wAULKZHBBOn9P9oihAisYL2WtGjvd+jOT4nghKxo1CrVUUc6TLEj2D62ZZlv5q5XSS5YBLSsytlR0eD1vUXnkmCkh3K43Gwoqsdi6+RARFEYsP5B4sq+w6bouM4+j355g1H7OUfkEI1aRWas929mQoiulRUb4lOtoUvGpnPvmQM5qV/cUc85mH4WBYNvBmDA+geILf0OgNomOyV1nVv4UXhHgpEeyOlys7G4nqbO3PjuV9nb/k7qvvdwKypuc9xA+rApTMiJDdj90mOCMWhlVESInkqnUZPrQzJrqEFLegdGV/YPuomyzPNQKy6GrL6NyKo1QMtGejJd0/1JMNLDuNwKm0rqMVkcxz/Zz9J2v0n29n8C8BfnVVhyzwrIEt5DdFo1GT4M8QohuoekCCORfihWWFRj4dlvd2Oxt/NFTKVix+i/UpU0tWXJ7/K5hNbvxOVS2F5uktU13ZwEIz2I+9dApM7c+YFIwoHP6b/xrwA85biAfRkXc9kJ6X5fwnu47NgQtAFIiBVCdC6VSkX/xDCvk1kB3IrCy8v3sbWsgXd/ObIYGoCi1rJl/HPUxY5C52hkxI/XYGwqps7s4ECNTNd0Z/JO30O43QqbS03UNtmPf7KfxZT/yOBf7gTgbeUMVqVczZUTMgOWJwIQrNf4vZS8EKLrhBl1HZpuORq1SsUV4zNRqWDVvhrWHahr9zy31simiS/SGNEfg7WKkT9ehb65in3VTTRYO/+LnOgYCUZ6ALdbYWuZieou2AQqumIFQ1feiFpxUpF+FqrpjzHnpGw06sAFIgC58aFtNs0SQvR8WbEhGH2oQ5QbH8r0wYkAvLmqkFpz+1/OnPpwNpz0Ks0hqQQ3FTHyhyvQWqrZWmqSvWu6KQlGujlFUdhW1kBlQ+cHIlEHVzJ0+Vw0LhtVySezbcxjxIcHo1UH9s8mMlhHfLgxoPcQQnQ+rUbNgKQwn65x9rBkMmKCMdtdvPzTvqMGF/ageNZPfh1rUCKhDXsZ+f0VOEyV7JTlvt2SBCPd2KFA5GCDtdPvHVW5mqE/XYfWbWOpeyRfDnwMRaPvlHv3i/ftzUoI0X3FhhpIjPD+y4ZWo+a6k7Ix6tTsqWzis01HVmc9pDk0nXVT3sIaFE9owx5G/XAF1RVllJukOmt3I8FIN3UoEKkwdUUg8jNDf7wWndvGUtdwno+/n7jI8E65d2KEkQg/ZN0LIbqvvIQwn2qPxIcZuXxcJgCFNWbcx5h6aQ7LYN2Uf2MzxhNq2s3IH66goPCAbKbXzUgw0g11ZSASfXAFQ34NRL53DeO1lIeYM6V/QMq8/5ZajU/1CIQQPYNeq2ZAom8joGOzornl5FxuPaXfcfPLmsMyWTflTWzGOMJMuxi29HJ27NmD09XJW5yLo5JgpJvpykAkrvgrhv74B/RuKz+4hvJWxiNcPrF/wHNEDsmI8S25TQjRc8SHG32argEYmhrZuqpPUZRjjpBYwrPbBCSDv7qIPbu3+nR/4T8SjHQjbrfC1tKuCUSS9/2HIatuQ6s4+MI1lkW5j/O78cf/xuEvRp2GzJiQTrmXEKJ76J8YhkHn+8eQw+XmjVUH+PfPB455niU8h7Unv4vl11U22Z+eT8mudT7fX/hOgpFuwu1W2FJq6pJk1YydLzNo7Z9R4+Zrw+ksH/YE543JCWhBs9/qlxAa8OXCQojuRadRMzg5wufr7K82s2JvNT/uqebHPVXHPLc5NJ21J79LU3g/DNZKEj6cRe2u5T73QfhGgpFuwOVW2FhST1Vn1xFR3KSvW0C/zX8DoHDAtahmPscpg5I7tRvRoXoSZCmvEH1SdIiejBjftn3ISwjj3BEpALz9cxG7KhqPeb49KIG1U9+mPmY4OruJiP9cgGXbYp/6IHwjwUgXa9n0rq7TK6uqnc1kL7uBvIJ/AbB7yJ/YO3Q+6k7KD2nthxr6J8hSXiH6spy4UMKDfFtFd2Z+IqMzonC5FZ7/fu9xR5mdhkjWT36dmoSJaFzNBH1wGY6VL/jUB+E9CUa6kN3pZn1R5+81o7McJO/Li8muXopN0fKA7lZ25lzdqX04JD06hBCDtkvuLYToHtRqFfkp4Wg03k/VqlQqrj4xi6zYEMx2F39fuue4y3fd2mA2TnyBsszzUSludN/cifuL+eCSZb+dTYKRLmJ1uFh7oJaG5s4NRAzV28n/chapzTupUcJ4OHoBo8+aS7C+8wOCIL2GrFhJWhVCQLBey+Ak3+oZ6bVqbpqaS3SwnoMNNl7+ad9xd+tVNHq2j3mUPUP+CIB6zUso714CtmNP9Qj/kmCkCzTZnKwprMVic3XqfY27P2fU0t8R46pmrzuZl/NeYvKpZ3fZctr+iWGStCqEaBUfbiTdx/yRiCAdN5+SS2SQjjMGJ3YsEV+l4sDA69g84f9waYyo9n6D8uo0qCnwqS+i41TK8cLGbqChoYGIiAhMJhPh4Z1TCTRQ6sx2NpXU43R13o9d5XaSvelJsva8BsAqZQibJ/ydnLSUTuvDbyVGGMlP8T2LXgjRu7jdChuK63yevna43F4Vawyv3cyw5ddjsFahGMJRnbsQBp7lU1/6so5+fsvISCc62GBlQ3FdpwYi+uYqRv5wRWsgskg/i+Lpb3ZpIKLTqsmTpFUhRDta8kcifB6xPTwQKatv5tsdBzvUriF6KD+f9hH1sSNR2Rpg0WWw5H7JIwkwCUY6yf5qM1tKTLg7sfpw896fGPn1OURVrcGpDWHThP8j6pzHiA7v2jyN/j7uSyGE6N0MWg1D0yL8Mo1ranbw+Fc7eW9NMV9uLe9QG3tQAuumvEVRvytbDqx4Ft46F5oqfe6PaJ98IgRYS1VVEwWVTZ12T6fDhm3JQ5y5bg6h9mpMYbn8cuqHVKWe3lo6uavEhfm2Y6cQom8IN+oYnOz7tHxEkI7TBiUA8OH6Ur7ZXtGhdopax+4R97Bl3DO4tMFQ+BM8Px52feVzn8SRJBgJoJYVM3WdWt696sB20j45jxl1/0ajUvjBeCo/nfQulvDsTuvD0ei0agYkyfSMEKJj4sON9EvwffPMs4YmM3NoEgD/WVvS4SkbgIPpM/jllA9ojhoAlmp492L47zywW3zul/gfCUYCpNZs5+f9nbd012Z3Urr0Rc5efTGDlT00EMJnuX/FcfbzGEO6R6LowMQwDFrZCE8I0XEZMSGkRfu2wgbg7GHJnDkkEYD31hSzeEvHpmwAzBG5rDr5fQ4OvqblwNpX4aXJUL7J536JFrKaxs8URWFftZn9VeZOu6fKVITxmz9xorIRgG36oZRMeQZNZFqn9eF4ZPWMEMJbitKyiaive3cpisInG8v44tdA5MoJmUzMjfXoGkk1Kxn0812omipArYUTb4OT5oNOpp/b09HPbyl96UfNdhfbykzUWzqpkJniJm3vv8nZ8jRaxYIdLasz5mIfcyMadfcZgQjSaxiQKNMzQgjvqFQqBieH43S7qfFh6wyVSsWsESkE6TRsKK5jTEaUx9coj5lA/bTPGLP1IfS7/ws/PQk7PoOZf4eM8V73ra+TkRE/UBSF0vpm9hxswuUO/I/T6nCxcf1q/mB6jvj6jQDUxIxiy8iHcEb1C/j9PaFSweiMaCKCfdt3QgghXG6FjX6oQQLgdLvR/roXl6IoOFyKR6v8VCoY1vgDsT/cC+ZfV9mMmQOn3A/G7vc51VU6+vktwYiPGq0OdlU0dspoiMutsGZXIWlb/o9LlS/RqVw4tcHsHTqfkpxLQNX9UoD6JYSSESMl34UQ/tGyuWi9X99zP9tUxsbiem45OZfIYL1HbZMMVgZueQL1xn+3HAiJh9MehKG/a9kJtI+TYCTAbE4X+6vNlNY1E+ifoKIobCquw7r2La5zvEWcqgGAPZGTqDjxIWwhXVfA7FhiwwwMS43oWDlmIYToIKfLzaYS/2wy2mRz8pdPt9JodRIVrOOGKbke75ll1GkY7thA6Ld3QO2+loOpY2D645Ayyuc+9mQSjASIzemiuNZCcW1zp0zJFNaY2b76Ky5vfIXh6pZ9Eqr0aRwY8xfqU6YE/P7eCtJrGJsV7VU5ZiGEOB6XW2FTST21PuSQHFLZaOXv3+2losGKVq3i9ydkMLGfZ4mtABmRGnIK/o36p7+BvQlQwfDLYOo9ENE9vzQGmgQjfmayOCipt3CwwdppVVRD6ncRuepRBjauAsCqCqJg0A1UDLgKRePZUGJn0qhVjMqMItwoeSJCiMBxuxW2lfm+ygbAYnfy2vJCNpbUA3BSv1h+Nybd42rRQXoNA0PNRK98BDYvajmoNcLYP8DE2yE42ue+9iQSjPhIURQamp1UNdmobLBisXfODruFNWb0DcWcVvkqiQc+Q4WCCzX7086nbPit2IPiO6UfvshPiZAqq0KITqEoCnsqmyiq8b0ImVtRWLylnE83lqEA2bEh3DV9gFeVq+PCDPR37MD4/YNQ1PKFEmNEy1LgE64Dfd/IpZNgxAMut4LF7qTZ7qLR5sTU7MDU7MDViRvaFVabWbthDSdXvc152uVoaQl+KtKmsy//NixhWZ3WF19kxoaQG+97xUQhhPBEUY2FPZWNfsnh21Zm4tXl+zl/VCon5ng+XXOIWg0pEUFk169At+xhqNzW8kRwLIy/sWX1TS9feSPBSAftrGigpLbZr9fsKEVpGWLcsflnpte/w0z1KjSqll9HZfyJ7B86j8boIV3SN28khBvJTwmXhFUhRJeoarSxtczkly+SFruTIJ2m9f1sT2UjEUE64sM8H/XVqFWkROjJLP8S/U+PQV1hyxPGSBh3fctISZDnNU96AglGOmh7WQNl9Z0fjOwoM1HwyxfMbP6UUzQbWo+XxJ1E2dCbaYgZ1ul98kVksI6R6VGo/bDLphBCeMtsc7KppB6LzX9T6xa7k/s+3YbF7uLcEcmcMiDBqx2FVSpICNWSVfElIaufhZo9LU/oQ2HE71uCkuiu30fMnyQY6aDODkbUTiuJRZ8Tv/01Yi0tq2PcqChNOIWyoTfRGDWo0/riLyEGLaMzo2TljBCiW3C63Owob/RLYitAncXOq8v3s7OiEYCUyCAuGZvGgETvP4+CdZBbvZTY9X9HXbX916Mq6H9my2hJ5sSW6KWHk2CkgzojGKlpsrFx2zZONi9mcuPn6G11ANjUQZRmzKJ8wJU0h2UGtA+BEqTXMCojCqOu+5SfF0IIgJI6C7sPNvplBaSiKPy0t5qP1pfSZHMCMDojilkjUkgI9yFhX1FIrf+Z9N2vE3xg6f+OJwyBcXNh8Hmg932jwK4iwUgHBSoYURSF3WV1NGz5LyfU/ZfJ6k2t+SDNwckU586mLPtCnPqem7xk1LUEIkF6CUSEEN2T2eZka6mJRqvTL9drsjn5dGMp3++uQlFa8kEWzBpCdIjv5RaCGwrI2PsWSfs/Qu1qGdVRDGGohlwEo66AJP9M3yuKgtXhxmJ3YrG7aLI5SY4MIiLI/+UYJBjpIH8HIzaHi107NxO7exFnOJcSr6pvfa44fCS1g66gOvU0FHXP3qNQAhEhRE/hdisU1pgprDH7rU5Uca2FDzeUYNRqmDs5p/V4o9VBmI81lrS2elL2/YeUfe8RbC5pPW6Jyadh0KU0DzgPbVAEWo0KjUqFSqVqndFRlJYlyi53y8PhcmN3ubE7Wx5Whxub03XEqqNhaZHEhRl86nd7JBjpIH8FIzpbLfHFX6Hb/gG51q2tx03qSIrTz6Vh4CU9Znnu8QTrNYyUqRkhRA/TZHOyo7wBkx/3tXG43K35clWNNv7y6VaGp0VyRn4imb7uy6W4iapcTcq+/xBfugS1u6XfLo2RquSTqUifSU3iJL8UwezqYKRnfz3vYiqHGce2/zK49htSalahVlqGAd2o2B06lsZBl9KQfiqKuvdUIg01ahmRHolBK4GIEKJnCTVoGZ0RRZnJyt7KJhxO34dJDk/c31pmwulWWHugjrUH6siODWFSv1jGZEZ79+VNpaYuYQJ1CRPQ2WpJKvyU5P3/IbShgMTixSQWL8auj6Qy9QwqMmZSHzuqW26Y2hEyMuLhyIjKZSes9Ef0Oz8hr/5HgvlftnZDVD4V6WdRkXYm9uBEv/azO4gO1TM0JQKtrJoRQvRwDpeb/dVmSuosft3io6TOwtfbDvLL/lpcv368GrRqxmRGM2tEiu95GYpCWN02Eos+I7FoMQZrZetT1uAkKtLO4mD6mTRGDvJoNU5Xj4xIMNKBYETjMBNT8SPh+78k4eCPBCn/Kzt8QElgc9RpRJ9wKc0RuX7tW3eSGh1EXnyY1BERQvQqzXYXBVVNVJj8swz4EFOzg5UF1SzfW83BBhtBOg1PXji0dVT5YIOVmBC9b1/u3C6iqn4m6cDnxJd+jdbR1PqUJSSVqpRpVKaejilm2HFHTHpkMPL888/zt7/9jfLycgYPHsyzzz7LpEmTjnr+Dz/8wLx589i2bRvJycnccccdzJ07t8P364pgRGurJ658KfElS4iu+AmN+387Q5Yr0fyoGUd11tmk559EkKH3znap1dA/MZyUyKCu7ooQQgRMk81JYbXZ70GJoijsrWyiusnO+JyY1mP3fLKVJquTQUnhDEgMY0BSGInhRq8rWKtdNmLLvyfxwOfEVPyIxvW/12ENSqAq5TQqU0+nLnY0qI+cMupxwciiRYuYPXs2zz//PCeeeCIvvvgir7zyCtu3byc9Pf2I8/fv309+fj7XXnst1113HStWrOCGG27g3Xff5fzzz/fri/HG4cGIvrmSuNJviS/9hqjKn1Er/6vgV61P5QPLCPZETyEtfyKDUiK92jypJwnWa8hPjZDdd4UQfYbF7qSw2kJFQ3PAdmivt9h58L/bj1huHBGko39CGCPSIxmT6f3uvmqnhdiKn4gv+ZrYsmVonebW5+yGaCpTTqUqZRq18eNak197XDBywgknMHLkSBYuXNh6bODAgZx77rksWLDgiPPvvPNOPvvsM3bs2NF6bO7cuWzatIlVq1Z16J6BDEb27NyCsv1z4ku/IbJmQ5vnKoJyMWdPpzJlGjXBOZisTt+K2/QgyZFB5CWESn6IEKJPsjldlNY1U1rfjM3h/6jE7VbYX2NmR3kDOysa2VvZhNPd8nF86sB4fjem5cu92ebk3z8fIDHcSFLE/7d3v7FRlfkewL/nnPlzmM60t/87tRVKIS3ClWALYQQkazclstdFN9mY3ITbxMQIEQ30hbfFmxh9U90YjQbEEBsT34iJpa5E3G137R9d6rolY1CJ6F3RIrSWInSm087/Z18MM+3QKZ2Z7cxpe76fZF7wzHMmz/nlF86v5zzPc1bAnqeiJNec9CICKeRHwc9/Q+lPXSi68leY/Ddi3wUNORiz78TVO34Ne/1vUVRUvODnmZHVNH6/H2fPnkVLS0tce2NjI86cOZPwmIGBATQ2Nsa17dq1C+3t7QgEAjAaZ//V7fP54PP54k4mI975b6y98GFc09nwWvwptBl/Dm9GcUkt9q+PrB9XAaim5fs4Jko1Kqi121BkXfgKmYhoqTAbFKwutmJVYQ7GPD5cvj6FaxP++Q9MkixLqC62orrYiv+6OzKh9p9XJ/DPqx6sKZ5+8/mV8Sn844frs463mg3Itxjx63Wl2LYm8mZhjy+I70YnkGNSkGM2IMdsgMVkwLXyX+Fa+a8ghQPIv/o5Sn7qQvHlv8LsHY2tyhGf/y+w+w9A/aMLdo6pSOnqOjY2hlAohNLS0rj20tJSjIyMJDxmZGQkYf9gMIixsTHY7fZZx7S1teG5555LZWhpEQWrIaDgrLQef/TXoTtUh59RgA3luXh4XSnWly/d3VFTJUnAnQUWVBXl8G4IEdFNsiyhxKaixKbCGwhhZNyL4XEvPL6F2dE1yqjIqC3LnfW+mwKLCb+vq8DwuBfD41MYHvfGdk2d8AXhm7E8+cqNKRzp+f9Zv21SZBgVCb/dWI6GddvwS+k29FQ/jc8//Qt2hP8OR+AzVIZ+AorXLeg5pSKtP/VvnWAjhLjtpJtE/RO1R7W2tqK5uTn2b5fLhcrKynSGelvStqfwP99uwyeXwzAbZGyrKcKTtSUoy9PHo5ioklwz1pRYYdHBnR8ionSpRgWrinKwqigHE74gfnZ5MeryLXhhMlOh1Yxd66e3ihBCYNIfwvVJP65PBmCfcb2SZQmrCi3w+EPw+IKY8ocggMgOrCEgPGNSxoQ/jFO/3IFT+B2A3+H4AzY0Vm7J2HnMJ6WrT1FRERRFmXUXZHR0dNbdj6iysrKE/Q0GAwoLCxMeYzabYTZn4TGBtQS7t6zHHT/dwL3Vhbq7GBfbzKgqzuEEVSKiFFnNBlhvPmaZ9Acx5vbj6oQPNyb9s7ZaX0iSJMUewVTkx39XXWzF//1m+s3vYSEw5Q9h0h9CIBSGTZ2+xpXlqti/sxr+UBjhsIB9TUXCVTbZktLV12Qyoa6uDt3d3Xj44Ydj7d3d3dizZ0/CYxwOB06dOhXX1tXVhfr6+oTzRbItUzOIFytFkVCetwKVBSt0V3wREWWCxWTAnYUG3FloQTAUxi+TfvziiXwmfaH5fyBD5BmFy61sqhF1K6ermTKNF2ekfDVqbm7G3r17UV9fD4fDgePHj2NoaCi2b0hraysuX76Mt99+G0Bk5cyRI0fQ3NyMxx57DAMDA2hvb8c777yzsGdCc5IkoCDHhLK8yHNPhRuXERFlhEGRY3NMAMAbCOHGZODmYxVti5PFLOVi5JFHHsG1a9fw/PPPY3h4GBs2bMDp06excuVKAMDw8DCGhoZi/auqqnD69GkcOnQIR48eRXl5OV577bWk9xih9JiNMgpyTCjMMaPQaop7fwIREWWHalRQlqfE5iL6g2GMTwVufvxwTQURCi/6jdAzjtvBL9Bbe7UiSZFkt5gU2FQDbKoRuaoRK0x8kR0R0WInhMCELwiXNwjXVACuqQA8/mDGNlybi9abnnHSQIYosgSTQYZBlmBQJMjS9OfWRUSJysFoH1mSoMgSFBlQ5MjvmQwyzAYZZoMCs0Hm+2KIiJYoSZJgU42wqcbYazfCYYEJfxBubxBubwBubxAT3uV9B4XFyL9JUSTkrYjcjbCpBlhMClSjwsciRESUFlmWkHvzLjcQKVCiS3rd3iAmfAG4bhYo/mCWb6FkCIuRNFhMCkpyVRRbzchdYUj7xUZERETJkOJWxkyvfPEFQ5jwRjZAi9xJCWLSH8zo8uJMYDGSJFkGSmwqKvMtyLNovySZiIjIbFBgtioonPEKj+hjnukiJfKoJxhavBUKi5F5yDJQkW/BnQUWqEZOCiUiosUt/jHPNG8gBJc3gAnv9F0Ub2BxLDVmMXIb9v9QUV1sZRFCRERLnmqMzGkssU23+YNhTPiCsGi8ApPFSAJW1YB19lzkreDjGCIiWr5MBhkFBpPWw2AxMpMsA1VFVqwssHC5LBERUZawGLnJYlbwn3fkwcaXxhEREWUVixEAZXkq1tlz+c4WIiIiDei+GFlVZOHba4mIiDSk+21CWYgQERFpS/fFCBEREWmLxQgRERFpisUIERERaYrFCBEREWmKxQgRERFpisUIERERaYrFCBEREWmKxQgRERFpisUIERERaYrFCBEREWmKxQgRERFpisUIERERaYrFCBEREWmKxQgRERFpyqD1AJIhhAAAuFwujUdCREREyYpet6PX8bksiWLE7XYDACorKzUeCREREaXK7XYjLy9vzu8lMV+5sgiEw2FcuXIFNpsNkiQt2O+6XC5UVlbi0qVLyM3NXbDfXa4Yr+QxVsljrJLHWCWPsUpeJmMlhIDb7UZ5eTlkee6ZIUvizogsy6ioqMjY7+fm5jJZU8B4JY+xSh5jlTzGKnmMVfIyFavb3RGJ4gRWIiIi0hSLESIiItKUrosRs9mMZ599FmazWeuhLAmMV/IYq+QxVsljrJLHWCVvMcRqSUxgJSIiouVL13dGiIiISHssRoiIiEhTLEaIiIhIUyxGiIiISFMsRoiIiEhTy74Yef3111FVVQVVVVFXV4dPPvnktv37+vpQV1cHVVWxevVqvPHGG1kaqfZSiVVvby8kSZr1+eabb7I4Ym309/fjwQcfRHl5OSRJwvvvvz/vMXrNq1Rjpee8amtrw+bNm2Gz2VBSUoKHHnoIFy5cmPc4PeZWOrHSa24dO3YMd999d2x3VYfDgY8++ui2x2iRU8u6GHn33Xdx8OBBPPPMM3A6ndixYwceeOABDA0NJex/8eJF7N69Gzt27IDT6cThw4fx1FNPoaOjI8sjz75UYxV14cIFDA8Pxz5r167N0oi14/F4sHHjRhw5ciSp/nrOq1RjFaXHvOrr68MTTzyBzz77DN3d3QgGg2hsbITH45nzGL3mVjqxitJbblVUVOCFF17A4OAgBgcHcf/992PPnj34+uuvE/bXLKfEMrZlyxaxb9++uLba2lrR0tKSsP/TTz8tamtr49oef/xxsXXr1oyNcbFINVY9PT0CgLh+/XoWRrd4ARCdnZ237aPnvJopmVgxr6aNjo4KAKKvr2/OPsytiGRixdyalp+fL958882E32mVU8v2zojf78fZs2fR2NgY197Y2IgzZ84kPGZgYGBW/127dmFwcBCBQCBjY9VaOrGK2rRpE+x2OxoaGtDT05PJYS5Zes2rfwfzChgfHwcAFBQUzNmHuRWRTKyi9JxboVAIJ06cgMfjgcPhSNhHq5xatsXI2NgYQqEQSktL49pLS0sxMjKS8JiRkZGE/YPBIMbGxjI2Vq2lEyu73Y7jx4+jo6MDJ0+eRE1NDRoaGtDf35+NIS8pes2rdDCvIoQQaG5uxvbt27Fhw4Y5+zG3ko+VnnPryy+/hNVqhdlsxr59+9DZ2Ym77rorYV+tcsqQsV9eJCRJivu3EGJW23z9E7UvR6nEqqamBjU1NbF/OxwOXLp0CS+99BLuu+++jI5zKdJzXqWCeRVx4MABnDt3Dp9++um8ffWeW8nGSs+5VVNTgy+++AI3btxAR0cHmpqa0NfXN2dBokVOLds7I0VFRVAUZdZf9qOjo7OqvqiysrKE/Q0GAwoLCzM2Vq2lE6tEtm7diu+++26hh7fk6TWvFore8urJJ5/EBx98gJ6eHlRUVNy2r95zK5VYJaKX3DKZTFizZg3q6+vR1taGjRs34tVXX03YV6ucWrbFiMlkQl1dHbq7u+Pau7u7ce+99yY8xuFwzOrf1dWF+vp6GI3GjI1Va+nEKhGn0wm73b7Qw1vy9JpXC0UveSWEwIEDB3Dy5El8/PHHqKqqmvcYveZWOrFKRC+5dSshBHw+X8LvNMupjE6P1diJEyeE0WgU7e3t4vz58+LgwYMiJydH/PDDD0IIIVpaWsTevXtj/b///nthsVjEoUOHxPnz50V7e7swGo3ivffe0+oUsibVWL3yyiuis7NTfPvtt+Krr74SLS0tAoDo6OjQ6hSyxu12C6fTKZxOpwAgXn75ZeF0OsWPP/4ohGBezZRqrPScV/v37xd5eXmit7dXDA8Pxz6Tk5OxPsytiHRipdfcam1tFf39/eLixYvi3Llz4vDhw0KWZdHV1SWEWDw5tayLESGEOHr0qFi5cqUwmUzinnvuiVv61dTUJHbu3BnXv7e3V2zatEmYTCaxatUqcezYsSyPWDupxOrFF18U1dXVQlVVkZ+fL7Zv3y4+/PBDDUadfdElgrd+mpqahBDMq5lSjZWe8ypRnACIt956K9aHuRWRTqz0mluPPvpo7P/14uJi0dDQECtEhFg8OSUJcXNmChEREZEGlu2cESIiIloaWIwQERGRpliMEBERkaZYjBAREZGmWIwQERGRpliMEBERkaZYjBAREZGmWIwQERGRpliMEBERkaZYjBAREZGmWIwQERGRpv4FsyORmjJ9cAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred, logk_1_pred = model.predict(np.concatenate([x_test, t_test], axis=-1), samples, processes, pde_fn=None,)\n",
    "\n",
    "plots(\n",
    "    logk_1_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c334e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
